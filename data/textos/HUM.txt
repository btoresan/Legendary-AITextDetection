Ao meu avô, Eurico Borges de Aguiar, principal influência que recebi para escolher a
medicina.
“Assim como o mais rápido no trono paterno se sentara, assim também logo
entre os diversos deuses dividiu os privilégios vários e fixou as classes no seu
império, mas, dos pobres mortais, caso nenhum fez; pelo contrário, aniquilar a raça
toda desejava, e outra nova criar. E a isso ninguém se opôs, senão eu. Eu ousei.
Livrei os mortais de, esquartejados, ao Hades descer”.
Ésquilo,
Prometeu Acorrentado
INTRODUÇÃO
Ao iniciar um livro como esse é uma conduta prudente lembrar dos
ensinamentos do Prof. Fernando Novais, para quem textos assim não se fazem com
certezas e nem com afirmações categóricas. Segundo ele, “em História, não pode
haver nunca a obra definitiva; tudo a que podemos aspirar são aproximações”.1
Várias foram as fontes onde pesquisei para chegar ao texto final. Concordo
com a visão da importância de se compreender a história das ciências da saúde não
como uma linha progressiva conectada por avanços e descobertas, mas como parte
de um processo, onde um conjunto de fatores atua e se relaciona entre si.2
O motivo principal que me levou a escrever esse livro foi a constatação de que
a maioria das escolas médicas de todo o mundo, inclusive no Brasil, tem
subestimado a importância do conhecimento da história da medicina.
Só depois de anos de experiência é que alguns médicos se preocupam com
leituras sobre filosofia e outras disciplinas culturais. Neste momento, então, passam
a se interessar também por essa fascinante aventura ao longo dos tempos.
Filósofos como Platão e Aristóteles foram estudantes das ciências da saúde. A
filosofia influenciou a medicina a ponto de Kurt Sprengel3 ter dito que “a filosofia é
mãe da medicina”. De modo inverso a ciência tem influenciado a filosofia, como são
exemplos a psicanálise e os estudos neurofisiológicos de como opera o intelecto.
Filosofia e ciência assentam-se na mesma base do espírito humano, ou seja,
no pensamento. Porém, distinguem-se pelo objeto de estudo. Enquanto a ciência
tem por objeto parcelas da realidade, a filosofia procura dirigir-se ao seu conjunto,
ou seja, a filosofia seria uma espécie de ciência universal, e sua função seria não
tanto resolver enigmas mas, sim, descobrir maravilhas, oscilando o seu maior
interesse entre a “concepção do eu” e a “concepção do universo”4.
Segundo Hegel, “a filosofia, ao ocupar-se do verdadeiro, só tem a ver com o
eternamente presente. Para a filosofia, tudo que pertence ao passado é resgatado,
pois a idéia é sempre presente e o espírito é imortal; para ela não há passado nem
futuro, apenas um
agora essencial”5.
Acredito ainda que a falta de uma melhor formação humanista tem trazido
graves conseqüências à forma como as ciências da saúde têm se desenvolvido.
As repercussões de uma visão equivocada da saúde refletem-se, na
sociedade, pela crença de que o ato médico é mais importante que as ações de
política sanitária para a melhoria da qualidade de vida da população.
1 Aproximações, Estudos de História e Historiografia.
2 Fonseca, Fontes para a história das ciências da saúde no Brasil (1808-1930).
3 Citado por Richard Leonardo, em History of Medical Thought. A palavra filosofia significa,
em grego, amor à sabedoria.
4 Johannes Hessen, Teoria do conhecimento.
5 Filosofia da História.
Por outra parte, também afeta de forma negativa a relação médico-paciente,
desde que, muitas vezes, o profissional passa a acreditar mais na solicitação de
exames complementares do que em um exame clínico bem feito.
Da mesma forma, a superespecialização tem levado à perda da noção do ser
humano como um todo, passando-se a vê-lo fragmentado, como se a sua pele, ou os
seus ossos, ou articulações não fizessem parte de uma pessoa única. Sabemos hoje,
que boa parte das doenças tem comprometimento sistêmico e que cada paciente
reage de uma maneira própria às enfermidades. Esta falta de uma visão holística é
conseqüência, também, do desconhecimento da história da medicina.
Segundo Edgar Morin6, “a hiperespecialização impede tanto a percepção do
global (que ela fragmenta em parcelas), quanto do essencial (que ela dissolve).
Impede até mesmo tratar corretamente os problemas particulares, que só podem ser
propostos e pensados em seu contexto”.
Acreditar, no entanto, que a formação de nível superior possa ser modificada,
sem, concomitantemente, ocorrerem mudanças profundas nos modelos que regem
atualmente a formação dos profissionais de saúde, seria demonstração de
considerável ingenuidade e de falta de pragmatismo. A abordagem das mudanças
deve ser sistêmica, incluindo desde os currículos e métodos de ensino até os
sistemas de avaliação de desempenho e de competências dos estudantes7.
Afora isto, a evolução da engenharia genética, da reprodução assistida, da
manutenção artificial de certas funções vitais e dos transplantes de órgãos, além de
outras conquistas científicas, tem levado à discussão de várias questões de caráter
ético, e de acentuada importância para o futuro da humanidade.
Para Heidegger8, o homem moderno encontra-se em situação de desamparo
devido à quebra na tradição causada pelo desenvolvimento da ciência moderna e
pelo domínio da tecnologia na cultura ocidental. O niilismo, que caracteriza parte da
civilização atual e que tem contribuído para o aumento do consumo de drogas com
suas repercussões negativas, como o incremento da violência nas grandes cidades9,
seria conseqüência da morte da tradição.
Uma outra maneira de abordar essa questão foi como o antropólogo Claude
Lévi-Straus se pronunciou: “No momento em que o homem não conhece nenhum
limite para seu poder, ele começa sua autodestruição”.10
Há várias maneiras de apresentar a história das ciências da saúde. Há livros
de centenas de páginas, com numerosas seqüências de nomes e datas. Há, ainda,
outros que procuram dividir esse relato através dos séculos. Uma forma que poderia
ser mais razoável e interessante de fazer essa descrição haveria de procurar detectar
seus momentos mais marcantes.
Segundo Thomas Kuhn11, a pesquisa científica pode ser dividida em períodos
de desenvolvimento relativamente tranqüilos, intercalados por períodos de alteração
importante, ou de verdadeiras revoluções no campo da ciência. Durante um
6 Em Os sete saberes necessários à educação do futuro.
7 Com uma metodologia de ensino centrada no estudante, uma pedagogia interativa e uma
avaliação eminentemente formativa.
8 Idéia compartilhada com Hannah Arendt.
9 Incluindo lesões e mortes por acidentes de trânsito, suicídios e vários tipos de crimes.
10 Citado por Simmons, J., em Os 100 maiores cientistas da história.
11 Autor de A estrutura das revoluções científicas.
determinado período, o conhecimento é governado por um paradigma geralmente
aceito.
O paradigma, essencialmente um marco conceitual envolvendo tanto a teoria
como a prática, permite a acomodação dos novos conhecimentos que vão sendo
adquiridos ao longo do tempo, até que um novo marco ou paradigma não mais
permita que esta acomodação continue a ser feita.
Toda esta estrutura é posta abaixo a partir do surgimento de um novo marco
conceitual. Um exemplo de como uma revolução como essa ocorreu, no campo da
biologia, foi a teoria evolucionista de Darwin, que derrubou por completo a teoria de
que cada espécie havia sido criada de modo independente, ou seja, de que as
características das espécies eram fixas.
Três momentos da história da arte de curar foram fundamentais, segundo
diversos autores, servindo, em conseqüência, como marcos de diferentes períodos
de seu desenvolvimento:
• O primeiro foi a publicação do livro de anatomia de Andreas Vesalius,
De humani corporis fabrica, em 1543, quando o ensino das bases
cirúrgicas da medicina passou, de um método especulativo e baseado
no estudo da anatomia de animais, para um método científico e
apoiado na dissecação de cadáveres humanos.
• O segundo momento importante foi a teoria dos germes, elaborada por
Louis Pasteur, em 1862, que anulou, em definitivo, a teoria da geração
espontânea, aceita desde a Antigüidade.
• O terceiro marco desta história foi a descoberta da estrutura helicoidal
do ácido desoxirribonucléico (ADN) por James Dewey Watson e Francis
Harry Crick, em 1953, e posteriormente, do código genético. A partir
desse período as ciências da saúde deram um salto qualitativo, cujas
conseqüências, no futuro, é impossível avaliar atualmente.
A última parte desta obra procura resgatar alguns momentos que se perderam
com o tempo. É interessante, por reproduzir verdadeiros clássicos da história da
ciência, e de como algumas doenças foram tratadas até o início do século XX.
Algumas personalidades são apresentadas através de seus próprios relatos, o
que contribui para enriquecer o período em que desenvolveram suas pesquisas e
obtiveram suas conquistas.
Uma conclusão que se pode tirar ao ler esse texto é a de que a humanidade
não deve apenas aos médicos a grande transformação por que passou a arte de
curar, desde os tempos mais remotos, até os dias de hoje.
Advogados, professores, jornalistas, engenheiros, físicos, químicos,
farmacêuticos, dentistas, fisioterapeutas, nutricionistas, veterinários, enfermeiros,
biólogos, psicólogos e até mesmo profissionais sem nenhum curso superior, como o
holandês Leeuwenhoek, inventor do microscópio, deram considerável contribuição
para o desenvolvimento desta nobre arte.
Além disso, inúmeras pessoas anônimas, e que jamais terão seus nomes
lembrados, mas que também deram uma grande contribuição às pesquisas e à
evolução das ciências da saúde, até mesmo por meio de seu singelo trabalho
cotidiano, são também merecedoras de respeito e admiração. A elas dedico esse
livro.
A arte primitiva de curar
A medicina pode ser definida como a arte de se ocupar dos fenômenos do amor,
próprios ao corpo.
Platão,
O Banquete
O início
Quando a humanidade, em seus primórdios, vivia em harmonia com a
natureza - e quando esta dominava o espírito humano, e não o contrário –, os
processos de cura eram essencialmente empíricos.
Foi assim, desta maneira mágica, que a medicina se desenvolveu. Em sua
manifestação popular ela permanece, até hoje, em estreita relação com o
aprendizado das diversas forças da natureza, de um lado, e as crenças em magia, de
outro.
Por meio da observação dos povos primitivos atuais, temos um retrato fiel das
formas de vida dos seres humanos no passado mais remoto.
Há quem afirme que o medo criou o sentimento religioso12. A fragilidade do
homem frente à natureza, às doenças e às demais dificuldades de sua miserável
existência tornava-o carente do sobrenatural, como forma de proteção em meio a
um cenário tão adverso.
Na sua origem, a prática da magia se confunde com a da religião,
concentrando-se em alguns indivíduos que passaram a ser considerados como
dotados de poderes extraordinários.
No dia em que surgiu o primeiro mago, surgiu também o primeiro sacerdote e
o primeiro médico.
Seria natural, em conseqüência, que aqueles que praticassem a medicina
primitiva fossem os mesmos que, conhecendo a fragilidade do ser humano e as
virtudes das plantas e dos venenos dos animais, também passassem a se atribuir
poderes diferenciados dos demais. Os mesmos que, possuidores de faculdades
fantásticas, eram tidos como capazes de convocar os espíritos dos mortos ou de
apaziguá-los.
A prática de suas funções torna-os mediadores entre o homem e os deuses, o
que os leva a alcançar o maior atributo divino de todos os tempos, o poder sobre a
vida e a morte e a capacidade de curar doenças.
O crescente conhecimento permite que fiquem cada vez mais poderosos.
Assim, para guardar seus segredos e manter sua fonte de domínio, eles
constituem uma casta, ligada por ritos especiais e, freqüentemente, por um sistema
complicado e secreto de iniciação.
Realizam, periodicamente, cerimônias de sacrifícios, ou ritos sangrentos, pelo
reconhecimento da importância do sangue como fonte de vida, já que os primeiros
caçadores acreditavam que a alma dos animais estava no seu sangue, partindo daí
também a crença de que por este meio poderiam apropriar-se da força vital do
inimigo.
12 Ambrogio Donini, em Breve História das Religiões.
Ou, ainda, realizam cirurgias, como as trepanações do crânio (feitas desde o
período neolítico), ou as cirurgias de mutilação e castrações até hoje usadas em
tribos africanas primitivas, que removem o clitóris de meninas cada vez mais jovens.
Uma atmosfera de mistério os envolve. Vestimentas coloridas, amuletos
sagrados, peles de animais e outros fetiches contribuem para diferenciá-los dos
demais.
Mas, por trás de toda esta aparente simplicidade, há uma dose de sabedoria.
Seja em decorrência da experiência acumulada, através da sugestão ou do uso de
plantas - atividade terapêutica reconhecida na atualidade - eles conseguem realizar
seus processos de cura.
Finalmente, pode-se dizer que a medicina se originou contemporaneamente
com a civilização, não como ciência, mas como uma crença de que era um dom
concedido pelos deuses.
A arte chinesa de curar
A China possui os textos médicos mais antigos que conhecemos. O pai da
medicina chinesa, Fu-Hsi, viveu há cerca de 2900 anos a.C., e inventou a filosofia
fundamental do yang e do yin.
Depois, por volta de 2700 a.C, surgiu Shen-Nung. Sua obra,
Pen Tsao Kang
Mu (
Classificação das Raízes e Ervas), aborda, principalmente, a farmacopéia
vegetal, com descrição superior a mil drogas, algumas usadas até hoje.
Outra contribuição da medicina chinesa é o uso do ferro (para anemias), do
arsênico (para as febres intermitentes), do mercúrio (no tratamento de algumas
infecções), e do ópio (para a dor). São da China, também, os mais antigos registros
sobre infusões obtidas com uma planta (Ma Huang), utilizada para tratar a asma,
que hoje se sabe, tem como componente ativo a efedrina. A substância aumenta a
freqüência cardíaca e produz dilatação da árvore brônquica.
Outra planta importante para os chineses era o ginseng. Acreditavam que nela
existiria uma substância que aumentava a virilidade. De sua raiz faziam chás que
deveriam ser bebidos por oito dias consecutivos. Recomendavam, ainda, que a raiz
também fosse ingerida para que se obtivesse um maior efeito terapêutico.
O imperador Huang-Ti , que viveu por volta de 2600 a.C., foi o autor do livro
Nei Ching (
Doutrina do Interior). Trata-se da reconstituição de diálogos entre o
imperador e um de seus ministros, Chi Po. Os diálogos versam sobre as funções do
corpo humano, suas doenças e suas curas.
É interessante constatar, nesta obra, a afirmação de que o sangue do corpo
humano estaria sob o controle do coração e seria regulado por ele; e que o sangue
circula de forma contínua, o que só viria a ser confirmado por William Harvey, no
século XVII.
Uma outra contribuição da medicina chinesa foi a crença de que o corpo era
formado por cinco elementos, ou ainda por cinco tipos de processos, cada um
representado por um arquétipo: terra, fogo, água, madeira e metal. A saúde seria
decorrência da harmonia entre tais elementos. Esta concepção veio, posteriormente,
a influenciar a medicina grega da Antigüidade, cuja teoria dos humores (líquidos ou
elementos básicos do organismo) tem origem nesta fórmula criada pelos chineses e
também pelos indianos.
O corpo humano seria uma miniatura do universo, e seria constituído dos
mesmos materiais desse universo. A doença deveria ser vista mais como uma
desarmonia entre o homem e o seu meio ambiente. A medicina tradicional chinesa
não faz diferença entre doença física e doença mental, sendo a doença mental
conseqüência da perda de harmonia entre o corpo e o espírito.
Aos cinco elementos corresponderiam não só órgãos, como também planetas.
Assim, o coração, o fígado, o baço, os pulmões e os rins estariam associados,
respectivamente, aos processos elementares simbolizados pelo fogo, madeira, terra,
metal e água, assim como aos planetas Marte, Júpiter, Saturno, Vênus e Mercúrio.
Como outros povos da Antigüidade, os chineses eram, porém, fracos em
anatomia, devido à proibição da dissecação de cadáveres. Acreditavam que, se o
corpo não se mantivesse íntegro, o defunto não poderia ser recebido no reino dos
mortos.
A medicina chinesa busca também o equilíbrio entre o yin (princípio feminino,
passivo, negativo, correspondente à lua, à terra, à escuridão, à delicadeza, ao
úmido, ao frio e ao lado direito) e o yang (princípio masculino, ativo, positivo,
correspondente ao sol, ao céu, à luz, ao poder, ao seco, ao quente e ao lado
esquerdo). Há ainda uma terapia yin, como os tratamentos com plantas medicinais, e
uma terapia yang, como a acupuntura e a moxibustão.
Segundo a lenda taoísta, o deus que formou o universo obteve êxito após
dividir o caos em seus dois elementos opostos, o yang e o yin.
Por meio da busca do equilíbrio entre os dois princípios opostos, mantinha-se
a saúde e curava-se a doença. De certa forma, o yang e o yin poderiam representar
o antagonismo existente entre os dois componentes do sistema nervoso autônomo, o
simpático e o parassimpático. Esta é a parte do sistema nervoso que independe da
nossa vontade, e que é responsável pelo controle dos nossos órgãos internos.
A interação dialética dos opostos constitui um dos elementos mais importantes
para o entendimento da natureza da criação e do desenvolvimento das civilizações.
Não só os chineses perceberam a importância deste fenômeno mas, depois deles,
também os indianos e, em seguida, os gregos, sob a forma de amor e ódio, até
chegarmos a Hegel, com a sua teoria da tese e antítese.
Os médicos chineses se concentravam no exame do pulso e na inspeção da
língua de seus pacientes para fazer seus diagnósticos, prognósticos e tratamentos. O
valor do exame do pulso seria equivalente ao de um instrumento de corda musical.
Nele, acreditavam, podiam reconhecer harmonias e desarmonias. O exame do pulso
era feito em onze diferentes partes do corpo.
Outra interessante contribuição da medicina chinesa foi uma técnica primitiva
de tentar imunizar contra a varíola, que consistia em fazer os jovens inalarem as
crostas de lesões de doentes, na esperança de que desta forma viessem a
desenvolver algum tipo de resistência contra a varíola. Os meninos aspiravam as
lesões com a narina esquerda e as meninas com a narina direita, respeitando os
princípios de yang e yin.
Duas outras importantes contribuições da medicina chinesa, até hoje
utilizadas, são a técnica da acupuntura e a moxibustão. A técnica da acupuntura,
com longas agulhas, é baseada na idéia de que o corpo é cheio de tubos
semelhantes a canais, uma idéia natural para os chineses, cuja agricultura era
baseada na irrigação por canais.
A acupuntura utiliza agulhas de ferro, prata ou ouro, de dimensões variáveis,
que são introduzidas na pele, em alguns dos 360 pontos distribuídos em doze
meridianos - ou trilhas nervosas - que percorrem o corpo e transmitem a energia
vital, ou
chi .
A cada território da pele corresponde um componente interno (víscera, osso,
articulação), partindo daí a correspondência entre os meridianos e a busca do
equilíbrio que a acunputura procura restaurar, já que para os chineses tudo que
existe no universo se encontra associado.
A orelha possui uma estrutura energética ligada diretamente aos órgãos,
segundo os acupunturistas. Existem 200 pontos auriculares. Colocadas nestes pontos
auriculares, as agulhas produziriam um grande efeito terapêutico.
No final, a acupuntura busca o restabelecimento do equilíbrio entre os dois
princípios opostos da vida, deixando extravasar o excesso de um ou de outro, e
reativando as conexões bloqueadas. As picadas das agulhas também liberam
substâncias analgésicas, as endorfinas, que elevam a tolerância à dor.
A moxibustão utiliza os mesmos meridianos da acupuntura, mas ao invés de
agulhas se aplica calor através de um canudo de papel, onde a erva seca da
artemísia é queimada.
Hoje reconhecida como especialidade médica, a acupuntura tem sido
empregada para tratar desde problemas da coluna vertebral até a ansiedade. A
analgesia obtida pela acupuntura é considerada atualmente uma alternativa mais
adequada do que a obtida pela anestesia da medicina ocidental para pacientes
idosos, ou com alguma doença de base grave, e que precisem se submeter a algum
tipo de cirurgia.
No século XX, foi desenvolvida no Japão uma nova forma de tratamento, o
shiatsu, que combina a estimulação manual com pressão sobre os pontos de
acupuntura, e meditação para relaxar o corpo e tratar a dor crônica.
Os chineses foram os introdutores da medicina legal, no ano de 1247 da era
cristã, quando o juiz Sung Tzu apresentou um tratado básico envolvendo a medicina
e o direito intitulado
Hsi Yüan Lu (Instruções aos Magistrados responsáveis pelas
investigações de mortes suspeitas de serem crimes)
. O livro continha informações
para a verificação precisa dos sinais presentes nas diferentes causas de morte não
naturais, como afogamento, envenenamento, estrangulamento, lesões por objetos
pontiagudos ou por contusões. Apresentava, ainda, métodos para se perceber as
diferenças entre os suicídios e os homicídios, além de conter instruções sobre
respiração artificial e até o uso de antídotos contra alguns venenos.
A arte mesopotâmica de curar
O primeiro texto médico da civilização ocidental surgiu na terceira dinastia de
Ur, de 2.158 a 2008 a. C., na Mesopotâmia, onde hoje é o Iraque. Trata-se de uma
tábua de argila dos sumérios, onde se recomendava, para o tratamento de feridas, a
associação de vinho, ameixas secas, zimbro (planta da qual se extrai o gim) e
bastante cerveja. Esta mistura era, depois, mantida junto ao corpo, como um
emplastro.
Heródoto13, o grande historiador da Antiguidade, assim descreve o início da
prática médica entre os mesopotâmios: “Eles traziam seus doentes até o local do
mercado, porque não tinham médicos; então aqueles que passassem pela pessoa
doente, conversavam com ela sobre a sua doença para descobrir se eles mesmos
não teriam sido afligidos pelo mesmo mal que aquela pessoa, ou se teriam visto
outros assim. Então, o passante conferia com ele e lhe recomendava que poderia ter
sucesso com o mesmo tratamento com o qual teria escapado da doença, ou também
se eles tinham conhecido outros que assim se teriam curado; e a eles não lhes era
permitido passar por uma pessoa doente em silêncio, sem inquirir a natureza de sua
indisposição”.
Foi na Babilônia, durante o reinado de Hamurabi (1948 a 1905 a.C.), que
surgiu o primeiro código de responsabilidade civil e criminal da profissão médica. O
artigo 215 do Código estabelecia:
- Se o médico realizar com sucesso uma grande operação ou curar um olho
doente de um homem livre, ele deverá receber dez moedas de prata.
- Se for em um escravo, deverá receber duas moedas de prata.
- Se o paciente for um cidadão livre e o médico o fizer perder a vida ou um
olho na operação, o médico deverá ter as suas mãos cortadas.
- Se o infortúnio ocorrer com um escravo, o médico deverá substituí-lo por
outro escravo.
Os mesopotâmicos usavam, para seus tratamentos, frutas, folhas, flores,
cascas de árvores e raízes de várias plantas. Também usavam minerais como
o cobre e o ferro, além de muita imundície, na crença de, com isto,
desagradar aos demônios e fazê-los sair do corpo doente. Usavam vários tipos
de preparações: pílulas, pós, enemas.
Os babilônios atingiram um elevado grau de desenvolvimento cultural:
conheciam a periodicidade dos eclipses, sabiam a posição dos planetas em
relação ao sol, observavam a passagem de meteoros, tinham conhecimentos
de matemática, de arquitetura e escultura.
A medicina dos babilônios era muito influenciada pela astrologia.
Acreditavam que tudo dependia de forças metafísicas relacionadas com os
astros. Assim como os astros influenciavam as forças da natureza, como o
movimento das marés que depende das mudanças da Lua, os humores do
corpo humano também deveriam sofrer a influência dos astros. É possível que
tenham afetado outras civilizações posteriores com suas crenças,
especialmente com esta associação entre medicina, astronomia e astrologia.
A arte egípcia de curar
Imhotep, o deus da medicina dos egípcios, é bem anterior a
Asclépio, deus da medicina dos gregos. Alguns chegam a dizer que ele
realmente existiu, tendo nascido 2.700 a.C. e que, provavelmente, foi um
sacerdote e perito na arte de curar. Segundo Durant14, Imhotep teria sido
nomeado pelo faraó Zoser seu principal ministro, em 2680 a. C. Vários
templos e monumentos foram construídos em homenagem a este grande
13 Historiador grego que viveu no século V a.C.
14 Em Heróis da História.
curador, como uma estrutura em pedra próxima à cidade de Memphis, onde
há uma pirâmide em degraus, em Sakkara, considerada a mãe de todas as
pirâmides. O nome Imhotep significa “o que vem em paz”.
A medicina no antigo Egito, assim como na Mesopotâmia, ficava sob a
responsabilidade dos sacerdotes e era ensinada em escolas situadas ao lado
dos templos de Imhotep. As principais ficavam nas cidades de On, Memphis,
Lais e Theben.
O que se sabe da medicina egípcia está nos papiros datados do
período entre 2200 a 1800 a.C., escritos na XII dinastia. Os que foram
encontrados na localidade egípcia de Kahun tratam apenas de doenças das
mulheres. Outros papiros do período de 1700 a 1500 a.C., escritos no início
da XVIII dinastia, estavam bem melhor conservados.
Estes últimos são chamados Ebers papiros, por terem sido
adquiridos pelo Prof. Georg Ebers15. Nascido em 1837, na Alemanha, tornou-
se egiptólogo em Iena, em 1865, e professor em Leipzig, em 1870.
Em 1873, comprou um volumoso rolo de papiros, medindo vinte
metros de comprimento, de um americano residente no Egito, Edwin Smith,
comerciante de antiguidades. O rolo teria sido encontrado junto de uma
múmia, e deveria ter sido escrito por volta do ano 1550 a.C.
Contém uma mistura de fórmulas mágicas, receitas para o
preparo de remédios, observações clínicas e tratamentos para lesões
causadas por traumas.
Entre as doenças descritas nos papiros a hematúria (presença de
sangue na urina) é freqüente. Posteriormente, pode-se verificar que se
tratava de casos de esquistossomose vesical (bilharziose), uma doença
causada pelo
Shistosoma haematobium, parasitose ainda hoje comum no
Egito.
As chuvas eram de ocorrência relativamente rara, mas não as
inundações causadas pelo Nilo. A cada ano, o rio ultrapassava as suas
margens, cobrindo as terras de cada lado de seu leito por mais de dois
quilômetros. Para irrigar o máximo de terra possível, em região onde a seca
era comum, os agricultores criaram um complexo sistema de canais para
represar as águas do Nilo.
Periodicamente havia enorme quantidade de água estagnada
nesses canais, um criadouro ideal não só para o desenvolvimento de
parasitoses como a esquistossomose como também para vetores como
mosquitos, permitindo com isso que a malária fosse outra doença
transmissível muito freqüente entre os egípcios, conforme foi constatado por
estudo realizado no Museu Antropológico de Turim, Itália.
Utilizando técnicas de biologia molecular, pesquisadores
conseguiram detectar uma proteína específica do
Plasmodium falciparum
(PfHRP2) em 21 de 50 múmias testadas e que apresentavam sinais de
anemia, como esplenomegalia e hiperostose porótica do crânio.
A tuberculose também era uma doença freqüente, apesar dos
papiros não lhe fazerem referência. Estudos dos ossos de múmias permitiram
15 Segundo Singer, em Science, Medicine and History.
a detecção de vários casos de tuberculose óssea, provocando lesões dos
corpos vertebrais, resultando em cifose e corcoveamento da coluna, lesão
conhecida como mal de Pott.
A magia fazia parte proeminente da vida social e religiosa dos
egípcios. Afetava não somente as relações dos homens com seus vizinhos,
como também com os mortos e os deuses. Segundo eles, a magia era um
meio de conseguir o atendimento às suas necessidades e aos seus desejos.
A doença era vista como sendo conseqüente à possessão de um
demônio, ou de um veneno que o ser maligno haveria introjetado no corpo
da vítima. Uma vez instalado, o demônio adoeceria a pessoa e o que o
médico deveria procurar fazer, primeiramente, era expulsar o invasor.
Nos papiros médicos, intercalados com as prescrições de drogas,
pode-se observar a citação de palavras mágicas, que serviriam para dar
maior eficácia aos remédios.
Alguns destes “medicamentos”, ou procedimentos, seriam mero
absurdo, não fosse a sua própria explicação lógica. É o caso da coproterapia,
a ingestão de excrementos prescrita como forma de expulsar o espírito
maligno que habitava o corpo do doente.
Enquanto os babilônios acreditavam ser o fígado a sede da vida e
o centro da circulação do sangue, os egípcios consideravam a respiração
como a função vital mais importante, e admitiam a imagem do ar móvel, o
pneuma, como o seu princípio essencial.
O conhecido culto aos mortos, com avançadas técnicas de
embalsamamento, devia-se à crença na existência da vida após a morte, e
para isto se exigia a conservação do corpo morto da melhor forma possível.
A prática de embalsamamento consistia no seguinte: retirava-se primeiro
o cérebro, e em seguida fazia-se uma abertura no abdômen, com uma faca
afiada, para a retirada de todas as vísceras da cavidade, que depois era
cheia com mirra, folhas de cássia e outras resinas misturadas ao incenso,
fechando-se o cadáver, em seguida, por meio de costura.
Depois o corpo era imerso em soda natural, por setenta dias. Em seguida
era lavado, envolvido em ataduras feitas de bisso, com uma camada de
goma. Finalmente, o corpo era entregue à família, que o colocava em caixão
de madeira, em forma humana, para mais tarde ser colocado na câmara
mortuária.
Depois de mortos, os faraós eram enterrados com todos os que os
rodeavam, para que continuassem servindo-os na outra vida. Armazenavam,
junto com as suas tumbas, alimentos e grandes tesouros na crença de
continuar desfrutando, após a reencarnação, de tudo com que se haviam
acostumado.
A medicina egípcia combinava o racionalismo empírico com o
misticismo. Os egípcios tiveram um elevado grau de progresso no campo da
higiene. Detalhamentos eram feitos para o sepultamento dos mortos e
regras estritas existiam orientando a limpeza das habitações, o preparo de
refeições e até para as relações sexuais. Toda a vida dos egípcios era
regulada por leis precisas, revestidas sob a forma de elementos religiosos.
Na medicina egípcia, muitas vezes os regulamentos religiosos e as
recomendações higiênicas se confundem.
Os sacerdotes só podiam usar roupas brancas, e evitavam alguns
tipos de comida como a carne de porco. A água só poderia ser bebida se
fosse fervida ou filtrada. A lei egípcia punia severamente o aborto artificial e
o abandono de crianças. Proibia também a prática de relações sexuais
durante a menstruação, e considerava a masturbação um vício vergonhoso.
Os egípcios foram os introdutores da uroterapia, ou seja, o uso
terapêutico da urina, segundo papiro do século XV a.C., onde se prescreve
uma fórmula para queimaduras constituída de sementes de abóbora, sal e
urina. Hoje sabemos que a urina contém uma série de substâncias com
atividade biológica, tais como uréia (principal forma de eliminação de
nitrogênio pelo organismo), uroquinase (enzima capaz de dissolver
coágulos), anticorpos, hormônios sexuais e outras moléculas.
Segundo Heródoto, havia uma grande especialização entre os médicos
do antigo Egito, havendo médicos para o tratamento de doenças das
mulheres, doenças dos olhos, doenças causadas por traumas e especialistas
em “doenças desconhecidas”, que seriam doenças cujas causas não eram
conhecidas e para as quais estariam indicadas as formulações mágicas.
A circuncisão era muito usada, e, geralmente realizada quando os
meninos atingiam a idade de 14 anos.
Como curativo de feridas, usava-se uma associação de mirra e mel,
enfaixados com linho, por um período de quatro dias. O mel tem atividade
antimicrobiana, porque existe no seu interior uma enzima que, atuando
sobre a glicose e o oxigênio, produz água oxigenada, com potente ação
sobre diversos tipos de bactérias e fungos. O fato de o mel ser uma
substância capaz de carrear água e levar as células microbianas à
dessecação (desidratando o meio interno) também contribui para aumentar a
sua efetividade.
Os egípcios também usavam cebola, alho e rabanete que, hoje se
reconhece, possuem alguma propriedade de combate às infecções. Para o
controle da natalidade utilizavam vários métodos, tais como o uso de
pessário, ou artefato circular semelhante ao atual diafragma, que obstrui o
colo do útero, e ainda a ingestão de resinas como mirra e seiva, ou de
plantas como a artemísia e a arruda.
Também preparavam remédios estranhos, a partir do cristalino de
porcos, sangue de lagarto, cérebro de leão e leite de mulher. Utilizavam
ainda purgantes, diuréticos, eméticos, sudoríferos e expectorantes, desde
que também eram adeptos da teoria humoral.
Há uma citação, em um dos papiros mais recentes, que diz: “Cure-o com
a faca e então queime-o com o fogo que ele não mais sangrará.” Esta
recomendação foi posteriormente seguida pelos gregos, que recomendaram
o uso do cautério em cirurgias.
A arte hebraica de curar
A medicina dos hebreus pode ser conhecida através da Bíblia (Antigo
Testamento) e do Talmude, livro sagrado, onde está registrada a tradição da religião
até hoje seguida pelos rabinos.
A doença é considerada como resultado da ira divina, e a cessação do
sofrimento somente poderá ser obtida através de orações, jejum e observação das
leis morais. Em conseqüência, há uma tendência a concentrar toda a capacidade de
cura nas mãos dos sacerdotes, que são os intermediários da vontade de um único
Deus. Também vêem as enfermidades como um processo purificador da alma e do
corpo.
O estudo do conhecimento médico, através da Bíblia, é desapontador,
segundo Guthrie16: “No Antigo Testamento há um pequeno lugar para o médico, se é
que houve este lugar, porque lá Deus é o responsável pelas curas”.
Este povo que, pela primeira vez na história, assegura direitos iguais para
todos os indivíduos, desde que obedeçam às suas rigorosas leis morais e
fundamentos religiosos, também pela primeira vez estabelece o conceito de
legislação sanitária, onde o interesse coletivo predomina sobre o individual. Em
épocas de freqüentes e terríveis epidemias, este novo conceito foi muito importante
para a preservação do povo judeu.
Entre as principais recomendações do judaísmo quanto à saúde estão as
práticas higiênicas (para entrar em contato com Deus era necessário estar sempre
limpo), a prática da circuncisão (o que traz menor possibilidade de contrair doenças
venéreas e câncer de pênis), e a proibição de comer carne de porco ( pelo risco, que
hoje se sabe, de teníase e cisticercose). Também criaram um dia semanal de
descanso, o sábado.
Alguns exemplos das práticas recomendadas no Antigo Testamento:
Quem quisesse defecar tinha de se afastar do acampamento, levando uma
pequena pá para depois enterrar suas fezes.
Todos deviam se lavar antes e depois das refeições, e após os contatos
sexuais. Qualquer tipo de secreção anormal dos órgãos sexuais tornava seu portador
“impuro”, de maneira que lhe era exigido abandonar o acampamento.
De todo aquele que tocasse em uma pessoa, que se acreditasse ter morrido
de alguma doença infecciosa, era exigido um isolamento por sete dias. Depois deste
período, devia purificar-se com uma solução de potassa, hissopo e cedro.
Os guerreiros que retornavam ao acampamento, depois de terem mantido
contato com outros povos ou tribos, precisavam ficar isolados por oito dias.
Medidas rígidas como essas permitiram a sobrevivência dos hebreus à difícil e
longa travessia do deserto. Iniciada a partir do ano 1500 a.C17, e guiada por Moisés,
a jornada durou quarenta anos para se completar. Em boa parte, a medicina dos
hebreus foi influenciada pelos egípcios e mesopotâmicos.
A arte indiana de curar
A história da medicina indiana é dividida em três períodos:
Um período mais antigo, que vai de 1500 até 800 a.C., chamado de período
védico porque as informações são derivadas, principalmente, dos Vedas
(palavra que significa conhecimento), os quatros livros sânscritos sagrados dos
indianos: Rig-Veda, Sama-Veda, Yajur-Veda, e Atarva-Veda. Os Vedas são
16 Douglas Guthrie, A history of medicine.
17 Segundo Hegel, em Filosofia da História.
hinos antigos, poemas filosófico-religiosos, preces e ensinamentos oriundos dos
povos arianos, que invadiram o vale do Indo por volta do ano de 1500 a.C.
Um período posterior, ou bramânico, que vai desde 800 a 600 a.C., sendo
que o bramanismo recebeu forte influência da religião dos povos arianos que
conquistaram a Índia. Possuíam um sistema de castas que se perpetuou no
bramanismo, além de transformarem as forças da natureza em deuses de
aspecto humano. Suas principais divindades foram Indra (deus do tempo e da
guerra), Varuna (deus das águas), Agni (deus do fogo) e Soma (deus das
plantas alucinógenas).
E um período chamado budista, que vai de 600 a.C. a 600 d.C., após o que
grandes partes da Índia foram submetidas ao islamismo, e a medicina árabe,
em conseqüência, passou a exercer grande influência no país.
O período bramânico tem essa designação porque é baseado na cultura
dominada pela casta dos sacerdotes desta religião, o mesmo ocorrendo com o
período budista, dominado pelos seus monges.
O primeiro período, ou védico, corresponde ao da medicina mais primitiva.
O período bramânico apresenta uma base mais racional, e a medicina hindu
atinge seu ápice no período budista, onde a educação médica passa a ter uma
formação teórica e prática mais elaborada, de forma semelhante à medicina
grega da Antigüidade.
Os três livros clássicos da medicina indiana são os livros de Charaka (início
da era cristã), Susruta (cerca de 500 d.C.) e Vagbhata (cerca de 600 d.C.).
Charaka catalogou mais de 500 remédios, classificando-os em cinco grupos,
de acordo com a natureza de sua ação: tônicos, sedantes, laxantes, purgantes,
eméticos e afrodisíacos.
Susruta é considerado o pai da cirurgia indiana. Identificou 1120 doenças,
classificando-as em sete grupos. Descreveu oito tipos de intervenções
cirúrgicas: incisão, punção, sondagem, escarificação, extração, sutura, excisão,
e drenagem.
Vagbhata, que nasceu em Sindh, hoje província do Paquistão, escreveu um
tratado conhecido como
Astanga Hrdaya, em três volumes, tendo recebido seus
ensinamentos de medicina aiurvédica de seu pai e de um monge budista,
chamado Avalokita. Sua obra é dividida em seis seções: Medicina Interna,
Pediatria, Ginecologia, Psiquiatria, Toxicologia, Cirurgia Básica, Terapia de
rejuvenescimento e Geriatria. Além de ser um resumo mais claro dos textos de
Charaka e Susruta, sua obra também inclui informação nova que não existia
nos textos anteriores, como seções sobre longevidade, higiene pessoal, causas
das doenças, influências das estações e do tempo sobre o organismo humano,
gravidez e possíveis complicações durante o parto e várias indicações de como
estabelecer um prognóstico e de como tratar determinadas doenças.
Na medicina indiana, a doença também era considerada como um castigo
divino, mas a crença na reencarnação, oriunda do budismo, trouxe uma
novidade a esta associação.
Segundo a tradição, no século VI a.C., Siddartha Gautama, jovem príncipe
que depois seria conhecido como Buda, “o iluminado”, abandonou a casa dos
pais, aos 29 anos de idade, em busca de uma vida de pobreza e ascetismo.
Depois de uma série de experiências fracassadas, ao pé de uma figueira,
percebeu finalmente sua grande revelação, que consistia na descoberta da
causa da dor no mundo e do caminho a ser seguido para sua libertação:
somente seria alcançado o estado perfeito de felicidade através da supressão
de toda forma de desejo e de satisfação dos anseios corporais, além do
aniquilamento da personalidade humana 18.
Recomendava Siddartha “que o homem supere a raiva pela bondade,
e o mal pelo bem. Que o ódio jamais termine em ódio; que o ódio termine em
amor”. Apesar de toda essa capacidade de doação e desprendimento, ele nunca
alegou que um deus falasse por seu intermédio. Suas cinco regras morais
recomendavam: não matar nenhum ser vivo; não tomar o que não for
oferecido; não mentir; não tomar bebidas embriagantes; e não ser impuro.
Segundo Buda, o ser humano estaria continuamente renascendo, até
que seu “karma” - ou seja, o conjunto das ações da vida de cada um que
determinava o seu destino - o levaria ao Nirvana , paz eterna, ou à fusão ao
universo, o que nada mais representa do que o eterno ciclo da criação,
desenvolvimento e destruição, seguido depois de nova criação e assim
indefinidamente, algo semelhante à atual teoria do big-bang de criação do
universo.
O Nirvana não representaria o paraíso depois da morte, mas a
libertação da alma de todo o egoísmo, ou do absurdo do individualismo gerador
dos males do mundo. Segundo Buda, quando aprendemos a amar a todos os
seres, e não somente aos nossos eus isolados, é que encontramos o Nirvana ou
a paz altruísta.
Para Siddartha, o nada seria o princípio de todas as coisas, tudo
surgiria do nada e para lá retornaria.
A atitude religiosa dos hindus em relação aos animais, estreitamente
ligada à teoria do “karma”, provavelmente explica porque a medicina humana e
a veterinária não eram separadas.
A ioga, oriunda da medicina aiurvédica, é uma filosofia deísta. Por
meio da prática da meditação e de exercícios, visa suprimir toda a atividade do
corpo e da mente, para desta forma permitir liberar o espírito do corpo. Os
adeptos da ioga devem buscar o caminho de superação de todo o tipo de
sofrimento e, com a ruptura da opressiva ligação de cada um ao mundo físico,
conseguir alcançar um estado espiritual de iluminação e libertação do corpo.
A dificuldade de se estudar a medicina indiana reside em se
conseguir separar os fatos da ficção nos seus documentos primitivos.
No Rig-Veda, de cerca de 1500 anos a.C., está descrito que o
tratamento das doenças naquele tempo consistia, principalmente, de magias e
feitiçarias. O trabalho seguinte, chamado de Atarva-Veda, contem muito mais
informações. Há descrição de várias doenças, como malária, tuberculose e
varíola. Há descrição também de 760 plantas medicinais.
Eram adeptos da teoria humoral, sendo o corpo constituído por quatro
elementos: ar, muco, bile e sangue. A doença era vista como uma
conseqüência da alteração do equilíbrio entre os elementos constituintes do
18 Ambrogio Donini, em Breve História das Religiões.
corpo. Também poderia se desenvolver devido a causas externas, como
acidentes e possessões por demônios, maldições e feitiçarias.
Contra as doenças provocadas por pecados (feitos nesta ou em outra
vida passada) prescreviam penitências, rezas e o pagamento de promessas
como únicas formas de terapêutica.
O médico indiano foi o primeiro a descrever o diabetes e provava o
gosto da urina de todos os pacientes. Foram muito avançados nas técnicas de
diagnóstico. Faziam parte do exame físico o exame do pulso, do ouvido, a
palpação e a ausculta.
Introduziram a cirurgia de catarata e a cirurgia de litotomia, para
retirada de cálculos da bexiga.
Uma outra contribuição da medicina indiana foi no desenvolvimento da
cirurgia plástica. A rinoplastia foi muito realizada, já que pelo direito penal o
castigo de vários delitos era punido com a amputação da orelha e do nariz. Isto
era comum em crimes de adultério, sendo que só as mulheres eram assim
castigadas. A folha de uma árvore era empregada para servir de molde para se
recortar um pedaço de pele da testa ou do antebraço, que depois era suturada
no local da amputação.
As mulheres só eram aceitas como parteiras, o que não diferia de outras
sociedades. Elas só passaram a ser admitidas como médicas a partir do século
XIV, na Europa.
A arte grega de curar
A importância da cultura helênica na civilização ocidental é inquestionável. Na
filosofia, na política, no teatro, na arquitetura, na matemática, só para citar alguns
exemplos, os gregos exerceram e exercem ainda hoje uma forte influência em nossa
civilização. Nada mais natural que também na medicina esta ascendência tenha sido
significativa.
A cultura grega originou-se da civilização minóica, da ilha de Creta. Protegidos
dos invasores pelo Mediterrâneo, os gregos foram hábeis navegadores, que
estenderam sua influência principalmente pelo mar Egeu. Constituíram uma
sociedade pacífica e voltada para a atividade comercial.
Com sua maneira reflexiva de ver o mundo, os gregos criaram a filosofia,
rejeitando em contrapartida a prevalência religiosa do mito, além de admitir a
diversidade de interpretações racionais de cada fenômeno.
Assim, a civilização grega era essencialmente laica e racionalista. Exaltava o
livre pensamento e colocava o conhecimento acima da fé. Era quase completamente
indiferente ao que lhes aconteceria depois da morte. Os gregos acreditavam que, ao
morrer, iam para o reino escuro de Hades, situado debaixo da terra, mas que
ninguém era punido ou recompensado pelo que havia feito em vida.
Com o livro
Elementos, Euclides, por volta de 300 a. C., deu considerável
contribuição à Matemática. Dividida em 13 partes denominadas “Livros”, o texto
aborda especialmente a geometria plana. A obra de Euclides mostra ainda como
pensar de uma forma lógica sobre qualquer assunto, ou seja, como construir, passo
a passo, uma teoria complexa, o que veio a influenciar consideravelmente o
pensamento de vários filósofos e cientistas, como Descartes, Spinoza, Gottfried
Leibniz e Isaac Newton19.
Thales de Mileto (625 a 548 a. C.), de forma surpreendente, previu o eclipse
do sol de 585 a.C, baseado em seus estudos astronômicos. Isto lhe deu grande
credibilidade, e por seus ensinamentos foi conseguindo destruir mitos e superstições
que envolviam as doenças. Naqueles tempos, as profecias e os prognósticos das
doenças eram dados pelos oráculos, ou por meio do exame do fígado de animais
sacrificados. É ainda atribuída Thales a afirmação de que a soma dos ângulos de um
triângulo é igual a dois ângulos retos e que os lados de triângulos semelhantes são
proporcionais.Thales também deu outra contribuição importante ao atribuir à água a
origem material de todas as coisas.
Além de Thales, a base científica inicial da medicina grega foi dada por
Pitágoras20 (580 a 497 a.C.), que também contribuiu para retirar da doença o manto
sobrenatural que havia até então. Este pensador, conhecido ainda hoje pelo teorema
que leva o seu nome, estabeleceu que os princípios da harmonia e proporção
governavam o universo, refletindo o macrocosmo. O mesmo devia ocorrer também
com o nosso corpo, ou microcosmo. É ainda atribuída a Pitágoras a primeira menção
ao formato esférico da Terra.
Aristóteles, outro nome importante dos primórdios da medicina, era filho de
médico, e escreveu três grandes trabalhos de Biologia:
A história dos animais,
Partes
de Animais e
Geração de Animais.
Deu ainda uma importante contribuição sobre a natureza da própria vida. Para
ele, a diferença entre matéria viva e não viva não dependia da sua constituição
material, mas sim da presença ou não de algo que denominava de psique, e que
poderia ser traduzido por alma ou por consciência. Aristóteles foi um dos maiores
sábios da Antigüidade, e no campo da medicina é considerado, ainda, o fundador da
anatomia comparada por seus estudos sobre anatomia de vertebrados e
invertebrados21.
O mais conhecido médico grego, e o que mais prestígio acumulou ao longo da
história, foi, sem dúvida, Hipócrates. Há testemunhos sobre sua real existência dados
por Platão e Aristóteles, sendo que este considerava Hipócrates o mais perfeito tipo
de médico que conheceu.
Para Hipócrates, nascido na ilha de Cós (450 a 370 a.C.), quem quisesse se
dedicar à medicina deveria ter vocação e uma grande capacidade de dedicação ao
trabalho e ao estudo. Seguindo a escola de Pitágoras, ele rompeu com a magia e o
misticismo e deu à medicina os primeiros fundamentos de uma ciência/arte racional.
Sugestão, crendice e mistério são indignos do padrão de conduta dos médicos,
ensinava.
Passou a dar importância primordial ao contato com o paciente, sendo
atribuída a ele a forma, ainda hoje empregada, de como se realizar uma consulta:
interrogar de forma consciente, escutar, observar, fazer exame físico, estabelecer
diagnóstico, fazer prognóstico e definir o tratamento.
19 Segundo Berlingoff e Gouvea, em A Matemática Através dos Tempos.
20 Bertrand Russel sobre Pitágoras:“Não sei de nenhum homem que tenha sido tão influente
na esfera do pensamento”.
21 Aristóteles acreditava que as características de cada espécie eram fixas, não havendo
possibilidade de evolução entre os seres vivos.
Sua doutrina poderia ser resumida com uma frase que repetia sempre para
seus alunos: “cada doença tem uma causa natural e sem causas naturais nada
acontece”. Suas aulas eram dadas à sombra de um plátano, árvore milenar ainda
hoje existente na ilha de Cós.
Em um período em que os médicos freqüentemente viajavam de um lugar a
outro, estabelecer um prognóstico adequado era o que de melhor se podia fazer, já
que as curas aconteciam mais pela resposta da natureza do que pelos tratamentos
empregados. Este foi um dos motivos da fama de Hipócrates e de outros
contemporâneos da medicina grega.
Os gregos do século V a.C. acreditavam que o universo era formado por
quatro elementos: água, terra, fogo e ar22. A cada um destes elementos
correspondiam qualidades intrínsecas: umidade e frio para a água, secura e frio para
a terra, calor e secura para o fogo e calor e umidade para o ar.
Hipócrates desenvolveu uma teoria, influenciado pelas outras culturas que
precederam a dos gregos, segundo a qual o organismo é constituído por quatro tipos
de humores: sangue, muco, bile amarela e bile negra. O sangue tinha como
características ser quente e seco. O muco frio e úmido. A bile amarela quente e
úmida, e a bile negra fria e seca. O sangue teria origem no coração, o muco no
cérebro, a bile amarela no fígado e a bile negra no baço.
Para haver saúde havia necessidade do equilíbrio entre estes humores. O
excesso ou a falta de algum deles produziria a doença. Isto teria a ver ainda com o
tratamento das enfermidades.
Se um dos humores, como o sangue, estivesse em volume maior do que o
necessário, deveria ser feita uma sangria e se restabeleceria o equilíbrio e, em
conseqüência, a saúde.
Este era o fundamento para o emprego dos medicamentos da época:
sangrias, purgantes e vomitórios, enemas, ervas, laxantes e banhos quentes, de
forma a induzir sangrias, vômitos, diarréias e sudorese.
Supunham que a eliminação do humor em excesso recomporia a saúde
perdida. Também havia recomendação para o uso de dietas e exercícios físicos.
Foi ainda Hipócrates quem deu as bases éticas da profissão. No famoso
juramento que os estudantes de medicina ainda hoje repetem - e que cita os deuses
gregos, Apolo, médico dos deuses, e pai de Asclépio (Esculápio em latim), deus da
medicina, que por sua vez era pai de Hígia, deusa da saúde, e de Panacéia, deusa da
cura -, formula alguns dos ainda respeitados preceitos do código de ética médica,
tais como não causar dano aos pacientes, não manter relações sexuais com o doente
e seus familiares, não praticar a eutanásia, não praticar aborto, guardar segredo
daquilo que ouvir de seus clientes, respeitar os seus mestres e os seus discípulos, e
manter comportamento digno de sua atividade profissional.
As escolas médicas gregas se desenvolveram ao lado dos templos de Asclépio,
onde havia abundância de doentes, porque para lá iam os enfermos atrás de suas
curas.
A ida dos doentes até os templos, na verdade, não era para serem tratados
como hoje se conhece.
Eles iam dormir no templo para sonhar com o próprio Asclépio, que durante o
sonho lhes revelaria o que fazer para tratar as suas doenças.
22 Teoria de Empédocles de Agrigento, que viveu na primeira metade do século V a.C.
Quando os doentes não conseguiam, por si mesmos, entender o significado
dos sonhos, os sacerdotes do templo os interpretavam e lhes diziam o que deveria
ser feito. Na verdade, o medicamento capaz de realizar as curas era a fé trazida por
cada um que vinha procurar auxílio. É interessante ainda observar a importância que
davam ao significado dos sonhos, o que muito tempo depois veio a ser ressaltado
com a fundação da psicanálise, por Freud.
As mais famosas escolas de medicina da antiga Grécia foram as de Rhodas,
Crotona, Cós e Cnido.
Todo aspirante à profissão médica tinha que procurar por si mesmo seu
aperfeiçoamento, que adquiria sob a forma de ensino privado (com outros médicos
mais experientes) ou freqüentando as escolas médicas tradicionais. Não se exigia
qualquer prova de suficiência antes de se poder dar início ao exercício da profissão.
Com isto surgiram muitos charlatães, o que dificultava a prática dos médicos com
formação adequada.
Acredita-se que nem tudo o que se atribui a Hipócrates foi realmente escrito
por ele, mas por outros médicos que viveram em períodos semelhantes, como
Crísipo, Êuripo e Praxágoras. Alguns dos seus conhecidos aforismos, no entanto,
permanecem como sendo parte de sua obra até hoje, como os seguintes:
“A vida é tão curta, e a arte é tão grande para ser aprendida, a ocasião fugaz,
a experiência enganadora, e o julgamento difícil”.23
“As doenças que a medicina não cura, a faca cura; aquelas que a faca não
cura, o fogo pode curar; mas as que nem o fogo cura devem ser incuráveis.”
“As pessoas que, ao tossir, expelem sangue espumoso, este sangue vem do
pulmão”.
“A fadiga não provocada indica doença”.
“Quando um convalescente come bem e não engorda, é um sinal
desfavorável”.
“Em todas as moléstias conservar a inteligência lúcida e o gosto pelos
alimentos é um bom sinal; o contrário é mau”.
“A tísica aparece, principalmente, entre as idades de 18 e 35 anos”.
“Nos ictéricos é mau sinal que o fígado endureça”.
“É mais fácil reparar as forças com alimentos líquidos do que com sólidos”.
“Aqueles que são gordos estão mais expostos à morte súbita do que os que
são magros”.
As obras de Hipócrates, junto com as de outros médicos gregos da
Antiguidade, foram reunidas na grande biblioteca de Alexandria, por Ptolomeu, um
dos generais de Alexandre Magno, rei da Macedônia e que teve Aristóteles como seu
preceptor, tendo sua educação sido digna do homem que a assumiu. Segundo Hegel
24, Alexandre favoreceu as ciências e foi, ao lado de Péricles, enaltecido como o mais
generoso protetor das artes da Antigüidade.
Estas informações, contidas na chamada Coletânea Hipocrática, foram
estimadas em um total de 131 obras, versando sobre os mais diversos assuntos,
como anatomia (área em que os gregos eram deficientes, já que era proibida a
dissecação de cadáveres e seus conhecimentos baseavam-se no estudo de animais),
23 Sobre a arte da medicina.
24 Em Filosofia da História.
fisiologia, patologia, terapêutica, diagnóstico, prognóstico, cirurgia e obstetrícia,
entre outros.
Alguns livros que fazem parte da Coletânea:
Sobre a medicina antiga -- aborda a arte da medicina a partir de práticas e
observações dietéticas.
Doenças epidêmicas – aborda, principalmente, as doenças encontradas na ilha
de Thasos.
Sobre o prognóstico – revela os profundos conhecimentos de Hipócrates sobre
os sintomas das doenças.
Sobre os ares, águas e lugares – alerta ao médico que doenças deverá
conhecer ao entrar em uma cidade, com determinadas condições climáticas. É um
clássico da geografia médica. Refere, pela primeira vez, a importância dos fatores
ambientais no surgimento das doenças.
A lei e o médico – aborda a atitude profissional do médico e as suas
obrigações éticas.
A escola de Alexandria
A cidade de Alexandria tornou-se o mais importante centro cultural da
Antigüidade.
No século III ª C ., o rei Ptolomeu II fundou a célebre biblioteca que chegou,
no seu auge, a ter mais de 500.000 volumes ou papiros. O
Museum , ou templo das
Musas como era chamado, constituía muito mais que uma simples biblioteca, sendo
verdadeiro centro científico e cultural, de ensino e de pesquisas, possuindo ainda
anfiteatro, jardim zoológico, templo e observatório.
A biblioteca foi incendiada primeiramente pelos romanos em 47 a. C. e depois
em 390 pelo bispo Teófilo, até ser finalmente destruída quando os árabes
conquistaram o Egito em 642.
Na medicina, nessa importante metrópole, despontaram Asclepíades,
Heróphilo e Erasistrato.
A escola de Alexandria teve como uma das principais causas de seu
desenvolvimento a prática de dissecação do corpo humano entre o final do século III
a.C. até o início do século II d.C. Isto permitiu um grande desenvolvimento da
anatomia e, consequentemente, da cirurgia.
Asclepíades dizia que o corpo era feito de átomos, ou corpúsculos elementares
imperceptíveis aos sentidos e que de forma contínua se moviam através dos poros e
canais do nosso corpo. Ele discordava da teoria dos humores de Hipócrates.
Considerava que muito mais do que medicamentos, o que se deveria fazer era ter
hábitos de vida saudáveis. Foi o primeiro médico grego a fazer sucesso em Roma,
tendo encontrado naquela sociedade, ociosa e opulenta, terreno fértil para suas
pregações. Recomendava dietas, exercícios físicos, caminhadas, banhos e
massagens.
Heróphilo, da Calcedônia, foi considerado o maior anatomista da Antigüidade.
Deixou uma detalhada descrição do cérebro, o descobrimento do significado da
pulsação e de seu emprego no diagnóstico de doenças, a distinção entre tendões e
nervos, e a relação entre eles e o cérebro. Ao contrário de Aristóteles, que
considerava o coração como a sede da inteligência e das emoções (o que continuou
por muito tempo a ser verdade na literatura), Heróphilo percebeu que era ao cérebro
que deveriam ser creditadas as funções mais nobres do nosso corpo. Acreditava,
ainda, na teoria dos humores dos gregos mais antigos.
Erasístrato discordou desta teoria, e acreditou que a atividade dos átomos
procedia do ar inspirado (pneuma, que significava a alma e o sopro da vida) que se
distribuía por todo o corpo, através das artérias.
Foi dele a informação de que o coração era a origem das artérias e veias.
Erasístrato, que deixou importante contribuição no campo da anatomia, foi acusado
da prática de dissecação em criminosos vivos, a vivissecção.
Sabe-se, hoje, que tanto Heróphilo como Erasístrato realizaram dissecação
pública de cadáveres humanos.
A denúncia de vivissecção feita a Erasístrato e a Heróphilo deve-se a Celso e a
Tertuliano (155 a 222 d.C.) e também a Santo Agostinho (354 a 430 d.C.). Galeno,
que foi posterior a Heróphilo e a Erasístrato, em nenhuma de suas obras corroborou
estas denúncias. Sendo tão crítico, e tão contrário às opiniões de Erasístrato, é
provável que estas afirmações fossem falsas e retratassem, na verdade, uma reação
à prática da dissecação em cadáveres humanos, o que foi condenado pela Igreja por
muitos séculos.
A arte romana de curar
O mais importante dos médicos romanos foi Aulus Cornelius Celsus, ou Celso.
Foi o primeiro a escrever sua obra em latim, ao invés do grego, como era a norma
para os textos científicos da época. Escrevia em um latim perfeito, sendo
extremamente organizado. Existem dúvidas quanto à sua profissão, uma vez que
escreveu obras abrangentes de conhecimentos de agricultura e teoria militar, e até
de filosofia e direito. A que versava sobre medicina,
De res medica, publicada em 30
d.C., foi a única a sobreviver, tendo sido reimpressa na Idade Média. Foi Celso quem,
pela primeira vez, definiu os quatro sinais da inflamação: dor, calor, rubor e tumor.
Também descreveu vários tipos de tratamentos ortopédicos, como redução de
fraturas e luxações.
Caius Plinius Secundus, ou Plínio, o velho (23 a 79 d.C.), também escreveu
uma obra gigantesca, em 37 volumes
, Historia Natural, versando sobre assuntos tão
variados quanto história, física, química, geografia e medicina. Era, na verdade, uma
compilação, que se supõe baseada nos escritos de quase 500 autores diferentes
sobre vários temas, os quais ainda hoje estão em uso.
Plínio foi, na verdade um jornalista de seu tempo. Seu legado era uma espécie
de enciclopédia popular, onde todos poderiam apelar diretamente e encontrar
sempre alguma informação importante, estórias ou até conselhos. Seus livros
descrevem os costumes, crenças, superstições e idéias da época em que viveu.
Sabendo que o Vesúvio estava em erupção, foi até a cidade de Pompéia para
verificar, pessoalmente, o acontecimento, como bom repórter que era. Mesmo
alertado do perigo que corria, recusou-se a abandonar o local.
No terceiro dia em que lá estava, após jantar foi se deitar para repousar um
pouco. Logo depois as torrentes de lava incandescente caíram sobre a cidade. Seu
corpo foi encontrado intacto, três dias depois.
Aparentemente, morreu intoxicado pelos gases venenosos emitidos pelo
vulcão, durante a erupção que destruiu Pompéia.
Pedanius Dioscórides(41 a 68 d.C.) foi médico dos exércitos de Nero, e teve a
oportunidade de conhecer centenas de plantas, durante suas viagens com os
militares. Catalogou as plantas de acordo com as doenças que curavam.
Elaborou uma espécie de farmacopéia, com a lista das substâncias e remédios de
que fazia uso a medicina para o tratamento das enfermidades. Seu livro, a
Hylikà ou
Matéria Médica, continha as descrições de 600 plantas, apresentava belos desenhos
e foi traduzido para vários idiomas, tendo sido usado como texto de referência por
mais de mil e quinhentos anos.
Constava de cinco livros: o primeiro abordava substâncias aromáticas, azeite,
ungüentos, árvores e seus sucos, resinas e frutos; o segundo versava sobre animais,
medicamentos de origem animal, legumes e cereais; o terceiro comentava sobre
ervas, raízes e seus sucos, além de sementes; o quarto livro era sobre outras ervas,
raízes e fungos; o quinto se referia a vinhos e remédios minerais.
A obra de Dioscórides apresenta 500 remédios de origem vegetal, 35 de
origem animal e 90 de origem mineral. Seguia sempre o mesmo princípio quanto à
apresentação dos medicamentos: caracteres de cada substância, sinonímia,
falsificações, comprovações, ações e uso médico.
Apesar de não terem desenvolvido muito a teoria e a prática da medicina, os
romanos ficaram na história por suas contribuições na área da saúde pública.
Criaram um sistema complexo de transportar e utilizar água à distância, que
incluía reservatórios em colinas, e que era servido por aquedutos que transportavam
o líquido para cisternas e daí para piscinas ou bacias de assentamento, onde o
sedimento se depositava. Com isto obtinham a melhoria da qualidade da água a ser
consumida nas fontes de rua e nas casas de banhos públicos, muito comuns na
Roma antiga, o que contribuía para elevar o nível de higiene pessoal da população.
Entre os séculos I e II d.C., ou seja, no seu apogeu, Roma chegou a ter uma
população de um milhão de habitantes. Para viabilizar o acesso de água a toda esta
gente, pode-se ter uma idéia da complexidade do sistema de abastecimento
desenvolvido.
Havia também uma grande preocupação com o destino dos dejetos. Para
resolver o problema, foi desenvolvido um sistema de captação da água das chuvas e
dos esgotos através de canos sob as ruas. Estes drenavam a água para uma rede de
encanamento de calibre crescente, até desembocar na cloaca máxima, no Rio Tibre.
No século II d.C. foi criado um serviço público de saúde para atender aos
cidadãos pobres que não tinham como pagar aos médicos. Nas cidades consideradas
pequenas, o Estado remunerava cinco médicos para atender ao público. Nas médias,
sete, e, para as grandes, até dez médicos eram contratados para esta função.
Muito antes da descoberta dos micróbios, os romanos se preocupavam com os
lugares encharcados e pantanosos. Procuravam aterrar estes lugares, ou misturar
água salgada ao charco, para inibir o crescimento de mosquitos, já que tinham
percebido uma forte associação entre áreas pantanosas e doenças. Sabemos, hoje,
que os mosquitos são transmissores de várias moléstias como a malária, a dengue e
a febre amarela.
Com Roma, os médicos constituíam uma classe protegida pelo Estado,
passaram a gozar da estima dos cidadãos, e chegaram a ocupar cargos da maior
relevância política. Até mesmo os médicos estrangeiros adquiriram direitos
semelhantes aos dos romanos, foram elevados ao topo da escala social e
participaram ativamente da responsabilidade pela definição das políticas de saúde
pública.
Sorano (Pai da Obstetrícia)
Sorano de Éfeso (98 a 138 d.C.), que pode ser considerado o pai da
Ginecologia e Obstetrícia, estudou e praticou medicina em Alexandria, e depois foi
exercer seu trabalho em Roma, no reinado de Adriano. Há quem o considere
somente inferior, em importância para a história da medicina, a Hipócrates e a
Galeno25.
Escreveu uma biografia de médicos, podendo ser por isso considerado o
primeiro autor de uma história da medicina.
Seu principal trabalho,
Gynaecia, em 4 volumes, tem duas cópias ainda hoje
preservadas, sendo uma delas na biblioteca do Vaticano. Nele descreve
detalhadamente o aparelho genital feminino e as formas de evitar a gravidez, como
o bloqueio do colo do útero com algodão, ungüentos ou substâncias gordurosas.
Apresentou várias causas que poderiam provocar a suspensão da menstruação, a
amenorréia, e que poderiam ser conseqüência desde a amamentação até infecções
genitais. Sua obra foi escrita principalmente para as parteiras.
Foi o introdutor da cadeira de parto, que tinha apoios para os braços e as
nádegas e uma abertura em forma de crescente. Recomendou determinados
procedimentos para os partos difíceis, especialmente nos casos em que o cordão
umbilical se apresenta antes do feto.
Detalha ainda a maneira de conduzir o parto nas apresentações anormais do
feto, incluindo o que se considera sua maior contribuição, ou a versão podálica.
Nesse tipo de conduta, recomenda que a parteira ,ou o médico que assiste a
gestante, delicadamente mova com a ajuda da mão, no interior do útero, o feto de
maneira a que os pés saiam antes do restante do corpo.
Descreveu, ainda, como fazer frente às eventuais complicações do parto, e
também abordou temas ligados à Neonatologia e à Pediatria.
Galeno (“ O príncipe dos médicos”)
Ninguém exerceu maior influência sobre a medicina do que Claudius Galen, ou
Galeno, médico grego que viveu de 129 a 200 d.C. Escreveu quase duzentos textos
de medicina, sistematizando todo o conhecimento da literatura médica greco-
25 Lopes, em A medicina no tempo.
romana. Sua produção científica foi tão grande que era impossível lê-la ou ensiná-la
durante o período de formação de um profissional.
Filho de um arquiteto, nasceu em Pérgamo, na época o maior centro cultural da
Ásia Menor e onde havia um famoso templo de Esculápio.
Por nove anos estudou medicina e filosofia em Somyrna, Corinto e Alexandria.
Depois, retornou à sua cidade e tornou-se médico dos gladiadores.
Após quatro anos foi para Roma, onde teve maior reconhecimento pelo seu
trabalho. Foi médico do imperador Marco Aurélio e, depois da morte deste, no ano
de 180, tornou-se conselheiro de Cômodo, e depois médico do imperador Sétimo
Severo, que sobreviveu a Galeno.
Foi seguidor da teoria dos humores da escola hipocrática, e a expandiu
classificando os temperamentos em quatro tipos:
1. Fleumáticos – relacionados com o flegma ou muco; pessoas preguiçosas,
frívolas; também relacionadas com a água (entre os quatro elementos).
Posteriormente, na Idade Média, a astrologia relacionou estas pessoas com os
signos de peixes, aquário e capricórnio.
2. Melancólicos – relacionados com a bile negra; pessoas teimosas, obstinadas;
relacionadas com a terra. Na astrologia correspondem aos signos de sagitário,
escorpião e libra.
3. Coléricos – relacionados com a bile amarela; pessoas audaciosas, exuberantes;
relacionadas com o ar. Na astrologia correspondem aos signos de virgem, leão e
câncer.
4. Sangüíneos – relacionados com o sangue; pessoas serenas, tranqüilas;
relacionadas com o fogo. Na astrologia correspondem aos signos de gêmeos,
touro e áries.
Galeno era extremamente vaidoso e a ele é atribuída a seguinte frase: “Eu fiz
pela medicina o que o imperador Trajano fez pelo Império Romano: abri estradas,
construí pontes. Eu sou o criador único do verdadeiro método de tratar doenças.”
E ainda, “Nunca, até o presente, cometi erro algum, já seja no tratamento ou
no prognóstico, como tem sucedido a muitos outros médicos de grande reputação.
Se alguém desejar alcançar renome, o único que necessita para isso é aceitar o que
eu tenho sido capaz de demonstrar”.
Sua atividade terapêutica baseava-se na teoria dos opostos: aplicava calor
se a doença havia sido causada pelo frio, ou purgativos se fosse conseqüência de
algum excesso alimentar. Também era pródigo no uso de medicamentos, que ele
mesmo produzia.
Devido ao fato de ter realizado estudos de anatomia apenas em animais, sua
obra continha alguns pressupostos falsos, como em relação aos órgãos internos.
Detinha, no entanto, um grande conhecimento de fisiologia em grande parte graças
aos seus estudos experimentais, feitos em animais.
É famoso um diagnóstico que fez em um paciente persa que se queixava de
perda da sensibilidade nos dedos de uma das mãos. Por meio de uma história clínica
bem feita, Galeno descobriu que o caso se devia a uma lesão da sétima vértebra
cervical, conseqüente a uma queda do paciente sobre uma pedra, episódio que
apenas provocou uma dor momentânea e que foi logo esquecida. Recomendou
repouso no leito e aplicação de um emplastro reconfortante e o paciente se curou.
Galeno declarava que toda alteração na função do organismo resultava de
algum tipo de lesão, e que toda lesão levava a algum tipo de alteração funcional, o
que ainda hoje é verdadeiro.
Foi, provavelmente, o primeiro a produzir lesões cerebrais em animais para
estabelecer a distinção entre lesões dos lobos cerebrais e aquelas relacionadas ao
tronco cerebral e cerebelo. Reconheceu sete dos doze pares de nervos cranianos e
fez a distinção entre nervos motores e sensitivos.
Após a morte de Galeno, procurou-se ordenar e estruturar seus ensinamentos
visando a criação de um sistema coerente, capaz de divulgar seus conhecimentos
aos estudantes de medicina dentro de um período de tempo razoável. Isto foi
conseguido por volta do século VI d.C., quando, em Alexandria, vários estudiosos da
obra de Galeno conseguiram resumi-la em 16 livros, com quatro partes: a primeira,
uma introdução (livros 1 a 4), a segunda dedicada à fisiologia (livros 5 a 8), a
terceira à patologia (livros 9 a 14) e a quarta à terapêutica e higiene (livros 15 e 16).
Sua influência perdurou por quase quinze séculos, em parte, provavelmente,
porque sua obra coincidia com várias posições do cristianismo. Para Galeno, tudo
era determinado por um Deus sábio e tudo era reflexo de sua perfeição, e essa
perfeição podia ser percebida no corpo humano. A influência de Galeno só diminuiu
quando Vesalius, no século XVI, mudou inteiramente o estudo da anatomia.
A decadência de Roma e o surgimento das civilizações religiosas
Várias foram as causas do declínio do mundo greco-romano, que se acentuou
com a mudança do imperador Constantino para Bizâncio, em 330 d.C. Segundo
alguns historiadores, foi o imperialismo a principal causa da queda da civilização
romana. A enorme dimensão do território conquistado por Roma tornava o império
difícil de ser administrado.
Outras causas citadas são a forte decadência moral da sociedade, que levava
à corrupção generalizada especialmente entre as classes dirigentes e mesmo no seio
do exército, além de grande opressão das minorias e pobreza generalizada da
população.
Também havia uma grande permissividade, havendo 32 mil prostitutas em
Roma, durante o reinado de Trajano, além de ser muito freqüente o
homossexualismo. No Coliseu, os gladiadores lutavam até a morte, tendo se
desenvolvido um lamentável gosto pela crueldade no seio do povo.
Pelo próprio crescimento de Roma e de outras cidades do império, com
grandes aglomerações de pessoas, aconteceram várias epidemias, que contribuíram
para enfraquecer ainda mais o já debilitado poder romano. Em 166, houve uma
epidemia de tifo exantemático. Em 251, de varíola. No ano de 543, no reinado de
Justiniano, houve uma outra epidemia de peste bubônica, que também provocou
milhares de mortes.
Diante de todo este quadro, existia um terreno fértil para o surgimento de
uma nova civilização que se baseasse em novos valores éticos e morais. Foi a partir
deste momento que surgiu a pregação de Jesus Cristo e, com ele, o que no início era
apenas uma seita, tornou-se em poucos anos uma religião de enorme apelo popular.
É importante ressaltar ainda que essa nova doutrina surgiu como uma síntese
do cristianismo, judaísmo e do helenismo, sendo dirigida a todos os homens e não a
um povo em particular como era comum às demais religiões da época.
Com Constantino passou a ser a religião oficial do Estado26, o que foi, em
parte, devido ao fato de uma grande parcela dos soldados romanos já serem cristãos
à época. Há, no entanto, quem diga que Constantino converteu-se em 312, após ter
visto, no céu, uma cruz em chamas com as palavras “Com este símbolo vencerás”27,
ao retornar da Gália para enfrentar rivais que lhe reclamavam o trono de Roma.
O islamismo surgiu como uma forma de unir o povo árabe em torno de uma
religião e de uma causa comum, através das pregações de Muhammad, ou Maomé,
no início do século VII. Seus ensinamentos estão contidos no Corão, onde a
revelação de Deus foi feita ao profeta pelo anjo Gabriel, ao longo de vinte e três
anos, conforme reza a tradição.
Segundo Maomé, “instruir-se é dever de todos os muçulmanos, homens,
mulheres, velhos e crianças.” E ainda dizia, “buscai a Ciência, do berço à sepultura.
Buscai a Ciência, ainda que seja na China.”
Inspirado pela religião judaica e cristã, o islamismo é monoteísta, crê apenas
em Alá, induz à prática da caridade e do perdão entre as pessoas, além de proibir o
consumo de bebidas alcoólicas e carne de porco.
Prega o jejum durante o dia, no mês sagrado do Ramadã, a prática da prece
cinco vezes ao dia, e a peregrinação à sua cidade sagrada, Meca, ao menos uma vez
na vida.
Maomé não foi somente o fundador de uma religião, mas também de um
estado árabe, com sede em Medina. Era dever do fiel conquistar para o Islã a maior
parte possível do mundo.
Após a morte de Maomé, em 632, uma grande onda de expansão sarracena
se espalhou pela Ásia, África e Europa. Cerca de cem anos após a morte do profeta
do islamismo, cerca de metade do mundo civilizado era dominado pelos
muçulmanos. Este império foi conquistado sem grandes lutas, mais pela fragilidade
apresentada pelos inimigos do que pela grande supremacia dos exércitos árabes.
Esta expansão motivou as cruzadas, de 1096 a 1272, guerra religiosa que
tinha como emblema recuperar a cidade de Jerusalém para os cristãos, mas que na
verdade visava reconquistar os territórios perdidos para os árabes.
Enquanto a influência do cristianismo na Europa Ocidental foi predominante,
entre os séculos V e IX, o islamismo teve seu apogeu entre os séculos VII e XIII.
26 O cristianismo foi declarado religião oficial no ano de 312.
27 Durant, em Heróis da História.
O declínio da importância da arte de curar
A Idade Média tem a duração de cerca de mil anos, ou, mais precisamente,
delimita-se entre a divisão do Império Romano em Império Romano do Ocidente e
do Oriente, em 395, e a queda de Constantinopla em 1453, pelos turcos otomanos.
Na sua primeira metade, houve um retrocesso na atitude da sociedade em relação
ao racionalismo, especialmente entre os séculos X e XI.
A mente do homem medieval estava voltada para a morte, que havia se
tornado uma obsessão coletiva. O símbolo da morte era encontrado em vários
lugares, desde sepulturas até anéis e ornamentos de residências.
A doença voltou a ser considerada como um castigo ou punição, ou como
resultado de possessões demoníacas. Em conseqüência, as pessoas recorreram a
rituais de magia ou às orações, e a prática da medicina entrou em um longo período
de descrédito e desprestígio.
O fato de as cidades da época serem verdadeiros aglomerados humanos, com
precárias condições de higiene, a falta de um sistema adequado de redes de água e
de esgoto e a não existência de uma rotina de retirada do lixo, com conseqüente
aumento da população de ratos e insetos, contribuíam para que as doenças
infecciosas ocorressem de forma freqüente, e não raras vezes de forma epidêmica.
A precariedade da medicina de então, que pouco podia fazer contra os
diferentes surtos, como nas epidemias de tifo, peste bubônica, varíola, difteria,
malária, febre tifóide, disenteria, além da lepra (hoje conhecida como hanseníase),
que era muito freqüente, contribuiu de forma significativa para a perda de
credibilidade na prática médica.
Somente a peste negra, em 1347 e 1348, eliminou cerca de 25 milhões de
pessoas na Europa, sendo que em alguns lugares a população foi reduzida em até
75%.
Arte de curar e cristianismo
Com a expansão do cristianismo, a partir do início da Idade Média, e a
associação renovada entre doença e pecado, nada mais natural que a Igreja Católica
estivesse constantemente presente no tratamento e nos cuidados oferecidos aos
doentes. A Bíblia é rica em citações de curas feitas por Jesus Cristo, além do que a
reparação física era acompanhada da expulsão de demônios ou de outros “espíritos
impuros”.
Em conseqüência, a Igreja assumiu crescentemente o atendimento à saúde, já
que o cristianismo pregava a fraternidade e a caridade para os humildes e os aflitos,
além de considerar o sofrimento como uma benção para a salvação da alma.
Além disso, com um considerável alheamento em relação ao que ocorria no
mundo real, o cristianismo levou muitos dos seus seguidores a uma maior
indiferença frente a acumulação de bens nesse mundo, o que também contribuiu
para sua menor participação nas atividades econômicas dos países europeus.
Ou ainda, como escreveu Weatherford28, “durante a maior parte da vida
humana, a religião usou histórias e rituais para despertar emoções como medo do
desconhecido, avidez de procurar o invisível, viver eternamente ou algum outro
produto que outrora não se podia obter na terra”.
Por outro lado, em tempos de conflitos sangrentos, ninguém podia encontrar
a paz e a calma necessária para cuidar dos pacientes fora das ordens religiosas.
Os hospitais surgiram como instituições cristãs. Santa Helena, mãe do
imperador Constantino, fundou um hospital no ano de 330, após a mudança da
capital do Império Romano para Bizâncio, que depois viria a ter seu nome mudado
para Constantinopla. Em 369 foi criado em Cesaréia, por São Basílio, um hospital
para a população carente.
Em razão de sua própria vida de recolhimento e de estudo, os monges
beneditinos acabaram assumindo a assistência médica no mundo ocidental por mais
de cinco séculos. A este período da história alguns denominam de período da
medicina monástica.
O fundador da ordem dos beneditinos, Benedicto de Nursia, a partir de
Montecassino, influenciou fortemente seus monges a cuidar dos doentes. Um dos
primeiros membros desta comunidade, Cassiodorus (490 a 575), que havia sido
ministro de Teodorico (rei de um dos povos germânicos que governou Roma), e que
depois aderiu à ordem beneditina, recomendava o estudo de plantas medicinais e
das obras dos médicos antigos. Com os monges missionários, a medicina ia se
infiltrando entre os povos que adotaram o cristianismo.
Em 805, os beneditinos passaram a receber instrução médica como parte de
seu aprendizado formal, sob o nome de física, e os médicos assim formados eram
chamados físicos.
A maioria dos medicamentos era feita pelos próprios monges, a partir de
plantas que eles mesmos cultivavam. Em cada mosteiro havia um jardim botânico,
de onde os religiosos coletavam material para o preparo de seus remédios, uma
farmácia, uma biblioteca e um lugar para tratar os doentes. Nas bibliotecas os
monges traduziam os textos clássicos gregos para o latim.
As santas casas de misericórdia se espalharam por todo o mundo, com várias
ordens religiosas assumindo o tratamento dos enfermos pobres.
Na França os hospitais eram conhecidos como Hôtel-Dieu. O primeiro surgiu
em Lyon, em 542. O de Paris, fundado no século VII, pelo bispo da cidade, S.
Landry, chegou a ter 1.200 leitos, sendo que apenas a metade com leitos individuais.
Os demais recebiam de três a cinco pacientes por leito. Os hospitais eram
inteiramente administrados por ordens religiosas.
A medicina leiga, apesar de continuar existindo, entrou em uma fase de
declínio, só voltando a recuperar parte de seu prestígio após o surgimento das
universidades européias, a partir do século XII.
O declínio da medicina monástica atinge seu ápice no século XI. Seu sucesso
levou os monges cada vez para mais longe dos mosteiros e de suas obrigações
religiosas.
Muitos passaram a ganhar muito dinheiro com a atividade e foram se
esquecendo da caridade na hora de tratar os enfermos mais pobres. Vários concílios
28 A História do Dinheiro.
da Igreja foram, de forma gradual, restringindo essas atividades médicas, até a sua
completa proibição.
Com o concílio de Tours, em 1163 (A Igreja não derrama sangue), a Igreja
proibiu os monges de realizarem cirurgias. Com isto, deixou de ser atribuição dos
médicos, desde que a maioria deles era de religiosos. A cirurgia passou, então, a ser
exercida apenas pelos barbeiros e charlatães de toda espécie.
Surgiram, ainda, novas ordens religiosas, como os dominicanos e os
franciscanos, claramente hostis à participação em atividades científicas.
Paulus de Aegina
Considerado como um dos maiores médicos de todos os tempos, viveu no
século VII e estudou em Constantinopla e Alexandria. Publicou uma coleção de sete
livros sobre diferentes temas, sendo o mais importante deles sobre cirurgia. Nele,
abordava o tratamento do câncer de útero e de mama, além da técnica de litotomia,
castração, tratamento de lesões ginecológicas, e de fístulas anais, hemorróidas e
fraturas. Foi, ainda, o criador de um sistema para irrigação vesical, por meio de uma
bexiga de boi ligada a um cateter, que seria um sistema precursor da atual sonda
vesical.
Os árabes
“Em medicina a verdade absoluta é um objetivo que não pode ser alcançado,
e tudo o que está escrito nos livros vale menos do que a experiência de um médico
sensato”. Esta frase é de Abu Bakr Muhammad ibn-Zakasiya al-Razi, mais conhecido
como Rhazes, um dos mais importantes médicos árabes, que viveu de 860 a 932.
O aforismo faz parte do livro
Liber medicinalis ad almansorem, que Rhazes
escreveu baseado em vários textos dos antigos gregos. Em outro de seus livros,
Liber de pestilentia, descreve com exatidão doenças como o sarampo e a varicela.
Contrário a todo tipo de charlatanismo, Rhazes combateu a importância
excessiva que se dava ao exame das urinas dos pacientes.
Na época, os médicos chegavam ao absurdo de acreditar até que o exame
deste material fosse suficiente para fazer o diagnóstico das doenças, mesmo sem a
presença dos seus clientes.
Avicena ou Abu Ali al-Husayn Ibn Sina, que viveu de 980 a 1037, é
considerado o maior médico árabe da Idade Média. Era extremamente inteligente,
sendo que aos dez anos de idade conhecia todo o Alcorão, o livro sagrado do
islamismo.
Com 18 anos já era considerado um médico experiente e, após curar o
príncipe de Bucara, de uma grave doença, foi recompensado com o acesso irrestrito
à sua biblioteca.
Escreveu uma obra fundamental,
Al Schafa, verdadeira enciclopédia filosófica,
onde procurava conciliar as idéias neoplatônicas com as doutrinas aristotélicas.
Suas concepções políticas tinham conteúdo aristocrático. Os governantes,
segundo Avicena, são os grandes solitários que, pelo seu isolamento, têm melhor
condição de alcançar a razão universal.
Sua principal obra médica, o
Canon, serviu como texto de referência no
mundo ocidental até o século XVII. Avicena também era grande admirador dos
antigos médicos gregos, e seus livros permaneceram fiéis aos seus principais
ensinamentos.
Abdallitif de Bagdá (1161 a 1231) foi o primeiro médico a encontrar erros na
obra de Galeno. Teve a oportunidade de examinar milhares de esqueletos,
especialmente de mortos de fome e de epidemias, então freqüentes no Egito, para
onde foi visitar Maimonides, outro grande médico árabe.
Entre as descobertas de Abdallitif, que o convenceram das vantagens da
investigação pessoal ao invés do conhecimento adquirido por meio dos livros da
época, a de que a mandíbula era um osso único, ao invés de formado por várias
peças, como Galeno apregoava.
Maimonides era um árabe de origem judia, nascido em Córdoba, e que viveu
de 1135 a 1204. Escreveu um tratado,
Guia dos Perplexos, onde tenta conciliar a fé
com a razão, apresentando uma teologia negativa segundo a qual o homem só pode
conhecer a Deus indiretamente, ou seja, por aquilo que Ele não é, tese que exerceu
considerável influência na filosofia cristã medieval.
Estava muitos séculos à frente de seu tempo, tanto em filosofia como na sua
visão da medicina. Acreditava em uma mente sadia em um corpo são, nos poderes
curativos da natureza, nos valores da dieta, repouso, exercícios, e em remédios
simples. Como Moisés, também escreveu sobre higiene.
Os árabes foram os grandes responsáveis pelo desenvolvimento da química,
tendo produzido novos remédios graças aos avanços que alcançaram no campo da
farmacologia e desenvolvimento dos métodos inicialmente utilizados pelos
alquimistas, como a cristalização, sublimação e destilação de substâncias.
Segundo os muçulmanos, os sete corpos celestes que conheciam(Sol, Lua,
Mercúrio, Marte, Vênus, Júpiter e Saturno) correspondiam aos sete dias da semana e
aos sete metais, isto é, ouro, prata, ferro, mercúrio, estanho, chumbo e cobre. Sob a
influência dos planetas, estes metais nasciam na terra a partir de uma substancia
comum, a pedra filosofal.
Os alquimistas tratavam de descobrir o segredo desse fenômeno, para assim
poder converter ferro ou chumbo em ouro. Diziam ainda que beber ouro significava
beber o elixir da vida, que era o segredo da eterna juventude, ou ainda da vida
eterna.
Nicholas Flamel, considerado o mais importante alquimista do século XIV,
investiu grande parte de sua vida na busca das transformações alquímicas que lhe
permitissem vir a encontrar a pedra fiolosofal.
Além disso, era muito interessado em ocultismo. Acreditava na cristalomancia,
ou seja na capacidade de enxergar o futuro por meio da produção de imagens
refletidas em objetos brilhantes.
Outro contemporâneo de Flamel, John Dee, achava que a chave da
transmutação de metais comuns para o desenvolvimento da pedra filosofal poderia
ocorrer por meio de mensagens angelicais obtidas através da cristalomancia.
Finalmente, pode-se afirmar que muitos dedicaram suas vidas e empenharam
suas fortunas na procura da pedra filosofal. Apesar de nunca a terem encontrado,
alguns acabaram descobrindo várias substancias químicas de grande utilidade, ainda
hoje bastante utilizadas.
As primeiras universidades
Apesar de haver uma ou outra faculdade isolada, como as de medicina, em
Montpellier, fundada no século IX; a de Salerno (no sul da Itália), criada no século X,
e a de direito, em Bolonha, criada no século XI, as universidades surgiram nos
séculos XII e XIII, como conseqüência do crescimento e da riqueza das cidades
européias medievais.
A escola de Salerno surgiu ao lado de um hospital fundado pelos beneditinos,
no século VII, ou seja, foi uma conseqüência da medicina monástica.
Bolonha foi a primeira universidade a ser criada, no século XII, sendo que
desde o ano de 1156 já contava com uma faculdade de medicina bem estruturada.
O ensino era eminentemente teórico, o que resultava na formação de poucos
médicos com alguma experiência prática, especialmente quanto à cirurgia. As
primeiras autópsias realizadas em Bolonha ocorreram no final do século XIII. As
seções eram comandadas por um professor, que de cima de sua cátedra (uma
grande estrutura elevada, com degraus e uma mesa de leitura) comandava a aula,
enquanto um colega mais novo,
ostensor, apontava a linha de incisão e um
funcionário subalterno,
demonstrator, executava a dissecação.
Mesmo com a eventual permissão de dissecações por ordem de magistrados,
como em casos de suspeita de envenenamento, somente em 1482 o Papa Sixto IV -
Papa de 1471 a 1484 - emitiu uma bula permitindo a prática em cadáveres humanos.
Em conseqüência, veio a promover o desenvolvimento da anatomia nas
universidades européias, como em Bolonha, Pádua, Paris e Montpellier. Com isto, o
ensino da cirurgia tomou novo impulso nas escolas médicas.
Neste período, as escolas de medicina das cidades italianas eram as de maior
prestígio no mundo e entre os séculos XII e XV foram criadas várias universidades na
França, Alemanha, Inglaterra, Holanda e Escandinávia.
Um dado interessante deste período era o fato de que tanto os professores
como os alunos vinham de vários lugares e países, mas como a língua universal do
mundo culto era o latim, todos se entendiam perfeitamente.
O surgimento da astrologia
Em todas as civilizações, e particularmente entre as mais antigas, os
movimentos do sol, da terra e das estrelas sempre fascinaram a humanidade.
Para os antigos egípcios, um novo sol era criado a cada dia, chegava ao seu
apogeu ao meio-dia e morria no crepúsculo. Em um antigo papiro a terra é
representada como uma figura deitada, coberta de folhas, e o corpo cintilante de
uma deusa celestial espalhando-se sobre ela, carregando dois barcos, um para levar
o sol nascente e outro para levar o sol poente.
Representações da terra como uma grande planície, acima da qual repousava
o firmamento, aparecem em histórias de hindus, gregos e diversos outros povos.
Acima da terra estavam as nuvens, e o brilho das estrelas à noite era proporcionado
pelo paraíso, que ficava além das nuvens.
Esta idéia de uma terra plana com o paraíso por cima perdurou por muitos
séculos, até que Pitágoras sustentou que ela era esférica. A visão que predominava,
no entanto, era de uma terra com diferentes formas geométricas.
Os antigos hindus acreditavam em uma terra hemisférica, sustentada por
quatro elefantes de pé sobre uma imensa tartaruga flutuando em um oceano
universal.
Qualquer que fosse a forma admitida para o nosso planeta, havia uma grande
preocupação a respeito de como ela estava apoiada. Uns achavam que flutuava na
água, outros achavam que possuía raízes, ou que se apoiava em doze pilares, e que
somente por meio de sacrifícios os pilares se manteriam eretos.
Alguns ainda achavam que a terra tinha o formato de um ovo, que flutuava na
água e que era cercada pelo fogo.
Estas idéias exóticas foram abandonadas quando Copérnico e Galileu
demonstraram que a terra é redonda, gira em torno do seu próprio eixo durante o
dia e viaja em torno do sol durante o ano.
Vários povos antigos observaram que diferentes grupos de estrelas, ou
constelações, ficavam perto do sol no alvorecer e no crepúsculo, em diferentes
períodos do ano. Um certo grupo de estrelas poderia estar próximo do nascer do sol
em um mês, e poderia estar acima dele ou mesmo não mais ser visto no mês
seguinte. Assim, uma constelação estava associada com cada mês, e 12 grupos de
estrelas ou constelações formariam o zodíaco.
Os grupos de estrelas bem acima do sol na alvorada e no crepúsculo foram
usados como uma espécie de bússola celestial.
O sol levaria, então, um ano para completar seu ciclo de viagem pelo paraíso.
A divisão do zodíaco em doze signos foi usada por diferentes povos, como os
caldeus, egípcios, hindus, persas, gregos e romanos.
O signo de carneiro é o primeiro na ordem porque é a constelação que
coincide com o equinócio de primavera, onde o tempo de duração dos dias e das
noites é igual.
Fisioterapia
Entre as várias modalidades de fisioterapia, a hidroterapia, e, particularmente,
os banhos em estâncias hidrominerais têm sido utilizados desde os tempos mais
remotos.
Na Grécia antiga, os templos de Asclépio eram construídos próximos a fontes
de água com propriedades de cura.
Os romanos tinham conhecimento das virtudes terapêuticas das águas e
também utilizavam a hidroterapia regularmente.
Na Idade Média, as águas de Montecatini e Karlsbad foram as mais populares.
A terapia baseada na água do mar, que vem desde a Roma antiga, onde era
indicada para casos de tuberculose, leva ainda hoje milhares de banhistas a
freqüentarem várias estações de veraneio existentes no litoral de diversos países.
As massagens eram também muito usadas desde a Antigüidade, e gregos e
romanos davam a elas grande importância como arma terapêutica.
Massagens e movimentação passiva dos membros, especialmente após
fraturas, passaram a ser muito empregadas com o passar do tempo.
Os exercícios de ginástica também têm o seu início desde a Antigüidade. No
século XVIII a ginástica era indicada como uma forma de adquirir domínio da
vontade sobre os movimentos e em oposição à tendência ao relaxamento do corpo.
A termoterapia era usada associada à hidroterapia, e, atualmente, por meio de
raios infravermelhos.
Ameríndios e doenças
Calcula-se que os índios da América sejam descendentes de povos asiáticos,
que teriam atravessado o estreito de Behring há trinta mil anos, e daí se dispersado
por todo o continente.
Apesar de alguns acreditarem que a América pré-colombiana não tenha
estado completamente isolada da Europa até o século XV (há evidências de que os
vikings aqui estiveram por volta do ano 1.000 d.C.), é provável que a sífilis seja uma
doença oriunda do Novo Mundo. Os mais modernos achados de paleopatologia, área
do conhecimento que estuda as doenças através de evidências arqueológicas,
sugerem que a sífilis endêmica acometia populações ameríndias da América do Norte
bem antes da chegada de Colombo, em 1492.
Por ocasião da chegada de Cabral, em 1500, havia em torno de quatro
milhões de índios em nosso território. Cabral não teria sido o primeiro a aqui chegar,
conforme documentos que relatam a passagem de outro navegador português,
Duarte Pacheco, em 1498, que teria desembarcado em um ponto próximo à fronteira
do Maranhão com o Pará, e que depois teria ido até a ilha de Marajó e conhecido a
foz do rio Amazonas. Suas descobertas só não foram divulgadas porque, segundo o
tratado de Tordesilhas, este território pertenceria à Espanha.
Pouco tempo depois da chegada dos portugueses, uma boa parte da
população indígena foi dizimada, principalmente pelas doenças trazidas pelos
homens brancos. Os índios não possuíam imunidade para viroses como o sarampo e
a varíola, de fácil e rápida propagação.
Hoje se explica esta grande susceptibilidade dos nossos índios às novas
doenças trazidas da Europa não como algum tipo de deficiência, mas sim como
conseqüência de as populações ameríndias serem biologicamente muito homogêneas
do ponto de vista genético.
Pelo fato de nunca terem tido contato com estes micróbios, eles não
desenvolveram a imunidade necessária para sua sobrevivência.
A arte de curar dos astecas,maias e incas
Tanto os astecas como os maias - povos que viveram no território hoje
correspondente ao México, Guatemala e Honduras - pouco acrescentaram ao que
hoje conhecemos. Era uma medicina primitiva, com forte conteúdo de misticismo.
Bastante impregnada de magia, mais ligada à feitiçaria e às crendices e pouco
diferente da de outros povos primitivos da América.
O tabaco era considerado como planta capaz de curar várias doenças. Era
usado como fumo, mastigado ou mesmo inalado como rapé.
Os incas, que ocuparam boa parte do território andino, apresentaram um
maior nível de desenvolvimento na área da saúde.
As pessoas com deficiências, as viúvas e idosos eram protegidos pelo Estado,
o que representava um grande avanço em termos de política social.
Pedaços de terra eram reservados para que essas pessoas pudessem ser
mantidas. Além disso, aos deficientes - surdos, mudos, cegos, paralíticos e
portadores de doenças congênitas - eram reservadas funções mais simples e para as
quais estivessem capacitados, como empregos de vigilantes, porteiros e empregados
domésticos.
Dos medicamentos usados pelos incas, entre os principais pode-se citar a
coca e a casca de uma árvore chamada “cinchona”, de onde mais tarde veio a se
extrair o quinino, antimalárico potente, e que até hoje é usado.
Doenças que mais importância tiveram na Idade Média
Lepra
A lepra representou a grande praga da Idade Média, tendo causado mais
pânico e medo do que qualquer outra doença. Na verdade, o termo servia para
enquadrar uma série de patologias com repercussão na pele, e que ia desde doenças
não infecciosas, como eczemas e psoríase, até varíola ou mesmo sífilis na sua fase
secundária.
Com o retorno dos cruzados às suas cidades de origem, muitos traziam
doenças, e a lepra, sendo endêmica entre a população pobre, alcançou proporções
epidêmicas nos séculos XIII e XIV.
O paciente leproso era totalmente discriminado, considerado impuro, sendo
obrigado a ficar em total ostracismo, e antes mesmo de sua morte ocorrer, a
sociedade o tinha como morto e destituído de todos os direitos civis. Quando
andava, carregava uma matraca para avisar aos demais de sua chegada, a fim de
preveni-los de qualquer contágio.
A Igreja Católica assumiu o encargo de combater a lepra para facilitar o
isolamento dos doentes, tendo criado vários leprosários desde o século VI. Eles
eram chamados de lazaretos porque, inicialmente, os doentes eram internados nos
mosteiros de S. Lázaro, em memória ao famoso leproso da Bíblia.
Somente na França, no início do século XIII, existiam dois mil lazaretos.
A peste negra
Duas pandemias de peste bubônica atingiram o mundo na Idade Média. A
primeira no reinado de Justiniano, do Império Romano do Oriente, em 542 e 543, e a
segunda que atingiu praticamente toda a Europa em 1347 e 1348, considerada a que
mais mortes causou em todos os tempos. Nela, a metade da população de Londres
morreu. Navios sem tripulantes vagavam pelo Mar do Norte e o Mediterrâneo,
espalhando a infecção quando chegavam às praias.
Em
Decameron, em 1353, Boccaccio assim descreveu as dantescas cenas que
presenciou: “A condição das pessoas era lamentável de se descrever. Elas adoeciam
aos milhares diariamente e morriam sem terem sido atendidas ou socorridas. Muitas
morriam nas ruas; outras morriam em suas casas, e só se ficava sabendo disto pelo
mau cheiro que exalavam de seus corpos em decomposição. Não havendo mais lugar
nos cemitérios para enterrar tantos corpos, eles eram empilhados às centenas em
grandes valas, como mercadorias de navio, e em seguida cobertos com um pouco de
terra”.
A provável origem desta última pandemia pode estar ligada a roedores
selvagens da Ásia Central, onde há um reservatório desta enfermidade, ou a
presença de animais silvestres portadores do agente da peste. Daí a doença foi para
a Itália e a França, e para a Alemanha, alcançando depois a Rússia. Os navios
tiveram grande importância para levar a doença para vários países, fazendo com que
a enfermidade se propagasse rapidamente.
Várias teorias estranhas foram criadas para explicar esta epidemia. Alguns a
justificavam pela conjunção dos planetas Saturno, Júpiter e Marte no dia 24 de
março de 1345, o que seria o prenúncio natural de que uma catástrofe viria a
ocorrer. Outros diziam que os poços haviam sido envenenados pelos judeus e pelos
leprosos, o que levou muita gente inocente a ser perseguida e até morta na fogueira,
acusada de bruxaria.
Por ser uma doença bacteriana transmitida através da pulga dos ratos, requer
que as condições higiênicas sejam precárias para o seu desenvolvimento. Os
aglomerados humanos que eram as cidades da Idade Média, além da falta de higiene
generalizada, favoreciam plenamente o surgimento destas infecções.
O isolamento dos doentes foi uma das raras alternativas tentadas para o
controle da doença. Se em uma casa houvesse uma pessoa acometida,
imediatamente as autoridades eram notificadas. Depois de examinados, e constatada
a infecção, os pacientes eram mantidos em suas casas e obrigados ao isolamento
todos os que tivessem tido contato com o doente. Por meio de mensageiros, os
familiares passavam a receber o que necessitavam para sobreviver.
O período de isolamento dos doentes e dos seus contatos, que no início era de
14 dias, chegou a ser de 40 dias em Veneza e em outras cidades européias. O termo
quarentena vem deste período de isolamento mais prolongado.
A morte negra do mar
Com as grandes navegações, iniciadas no final do século XV e início do século
XVI, surgiu uma nova doença que levava os marinheiros à morte por hemorragia.
Nas longas viagens, que levavam meses, o escorbuto era uma doença freqüente e
aterrorizante. Ele já havia provocado devastações, anteriormente, em cidades
sitiadas, quando se cortava o suprimento de provisões.
Na viagem em que descobriu o caminho marítimo para as Índias, em 1498,
Vasco da Gama perdeu cinqüenta e cinco marinheiros devido à doença.
Por mais de cem anos o escorbuto levou muitos marinheiros à morte.
Em 1601, no entanto, foi feita uma interessante experiência com uma
esquadra inglesa comandada por James Lancaster. Cinco navios partiram da
Inglaterra com destino à Índia. Nesta viagem foram administrados, todos os dias,
três colheres de chá de limão aos homens que serviam no maior dos navios. Quando
a esquadra atingiu o cabo da Boa Esperança, havia já um grande número de
marinheiros com escorbuto nos outros quatro navios menores e que não haviam
recebido suco de limão. No navio maior não houve casos da doença. Apesar dos
resultados bastante evidentes, esta experiência não foi devidamente considerada na
época.
Somente em 1795 o almirantado inglês ordenou que durante as viagens
transoceânicas todos os marinheiros recebessem uma provisão diária de suco de
limão, o que lhes dava um adequado aporte de vitamina C, como se sabe
atualmente.
Outras doenças medievais
Algumas doenças eram conhecidas na Idade Média com denominações que
não mais existem. Outras eram conhecidas por mais de um nome ou expressão e
representariam hoje não uma, mas sim um conjunto de doenças, tais como:
1. “Doença de São Valentim” ou “mal caduco” – equivaleria a epilepsia.
2. “Penitência de São Quirino” ou “Vingança de São João” – equivaleria a tumores,
varizes e furúnculos.
3. “Fogo de Santo Antonio” – poderia ser hoje a erisipela, a gangrena e até mesmo
a cólera.29
4. “Baile de São Vito” – doença surgida em 1374, quando muitas pessoas
começaram a dançar como neuróticos possessos. Suspeita-se que possa ter sido
um quadro de histeria coletiva. Há autores que também atribuem a esta doença
causas neurológicas, como corea e Parkinson.
29 Segundo Sournia, o que teria ocorrido foi uma intoxicação por um cogumelo parasita do centeio(ergotismo), que atingindo
pequenas artérias dos membros provocaria dor e ardor consideráveis, seguidos de amputações espontâneas.
A arte empírica de curar
A medicina consiste em pôr medicamentos que não se conhecem em um corpo que
se conhece menos ainda. Voltaire
As novas idéias filosóficas (séculos XVI e XVII)
No famoso mito da caverna30, Platão compara os homens a prisioneiros
guardados sob ferros, onde podem somente olhar para uma única direção. Com uma
fogueira às suas costas, considera suas sombras como parte do mundo real. Quando
um dos prisioneiros escapa, e saindo encontra a luz do sol, conhece a verdade e
percebe que até então fora ludibriado pela própria imaginação, e reflete com tristeza
sobre sua longa vida em meio à escuridão. Reconhece, ainda, que ao escapar da
caverna e de suas trevas alcança a luz da verdade e da consciência. Passa então a
ser um filósofo, pois é ele quem possui o conhecimento real das coisas.
Após o longo período de trevas da Idade Média três filósofos foram
particularmente importantes para incentivar o pensamento científico: Francis Bacon,
René Descartes e John Locke. Entretanto, outros pensadores foram também
essenciais para o desenvolvimento de uma filosofia da ciência moderna, como foi o
caso de Hobbes, Hume, Pascal, Spinoza, Berkeley e Leibniz.
Bacon, advogado, membro do Parlamento, criador da frase “Saber é poder”,
teve no livro
A promoção do saber a sua obra mais importante.
Todo o fundamento de sua filosofia era prático: por meio de descobertas e
invenções científicas a humanidade poderia dominar as forças da natureza e, a partir
daí, vir a ter uma vida melhor. Isto vinha em oposição aos gregos, para os quais a
ciência era uma tarefa essencialmente especulativa e de menor importância.
Foi o primeiro filósofo a ressaltar o valor do método indutivo, através do qual
pode-se partir da experiência particular para as generalizações e leis. Foi ainda
pioneiro em dar ao procedimento científico uma sistematização lógica.
Recomendava a anotação de todos os fatos conhecidos, e que todas as novas
observações e os resultados de novos experimentos fossem tabulados, para que a
conexão entre os fenômenos e suas resultantes leis gerais pudesse se manifestar
mais facilmente.
René Descartes, considerado o fundador da filosofia moderna, é o autor da
frase “Penso, logo existo”, primeiro princípio da sua filosofia. O conhecimento de
nossos próprios pensamentos é o único fato absolutamente verdadeiro. Este princípio
enfraquece o que percebemos pelos sentidos quando comparado com o que
captamos pelo raciocínio.
Teve como obras mais importantes o
Discurso sobre o método e as
Meditações. Sua filosofia se baseia na dúvida metódica, ou em um ceticismo
metódico que poderia ser assim apresentado:
- Jamais aceitar como verdade senão aquilo que percebo como tal.
30 República, de Platão.
- Dividir cada uma das dificuldades em quantas partes quanto possíveis e
quantas necessárias para resolvê-las.
- Conduzir por ordem meus pensamentos, a começar pelos objetos mais
simples e mais fáceis de serem conhecidos, para galgar, pouco a pouco,
até o conhecimento dos mais complexos.
- Fazer em toda parte enumerações tão completas e revisões tão gerais que
tivesse a certeza de nada ter omitido.
Em seu livro
La Géometrie, deu considerável contribuição à evolução da
Matemática, sendo a ele atribuída a notação que utilizamos para as equações, como
letras minúsculas do fim do alfabeto (x,y,z) para quantidades desconhecidas e letras
minúsculas do início do alfabeto (a,b,c) para quantidades conhecidas, assim como
expoentes sobre uma variável para indicar potências.
Com o
Discurso sobre o Método, inaugura a epistemologia, dizendo que a
razão ou o senso comum, orientado pelo método, seria suficiente para o acesso à
verdade, não sendo mais privilégio de poucos eleitos.
Com a criação do método científico31, e em decorrência, com a criação das
ferramentas analíticas, a ciência e o conhecimento passam a ser democratizados e
acessíveis a um maior número de pessoas.
Apesar de Descartes ter proposto que corpo e mente atuam de forma
separada, como uma inferência da sua famosa frase “penso, logo existo”, e que
ainda como conseqüência disso haveria uma hierarquização entre a razão (ligada ao
cérebro) e as emoções (ligadas à alma), estudos de neuroanatomia, neurofisiologia e
neuropsicologia têm demonstrado que corpo e mente estão intimamente ligados, e
que as emoções e a racionalidade estão igualmente relacionadas ao desenvolvimento
da nossa estrutura de pensamento, e de como conseguimos lidar com as questões
que afetam o nosso cotidiano. Sem as emoções a razão não se desenvolve de
maneira adequada, e também sem a razão as emoções podem atuar de forma
contrária ao interesse social.
John Locke, um dos pioneiros do liberalismo filosófico, teve como uma de suas
características marcantes a falta de dogmatismo. Segundo ele, a verdade é difícil de
ser averiguada e um homem prudente sempre defenderá suas opiniões com uma
certa medida de dúvida, o que é reflexo da influência que as idéias de Descartes
tiveram sobre ele. Sua obra fundamental,
An essay concerning human
understanding, publicada em 1690, trata de forma sistemática as questões da
origem, essência e certeza do conhecimento humano.
O amor à verdade, segundo Locke, é uma coisa muito diferente do amor a
uma doutrina particular proclamada como a verdade. O entusiasmo, esquecido da
razão, coloca as fantasias, em lugar da razão, no cérebro de um homem.
Locke é considerado o fundador do empirismo, doutrina segundo a qual todo
o nosso conhecimento deriva da experiência, à exceção da lógica e da matemática.
Condenava o absolutismo de todas as formas, sendo considerado o pai da
teoria política liberal dos séculos XVII e XVIII. Acreditava que, se os homens nasciam
31 Conjunto de concepções sobre o homem, a natureza e o próprio conhecimento que
permitem o desenvolvimento de ferramentas que levam à contínua construção do
conhecimento científico.
iguais, deviam ter direitos iguais, assim como os necessários à sua sobrevivência, a
exemplo do direito ao trabalho e à propriedade.
Tanto Bacon, como Descartes e Locke eram contra a escolástica, doutrina
fortemente influenciada pela Igreja, que manteve assim a filosofia refém da teologia
durante toda a Idade Média, sendo seus principais pensadores Santo Agostinho e
São Tomás de Aquino.
Os filósofos desse período contribuíram de forma significativa para construir o
iluminismo, que deslocou o centro do interesse e das preocupações com o destino da
alma, no outro mundo, em direção à melhoria das condições de vida no mundo em
que vivemos.
A partir das idéias do iluminismo houve uma revisão do estado autoritário, nos
países onde exerceu maior influência, como na Inglaterra, França e na colônia
inglesa de onde surgiram os Estados Unidos da América.
A Renascença
O que caracteriza o período da história posterior à Idade Média é a
decrescente autoridade da Igreja e a crescente autoridade da ciência.
Esta menor influência da Igreja teve a contribuição de Martinho Lutero (1483
a 1546) e de Calvino (1509 a 1564), que criaram uma nova religião, o
protestantismo, logo disseminado por vários países europeus.
Outro fato marcante foi a criação do tipo móvel de impressão por Gutenberg,
que imprimiu o primeiro livro, uma Bíblia, por volta de 1455. Com isto, a difusão do
conhecimento foi grandemente expandida, e mais pessoas puderam ter acesso às
informações.
No início da Renascença italiana, a ciência ainda desempenha um papel
limitado, desde que a oposição à Igreja estava voltada para os valores da cultura
greco-romana clássica. Somente a partir de Copérnico, com a publicação de seu livro
Sobre as revoluções das esferas celestes, em 1543, a ciência começa realmente a
produzir mudanças profundas na sociedade européia.
Nascido em Pisa, em 1564, filho de um nobre culto, mas empobrecido
chamado Vincenzio Galilei, que queria torná-lo mercador, Galileu Galilei começou a
estudar medicina aos 17 anos, curso que não concluiu. Seu maior interesse eram as
investigações e estudos matemáticos.
Em 1589 foi convidado para lecionar a disciplina na Universidade de Pisa e,
três anos depois, na Universidade de Pádua, onde ensinou por 18 anos.
Teve o mérito de introduzir o racionalismo matemático como base do
pensamento científico, além de ter feito várias pesquisas no campo da Mecânica e
que depois viriam a ser usadas por Newton.
Aperfeiçoou o telescópio32, e por meio dele desenvolveu vários estudos
astronômicos. Em 1609 já havia conseguido desenvolver um aparelho com aumento
de 30 vezes, o que lhe permitiu desenvolver grandes avanços na ciência.
Descreveu a irregularidade da superfície lunar, descobriu mais de 500 estrelas
nunca vistas antes, observou que a Via Láctea era formada por grande número de
estrelas, descobriu os quatro satélites de Júpiter e também as manchas solares.
Publicou vários livros, entre eles um de apoio à teoria heliocêntrica de
Copérnico.
Suas obras se tornaram mais perigosas porque as publicava em italiano33, ao
invés do latim, como era habitual à época.
Contrariou a teoria geocêntrica que, segundo ele, era baseada apenas nas
alegorias existentes nas Escrituras. Com isto, foi perseguido pela Santa Inquisição,
tendo no final da vida de se retratar para escapar da fogueira.
Na sentença, publicada em 1633, foi declarado suspeito de heresia, obrigado a
abjurar a doutrina de Copérnico e condenado à prisão domiciliar até morrer, em
1642.
Galileu foi importante ainda pelo livro
Il Saggiatore (O Ensaiador), publicado
em 1623, onde escreve como verdadeiro filósofo da ciência. Nele diz que para a
filosofia se tornar Ciência deve se livrar do domínio da autoridade, ou seja, faz a
defesa da liberdade de pensamento e ainda que a Filosofia verdadeira deva se
basear fundamentalmente na observação, raciocínio e na Matemática.
Ao longo do tempo, a espécie humana foi se deslocando do centro para a
periferia do universo. Hoje, quando sabemos que fazemos parte de apenas uma
galáxia - com trezentos bilhões de estrelas no seu interior –, em meio a bilhões de
outras existentes no universo, é que nos damos conta da real importância dos seres
humanos, o que contraria de forma significativa a concepção inicial, quando
predominavam as idéias de Ptolomeu.
Nas artes, são expoentes da Renascença os italianos Michelangelo (1475 a
1564), Leonardo da Vinci (1452 a 1519) e Raphaello (1483 a1521), os quais
chegaram a dissecar dezenas de cadáveres para melhor conhecer a anatomia
humana e assim aperfeiçoar a sua técnica, criando obras de extraordinária beleza.
Além deles, foram também muito importantes os venezianos Ticiano, Tintoretto e
Veronese.
Giorgio Vasari (1511 a 1574), notável crítico e historiador da arte, além de
arquiteto e pintor, publicou em 1550 o livro
As vidas dos melhores pintores,
escultores e arquitetos, onde cita o florentino Antonio Pollaiuolo(1432 a 1498) como
um dos primeiros artistas a fazer dissecações do corpo humano. Seu trabalho mais
importante foi a pintura “O Martírio de S. Sebastião”, onde são demonstrados
claramente os resultados dessa pesquisa anatômica.
Nas artes, a Renascença recebeu o nome de naturalismo.
Leonardo da Vinci deixou considerável acervo de obras com estudos
anatômicos. É, ainda hoje, tido como um dos maiores anatomistas de todos os
32 O inventor do telescópio foi o holandês Hans Lippershey, em 1608.
33 Como no Dialogo sopra i due massimi sistemi dei mondo – tolemaico e copernicano, onde
justifica seu apoio à teoria de Copérnico.
tempos. No livro escrito sobre Leonardo, White34 apresenta vários desenhos do
artista, como estudos dos músculos das mãos e do rosto, do braço e do ombro, do
cérebro, do olho, etc.
Filho ilegítimo de um tabelião chamado Ser Piero, com uma camponesa de
nome Caterina, Leonardo nasceu em uma pequena cidade da Toscana chamada
Vinci, e desde cedo apresentou uma notável abundância de talentos, o que o levou a
tratar com certa leviandade seu potencial artístico.
Raras vezes concluía uma pintura, além de ser dado a experiências técnicas
arrojadas. Dizia que o primeiro objetivo de um pintor era fazer uma superfície plana
parecer um corpo em relevo que se projeta dessa mesma superfície.
É o autor do quadro que é considerado o mais famoso e valioso de todos os
tempos, a Mona Lisa ou La Gioconda, como é mais conhecida na Itália. A obra,
atualmente exposta no museu do Louvre, em Paris, procura retratar a terceira
esposa do rico comerciante toscano Francesco del Giocondo, chamada Lisa di
Gherardini e que na época teria cerca de 25 anos. Leonardo levou três anos para
concluí-la (1503 a 1506).
Outros quadros famosos de Leonardo são Baco (1513), São João Batista
(1508 a 1513), A Virgem e o Menino com Sant’Ana (1508 a 1510), a Dama com um
Arminho (1488 a 1490), a Ginevra de Benci (1475) e La Belle Ferronière (1495 a
1499).
Em todos pode-se encontrar a técnica apurada de Leonardo, como o
movimento interno conhecido como
contrapposto (modelo sentado numa posição
enquanto o rosto olha para uma direção diferente) , o jogo de sombras, a aparência
algo encoberta, como se envolvida em névoa e uma certa sugestão de androginia.
A Renascença representa uma época de renovação no domínio das artes e
das ciências, sendo que o espírito de liberdade e crítica passa a se opor ao princípio
da autoridade que era a regra até então.
Andreas Vesalius (O reformador da anatomia)
Filho de uma família de médicos, Vesalius nasceu em 1514, em Bruxelas.
Estudou medicina em Paris, e depois se estabeleceu em Pádua, onde ao final de
1537 foi nomeado professor. As obras dos naturalistas italianos tiveram enorme
influência no desenvolvimento do seu trabalho.
No ano de 1543, então com 28 anos de idade, publicou o monumental tratado
de anatomia
De Humanis corporis fabrica (sobre a construção do corpo humano),
constituído de sete volumes e setecentas páginas, com ilustrações coloridas à mão.
Foi o primeiro texto compreensivo sobre o tema e que rompe com a tradição,
demonstrando que Galeno estava errado em vários aspectos, como quanto à
estrutura do coração, o trajeto das veias, o osso esterno, o fígado, o ducto biliar, o
útero e outros aspectos da anatomia. Os estudos do médico grego foram feitos em
animais, enquanto Vesalius tinha escrito seu livro sobre conhecimentos adquiridos
através da dissecação de cadáveres humanos.
Vesalius foi um homem extremamente culto, tendo traduzido várias obras dos
clássicos gregos, árabes e hebraicos.
34 Em Leonardo, o primeiro cientista.
Como contradizer Galeno era uma heresia, foi muito criticado pelos seus
contemporâneos. Apesar de ser professor das cadeiras de medicina e anatomia em
Pádua, acabou por se aborrecer com tantas e tão infundadas críticas que resolveu
abandonar a cátedra e aceitou o convite para servir como médico do imperador
Carlos V, e depois de Filipe II, da Espanha.
Anos mais tarde teve reconhecido o seu mérito e, a partir de então, passou a
ser considerado como realmente merecia, ou seja, como um dos médicos mais
notáveis da história.
Em seu trabalho, demonstrou ainda ter sido um erro separar a cirurgia da
medicina.
Consta que teria sido condenado à morte pela Inquisição, por ter dissecado
um nobre enquanto ainda vivo. Vesalius teria se equivocado, e só tarde demais
percebera que o coração ainda batia. Por interferência de Felipe II, sua sentença
teria sido substituída por uma peregrinação à Jerusalém.
Após a ida a Terra Santa, em 1564, o navio em que viajava afundou na ilha de
Zante, Grécia, onde acabou morrendo de fome após caminhar por três dias por um
terreno deserto.
Os anfiteatros anatômicos
A curiosidade pública em relação às dissecações cresceu extraordinariamente
no século XVI. O público era convidado como se fosse assistir a uma peça teatral, e
eram feitos convites solenes para as pessoas influentes.
Em algumas cidades foram construídos anfiteatros anatômicos, como em
Pádua, em 1545, e em Leipzig, em 1580.
Girolamo Fracastoro (Criador da teoria do contágio)
A palavra sífilis foi criada por Fracastoro, em um célebre poema intitulado
Syphilis Sive Gallicus Morbus, ou Sífilis, o mal francês. Esta obra procurava atribuir o
surgimento da doença aos franceses, enquanto estes a atribuíam aos italianos.
Publicado em 1530, este longo poema descrevia a história de um pastor de
ovelhas, chamado Syphilis, que por render honras divinas a seu rei, ofende Júpiter. A
divindade manda à terra Apolo, que pune o pastor inflingindo-lhe o castigo de uma
nova doença, para a qual não existe cura conhecida.
Fracastoro foi professor da Universidade de Pádua, viveu de 1483 a 1553, e
alguns dizem que seu interesse pela sífilis era conseqüência de também ser portador
da doença.
A sífilis foi detectada pela primeira vez em Barcelona, cidade para onde
retornaram os marinheiros de Colombo, após a descoberta da América. Hoje se sabe
que a doença é oriunda do Novo Mundo.
A Europa possuía condições muito propícias para o desenvolvimento desta
nova pandemia. Somente em Veneza, com uma população de 300 mil pessoas, havia
12 mil prostitutas.
Em 1546 Fracastoro publica sua obra mais importante,
De contagione et
contagiosis morbis, onde formula teorias que, de forma surpreendente, se
aproximam bastante da moderna teoria dos germes causadores de infecções. Isto,
em uma época em que ainda não havia conhecimento dos micróbios, pode ser
considerado como bastante significativo.
Fracastoro distinguia três tipos de contágio: um direto de pessoa a pessoa;
um segundo, através de objetos ou roupas contaminadas pelo doente; e um terceiro,
que seria transmitido pelo ar. Ele dizia que os veículos destas doenças teriam o
poder de rapidamente a reproduzirem. Suas teorias só vieram a ser confirmadas
séculos depois, com Pasteur e Koch.
Paracelso (Gênio ou charlatão?)
“A medicina não é apenas uma ciência, mas também uma arte. Ela não
consiste em compor pílulas, emplastros e drogas de todas as espécies, trata, ao
contrário, dos processos da vida, que devem ser compreendidos antes de serem
orientados. Uma vontade poderosa pode curar, em um caso em que a hesitação, ou
a dúvida, pode desembocar em fracasso. O caráter do médico pode atuar mais
poderosamente sobre o enfermo do que todas as drogas empregadas.”, disse
Phillippus Teophrastus von Hohenheim, mais conhecido por Paracelso, nome como
quis ser chamado por sua oposição a Celso e a outros médicos da Antigüidade.
Nascido na Suíça, em 1493, Paracelso foi um dos estudiosos mais
controvertidos de toda a história. Seu interesse variava desde as ciências ocultas,
magia, astrologia e alquimia, até a ciência natural.
Viajou por diversos lugares, tendo estudado em Viena, Colônia, Paris e
Montpellier. Viveu ainda na península ibérica, Pomerania, Polônia, Lituânia e Rússia.
Sobre sua vida e obra foi escrita mais de uma dezena de livros, em diversos
idiomas.
Devido às curas feitas em personalidades importantes da época, como Erasmo
de Rotterdam, foi convidado a lecionar na universidade da Basiléia, a mais antiga da
Suíça.
Lá, escandalizou a todos fazendo a sua primeira conferência em alemão, ao
invés do latim tradicional, além de ter criticado de forma violenta os trabalhos de
Galeno e Avicena, chegando ainda a queimar algumas de suas obras em público.
Suas opiniões, que atacavam profundamente as bases da medicina antiga,
além da violência e impetuosidade de sua personalidade produziram tantos inimigos
que sua permanência na universidade se tornou impossível.
Após dois anos, Paracelso teve de abandonar Basiléia e retornar à sua vida de
médico errante.
Com ele, os remédios feitos com substâncias químicas foram introduzidos na
medicina e a farmacologia começou a fazer uso de diversos novos produtos.
Dizia que todas as medicinas se apoiavam em quatro pilares básicos: filosofia,
astrologia, alquimia e virtude.
Uma importante contribuição de Paracelso, que não teve a repercussão
adequada na época, foi sua percepção do poder do éter como anestésico. Verificou
que, ao acrescentar a substância à ração de aves domésticas, no intuito de tornar a
ração mais doce, elas caíam em sono profundo e mais tarde acordavam sem
apresentar nenhum dano. Somente no século XIX o éter passou a ser empregado
como anestésico em cirurgias.
Paracelso acreditava que a matéria era feita de enxofre, mercúrio e sal, mas
isto em sentido simbólico. Ele acreditava no sal como um elemento indestrutível pelo
fogo; no mercúrio, um fluido que era vaporizado, mas não destruído pelo fogo; e no
enxofre, tanto modificado como destruído pelo fogo. Estes princípios estavam
contidos no “grande mistério”, a partir do qual os quatro elementos principais da vida
surgiram: água, fogo, terra e ar.
Seu interesse em ocultismo pode ser avaliado pelo texto seguinte: ”Se minha
vontade se encher de ódio contra alguém, precisará expressar este sentimento de
alguma maneira. E isto será feito justamente através do corpo. Sem dúvida, se
minha vontade for demasiadamente violenta ou ardente, pode acontecer que meu
desejo chegue a perfurar e ferir o espírito da pessoa odiada. E também posso
encerrá-lo à força numa imagem que eu consiga fazer dela, deformando-a e
distorcendo-a a meu gosto, atingindo assim também a intenção de atormentar meu
inimigo"
No entanto, ele alertava: “Por outro lado, todo aquele que permanece
impregnado de ódio, nunca querendo o bem, pode atrair para si todo o mal desejado
aos outros. Porque existindo o feitiço maléfico somente com a permissão do espírito,
pode acontecer que as imagens do malefício se transformem em doenças, tais como
as febres, epilepsias, apoplexias e outras. Por isto, é bom não zombar destas coisas.”
Dizia ainda que “o progresso só pode se apoiar na experimentação, e nas
conclusões que desta se puderem deduzir”.
Paracelso morreu em 1541, provavelmente de câncer, em Salzburgo.
Após a sua morte continuou tendo vários seguidores, especialmente na
Inglaterra e na Alemanha, sendo que a maioria dessas pessoas pertencia à seita dos
rosacruzes, que até hoje existe.
Jean Fernel(Continuador da obra de Vesalius)
Considerado um dos grandes anatomistas do século XVI, viveu de 1497 a
1558. Foi médico do rei Henrique II, e tinha paixão pela Astronomia. Foi professor
de medicina em Paris, e contribuiu para a correção de alguns conceitos de Galeno.
Escreveu
A Medicina Universal, dividido em fisiologia, patologia e terapêutica.
Foi o primeiro que descreveu o quadro da apendicite e que sugeriu a origem sifilítica
dos aneurismas da artéria aorta. Também foi pioneiro em acreditar que a gonorréia e
a sífilis eram doenças distintas.
Opunha-se à astrologia, ao contrário da maioria dos médicos de sua época.
De natureza melancólica, Fernel morreu pouco tempo após o falecimento de
sua esposa.
Ambroise Paré (O patrono da medicina militar)
Paré, como médico militar, (1510-1590) acompanhou uma grande força
expedicionária que o rei Francisco I, da França, havia enviado até à Itália, no intuito
de conquistar Turim.
Houve então várias batalhas, com muitos feridos de todos os tipos de armas,
mas, principalmente, por armas de fogo. Naquela época se acreditava que as feridas
causadas por estas armas eram venenosas, devido à pólvora, e que o melhor
tratamento para isto era a cauterização com óleo fervente.
Esta prática provocava dores e grandes sofrimentos aos soldados. Paré a usou
até que, certa noite, o óleo acabou e ele foi obrigado a substituir por uma mistura de
água de rosas, gema de ovo e terebintina.
Ficou surpreso quando, ao despertar, verificou que os pacientes tratados com
a mistura estavam passando muito bem, quase sem dor, enquanto os tratados com
óleo fervente, além de apresentarem sinais de inflamação nas suas feridas, se
queixavam de fortes dores. A partir daí, Paré decidiu não mais tratar seus pacientes
da forma cruel como era habitual até então.
Paré, filho de um cirurgião-barbeiro, começou sua prática com o pai. Essa
categoria profissional, inferior à dos cirurgiões formados em universidades, tinha
como funções o tratamento de feridas, a cauterização, a punção de abscessos, além
de fazer a barba de seus clientes. Também faziam sangrias.
Apesar de desconhecer os idiomas da ciência formal da época, ou o grego e o
latim, Paré veio a se tornar o maior cirurgião da França, tendo sido médico de quatro
reis de seu país ( Henrique II, Francisco II, Carlos IX e Henrique III). Foi o introdutor
da técnica de ligadura das artérias para o controle das hemorragias, abandonando
também, neste caso, o uso do calor para estancar as hemorragias. Também
reintroduziu a correção cirúrgica para lábio leporino, que estava esquecida desde os
árabes. Aboliu a castração para o tratamento rotineiro das hérnias masculinas.
Em 1561 publicou a obra
Cirurgia Universal, onde apresentava novas técnicas
cirúrgicas e instrumentos que havia desenvolvido ao longo de sua prática
profissional.
Um dia, após ter curado um oficial gravemente ferido em uma batalha, Paré,
com humildade, disse: “Eu o tratei e Deus o curou”.
Johann Weyer (Fundador da Psiquiatria Moderna)
Em 1231 o papa Gregório IX determinou à ordem dominicana o encargo de
perseguir e eliminar os hereges por meio da Inquisição. Foram instaladas seções
permanentes em todos os países católicos, sendo a tortura seu principal meio de
investigação.
Durante o século XVI, com a crescente independência das instituições de nível
superior do controle pelas autoridades, a astrologia até então apoiada fortemente
pelos médicos passa a não ser mais tão considerada.
No entanto, em outros segmentos da sociedade, a crença em feiticeiras e no
seu poder, chega ao seu mais elevado grau.
Desta forma, e ainda vendo-se mais ameaçada pelo surgimento do
protestantismo, a Igreja publica, em 1485, um livro denominado
Malleus Maleficarum
(Martelo das Bruxas), feito por dois inquisidores dominicanos, reconhecendo as
feiticeiras como suas inimigas, e detalhando as etapas por que as pessoas suspeitas
deveriam passar: prisão, interrogatório, tortura e execução.
O alvo principal do livro eram as mulheres, definidas como seres inferiores e
impuros por natureza, sendo considerados pelos autores verdadeiros instrumentos
do demônio.
Pelo fato de acreditarem que as bruxas eram cúmplices do diabo, os
inquisidores as condenavam à morte na fogueira.
Em 1563, o médico alemão Johann Weyer publicou um livro,
De Praestigiis
Daemonius (Sobre Bruxarias), onde sustenta que essas pessoas tão perseguidas
eram, na verdade, pobres cidadãs ignorantes, que haviam perdido o controle
emocional, e suas mentes haviam se deteriorado. Isto, em uma época de tantas e
tão freqüentes perturbações e calamidades, era um fenômeno compreensível de
ocorrer.
Weyer acreditava que as confissões obtidas por meio de tortura constituíam
um terrível engano. Negava a possibilidade da transformação de homens em animais
e a de que as bruxas pudessem voar em cabos de vassoura, como era a crença da
época.
Dizia, ainda, que pesadelos e possessões eram devidos a angústias,
apreensões ou sugestão. Poções mágicas, feitiçaria e crenças poderiam levar
algumas pessoas à insanidade, mas nunca a conseguirem realizar as finalidades
mágicas desejadas. As artes diabólicas e seus fantasmas não deveriam amedrontar
ninguém.
Seu livro fez grande sucesso, apesar do grande risco que correu ao divulgar
estas opiniões, e certamente contribuiu para melhorar a mentalidade de muitas
pessoas que viveram no seu tempo.
Infelizmente, no entanto, a caça às bruxas continuou ainda sendo bastante
utilizada, com seu apogeu ocorrendo durante os anos 1600, décadas depois da
publicação do livro de Weyer.
Fabrizio de Acquapendente (Descobridor das válvulas das veias)
Discípulo de Gabriel Fallopio - descobridor das trompas do aparelho genital
feminino -, Fabrizio (1537 a 1619) sucedeu ao seu mestre como professor de cirurgia
da universidade de Pádua, aos 28 anos de idade. Tinha uma grande paixão pela
anatomia, tendo compreendido que somente por meio do domínio desta matéria o
cirurgião poderia operar com sucesso. Em 1603 publicou sua obra mais importante,
De Venarum Ostiolis, onde descreveu, pela primeira vez, as válvulas das veias. Este
achado demonstrou que o sangue só circula em um sentido, ou no sentido do
coração. Esta descoberta foi fundamental para que um de seus alunos, o inglês
William Harvey, viesse após alguns anos a descrever a circulação do sangue.
Fabrizio morreu em 1619, envenenado por adversários invejosos do seu
grande sucesso profissional, já que ao longo de sua vida recebeu provas de
reconhecimento pelo muito que fez pelo desenvolvimento da ciência.
As transformações européias
Com o descobrimento da América por Colombo, e das novas rotas comerciais
do Atlântico e do Índico, houve uma substancial diminuição da importância
econômica dos portos da Itália.
O poder das cidades de Veneza e Genova começou a declinar, ao mesmo
tempo em que o território italiano sofreu seguidas devastações pela invasão de
soldados da França, Alemanha e Espanha, além da rivalidade entre as cidades
italianas ter sido relevante para aumentar o seu desgaste. Em conseqüência, o
conhecimento médico foi interrompido em seu processo de rápido crescimento
naquela região da Europa.
Na Alemanha, além de sangrentas disputas religiosas, a guerra dos 30 anos
contribuiu para interromper um processo de desenvolvimento que parecia ser
extremamente favorável ao povo alemão.
Neste mesmo período, a Inglaterra e a Holanda alcançaram o apogeu de seu
poder marítimo, tendo como conseqüência reflexos na sua atividade comercial, o que
lhes trouxe grande riqueza material.
Na Inglaterra isto se refletiu no florescimento das artes, como no teatro de
Shakespeare, assim como das ciências, em Newton, e na medicina, em Harvey. Na
Holanda houve o surgimento de pintores como Rembrandt e de cientistas como
Leewenhoek .
A Mecânica newtoniana
Isaac Newton nasceu em Woolsthorpe, Inglaterra, em 25 de dezembro de
1642, filho de um pequeno fazendeiro que faleceu alguns meses antes do
nascimento do filho.
Em 1646 sua mãe, Hannah, casou novamente e Newton foi então morar com
a avó materna.
Em 1653, quando sua mãe tornou-se viúva pela segunda vez, Newton foi
frequentar a escola de Grantham, onde aprendeu Latim, o que veio a lhe ser útil em
sua carreira de cientista.
Após concluir o curso secundário, em 1661, foi para o Trinity College, em
Cambridge.
Em 1665 obteve o grau de bacharel em Humanidades, tendo sido autodidata
em Matemática por essa disciplina não constar do currículo de sua faculdade.
Ao mesmo tempo em que se interessava por ciência, Newton também
cultivava um lado místico, dedicando muito do seu tempo a estudos sobre Alquimia e
Teologia.
Seus estudos sobre Mecânica iniciaram-se no mesmo ano de conclusão de seu
curso, ou seja, em 1665.
Sua principal obra,
Philosophiae Naturalis Principia Mathematica, onde são
apresentadas suas principais descobertas e princípios, foi publicada pela primeira vez
em 1687. Nela apresenta os fundamentos dos princípios básicos do movimento e de
sua aplicação aos planetas, cometas, Lua e sobre seus efeitos sobre as marés.
Leis de Newton:
1.Todo corpo continua em seu estado de repouso, ou de movimento uniforme
em uma linha reta, a menos que seja compelido a mudar esse estado por forças
aplicadas sobre ele.
2.A mudança do movimento é proporcional à força motriz impressa, e ocorre
na direção da linha reta em que a força é impressa.
3.Para cada ação existe sempre uma reação igual e contrária, ou seja, as
ações recíprocas de dois corpos, um sobre o outro, são sempre iguais e dirigidas
para partes contrárias.
Entre outras aplicações, Newton deduziu que o movimento de um planeta é o
resultado da competição entre a tendência do planeta em se mover em uma linha
reta com velocidade constante – caso nenhuma força atue sobre ele – e o
movimento correspondente a força gravitacional dirigida para o Sol.
Suas descobertas foram fundamentais para o desenvolvimento da ciência em
geral e da Física em particular.
Desde 1703, Newton presidiu a mais importante sociedade científica de sua
época, a Royal Society.
Foi sagrado cavaleiro em 1703 e faleceu em 20 de março de 1727, sendo
enterrado na abadia de Westminster.
William Harvey (A descoberta da circulação do sangue)
Com Harvey a medicina inicia uma nova fase. Ao invés da ênfase nos estudos
anatômicos, a prioridade passa a ser a fisiologia. Nascido na Inglaterra, em
Folkestone, a dois de abril de 1578, era o mais velho de oito irmãos. Foi o único a
seguir a carreira médica. Estudou em Pádua, onde se formou em 1602.
Discípulo de Fabrizio, publicou, em 1628, sua grande obra:
Uma dissertação
anatômica sobre o movimento do coração e do sangue em animais. Nela, decifra o
fenômeno da circulação do sangue.
Sugere que o coração é como uma bomba pulsátil, que trabalha como um
músculo qualquer, contraindo e relaxando. Que a contração do ventrículo esquerdo
provoca a expansão da artéria aorta, que leva o sangue para os órgãos. Que o
sangue retorna ao coração através das veias. Daí vai até a aurícula direita, desta
para o ventrículo direito, que depois se contrai e leva o sangue até os pulmões pela
artéria pulmonar. Em seguida, oxigenado, o sangue segue pelas veias pulmonares
até a aurícula esquerda. Daí para o ventrículo esquerdo, e assim por diante de forma
contínua, sem cessar.
Outro grande mérito de Harvey foi desenvolver experiências simples para
confirmar as suas hipóteses. Dizia ele que o sangue transportado pela aorta só
poderia vir das veias. Se uma artéria de um animal for cortada, ele vai sangrar até
morrer. O sangramento vai se tornando cada vez mais lento até o seu esgotamento,
e o animal morre. “A razão da morte deve ser porque o sangue perdido não atinge
as veias, e assim não pode retornar às artérias”, concluiu o cientista.
Para explicar a conexão entre as artérias e as veias, imaginou a existência de
pequenos vasos comunicantes entre eles. Como em seus trabalhos nunca usou o
microscópio - que só veio a ser desenvolvido ao final do século XVII -, não pôde
confirmar a presença dos capilares sangüíneos, o que só se realizou com os estudos
de Marcello Malpighi, em 1661.
Retornou à Inglaterra e teve ainda em vida o reconhecimento pelo seu
trabalho, tendo sido médico de dois reis ingleses.
Com Harvey surge a idéia de que cada órgão tem uma função a ser
descoberta quanto à sua forma de atuar e quanto às suas relações com os outros
órgãos e o corpo como um todo. Morreu em 1657, em Londres, aos 79 anos de
idade.
Duas conclusões lógicas e fundamentais foram obtidas com a descoberta de
Harvey:
- A possibilidade de se injetar medicamentos por via venosa.
- A possibilidade de repor sangue, por meio de transfusão venosa.
As primeiras sociedades e revistas científicas
Em Londres, em 1662, alguns súditos ingleses mais esclarecidos decidiram
organizar a primeira sociedade científica35, que por ser patrocinada pelo rei Charles
II, foi denominada
Royal Society for Improving Natural Knowledge, tendo seus
fundadores sido influenciados pelos trabalhos de Francis Bacon. Em um de seus
livros, o filósofo relatava como deveria operar uma instituição de pesquisa36.
A Royal Society lançou, em março de 1665, a primeira edição de sua revista,
denominada
Philosophical Transactions, que, na verdade, sucedeu ao
Journal des
Savants, publicado em Paris, em janeiro de 1665. No entanto, enquanto a
Philosophical Transactions se interessava por estudos científicos, o periódico francês
concentrava-se em temas ligados à área de humanidades.
Leewenhoek (O surgimento do microscópio)
Filho de um fabricante de cerveja da cidade holandesa de Delft, Anton van
Leewenhoek ficou órfão de pai aos 16 anos de idade. Isto o obrigou a se empregar
em uma fábrica de tecidos, como contador ajudante. Foi ali que conheceu as lupas
utilizadas para contar os fios de linhas, e que tinham pouca capacidade de aumento.
Só conhecia o idioma holandês por não ter tido condições de desenvolver uma
formação melhor, devido às dificuldades financeiras que enfrentou.
Estimulado pelo seu trabalho, começou a desenvolver lupas com aumentos
cada vez maiores, polindo lentes biconvexas e montando-as entre dois pedaços de
metal.
35 Segundo Brody, a primeira sociedade científica surgiu na Itália, em 1657, com o nome de
Academia de Experimentação.
36 Segundo Durant, em Nova Atlântida, Bacon pautou os objetivos dessa sociedade científica.
Ao longo de sua longeva existência (1632 a 1723) desenvolveu cerca de 400
instrumentos, que chegaram a produzir aumentos de até 275 vezes. Com suas lupas
visualizou, pela primeira vez, o fascinante mundo microscópico. Examinou vários
tipos de águas: da chuva, da neve, de poços, de rios e do mar. De cada preparação,
que mantinha montada por tempo indefinido, procurava anotar suas próprias
observações.
Regnier de Graaf, famoso médico e anatomista de quem veio a se tornar
amigo, colocou-o em contato com a Royal Society, de Londres. A partir de então,
Leeuwenhoek escreveu centenas de cartas para aquela sociedade científica, sendo
que em 1676 descreveu, pela primeira vez, as diferentes formas como as bactérias
se apresentam.
Além de, pela primeira vez, haver visualizado as bactérias, ele percebeu que o
vinagre as eliminava. Hoje sabemos que o fato de haver ácido acético no vinagre é
que o torna bactericida. Também verificou que o calor era capaz de matar os
animáculos (termo que usava para os micróbios).
Se estas suas duas observações tivessem merecido maior atenção na época,
certamente a implantação da cirurgia asséptica e a antissepsia teriam sido
implantadas mais cedo, o que só veio a ocorrer no final do século XIX.
As primeiras estatísticas
A partir do século XVII, dois ingleses, William Petty e John Graunt,
perceberam a importância de um estudo quantitativo de problemas de saúde como
subsídio para a melhoria da qualidade de vida dos cidadãos.
Em 1662, Graunt publicou um livro com o título
Natural and Political
Observations Made Upon Bills of Mortality. Seus estudos baseavam-se nos registros
anuais de Londres, que tinham sido coletados pelo governo e resumem esses
registros como tabelas numéricas para o intervalo entre 1604 a 1661.
Graunt, junto com seu amigo Petty, criaram uma nova forma de obter
informação sobre a população por meio da análise de dados oficiais como os
registros de nascimento e de mortalidade.
Apesar de reconhecer a precariedade e a imperfeição dos dados que obteve,
Graunt acreditava que se fossem interpretados de maneira correta poderiam fornecer
informações úteis ao desenvolvimento de medidas que contribuíssem para diminuir
a mortalidade da população.
Petty percebeu ainda que o controle das doenças comunicáveis e uma
mortalidade infantil menor poderiam ainda contribuir para o aumento da população e
que para isso ser possível haveria a necessidade de uma considerável melhoria da
formação dos médicos. Em 1676 ressaltou, em uma conferência em Dublin, ser
obrigação de o Estado promover o progresso da medicina de forma a melhorar as
condições de vida da população.
Na França, a mortalidade de crianças de até um ano de idade era bastante
elevada. No
Hospital de Crianças Abandonadas de Paris, no período de 1771 a 1777,
entre 31.951 nascimentos houve 25.476 óbitos nessa faixa etária ou uma
mortalidade de 80%.
A tabela a seguir se refere aos nascimentos e falecimentos da cidade inglesa de
York, Inglaterra, de 1770 a 1776:
Ano Nascimentos Falecimentos
Homens Mulheres Total Homens Mulheres Total
1770 237 230 467 203 214 417
1771 225 226 451 225 260 485
1772 238 252 490 220 288 508
1773 244 232 474 241 258 499
1774 214 239 453 173 209 382
1775 255 235 490 237 251 488
1776 255 243 498 177 219 396
Total 1668 1655 3323 1476 1699 3175
Neste período, a mortalidade por problemas ligados à gestação e ao parto era
considerável, o que, de certa forma, explica o maior número de falecimentos entre
as pessoas do sexo feminino.
Thomas Sydenham (O Hipócrates inglês)
Enquanto a tendência da medicina no século XVII era direcionada para as
ciências exatas, como a física, a química e a matemática, Sydenham preconizava a
volta do médico ao aprendizado à beira do leito do paciente.
Durante sua existência(1624 a 1689), muitos acreditavam que a principal
tarefa do médico era se devotar aos estudos anatômicos ou aos cálculos
matemáticos. Sydenham devotou sua vida à prática clínica.
Apresentou um conceito mais claro das doenças, separando os sintomas
principais dos secundários. Segundo dizia, quando uma determinada doença ataca o
organismo, este por sua vez procura resistir por meio de suas próprias defesas,
sendo os sintomas o resultado desta luta entre o organismo e a enfermidade. A dor,
a febre, a fraqueza não seriam a doença, mas simplesmente as provas da luta e do
esforço que faz o organismo para se defender.
Foi um dos pioneiros na utilização da casca de cinchona (quinina) para o
tratamento da malária, recém trazida do território inca, no Peru.
O fato de se vir a conhecer um medicamento com ação específica para uma
doença causou forte emoção no meio médico da época. Deduziu-se, então, que a
condição básica para a instituição de um tratamento eficaz seria um diagnóstico
correto prévio.
Sua eficiência não podia ser explicada por nenhuma teoria previamente
formulada, e geralmente equivocada, como a teoria humoral, ou ainda pela expulsão
de algum tipo de demônio ou assombração do corpo do doente.
Boerhaave (O Hipócrates holandês)
Hermann Boerhaave concluiu o curso de medicina na Universidade de Leiden,
e em 1701 era um dos seus professores, aos 33 anos de idade.
Admirador de Sydenham ressaltava a importância do aprendizado à beira do
leito dos pacientes, e a volta ao estudo dos textos hipocráticos.
Além de lecionar medicina, também foi professor de Botânica e de Química,
em seu país.
Sua contribuição mais importante para o conhecimento médico foi o conceito
de doença como um processo de alteração funcional, e não como algo independente
do organismo.
Percebeu a importância dos estudos anátomo-patológicos, ou que as
alterações ocorridas após a morte deveriam ser correlacionadas com os sintomas e
doenças apresentadas pelos enfermos ainda em vida.
Ao longo da vida teve enorme reconhecimento profissional, acumulando
grande fortuna, além de deixar seguidores que contribuíram para o desenvolvimento
do conhecimento médico.
Albrecht von Haller, seu aluno mais brilhante, desenvolveu estudos em várias
áreas, era pessoa de grande erudição, e teve na área da fisiologia dos vasos
sangüíneos e do sistema nervoso suas maiores descobertas científicas.
John Hunter(Uma nova cirurgia )
Considerado, juntamente com Paré e Lister, como um dos maiores cirurgiões
de todos os tempos, John Hunter fez com que a cirurgia passasse de um nível
estritamente técnico para o de uma ciência experimental. Segundo foi dito, Hunter
foi para os cirurgiões o mesmo que Mozart para os músicos. Antes dele, os cirurgiões
eram pouco valorizados pela sociedade.
Irmão do anatomista William Hunter com quem muito aprendeu durante a
vida, John foi o fundador da anatomia patológica na Inglaterra.
Introduziu a alimentação artificial, através de um tubo flexível passado até o
estômago, e também de um aparelho para reforçar a respiração.
Inovou na cirurgia de aneurisma, demonstrando que apenas com a ligadura
da artéria na área anterior à lesão o paciente seria curado. Antes desta modificação
proposta por Hunter, fazia-se a ligadura do aneurisma em seus dois extremos para
depois retirá-lo, o que aumentava de forma considerável o risco cirúrgico e suas
complicações pós-operatórias.
Publicou vários livros, incluindo um sobre odontologia, em 1771, só sendo
precedido nesta ciência pelo francês Pierre Fauchard, que publicou sua obra em
1728.
Com a finalidade de avaliar se a gonorréia e a sífilis teriam a mesma causa,
Hunter se auto-inoculou com material de paciente com gonorréia. Para sua
infelicidade, o paciente era portador das duas doenças, o que contribuiu para manter
a crença de que possuíam a mesma etiologia.
Morreu em 1793, após sofrer um infarto desencadeado por uma violenta
discussão a respeito da nomeação de seu sucessor no Hospital S. George.
Morgagni, o fundador da Anatomia Patológica
Giovanni Batista Morgagni (1682 a 1771), aos vinte e nove anos, era professor
de medicina na universidade de Pádua. Publicou vários livros, sendo que a sua
importância maior reside na ligação que realizou pela primeira vez na história da
medicina, entre as alterações encontradas nos órgãos doentes e as manifestações
clínicas das respectivas patologias.
Notou as diferenças anatômicas entre o órgão normal e o doente, e
demonstrou que, para cada anormalidade anatômica, correspondia uma alteração
funcional.
Dizia que as necrópsias só seriam úteis quando quem as realizasse tivesse
profundo conhecimento da anatomia normal e de uma detalhada e precisa história
clínica do paciente.
Para ele, o importante era procurar a origem da doença a partir das alterações
visíveis que teria provocado no corpo.
A arte de curar no Brasil (Os primeiros tempos)
Os jesuítas37 chegaram ao Brasil em 1549, junto com o governador-geral
Tomé de Souza, permanecendo no país até 1759 quando foram expulsos por
Sebastião José de Carvalho e Melo, conde de Oeiras e marquês de Pombal, poderoso
ministro de D. José I.
No período em que estiveram aqui, os jesuítas foram importantes não só na
catequização dos índios, como na educação e na assistência aos enfermos, atuando
principalmente como enfermeiros e boticários, mas também como médicos.
No tempo da catequese eles realizaram intensa campanha para desacreditar
os pajés, até substituí-los, junto aos índios, como curadores. Os resquícios da arte
médica indígena, fundidos com o que restou da arte africana, persistiram apenas
entre os curandeiros e pais-de-santo dos candomblés e dos centros de baixo
espiritismo.
Em 1487 a Santa Inquisição se estabeleceu em Castela, Espanha. Em
conseqüência, Portugal recebeu, em curto espaço de tempo, centenas de milhares
de judeus tentando escapar da perseguição religiosa. Desses, por volta de trinta mil
se converteram ao catolicismo. Eram os cristãos-novos, que fugiram em busca de um
37 A criação da Companhia de Jesus foi a mais eficiente reação da Igreja Católica à reforma
protestante, com o intuito de fazer frente às escolas protestantes por meio de uma poderosa
ação pedagógico-educativa.
local onde pudessem trabalhar e viver em paz com as suas famílias. Conseguiram
viver tranqüilos em Portugal até que, em 1496, D. Manuel I determinou a sua
sumária expulsão das terras lusitanas.
Muitos buscaram o exílio e outros permaneceram em troca de suas posses.
Em 1506, por inspiração de dois frades, houve uma grande matança de judeus em
Lisboa, que ficou conhecida como a “matança de S. Domingos”, onde duas mil
pessoas foram assassinadas.
A partir de 1531 o Santo Ofício foi instalado em Portugal, e com isso vários
convertidos emigraram para o Brasil, mas mesmo aqui nem sempre conseguiram
escapar do fanatismo religioso.
O primeiro médico a exercer o seu ofício no Brasil foi um cristão-novo, Jorge
de Valadares, que aqui chegou em 1549, junto com o governador-geral.
Em uma carta datada de 1550, o Padre Manuel da Nóbrega assim se dirigia ao
Padre Simão Rodrigues, então em Lisboa: “Esta terra é muito sã para viver; e o
confirmo agora, dizendo que me parece a melhor que possa achar, pois desde que
estamos cá não ouvi que nenhum morresse de febre, mas somente de velhice e
muitos de mal gálico ou de hidropsia”.
Nesta terra abençoada havia, no início, dois tipos de profissionais: os físicos,
que exerciam a medicina, e os cirurgiões barbeiros.
Além dos atos operatórios mais comuns na época (amputar, reduzir luxações e
tratar ferimentos e fraturas), ainda faziam sangramentos, aplicavam sanguessugas,
arrancavam dentes e também cortavam o cabelo e a barba dos seus clientes.
Começavam como aprendizes ou ajudantes dos profissionais mais velhos e, depois
de experientes na arte, eram examinados. Os aprovados recebiam a “carta de
cirurgião-barbeiro”, que lhes regularizava a profissão.
Já os físicos estudavam em escolas de medicina européias, como em Coimbra
e Salamanca.
Havia também os cirurgiões-diplomados - formados em outras escolas
européias, como em Montpellier, na França -, que para aqui vieram, especialmente
no século XVIII.
O primeiro hospital foi construído em Olinda, em 1540, a Santa Casa de
Misericórdia. Três anos depois foi construída a de Santos. A de Salvador foi fundada
em 1550.
No século XVI houve várias epidemias em nosso território, sendo que só na de
varíola, ocorrida em 1563, morreram 30 mil pessoas em três meses.
As vítimas da Santa Inquisição eram deportadas do Brasil para os cárceres de
Lisboa, seus bens confiscados, torturadas e estimuladas a delatar outras pessoas,
parentes ou não, que depois vinham a ter o mesmo destino do denunciante. Alguns
chegaram a ser denunciados pela simples inveja que seu sucesso profissional
despertava em pessoas menos capazes.
A perseguição só terminaria em 1810, após a assinatura do
Tratado de
Comércio e Navegação e de Amizade e Aliança entre Portugal e a Inglaterra. No seu
artigo 9º, estipulava que a Inquisição não mais atingiria os domínios meridionais da
Coroa de Portugal.
Com a liberdade religiosa houve uma considerável melhoria da qualidade de
vida no Brasil. Os emigrantes começaram a prosperar, construíram seus cemitérios e
suas casas de oração.
O uso indiscriminado das sangrias, no Brasil, só deixou de ocorrer após a
epidemia de febre amarela, em 1850. Tantos foram os pacientes que morreram
depois de sangrados que os médicos não tiveram mais dúvida em considerar esta
prática como prejudicial aos seus pacientes.
Os primeiros livros de medicina publicados no Brasil
Três livros merecem destaque como os primeiros publicados em nosso país,
no final do século XVII e início do século XVIII. São eles: o
Tratado único das
bexigas e sarampo, de Simão Pinheiro Morão, publicado em 1683, e que trata,
principalmente, de epidemias de varíola; o
Tratado único da constituição pestilencial
de Pernambuco, de João Ferreira Rosa, publicado em 1694, e que trata de epidemias
de febre amarela; e as
Notícias do que é o achaque do bicho, de Miguel Dias
Pimenta, publicado em 1707, e que trata do “mal do culo” ou “mal de Angola”.
Descreve uma doença disentérica que levava à morte, com gangrena do reto e que
também costumava provocar prolapso retal. Hoje poderíamos especular que se
tratava de casos de disenteria bacilar, doença causada por bactérias do gênero
Shigella, ou mesmo de disenteria amebiana.
Todos os três autores eram médicos de origem portuguesa.
A importância histórica dos dois primeiros livros reside, principalmente, no fato
de serem considerados os pioneiros em tratar da epidemiologia de doenças
encontradas no Brasil.
Bernardino Ramazzini (Pai da Saúde Ocupacional)
Nasceu em Carpi, no ducado de Módena, em 5 de novembro de 1633. Quando
criança foi educado pelos jesuítas e formou-se em medicina, pela Universidade de
Parma, em 1659.
Em seguida, exerceu a medicina em Módena, quando passou a se interessar
pelas doenças associadas com vários tipos de atividades laborativas.
Apesar de não ter sido o primeiro a redigir um texto sobre a saúde dos
trabalhadores, Ramazzini foi quem primeiramente se aprofundou no tema.
Publicou, em 1700, o livro
Discurso sobre as doenças dos artesãos, onde
abordou os riscos para a saúde de quarenta e dois grupos de trabalhadores, desde
mineiros até cirurgiões. Descreveu as relações que existiam entre as doenças e as
ocupações, e o que deveria ser feito para diminuir as doenças profissionais.
Há capítulos sobre doenças de boticários, padeiros, moleiros, pintores e
saboeiros, além de abordar o envenenamento por metal que ocorria com os
trabalhadores metalúrgicos e a presença de silicose entre os que trabalhavam com
pedras.
No décimo capítulo de seu livro apresenta uma pitoresca história ocorrida com
trabalhadores das minas de enxofre. Nela, descreve um caso de uma mulher cujo
marido chega inesperadamente em casa, fazendo com que ela escondesse o amante
embaixo da cama e o cobrisse com um cobertor que havia sido limpo com enxofre.
Entretanto, o amante é rapidamente descoberto devido ao acesso de tosse e de
espirros que os resíduos do material lhe provocam.
Recomendava que, em toda consulta, os médicos deveriam perguntar aos
pacientes sobre suas ocupações profissionais, e que isso poderia ter relevância para
a elaboração de uma correta história clínica.
Morreu em 1714, com 81 anos, em plena atividade profissional, devido a um
acidente vascular cerebral.
Além do mérito de dedicar a vida ao estudo da saúde ocupacional, Ramazzini
era também um excelente clínico. Reconhecia a importância do uso parcimonioso dos
medicamentos, e dizia: “Em combinações inapropriadas há uma modificação da
qualidade das drogas e por isso não se deve combinar diferentes remédios onde não
se conhece perfeitamente sua compatibilidade”.
Esta é uma regra válida até os dias de hoje, desde que a interação
medicamentosa entre drogas incompatíveis pode agravar, ao invés de curar as
doenças.
A Revolução Francesa
A revolução que mudou a história da humanidade, no final do século XVIII,
teve entre seus principais mentores iluministas como Locke, com a sua teoria política
liberal; Voltaire, que também adepto da teoria liberal, era contrário a qualquer tipo
de religião para as classes ricas, porém não para a população pobre, segundo ele,
indigna de ser esclarecida38; Montesquieu, com sua famosa teoria da separação dos
poderes (legislativo, executivo e judiciário), que dizia ser a virtude a base da
democracia; e Rousseau, que com sua teoria democrática, exposta em
O contrato
social, trouxe a legitimidade necessária ao desenvolvimento das formas de governo
representativas, como hoje as conhecemos. Foi ainda importante por desvincular a
ética do saber, introduzindo o racionalismo ético, ao invés do racionalismo
puramente teórico, como era a regra até então.
Dizia, ainda, Rousseau39: “enquanto só o poder estiver de um lado e o
conhecimento e a compreensão sozinhos de outro, o letrado raramente fará o estudo
de grandes questões, os príncipes ainda mais raramente farão grandes ações, e o
povo continuará a ser mesquinho, corrupto e miserável”.
A Revolução Francesa contribuiu, também, para a evolução da medicina ao
criticar o método até então utilizado nas universidades, essencialmente apoiada na
autoridade dos livros, em favor da observação direta dos pacientes ou na ênfase do
exame clínico, na criação de hospitais e no exame necrológico40.
38 Em Para compreender a ciência.
39 Em O contrato social.
40 Segundo Foucault, em O nascimento da Clínica, citado por Roy Porter.
A libertação dos doentes mentais
A partir da Revolução Francesa, as novas idéias de liberdade, igualdade e
fraternidade passaram a ser uma constante preocupação para boa parte da elite
intelectual da época.
O estado de confinamento e crueldade em que viviam os doentes mentais até
o século XVIII era inimaginável. Eram trancados em prisões, casas de correção e
asilos, e vigiados por pessoas ignorantes, que acreditavam ser a insanidade produto
do pecado e do demônio, ou de outras causas tão absurdas como essas.
Conforme Foucault41:
“Estranha superfície, a que comportava as medidas de internamento. Doentes
venéreos, devassos, dissipadores, homosseexuais, blasfemadores, alquimistas, libertinos: toda uma
população matizada se vê repentinamente, na segunda metade do século XVII, rejeitada para além de
uma linha de divisão, e reclusa em asilos que se tornarão, em um ou dois séculos, os campos
fechados da loucura”.
Ainda segundo Foucault, chegava-se até a chicotear publicamente pessoas
acometidas de loucura, além de serem perseguidas numa corrida simulada e
escorraçadas da cidade a pauladas.
O tratamento dado ao doente mental era conseqüência da ignorância,
superstição e condenação moral que o cercava.
Em 1791, Joseph Daquin publicou o livro
Philosophie de la folie, onde
recomendava a abolição das cadeias e confinamentos para os doentes mentais, além
de considerar estes procedimentos como muito prejudiciais aos pacientes.
Na Itália, Vicenzo Chiarugi publicou, em 1793, um livro sobre a loucura,
Della
pazzia in genere e in especie, onde relata as modificações desenvolvidas por ele, em
Florença.
Com um tratamento humanizador, com mais liberdade para os pacientes, e
com restrição apenas aos mais violentos, conseguiu grandes progressos. Segundo
Chiarugi, as doenças mentais podiam ser divididas em três grupos:
Insanidade, com alteração na atividade sensorial, oscilando entre melancolia,
mania e demência.
Mania, que se manifestava através do excesso de audácia da vontade.
Demência ou insanidade geral, sem manifestações emocionais, caracterizada
por deficiência tanto da inteligência como da vontade.
Ressaltou, ainda, a importância da psicoterapia e de um tratamento que tanto
poderia estimular como sedar, dependendo da condição do doente, se era hiperativo
ou atônico.
No entanto, o grande reformador do tratamento dos alienados foi Philippe
Pinel, médico do Bicêtre Hospital de Paris, que, após a perda de um amigo
acometido por uma doença mental, passou a dedicar sua vida à psiquiatria.
Convencido de que um tratamento mais humano poderia ser mais efetivo,
libertou 53 pacientes que estavam internados com o diagnóstico de insanidade, após
convencer a Assembléia Nacional de que, assim agindo, estaria em consonância com
os ideais da Revolução Francesa.
Em 1801 publicou um tratado médico-filosófico sobre a enfermidade mental,
onde afirmava que a origem da doença se devia a alterações patológicas do cérebro.
41 Em História da Loucura.
Um dos mais importantes efeitos da reforma do tratamento desses doentes foi a
implantação dos hospícios, a partir do início do século XIX.
Jenner (A primeira vacina)
A técnica de variolização, que consistia em inocular em uma pessoa material
de lesão de varíola de outra, com a forma benigna da doença, era conhecida desde
os tempos mais remotos, na China. Ficou esquecida durante muito tempo, até que
dois médicos formados em Pádua, Emmanuele Timoni e Jacob Pylarini, a resgataram
durante passagem por Constantinopla, na Turquia, no início do século XVIII.
No entanto, somente em 1719, por meio da mulher do embaixador inglês na
Turquia, Lady Wortley Montagu, esta técnica foi divulgada de forma mais ampla, na
Inglaterra. Ela popularizou a variolização ao defender publicamente seu uso,
inclusive vacinando desta forma seus dois filhos. Ela foi uma mulher muito bonita,
até contrair varíola em 1717, em Constantinopla, tendo seu rosto ficado desfigurado
por várias cicatrizes em conseqüência da doença.
Apesar de ter sido um avanço, a variolização não era uma técnica totalmente
isenta de riscos. Algumas vezes ocorriam formas graves da doença, após a
inoculação do material. Havia, em conseqüência, que se buscar uma outra maneira
de tornar as pessoas imunes à varíola.
Edward Jenner nasceu em Berkeley, em 17 de maio de 1749, tendo sido o
oitavo filho de um pastor da igreja anglicana.
Jenner era um médico escocês que havia se interessado pelo estudo de
história natural, tendo conseguido uma bolsa da Royal Society of England, para
estudar o mamífero ouriço e o pássaro cuco. Em suas peregrinações pelo campo, ao
longo de suas pesquisas, Jenner entrou em contato com várias camponesas que
haviam adquirido a forma bovina da varíola, mas nenhuma delas teria adquirido a
varíola humana. Essa informação foi fundamental para o desenvolvimento do seu
trabalho.
Em 1788 houve uma epidemia próxima à cidade onde Jenner vivia, e ele então
observou que as pessoas que haviam tido a varíola bovina também não adquiriram a
forma humana da doença.
Continuou observando a relação entre uma e outra doença por 25 anos, até
se convencer de que poderia tentar padronizar uma técnica de proteção contra a
varíola humana usando material obtido a partir das lesões da varíola bovina.
Em 14 de maio de 1796, Jenner vacinou um garoto de oito anos, James
Phipps, com secreção de uma camponesa, Sarah Nelmes, cujas lesões das mãos
estavam em estágio ativo da varíola bovina. O experimento ocorreu conforme Jenner
esperava: seis semanas após a vacina, o garoto recebeu doses consideráveis de
material da varíola humana nos dois braços e mesmo assim não desenvolveu a
doença.
Em 1798 publicou os seus estudos sobre a vacina contra a varíola, que foram
recebidos de forma entusiástica em toda a Europa.
Jenner demonstrou que uma doença poderia prevenir uma outra, mas ainda
não se tinha conhecimento de como isto ocorria. Tratava-se, na verdade, de uma
reação cruzada entre os anticorpos produzidos contra a varíola bovina, e que
também conseguiam neutralizar os vírus da varíola humana, devido às semelhanças
existentes entre os dois tipos de vírus, em termos de constituição molecular, por
pertencerem à mesma família dos poxvírus. Essa informação só veio a ser conhecida
na segunda metade do século XX.
O início da geografia médica
O interesse pela relação entre geografia e saúde vem desde a Antigüidade. O
livro de Hipócrates
Sobre Ares, Águas e Lugares, que aborda a ocorrência de
diferentes doenças em diversas partes do mundo, influenciou muitos profissionais em
diferentes períodos da História.
Em 1792, o alemão Leonhard Ldwig Finke publicou a obra
Versuch einer
allgemeinen mediicinish-praktishen Geographie (Um ensaio sobre uma Geografia
Médica-Prática), em que levanta uma série de questões pouco ou ainda não
exploradas até então.
Por ser um médico que por dever de ofício tinha de visitar seus pacientes em
cidades e vilas do seu distrito, Finke examinava as fontes de água, fazia
levantamentos das condições sanitárias, elaborava relatórios sobre a saúde da
população e reunia dados sobre clima, plantas e modo de vida dos cidadãos.
O livro de Finke tinha três volumes, sendo que o último continha um manual
de como realizar obras semelhantes à sua. Finke divide sua obra em uma geografia
das doenças, uma geografia da nutrição e uma geografia da atenção médica.
Finke sugeria que não só a localização geográfica, como também o tamanho
de cada área deveria ser descrito. Em seguida deveria existir uma seção histórica
contendo informação suficiente para o entendimento das condições do momento.
Animais e plantas deveriam ser determinados. Deveria ser incluída a estrutura
econômica, social e política da região, assim como os dados estatísticos de
nascimentos e mortes. As doenças que provocassem os falecimentos deveriam ser
listadas, assim como os anos onde teriam ocorrido epidemias.
As doenças mais freqüentes deveriam ser descritas, assim como eventuais
fatores a elas associados, tais como clima, hábitos da população e outras
informações consideradas relevantes para o entendimento da situação.
Dizia que o levantamento deveria ser concluído com a apresentação das
medidas governamentais a serem implementadas para o controle das doenças
epidêmicas, assim como a ajuda a ser oferecida à população mais carente.
Os hospitais deveriam ser incluídos, quando existentes.
A obra de Finke deve ser compreendida como constituindo uma primeira etapa
na formação da medicina social, ou seja, a medicina do Estado.
Johann Peter Frank(A polícia médica)
Johann Peter Frank (1748 a 1821) publicou em 1778 um livro sobre a Polícia
Médica, onde fez amplo uso da estatística para estabelecer a importância das
medidas a serem tomadas em saúde pública, que considerava um dever do Estado.
Suas propostas demonstravam estar bastante influenciadas pelo iluminismo.
Dizia que a miséria era a mãe das doenças, sugerindo que houvesse maior
preocupação com a assistência à gestante e às crianças, cuidados com a
alimentação, abastecimento de água, destino do lixo e do esgoto, e maior limpeza
das cidades. Criticava o descaso com que os monarcas mantinham a maioria do seu
povo.
A partir de Frank foi criada, em diversos países, uma nova consciência
sanitária, levando a um maior controle e fiscalização das medidas ligadas à higiene e
à saúde da população.
A Revolução Industrial e a Reforma Sanitária
A passagem, na Inglaterra, de uma economia essencialmente agrária para
outra baseada na industrialização42, entre o final do século XVII e o início do século
XVIII, foi chamada de Revolução Industrial.
Por ter sido o primeiro país industrial moderno, as reformas da saúde pública
também foram iniciadas na Inglaterra.
Desde o século XVI havia alguma preocupação dos governantes ingleses com
o problema da pobreza de sua população. Com a criação da “Lei dos Pobres”, a
administração de cada localidade era responsável pelo apoio aos seus indigentes.
Esta visão assistencial chocava-se com o ideário liberal, preconizado por Adam
Smith. O teórico inglês foi o autor de
A riqueza das Nações -
Investigação sobre a
sua natureza e as suas causas, livro editado em 1776 e que inspirou David Ricardo a
descrever, pela primeira vez, o conceito de modelo econômico como uma abstração
simplificadora da realidade econômica.
Em seu livro, Smith procura demonstrar sua crença no crescimento da
produtividade do trabalho, que teria origem em mudanças na divisão e
especialização do processo de trabalho, proporcionando, em contrapartida, o
aumento do excedente sobre os salários e com isso permitindo a acumulação de
capital, variável determinante da oferta de emprego produtivo.
Por sua vez, a pressão por demanda de mão-de-obra sobre o mercado de
trabalho, causada pelo processo de acumulação de capital, provocaria um
crescimento concomitante dos salários e, em razão das melhorias de condições de
vida dos trabalhadores, também haveria melhorias para o restante da população.
O aumento paralelo do emprego, salários e população, ampliariam os
mercados, o que representaria para o capital o fundamento básico do
desenvolvimento da economia.
Smith acreditava, em conseqüência, que o próprio mercado regularia a
sociedade e que a iniciativa privada era a fonte do progresso dos povos.
42 Ou seja do feudalismo, onde a base da economia era a terra, para o capitalismo onde a
produção de mercadorias, em larga escala, passa a acontecer nas fábricas, ao invés da
produção artesanal, como antes.
Em vista disso a política assistencial entrou em declínio, já que a pobreza era
vista mais como uma conseqüência da deficiência moral dos indivíduos. Por este
raciocínio, qualquer ajuda estimularia o ócio e a irresponsabilidade dos mais pobres.
Outra influência considerável para uma visão negativa dos pobres foi oriunda
do calvinismo que, segundo Weber43, exerceu forte influência nos países mais
desenvolvidos da Europa nos séculos XVI e XVII. Pela doutrina da predestinação,
fundamento da moralidade puritana, a providência divina trabalharia apenas para
aqueles que são predestinados à vida eterna. E ainda, segundo Calvino, somente
enquanto o povo fosse mantido pobre ele se conservaria obediente a Deus.
Com a crescente industrialização e o maior aumento da oferta de empregos
nas cidades, os centros urbanos sofreram rápidas e significativas mudanças. Entre
1801 e 1841 a população de Londres passou de 958 mil para quase dois milhões de
habitantes e o mesmo ocorreu em outras cidades inglesas, como Birmingham,
Liverpool e Manchester.
Ao lado deste crescimento, a situação do saneamento urbano e das moradias
era extremamente precária. Nas casas da população pobre, muitas vezes, não havia
sequer privadas. Os dejetos eram transportados em urinóis até a rua, onde eram
esvaziados.
Em Manchester havia mil e quinhentos porões, onde, muitas vezes, cinco
pessoas dormiam na mesma cama.
Os baixos salários impediam a classe trabalhadora de ter melhores condições
de vida. A sujeira, a doença, as condições insalubres de trabalho44 e de moradia,
tudo, enfim, contribuía para tornar a existência quase insuportável.
Surgiram, em conseqüência, várias epidemias (cólera, febre tifóide, tifo) que
atingiram, principalmente, as famílias dos pobres.
Percebeu-se ainda, que estas epidemias provocavam uma considerável perda
econômica, que era prejudicial a todos e o seu custo representava, na verdade, um
desperdício para o Estado.
Em 1842 foi divulgado um relatório cujo autor, o advogado Edwin Chadwick, é
considerado um dos pioneiros da saúde pública. Nele foram analisadas as precárias
condições sanitárias da população trabalhadora da Grã-Bretanha.
O relatório demonstrou haver uma relação direta entre as deficiências de
condições de vida das populações pobres (insalubridade das habitações, imundície do
meio ambiente, falta de abastecimento de rede de água potável e de esgoto, falta de
coleta regular de lixo, desnutrição) e as doenças que as afligiam.
Demonstrava, ainda, que uma boa parte dessas doenças seria evitável, e que
as medidas preventivas mais importantes a serem tomadas diziam mais respeito à
engenharia civil e ao aumento do poder aquisitivo das massas do que à medicina.
O relatório de Chadwick promoveu uma série de conseqüências positivas na
área da higiene, concluindo por levar à criação, em 1848, do Conselho Geral de
Saúde, que passou a fiscalizar e melhorar as condições sanitárias de cada localidade.
No mesmo ano foi criada a função de médico de saúde pública, sendo que o
primeiro foi designado para atuar em Londres.
43 Max Weber, em A ética protestante e o espírito do capitalismo.
44 Com jornadas de trabalho de até 16 horas diárias, empregando crianças e com péssimas
condições de trabalho.
Depois de surgir na Grã-Bretanha, a reforma sanitária em pouco tempo
influenciou a política de outros países da Europa e dos Estados Unidos da América,
passando a saúde pública a ser considerada como um dever do Estado.
Em nosso país, essa visão só se tornou realidade com a Constituição de 1988,
como determinado pelo art. 196: “A saúde é direito de todos e dever do estado”.
Laënnec (O criador do estetoscópio)
René Théophile Hyacinthe Laënnec é considerado o criador do diagnóstico
clínico das doenças torácicas. A sua descoberta da auscultação mediada foi feita
através do uso de um cilindro de papel, o precursor do atual estetoscópio, palavra
oriunda do grego (stethos/scopein) que significa examinar o peito.
Como verificou que obtinha maior discernimento dos sons emitidos a partir do
tórax usando este artifício, logo depois passou a utilizar tubos ocos de madeira.
Dois anos após a sua descoberta, publicou um livro sobre a clínica de
auscultação das doenças pulmonares e cardíacas, em 1819. Nele apresenta, em
detalhe, os diferentes sinais, em diversas doenças, obtidos pela percussão e pela
ausculta.
Em seu livro
, Tratado da Auscultação Mediada, apresentou excelentes
descrições da tuberculose, pneumonia, bronquiectasia, pneumotorax, enfisema,
câncer de pulmão, além dos sons emitidos pelo coração.
Veio a falecer aos 45 anos, vítima da tuberculose, doença que de forma tão
brilhante descreveu em seus livros.
Semmelweis (Um mártir da infecção hospitalar)
Ignaz Philipp Semmelweis nasceu na Hungria, e em 1846 tornou-se assistente
da Primeira Clínica Obstétrica de Viena. Esta enfermaria tinha adquirido uma péssima
fama, devido aos altos índices de mortalidade entre as puérperas.
Quando Semmelweis assumiu o posto de assistente, 36 pacientes faleceram
entre 208 pacientes, uma taxa de mortalidade de mais de 17%. As parturientes
internadas neste hospital eram mulheres pobres. As ricas tinham seus filhos em suas
próprias casas.
A outra clínica obstétrica, a Segunda Clínica, do mesmo hospital, era
freqüentada apenas por parteiras, que lá eram treinadas por outras mais
experientes. Já na Primeira Clínica trabalhavam os estudantes de medicina e seus
professores, também médicos.
Na Segunda Clínica, das parteiras, a mortalidade era menor que 1%, segundo
levantamento de Semmelweis.
Estes números espantaram o médico húngaro, que passou a procurar a razão
de tanta discrepância, desde que o esperado seria uma menor taxa na clínica onde
trabalhavam os doutores.
Em 13 de fevereiro de 1843, o médico americano Oliver Wendell Holmes fez
um comunicado à
Boston Society for Medical Improvement, onde dissertava sobre o
contágio da infecção puerperal, e afirmava que as gestantes nunca deveriam ser
atendidas por médicos que tivessem conduzido necrópsias ou atendido a casos de
infecção puerperal.
E, ainda, que a doença seria transmitida de um paciente para outro. E, ainda,
que seriam medidas preventivas eficientes os médicos assistentes lavarem as mãos
com solução de cloreto de cálcio, e trocarem as roupas após atender a um caso de
infecção puerperal.
Esta comunicação feita por Holmes provocou violenta oposição dos médicos
locais, que não a aceitaram.
Apesar de não ter tido conhecimento do trabalho de Holmes, Semmelweis
continuou tentando descobrir a causa do seu paradoxo.
Em 1847, seu amigo patologista, Kolletschka, morreu dias depois de ter se
ferido durante uma necrópsia, após cortar o dedo com seu bisturi.
Ao ler a descrição da necrópsia do corpo do amigo, constatou que o quadro
era idêntico ao das pacientes que morriam de infecção puerperal.
Concluiu, então, que as taxas elevadas de mortalidade deveriam ser causadas
por algo que os estudantes trariam da sala de necrópsia, vindo a contaminar as
mulheres internadas. Como na Segunda Clínica as parteiras não freqüentavam a sala
de patologia não trariam esta contaminação, o que explicaria as diferenças de
mortalidade encontradas. Neste período, ainda não se conhecia a teoria dos germes
causadores de doenças infecciosas.
Em conseqüência, a partir de 15 de maio de 1847, Semmelweis passou a
exigir maior rigor na atitude de prevenção das infecções. Colocou na entrada da
Primeira Clínica um cartaz dizendo que todo médico ou estudante, sem exceções, era
obrigado a lavar as mãos com solução de ácido clórico antes de entrar na clínica
obstétrica, quando proveniente da sala de necrópsia.
Mesmo com muitas reclamações e incompreensão generalizada, Semmelweis
conseguiu que suas ordens fossem cumpridas, e em poucos meses as taxas
baixaram para 3%.
Posteriormente, verificou que além da transmissão da doença ocorrer de
mortos para vivos, também podia acontecer entre pacientes vivos, através das mãos
dos médicos. Inaugurou uma nova fase da sua luta, determinando a mais rigorosa
desinfecção das mãos, após cada exame.
Supervisionava a esterilização dos instrumentos, que até então eram limpos
no sobretudo dos cirurgiões, em todos os hospitais da época, e passou a remover as
parturientes portadoras de processo inflamatório para unidades de isolamento.
Em 1848 a taxa de mortalidade da Primeira Clínica diminuiu, pela primeira vez,
para 1,33%.
Apesar do sucesso alcançado, Semmelweis adquiriu muitos inimigos com a sua
cruzada. Com isso, teve de sair de Viena neste mesmo ano e foi para Budapeste, sua
cidade natal.
Em 1860 publicou suas descobertas sobre a febre puerperal em um livro que
foi mal recebido pelos médicos. Só uma ou outra voz se levantou em seu apoio.
Cinco anos depois da publicação começou a apresentar sinais de insanidade mental,
sugestivas de esquizofrenia.
Morreu em 1865, vítima de septicemia, após ferir o dedo na sua última
autópsia, de forma semelhante ao que havia ocorrido com seu amigo Kolletshcka.
O surgimento da Homeopatia
Até o final do século XVIII o arsenal terapêutico da medicina era muito
limitado. A quinina era usada contra qualquer tipo de febre, assim como o cloreto de
mercúrio (calomelano), que era empregado até para tratamento da sífilis.
Além disso, os doentes tinham que se sujeitar a procedimentos heróicos, à
base de sangrias (sanguessugas, ventosas ou mesmo punção venosa), purgativos e
eméticos, além da vesiculação, onde substâncias irritantes eram colocadas sobre a
pele do doente, provocando queimaduras e depois infecções. Acreditava-se que,
agindo assim, os médicos estariam eliminando as impurezas responsáveis pelas
doenças.
Neste período, muitos pacientes morriam mais pelas conseqüências das
agressões sofridas com os tratamentos do que pelas próprias doenças.
George Washington, presidente dos Estados Unidos da América, recebeu no
dia 17 de dezembro de 1779 o seguinte tratamento para uma infecção de garganta:
pela manhã, sofreu uma sangria de meio litro, sem demonstrar melhora; logo outro
médico foi chamado, aplicou vesiculação no pescoço e retirou mais meio litro,
também sem resultado; vieram dois outros médicos e fizeram outra sangria, de um
litro, além de administrar o cloreto de mercúrio. Às 22 horas, o ilustre paciente
faleceu.
Foi neste cenário que surgiu o médico alemão Samuel Hahnemann. Em 1790,
ele lançou as bases da homeopatia, após traduzir o livro
Matéria Médica, de William
Cullen, professor da Universidade de Edimburgo, Escócia.
Ao contrário de Cullen, que acreditava que o efeito da quina (de onde era
extraída a quinina) se devia a uma ação no estômago, Hahnemann teria ficado
surpreso ao experimentar a droga nele mesmo e verificar que seus efeitos eram
semelhantes àqueles que surgiam na própria doença que ela curava.
A partir daí, lançou o princípio de que o semelhante se cura pelo semelhante,
e que quanto mais diluído - ou dinamizado - mais ativo é o medicamento.
Com estes dois fundamentos básicos o método de Hahnemann teve um
sucesso extraordinário, já que sua terapêutica não era iatrogênica como costumava
ser a regra da medicina de então. Em 1823, viu-se obrigado a deixar Leipzig, devido
à hostilidade dos boticários e médicos da cidade, que se sentiam prejudicados por
ele.
Foi neste contexto histórico que surgiu a homeopatia. Era nitidamente
superior à alopatia por não agravar o estado do doente. No entanto, com o
desenvolvimento da quimioterapia, a homeopatia foi perdendo terreno para os
medicamentos alopáticos, o que fez com que quase desaparecessem as escolas
médicas homeopáticas após as primeiras décadas do século XX.
Pela teoria de Hahnemann, o efeito terapêutico das suas formulações não
podia ser aferido pelas propriedades físico-químicas dos medicamentos, desde que
dependem da concentração das moléculas de cada substância.
No entanto, a tentativa de explicação através do argumento de que as
diluições – dinamizações - liberariam uma “energia interna” dos remédios não
encontra fundamento científico capaz de apoiá-la.
Outros autores procuram explicar a ação destas drogas afirmando que
mobilizariam reservas alternativas do próprio organismo. Fica difícil entender quais
reservas seriam arregimentadas de forma diferente pelos medicamentos
homeopáticos e pelos alopáticos. A imunidade não parece ser capaz de fazer tão
sutil discriminação.
Segundo o poeta Heine, a homeopatia é útil nas doenças do amor, onde se
deve aplicar o princípio de que o semelhante cura o semelhante, ou um novo amor é
o melhor remédio para um amor fracassado.
O início da homeopatia no Brasil
Em 1840, o Dr. Pedro Chernovitz, médico polonês que emigrou para o Brasil,
assim se expressava sobre a situação dos médicos, no Rio de Janeiro: “Se começo a
pensar na minha profissão, vejo como o povo está enganado, achando que o vento
da boa fortuna elevou-me acima da multidão. Mas a maioria dificilmente consegue
ganhar seu sustento. Há, portanto, muitos que não conseguiriam sobreviver se não
tivessem outros rendimentos”.
Foi neste contexto que surgiu a homeopatia no nosso país. Em dezembro de
1843 o francês Benoit Mure, formado em medicina em Montpellier e que depois
estudou com o próprio Hahnemann, fundou, na capital do Império, o Instituto
Homeopático do Brasil.
Devido às dificuldades por que passavam os médicos aqui instalados, era de
se esperar que houvesse uma forte reação contra a nova maneira de tratar as
doenças.
A homeopatia era não só mais acessível às camadas mais pobres, que
freqüentemente os homeopatas atendiam gratuitamente, mas também uma
alternativa bem-vinda aos métodos agressivos da terapêutica oficial.
Benoit Mure tornou-se logo o alvo das campanhas de desmoralização dos que
se julgavam prejudicados pelo surgimento desta nova concorrência profissional.
Foi acusado de ter comprado o seu diploma e até de ter assassinado sua
enteada. Foi ainda denunciado por prática ilegal da medicina, envenenamento de
paciente e outras calúnias menores.
Com isto, foram bloqueadas no parlamento suas tentativas de legalização do
ensino da homeopatia.
Além da luta por um disputado mercado de trabalho, a luta corporativa dos
médicos também era devida a divergências de conteúdo que sempre colocaram a
medicina alopática e a homeopatia em campos opostos, ao longo da história.
Mesmer e o magnetismo animal
Por meio do tratamento com o imã, Franz Anton Mesmer desenvolveu uma
forma de tratamento que teve muita aceitação no século XIX. O seu método,
também chamado de mesmerismo, nada mais era que um tipo de sugestão, hipnose
ou “sono nervoso” 45.
Sua tendência pelo inusitado podia ser percebida pela tese com que concluíra
o curso de medicina:
Da influência dos astros sobre os corpos humanos.
O princípio, segundo Mesmer, se baseava em uma força que emanava do
médico, que existia em todos os seres vivos e que permitia estabelecer relações
mútuas entre eles. Com o auxílio desta força, um organismo poderia fazer a
modificação de outro através da ação da vontade.
Por causa de sua exteriorização, comparável à força do imã, denominou-a
“magnetismo animal”. Esfregando imãs nos membros dos doentes, acreditava
proporcionar uma influência semelhante à exercida pela ação gravitacional da Terra.
Nos trabalhos de Isaac Newton, publicados anteriormente, o físico dizia haver
“um espírito sutil que permeia e jaz no âmago de todos os corpos densos; por sua
força e atuação, as partículas físicas se atraem uma à outra”. Provavelmente estes
trabalhos influenciaram bastante o médico.
Através da aplicação das mãos, ou por passes com as mãos, Mesmer
pretendia curar diretamente as enfermidades nervosas, e indiretamente todas as
demais.
Alguns dos seus seguidores fizeram uma fusão entre o mesmerismo e a
religião. Segundo este tipo de associação, os doentes que poderiam ser curados pelo
magnetismo seriam apenas os que fossem puros e livres de pecado. E, também,
somente os médicos abençoados por Deus poderiam fazer uso desta grandiosa força
magnética.
Ainda hoje algumas religiões, que utilizam passe, usam a técnica de Mesmer
no intuito de livrar as pessoas de seus males, assim como de possessões
demoníacas.
Por outro lado, há quem afirme46, no entanto, que a contribuição de Mesmer
foi relevante por ter previsto a importância que o inconsciente joga em nossas vidas.
Assim, apesar de suas excentricidades, Mesmer poderia ser considerado um
precursor de Freud.
Início da pesquisa experimental em fisiologia
A partir do final do século XVII, a medicina deixou de se preocupar tão
somente com o estudo da anatomia e passou a se voltar também para os primeiros
estudos de fisiologia e patologia de uma forma mais científica.
Houve trabalhos para a detecção da perspiração insensível, feitos pelo italiano
Santorio Santorio (1561 a 1636) e depois por outros pesquisadores como François de
la Boe, também chamado de Sylvius(1614 a 1672), autor de interessantes estudos
sobre o papel da saliva, suco pancreático e da bile na digestão.
45 Em Histórias Esquecidas da Ciência.
46 Ibidem.
O holandês Cornelius Bontekoe (1614 a 1687) dizia que o engrossamento do
sangue era o responsável por um grande número de doenças. Para afiná-lo,
recomendou o uso do chá. Posteriormente, foi criticado por ter interesses na
divulgação do produto devido às suas relações com ricos comerciantes de chá
holandeses.
Albrecht von Haller(1708 a 1777), de Berna, realizou vários trabalhos sobre a
fisiologia da atividade muscular. Desenvolveu o conceito de irritabilidade, envolvendo
nervos e músculos.
Após o descobrimento do oxigênio, por Scheele e Priestley, depois de
Cavendish ter demonstrado que o ar era uma mistura quase constante de nitrogênio
(78%) e oxigênio (21%), Lavoisier (1743 a 1794) comprovou que tanto a
combustão, como a respiração, implicam um consumo de oxigênio do ar, com
emissão de gás carbônico no final. Reconheceu ainda, que o calor produzido nas
trocas metabólicas depende da oxidação de carbono pelo organismo animal.
Doenças que mais importância tiveram até o final da Idade Moderna
Tuberculose
Muito antes de provocar doença no ser humano, a tuberculose era endêmica
em animais desde o período paleolítico. O agente que causava infecção àquela época
seria, provavelmente, o Mycobacterium bovis (M. bovis), que causa doença no gado
e que pode ser transmitido, pelo leite, a outras espécies.
À medida que o homem passou a adotar a agricultura como modo regular de
produção - por volta de 7.000 a.C. -, começou a se estabelecer em aglomerados e a
domesticar algumas espécies de animais, como o gado, porcos e cabras. A partir daí,
a tuberculose surgiu como doença em humanos, mas ainda em uma forma pouco
freqüente.
Conforme já citado anteriormente, foram encontradas diversas múmias
egípcias apresentando quadros de infecção por micobactérias.
Quando as cidades foram se tornando maiores, as condições ambientais para
a transmissão da doença também foram aumentando, modificando-se o débil
equilíbrio que havia entre o bacilo e o indivíduo.
Acredita-se que o bacilo da tuberculose humana, o Mycobacterium
tuberculosis, tenha se originado a partir do M. bovis, como um mutante, e que tenha
sido introduzido na Europa no século XVI.
Após a eliminação dos mais sensíveis ao bacilo, por meio de uma pressão
seletiva sobre a espécie humana, uma proporção crescente da população mostrou
resistência à infecção e ela passou a apresentar, predominantemente, um quadro
endêmico de doença pulmonar crônica.
A bactéria continuou sem causar grandes problemas, em termos de doença,
até que as condições ambientais da Europa, a partir do século XVII, possibilitaram a
sua disseminação entre grandes aglomerados urbanos de pessoas que viviam em
porões, com alta promiscuidade e pouca possibilidade de se proteger do frio.
Estas condições nunca, anteriormente, haviam sido encontradas em toda esta
extensão na história da humanidade.
A partir daí e até o final do século XVIII e início do século XIX, a epidemia
cresceu e se espalhou pela Europa e América do Norte, sendo que os óbitos devidos
à tuberculose chegaram a constituir 25% do total, no seu auge.
Na América do Sul, Ásia e África a situação atingiu o seu clímax no início do
século XX, ou cerca de cem anos depois.
Cólera
A existência de doença grave, provocando a morte por intensa diarréia, com
quadro de desidratação e vômitos, tem sido descrita desde a mais remota
Antigüidade.
Não há consenso de quando o cólera, em sua forma epidêmica, foi
primeiramente descrito. No subcontinente indiano era sabidamente endêmico desde
o século XV, quando os exploradores portugueses retornaram da viagem de Vasco da
Gama e contaram suas experiências asiáticas.
Com o aumento e freqüência das viagens transoceânicas, a partir dos séculos
XV e XVI, a doença começou a se espalhar por outros continentes e países. Houve
grandes epidemias em 1817, em 1822 e em 1829, esta atingindo a Europa e em
seguida a América, três anos mais tarde.
Nas epidemias que ocorreram em Londres, em 1848/1849 e na de 1853/1854,
um médico inglês, John Snow, se tornou bastante conhecido por seus estudos sobre
essas duas epidemias.
Filho de um carvoeiro, Snow nasceu em 1813 e desde cedo demonstrou que
desejava ser médico. Com 14 anos tornou-se aprendiz do Dr. William Hardcastle. No
verão de 1831, ainda com apenas 18 anos, Snow enfrentou uma epidemia de cólera
em Londres, ainda como aprendiz do Dr. Hardcastle. Na época, havia pouco ou
quase nada a fazer pelos pacientes e a mortalidade pela doença era bastante
elevada. Ao término da epidemia, em 1832, 50 mil pessoas haviam falecido.
Durante os 16 anos seguintes, Snow, após formar-se em medicina, passou a
atuar profissionalmente, iniciando ainda estudos sobre os efeitos anestésicos do éter
e do clorofórmio.
Em setembro de 1848, uma nova epidemia de cólera atingiu Londres. Snow
acreditou que poderia interromper a progressão da doença, caso conseguisse
determinar exatamente como ela se disseminava.
Verificou que a primeira vítima dessa epidemia, John Harnold, comerciante
marítimo, tinha chegado de Hamburgo em 22 de setembro. Após desembarcar,
Harnold alugou um quarto em uma comunidade de Londres, onde rapidamente
desenvolveu os sintomas do cólera e veio a falecer.
Snow falou com o médico assistente, que lhe relatou que poucos dias após a
morte de Harnold, outro homem que alugou o mesmo quarto também veio a ficar
doente e morrer oito dias depois. Deduziu, assim, que o segundo caso era uma forte
evidência de contágio. Suspeitou que o quarto onde o comerciante houvesse estado
não teria sido limpo e que talvez os germes tivessem, em conseqüência,
permanecido no lençol da cama onde o comerciante morrera.
Nessa época a teoria dos miasmas, ou ares contaminados, ainda era aceita
como verdade. Não se tinha conhecimento do papel dos micróbios nas doenças
infecto-contagiosas.
Como mais casos iam surgindo, Snow começou a examinar os pacientes
doentes. Todos relatavam que os primeiros sintomas tinham sido problemas
digestivos. Deduziu, então, que isso provava que a doença deveria ser contraída por
meio da ingestão de água ou comida poluída. E que, se ao contrário, as vítimas
tivessem absorvido o “veneno do cólera” por meio de ar poluído, como a teoria dos
miasmas fazia supor, então os sintomas deveriam ser respiratórios e não ligados ao
trato gastrintestinal.
Apesar de ter discutido suas teorias com outros colegas, Snow continuou sem
receber apoio científico.
Durante o segundo ano da epidemia, em 1849, sentiu-se na obrigação de
procurar convencer as autoridades que a doença estava se propagando por meio da
água contaminada. Publicou um texto de 39 páginas com o título
On the mode of
communication of cholera, que continha argumentos e documentação necessária
para evidenciar apoio à sua teoria. No entanto, seu trabalho não teve a repercussão
desejada.
Estudando registros municipais, descobriu que duas companhias privadas
forneciam água para aquele distrito. Uma das empresas, denominada Southwark and
Vauxhall Water Company, retirava água de uma região do Tamisa conhecida por ser
poluída por saídas de esgotos. Já a outra, Lambeth Water Company, influenciada
pela campanha de Snow, recentemente tinha passado a retirar água de um local
acima da chegada do rio a Londres, onde não havia poluição pelos esgotos.
Decidido a expandir suas pesquisas, conseguiu o engajamento de outro
colega, o Dr. Joseph Whiting, que com ele dividiu as visitas às residências das
pessoas que morreram da doença. Ao consolidar os dados levantados, entre 8 de
julho e 5 de agosto de 1853, verificou que houve 334 óbitos, sendo 286 em
residências atendidas pela empresa Southwark e apenas 14 nas atendidas pela
Lambeth, ou uma mortalidade bem mais elevada entre a população atendida pela
Southwark. Continuando com seus estudos, Snow pode verificar que o número de
óbitos foi ainda maior até o final da epidemia, conforme quadro apresentado em
seguida:
População nas áreas de distribuição de água e mortes por cólera, de acordo com a
companhia fornecedora do produto, Londres, 1853/1854.
Fornecimento
de água
População
em 1851
Nº de
mortes
Taxa de letalidade por 10000 habitantes
Southwark 167.654 844 50/10000
Lambeth 19.133 18 9/10000
Área comum 300.113 499 16/10000
Assim, Snow pôde demonstrar que o risco de se contrair o cólera era mais de
cinco vezes maior entre a população servida pela companhia Southwark, que
continuava retirando a água de dentro da cidade de Londres, ao contrário da outra,
Lambeth, que recolhia o produto bem antes da chegada à cidade.
Demonstrou, a partir daí, haver uma relação entre as mortes ocorridas e o
grau de poluição do Rio Tâmisa, de onde as companhias de distribuição de água
coletavam o líquido que era distribuído à população.
Ficou claro, depois do trabalho de Snow, que os esgotos não poderiam
continuar contaminando as fontes de água da população. Sem um tratamento
adequado dos dejetos humanos, a doença jamais seria controlada de forma eficaz. E,
ainda, que a qualidade da água a ser ingerida pelas pessoas, principalmente crianças
e gestantes, deveria ser a melhor possível. Por suas importantes contribuições ao
entendimento de como as epidemias de cólera aconteciam e de como seria possível
preveni-las, Snow é considerado o pai da epidemiologia.
O trabalho de Snow é importante, também, porque na sua época ainda não se
tinha conhecimento do agente causador do cólera, o Vibrio cholerae, que só veio a
ser isolado por Robert Koch em 1883.
Além de ter atuado como epidemiologista, Snow também deu importante
contribuição ao desenvolvimento da anestesia, tendo aperfeiçoado os primeiros
inaladores utilizados na mistura éter-ar, administradas aos seus pacientes. Foi Snow
quem empregou a anestesia durante o parto do oitavo filho da rainha Vitória, o que
contribuiu bastante para que os religiosos passassem a aceitar o emprego de
analgesia em obstetrícia. Até então se dizia que a própria Bíblia exigia que as
mulheres devessem sempre ter seus partos com dor.
A arte moderna de curar
Não há povo sem história ou que possa ser compreendido sem ela.
Eric Hobsbawn
As idéias filosóficas do século XIX
Alguns filósofos foram mais influentes sobre o desenvolvimento da sociedade,
e, principalmente, da ciência no século XIX: Kant, Hegel , Comte, Marx e Nietzsche.
Imannuel Kant (1724 a 1804), um dos mais importantes filósofos modernos,
tinha como princípio que cada homem deveria ser considerado como um fim em si
mesmo, uma forma de apresentar a doutrina dos direitos do homem.
É considerado fundador do criticismo, método de filosofar que consiste em
investigar as fontes das próprias afirmações e objeções e as razões em que elas se
assentam. Dizia Kant47 que “o primeiro passo nas coisas da razão pura, aquilo que
caracteriza a sua infância, é dogmático. O segundo passo é céptico e ajuda à
circunspecção do juízo, impulsionado pela experiência. Mas é necessário um terceiro
passo, o do juízo amadurecido e viril”.
Kant era ardoroso defensor da liberdade, e dizia que “não pode haver nada
pior do que um homem dever estar sujeito à vontade de outro”.
Em seu livro mais importante,
A crítica da razão pura (1781), busca provar
que, embora nada de nosso conhecimento possa transcender a experiência, existe
ainda uma parte do entendimento que não depende dos sentidos. É a capacidade de
formar, criar ou aperfeiçoar conhecimento em virtude da natureza e estrutura da
razão pura, que existe a priori. Este conhecimento abrange não só a lógica e a
matemática, mas ainda muita coisa que não pode ser nela incluída, nem dela
deduzida. No mesmo livro, Kant definia a síntese como o “ato de juntar diversas
representações umas às outras e de conceber sua multiplicidade sob a forma de um
conhecimento único”.
Próximo ao final de sua vida publicou o livro
A Paz Perpétua, onde advoga a
criação de uma federação de Estados livres, que firmassem um acordo para acabar
com a guerra. Segundo Kant, a guerra só poderia ser evitada mediante a instalação
de um governo internacional.
Georg Wilhelm Friedrich Hegel (1770 a 1831) afirmava que nada é
completamente real, exceto o todo. Nada pode ser inteiramente verdadeiro, a menos
que se refira à realidade como um todo.
O todo é chamado por Hegel
O Absoluto e é espiritual.
O Absoluto não é
estático, mas dinâmico, e desenvolve-se de acordo com sua fundamental lei interna:
a dialética.
No texto
Fenomenologia do espírito, formula sua concepção do processo de
formação da consciência como resultado da interação de três elementos básicos, o
que veio, posteriormente, a influenciar outros filósofos:
47 Citado por Johannes Hessen, em Teoria do conhecimento.
1. As relações morais, ou seja, a família e a vida social.
2. A linguagem, ou os processos de simbolização.
3. O trabalho, ou a forma como o homem se relaciona com a natureza para
dela extrair seus meios de subsistência.
A obra de Hegel é tão relevante que influenciou tanto setores de direita –
como quando apóia políticas conservadoras - como de esquerda – quando serve de
inspiração para filósofos como Feuerbach e Marx -, ou na utilização da dialética para
a compreensão da realidade e construção do conhecimento.
Movimento dialético é aquele que se faz segundo uma tese (afirmação), uma
antítese (uma negação) e uma síntese. Por meio do movimento dialético é que o
mundo avança. A dialética hegeliana considera a síntese no sentido de uma etapa de
superação da contradição entre tese e antítese.
Segundo Hegel, a razão é a certeza consciente de ser toda a realidade. Em
sua separação uma pessoa não é totalmente real, mas o que é real nela é a sua
participação na realidade como um todo. À medida que nos tornamos mais racionais,
esta participação vai aumentando.
Para Hegel, o mais importante era o Estado. Ele seria a corporificação da
liberdade racional. Dizia ainda que toda a realidade espiritual, possuída por cada
cidadão, só se viabilizaria por meio do Estado.
A história tem grande relevância para o filósofo alemão, sendo o modo de
compreensão do sujeito um processo essencialmente histórico. Assim cada
consciência é consciência de seu tempo, tendo sido também o primeiro a elaborar
uma filosofia da história.
Auguste Comte (1798 a 1857), filósofo francês, criou o sistema positivista, que
era uma espécie de revolta antimetafísica, ou um ceticismo metafísico. Deveríamos
limitar-nos ao positivamente dado, aos fatos imediatos da experiência, fugindo de
toda a especulação metafísica. Só haveria um conhecimento e um saber, que seria
aquele próprio das ciências. Só a ciência poderia penetrar os aspectos do mundo
acessíveis à experiência. Assim, a filosofia não seria algo diferente da ciência. Seria
apenas a coordenadora dos resultados dos diversos tipos de ciências, procurando
sua harmonização. Segundo Comte, haveria apenas três métodos de filosofar: o
teológico, o metafísico e o positivo. O primeiro seria o ponto de partida da
inteligência humana, o terceiro, seu estado perfeito, e o segundo serviria apenas
como etapa de transição.
Sobre a relação entre filosofia e ciência pode-se dizer que “a ciência deslinda a
difícil essência dos fatos subjacentes aos problemas do mundo e da vida, e a filosofia
esclarecida provê as salvaguardas necessárias para dispersar as ilusões”48.
Marx, como Comte, considerava a metafísica de forma depreciativa, e dizia
que “os filósofos não têm feito até aqui senão interpretar o mundo de diferentes
maneiras; trata-se agora de transformá-lo”. Há quem considere esta alegação de
Marx o marco decisivo na história da teoria política, quando a filosofia se tornou
ideologia. Acreditava que a transformação das sociedades se faz por meio de suas
48 Max Schoen, segundo Leonardo, em History of Medical Thought.
próprias contradições internas, sua análise apoiando-se em duas bases
metodológicas, o materialismo histórico e o materialismo dialético.
Para Marx a história deve ser analisada a partir da infraestrutura (recursos
materiais, econômicos, etc.) e da luta de classes. Não aceita, em consequência, a
interpretação de que a história é feita pela ação isolada de determinadas pessoas,
mas por meio do conflito de interesses considerados antagônicos, como os de senhor
feudal e servo ou de capitalista e proletário.
Nietzsche, considerado “o filósofo do relativismo”, estabeleceu as bases
intelectuais do existencialismo e de um historicismo radical que caracteriza a idade
moderna.
Louis Pasteur e a teoria dos germes
“O cientista criador tem muito em comum com o artista e o poeta. O
pensamento lógico e a capacidade analítica são atributos necessários a um cientista,
mas estão longe de serem suficientes para o trabalho criativo. Aquelas intuições na
ciência que conduziram a grandes avanços tecnológicos não foram, logicamente,
derivadas de conhecimento preexistente: os processos criativos em que se baseia o
progresso da ciência atuam no nível do subconsciente”. Esta afirmação do físico e
biólogo Leo Szilard49 pode, perfeitamente, se adaptar a Pasteur, que sem nenhuma
dúvida foi um dos maiores gênios da humanidade. Nascido na cidade francesa de
Dôle, era filho de um artesão que havia sido sargento no exército de Napoleão.
Patriota, investiu suas energias e, por isto, contribuiu de forma significativa
para resolver problemas práticos de várias indústrias e da agricultura da França.
Dono de uma intuição científica brilhante, desenvolveu pesquisas em várias
áreas. Graduou-se em química e, com 26 anos, estabeleceu a existência da
assimetria molecular em cristais ácidos, como o ácido tartárico.
Em 1856, devido a problemas das indústrias de produção de bebidas da
França, foi chamado para tentar resolver uma questão que lhes estava causando
grandes prejuízos. De tempos em tempos o vinho ou a cerveja azedavam.
Usando seu microscópio, Pasteur observou que, quando a fermentação dos
açúcares se processava normalmente, produzindo álcool, havia formas arredondadas.
Quando o vinho azedava e havia produção de ácido láctico, surgiam bacilos longos.
Descobriu ainda que as formas esféricas eram fungos (leveduras),
responsáveis pela produção do álcool. Com o resultado de suas pesquisas, ficou
provado ser a fermentação conseqüência da ação de microrganismos vivos e não um
evento puramente químico, como se acreditava até então.
Demonstrou que aquecendo o vinho por um curto período, a uma temperatura
entre 55 e 60ºC, morriam os bacilos inconvenientes sem, no entanto, alterar as
propriedades do vinho. Estava descoberta a pasteurização, princípio de desinfecção
ainda hoje utilizado para o tratamento do leite.
Em 1857 percebeu que certos microrganismos não cresciam na presença do
ar, mas somente na sua ausência (anaeróbicos), enquanto outros só se
multiplicavam quando havia oxigênio (aeróbicos). Sua publicação, que recebeu o
49 Citado por Antonio Damásio, em O erro de Descartes.
título
Mémoire sur la fermentation appelée lactique, pode ser considerada um dos
marcos da microbiologia.
Esta descoberta de Pasteur foi extremamente importante para a medicina,
pois levou à conclusão de ser a putrefação uma conseqüência da atividade dos
micróbios, semelhante à que ocorria na fermentação. A partir daí, alguns cirurgiões
passaram a utilizar procedimentos visando à prevenção das infecções pós-
operatórias.
Continuando com seus trabalhos, Pasteur demonstrou a existência de
micróbios no ar. E que estes podiam contaminar líquidos ou sólidos produzindo a sua
deterioração. Se, no entanto, o ar fosse filtrado, ou mesmo se fossem eliminados os
microrganismos, como através da fervura, sem que se permitisse uma nova
exposição ao ar, nada acontecia e nenhum germe era observado.
Por sugestão do também químico Antoine Jêrome Balard, de quem foi
assistente, Pasteur utilizou em suas experiências frascos com “gargalo em pescoço
de cisne”, que permitiam a saída do ar aquecido, sem, no entanto possibilitar a
entrada de novas bactérias e fungos. Isto foi fundamental para refutar, em definitivo,
a teoria contrária à sua.
Com isto, Pasteur demonstrou que a teoria da geração espontânea não tinha
qualquer fundamentação, apesar de ser aceita pela sociedade científica desde
Aristóteles.
Entre 1865 e 1868 ajudou a indústria da seda francesa a eliminar duas
doenças,
pébrine e
flacherie, que estavam causando grandes prejuízos. Demonstrou
o caráter microbiológico das duas e como evitá-las.
Uma das grandes descobertas de Pasteur foi ter percebido que, por meio de
passagens sucessivas em animais de laboratório, ou mesmo apenas em meios de
cultura com variação das condições ótimas de incubação, poderia aumentar ou
diminuir a capacidade dos microrganismos de causar doenças.
Conhecedor deste princípio, dele fez uso para produzir vacinas contra a cólera
das aves, o bacilo do antraz e contra o agente da raiva. Nunca chegou a conhecer o
microrganismo responsável por esta doença(o vírus da raiva só pode ser visto por
microscopia eletrônica), apesar de ter conseguido desenvolver um método capaz de
evitá-la.
Em seis de julho de 1885 aplicou, pela primeira vez, a vacina anti-rábica em
um garoto de oito anos, Joseph Meister, mordido catorze vezes por um cão com
hidrofobia, dois dias antes.
Os pais do garoto pediram a Pasteur que salvasse o seu filho. Ele, então, fez
aplicação no menino de 12 injeções da vacina, com potência crescente,
gradualmente, ao longo de duas semanas.
O garoto sobreviveu, apesar dos receios do cientista. Poucas semanas depois,
apresentou seu relatório sobre a prevenção da raiva na Academia de Ciências de
Paris. Em um ano a vacina foi aplicada em 350 pessoas que haviam sido mordidas,
sem nenhum óbito.
A fama de Pasteur logo se difundiu pela comunidade internacional e o seu
método foi reconhecido como um grande avanço da medicina.
A partir daí recebeu o apoio de toda a sociedade francesa e mundial pelo
conjunto de sua obra, de tanto significado para a humanidade.
Recebeu doações de vários países, o que lhe permitiu criar o Instituto Pasteur,
em Paris, de onde surgiram várias gerações de grandes cientistas, que, como ele,
muito contribuiu para o progresso da ciência.
Pasteur morreu em 1895, e a admiração que recebe dos franceses, até hoje,
não tem paralelo com nenhum outro personagem da história da França.
Em 1940, o mesmo Joseph Meister, que havia sido vacinado quando tinha oito
anos de idade, era o curador do Instituto Pasteur, em Paris.
Quando os alemães, durante a Segunda Guerra Mundial, exigiram as chaves
do mausoléu construído em homenagem ao fundador do Instituto, Meister se
suicidou por não aceitar que alguém viesse a violar o túmulo do grande herói de sua
pátria e a quem ele devia a própria vida.
Charles Darwin e a teoria da evolução
Filho de ingleses, Charles Robert Darwin nasceu em Shrewsbury, Inglaterra,
em 12 de fevereiro de 1809. Aos oito anos perdeu a mãe. O pai, que era médico,
assim como o seu avô paterno, convenceu-o a estudar medicina na Universidade de
Edimburgo, mas o que o encantava mesmo era o estudo de plantas e animais.
Deixou o curso de medicina por não ver nesta carreira nada que lhe interessasse.
Bacharelou-se em Artes, em janeiro de 1831, em Cambridge. A leitura do
volumoso texto de Humboldt (
Narrativa Pessoal, com sete volumes e 3754 páginas),
em que relata sua viagem à América do Sul, causou forte impressão em Darwin. A
partir daí, passa a querer viajar por todo o planeta, especialmente em regiões ainda
pouco exploradas, onde, segundo Humboldt, “deveriam existir novas espécies de
plantas e animais ainda desconhecidas”.
Em 1831, aos 22 anos, foi escolhido para ser o naturalista do navio Beagle,
que passaria cinco anos viajando ao redor do mundo. Era uma pequena embarcação,
com 27 metros de comprimento, por 7,5 metros de largura, possuindo dez canhões
de bronze e 73 tripulantes.
O principal continente estudado foi a América do Sul, principalmente o
arquipélago de Galápagos, próximo à costa do Equador.
Esteve no Brasil, durante o ano de 1832, tendo visitado Salvador e o Rio de
Janeiro. Por onde passava descrevia espécies, observava a natureza, relevo e clima.
Anotava tudo o que encontrava.
Depois de cinco anos de viagem, e vários cadernos de anotações, ficou algum
tempo refletindo sobre o material que tinha coletado. Foi a doutrina da população de
Malthus50 -
Essays on population - estendida ao mundo das plantas e dos animais,
que o leva à conclusão de suas pesquisas que resultaram no livro
A origem das
espécies, publicado em 1859.
Sua teoria se baseia, fundamentalmente, na evidência de que na batalha pela
vida só os mais bem adaptados sobrevivem, o que o levou a desenvolver a tese da
seleção natural. E, ainda, que é o meio ambiente o principal estímulo para a seleção
natural, ou seja, a superpopulação e a competição (pelos alimentos, pelo parceiro
sexual, pela liderança do grupo, etc.) conduziriam a uma seleção natural, onde os
50 Considerado por John Maynard Keynes o primeiro economista da história.
mais bem adaptados ao meio ambiente emergiriam como os vitoriosos da “guerra da
natureza”. Ou ainda resumindo, poderíamos dizer que apenas os membros mais
aptos de cada espécie sobrevivem aos elementos gradualmente modificáveis do
ambiente. Eles se adaptam às mudanças, enquanto os mais frágeis – ou menos
aptos - não o conseguem.
Ele descartava a idéia anterior de que as espécies eram fixas, e que animais e
plantas foram originalmente criados como os encontramos atualmente.
A aplicação da sua teoria pôs um fim na teoria antropocêntrica, de que o
universo foi criado para o homem. Representou para o século XIX o mesmo que
Galileu para o século XVII.
Darwin constatou que a natureza vive em contínua transformação, que as
espécies evoluem e que o aparecimento de novas espécies resulta de uma
descendência com modificações.
Desta forma, a sobrevivência ou não da prole dependeria das características
do meio, e nisto residiria a importância da seleção natural. Só os dotados de novos
caracteres permaneceriam, enquanto aqueles que não os tivessem seriam extintos.
Acreditava, ainda, haver uma participação significativa da seleção sexual, que
também contribuiria para que os mais bem adaptados sobrevivessem.
Apesar de inicialmente não ter considerado importante a contribuição de Jean
Baptiste Lamarck, que o precedeu na teoria evolucionista, ou que as diferentes
formas de vida se haviam desenvolvido gradualmente, partindo de uma origem
comum, nas edições posteriores de seu grande livro Darwin fez o devido
reconhecimento àquele cientista.
Lamarck acreditava, erradamente, que as variações produzidas pelos efeitos
do uso e desuso de determinados órgãos (a função faz o órgão) em resposta a
estímulos externos (primeira lei), e pela herança direta destas alterações (segunda
lei), contribuiriam para a hereditariedade dos caracteres adquiridos e, em
conseqüência, para a seleção dos mais habilitados.
O exemplo clássico da lei do uso e desuso é “o pescoço das girafas que
cresceu para que elas pudessem se alimentar das folhas das altas árvores da região
em que viviam”.
Em parte por ainda não existir conhecimento sobre genética em sua época, a
teoria de Darwin não contemplou as possibilidades que as mutações poderiam
acrescentar para a seleção natural. E, ainda, que muitas características das espécies
de animais e de plantas não necessariamente teriam algum valor para a sua
sobrevivência, mas seu trabalho teve profunda significação em várias áreas do
conhecimento, e, especialmente, para as ciências biológicas.
Entre as conseqüências da teoria da evolução para o desenvolvimento da
biologia pode-se citar a pesquisa para tentar encontrar novas drogas contra bactérias
multiresistentes, ou o melhoramento genético de grãos para se encontrar mudas que
sejam mais resistentes a pragas.
Atualmente sabemos, por meio de estudos de genética molecular, que somos
mais parecidos com os chimpanzés (a diferença entre os dois tipos de ADN é inferior
a 1%) do que imaginávamos. Enquanto isto, a diferença entre o ADN dos
chimpanzés e dos gorilas é de 3%, ou cerca de três vezes maior. É possível que os
humanos e os chimpanzés tenham tido um ancestral comum há cerca de cinco
milhões de anos51.
Claude Bernard (Um grande fisiologista e bioquímico)
Claude Bernard nasceu em 1813, na França, na vila de Saint Julien. Seu pai
produzia vinhos caseiros, mas acabou falindo e ficando com muitas dívidas. Por isto,
com a idade de 16 anos Claude Bernard arrumou um emprego, em Lion.
Seu patrão, o Sr. Millet, era farmacêutico e um dos medicamentos que
preparava era a chamada teriaga. Essa mistura de vários e surpreendentes
componentes (algumas vezes até com mais de cem substâncias),era usada como se
fosse uma panacéia, o que fez com que o jovem funcionário duvidasse da arte de
curar de sua época.
Com 19 anos resolve mudar de vida e, demonstrando pretensões literárias,
embarca para Paris levando em sua mala uma peça de teatro em cinco atos.
Lá, procura um famoso crítico, o Sr. Saint Marc Girardin, a quem entrega o
manuscrito. Para sua surpresa, este lhe diz o seguinte: “Meu caro, a literatura não é
um ofício com o qual se ganha o pão. Posso dizer que tive mais êxito que muita
gente, mas se pudesse voltar atrás, eu me matricularia na faculdade de medicina.
Faça o senhor o que eu deveria ter feito”.
Claude Bernard atendeu ao conselho do crítico literário e logo depois começou
a estudar medicina. Após a formatura passou a trabalhar no Hôtel-Dieu, de Paris,
com François Magendie, um dos grandes fisiologistas da época. Este não tinha, no
entanto, o talento e o brilhantismo de seu discípulo, que superou o mestre com
inúmeros trabalhos de enorme importância para as ciências da saúde.
Bernard desenvolveu uma série de pesquisas, especialmente na área do
metabolismo e fisiologia. Descreveu a importância do glicogênio do fígado na
regulação da glicose sangüínea. O glicogênio é uma reserva de glicose do organismo.
Sempre que o nível sangüíneo de açúcar diminui, o fígado libera glicose para a
circulação, a partir do glicogênio.
Fez ainda trabalhos sobre o sistema nervoso simpático (o responsável, entre
outras coisas, por aumentar as batidas do nosso coração), descreveu a importância
da secreção do pâncreas na digestão dos alimentos(gorduras, açúcares e proteínas)
e desenvolveu estudos nas áreas de farmacologia e toxicologia.
No entanto, o principal conceito biológico que Claude Bernard desenvolveu foi
descrever a tendência do organismo a manter o equilíbrio do meio interno, mesmo
que as condições externas sejam adversas. As nossas glândulas, através de seus
hormônios, atuam no sentido deste equilíbrio, a homeostase.
Claude Bernard morreu em 1878, após ter dedicado quarenta anos de sua
vida à pesquisa em laboratório. Suas descobertas ultrapassaram o seu próprio
tempo.
51 Kevin Davies, em Decifrando o genoma.
A morte da dor
Antes da descoberta dos anestésicos inalatórios, os cirurgiões usavam,
excepcionalmente, a intoxicação pelo álcool, haxixe ou mesmo o ópio, tomado pela
boca, para casos em que se necessitasse de um completo relaxamento muscular.
A norma, no entanto, eram as cirurgias sem qualquer tipo de anestesia.
Alguns ainda tentavam o hipnotismo ou ainda o mesmerismo (ou sugestão).
Há relatos de cirurgias de emergência, como em amputações de um membro
em conseqüência de fratura exposta, em que eram utilizados métodos físicos, como
colocar o membro em gelo ou até mesmo produzir isquemia, com o uso de um
torniquete.
Houve, ainda, casos em que a produção de inconsciência foi provocada por
uma pancada na cabeça ou por meio de estrangulamento, o que atenuava a
produção da dor mesmo que a um alto custo para o paciente.
Entretanto, o método mais empregado para se conseguir um campo cirúrgico
relativamente tranqüilo era, simplesmente, a contenção do paciente pela força. Não
é preciso muita imaginação para perceber que a cirurgia fosse vista, então, como o
último recurso no tratamento dos doentes.
Nos Estados Unidos da América, Crawford W. Long persuadiu um jovem,
James M. Venable, a inalar éter sulfúrico enquanto retirava um pequeno tumor de
seu pescoço - um cisto sebáceo infectado - em 30 de março de 1842. A cirurgia teve
três testemunhas: Andrew Thurmond, William Thurmond e Edmund Rawls.
Seus conhecimentos sobre os efeitos da droga vinham de seu tempo de
estudante, por meio de demonstrações feitas por professores de Química com seus
próprios alunos.
Long continuou usando o éter em várias outras cirurgias, porém a comunidade
científica nada sabia sobre o episódio, até que o fato fosse relatado em artigo
publicado em 1849, no
Southern Medical and Surgical Journal, onde Long afirmava
ter aplicado éter a alguns pacientes em seu consultório, na pequena cidade de
Jefferson, em Atlanta, durante o ano de 1842.
O óxido nitroso foi sintetizado por Priestley em 1776, mas apesar de se saber
de suas propriedades anestésicas desde 1796, nunca havia sido utilizado em
cirurgias. Seu uso se restringia à produção de euforia, como um lança-perfume que
era usado nos carnavais de antigamente.
Enquanto assistia a uma espécie de show circense onde as pessoas inalavam
o óxido nitroso para provocar risos, em 10 de dezembro de 1844, o dentista Horace
Wells percebeu que um dos que havia inalado o gás tinha machucado gravemente a
perna, sem, no entanto, manifestar ter sentido qualquer tipo de dor.
Rapidamente chegou à conclusão do significado deste achado. No dia
seguinte, Wells, que além de dentista era estudante de medicina, teve um dos seus
próprios dentes extraído, por um assistente, sem dor. Quem aplicou a anestesia com
o óxido nitroso foi o responsável pelo show, Gardner Colton.
A partir daí, Wells passou a transmitir a boa notícia pelo mundo afora. No
entanto, em uma de suas demonstrações do poder anestésico do gás fracassou,
provavelmente porque o tempo de indução da anestesia foi muito breve, ou porque a
dose do anestésico foi pequena.
Um de seus alunos, William T. Morton, que presenciou a tentativa fracassada
do mestre, aprendeu com Charles Jackson, um médico e químico internacionalmente
conhecido, o poder anestésico do éter sulfúrico. Depois de experimentá-lo em
animais, em 30 de setembro de 1846, em seu consultório, na cidade de Boston, fez
uma extração dentária em um de seus clientes, sem dor.
Logo o fato foi bastante divulgado e, em 16 de outubro de 1846, Morton
anestesiou, usando uma espécie de máscara inalatória rudimentar, Edward Gilbert
Abbott, enquanto John Collins Warren, um famoso cirurgião do Massachussets
General Hospital, fazia a extração de um tumor vascular do pescoço do paciente.
Ao final da cirurgia, sem que o paciente tivesse manifestado ter sentido
qualquer tipo de dor, Warren disse para os estudantes que haviam assistido a
operação: “Cavalheiros, isso não é uma farsa”.
Em 16 de novembro de 1846, o feito foi anunciado em um artigo publicado no
Boston Medical and Surgical Journal.
Morton tentou patentear o uso do éter como anestésico, mas acabou não o
conseguindo.
Após a introdução do éter, seguiram-se novas experiências utilizando o
clorofórmio, principalmente na clínica obstétrica. Quem primeiro utilizou este
anestésico em obstetrícia foi o médico escocês James Young Simpson, que também
foi o pioneiro no uso do éter para aliviar a dor do parto, em uma experiência ocorrida
em 19 de janeiro de 1847, em uma paciente que estava sofrendo dores violentas,
durante um parto muito complicado.
Posteriormente se verificou que o clorofórmio é tóxico para o fígado e produz
severa depressão cardiovascular. Sua única vantagem sobre o éter é o fato de não
ser inflamável. Mesmo assim foi muito utilizado, por quase cem anos, principalmente
na Grã-Bretanha.
O efeito da descoberta dos anestésicos foi fundamental para o
desenvolvimento das especialidades cirúrgicas. Antes o cirurgião tinha que ser
extremamente rápido, além de raramente o paciente se encontrar relaxado e sem
demonstrar grande sofrimento, o que dificultava bastante o desenvolvimento das
habilidades dos cirurgiões.
As vidas envolvidas na descoberta do uso cirúrgico dos anestésicos não
tiveram um desfecho feliz.
Wells viciou-se em clorofórmio e suicidou-se em 1848, na prisão de Tombs.
Charles Jackson morreu aos 75 anos, em 1880, num hospício de Sommerville, onde
viveu por sete anos. Long não teve reconhecimento pela primazia no uso da
anestesia em cirurgia e morreu empobrecido, depois da guerra civil norte-americana.
Morton faleceu em 1868, de uma crise cardíaca, pobre e amargurado por não ter
conseguido patentear o uso do éter e nem do aparelho que inventara para inalação
do anestésico.
Um monumento erguido pelos cidadãos de Boston sobre a sepultura de
Morton, em um cemitério próximo à cidade, tem os seguintes dizeres em sua lápide:
Inventor e divulgador da anestesia inalatória
Antes dele, em todos os tempos, cirurgia era agonia
83Por meio dele a dor em cirurgia foi evitada e anulada
Desde então a ciência passou a controlar a dor
Rudolph Virchow (E a patologia celular)
Formado em medicina, em Berlim, em 1843, Virchow fundou a revista
Arquivos de Anatomia Patológica, em 1847.
No seu primeiro trabalho publicado neste periódico, dizia que uma hipótese
não provada, de qualquer tipo, representava o mesmo que um barco muito frágil
para velejar, e descartava a noção de que qualquer homem fosse infalível a respeito
de julgamento ou de conhecimento.
Pessoa de grande cultura e variados interesses, Virchow atuou em áreas tão
díspares como anatomia, patologia, epidemiologia, saúde pública, antropologia,
arqueologia, magistério e política.
Em 1849, ao investigar uma epidemia de tifo no interior da Alemanha, ficou
muito impressionado com o que viu. Em seguida, publicou um relato indignado das
condições miseráveis em que os trabalhadores viviam. Isto lhe custou o emprego,
mas não arrefeceu a sua capacidade de luta. Pelas suas posições liberais foi eleito
parlamentar, junto ao Reichstag, no período de 1890 a 1893.
Em medicina desenvolveu a teoria da patologia celular - “toda célula provem
de outra célula” -, que dizia que o local da doença deveria ser procurado na célula,
enquanto as alterações macroscópicas e microscópicas do organismo eram
conseqüência da reação das células às causas de cada doença.
Cada parte do corpo doente mantinha uma relação parasítica com o resto do
corpo sadio ao qual pertence, e que viveria às custas do organismo. Este conceito é
correto, especialmente nas doenças crônico degenerativas, como o câncer.
A doutrina da patologia celular, descrita pela primeira vez em 1858, era
baseada no estudo de estruturas vivas e da observação de que a aparência
microscópica de células vivas se modificava profundamente com a doença.
Se admitirmos que a vida com saúde seja decorrência do funcionamento
normal das células, incluindo o seu metabolismo, é razoável acreditar que alterações
no funcionamento e na forma destas células levem o corpo a adoecer. Neste caso o
organismo ficaria doente desde um estágio subclínico (onde ainda não apareceriam
sinais e sintomas da doença) até o estágio clínico (onde já existiriam manifestações
clínicas da enfermidade).
Ao fazer 80 anos, Virchow recebeu um prêmio de 80 mil marcos, além de uma
medalha de ouro oferecida pelo imperador da Alemanha, em reconhecimento à sua
grande contribuição ao desenvolvimento da ciência.
Morreu em 1902, quando então foi dado o seu nome ao maior hospital de
Berlim.
Robert Koch (Fundador da Bacteriologia)
Um dos treze filhos de um supervisor de minas da Alemanha, Koch nasceu em
1843, e se formou em medicina em Göttingen, tendo sido aluno de Jacob Henle,
considerado um dos responsáveis pelo desenvolvimento da teoria do contágio52.
Atuou como oficial médico durante a guerra franco-prussiana. Depois, em 1872, foi
para uma pequena cidade, Wollstein, próxima à fronteira com a Polônia.
Lá, isolado da comunidade científica, e trabalhando em um laboratório
improvisado, separado do consultório por uma cortina, Koch desenvolveu uma série
de pesquisas que revolucionaram a bacteriologia e, em decorrência, a medicina.
Seu microscópio foi presente de aniversário dado por sua mulher.
Desenvolveu um método primitivo de fazer microfotografias, de boa qualidade, e
improvisou uma estufa de incubação.
Em sua época, os meios de cultura usados em bacteriologia eram líquidos, o
que dificultava enormemente o isolamento bacteriano.
Para tornar viável trabalhar com um só tipo de bactéria de cada vez, Koch
resolveu acrescentar gelatina ao meio e, com isso, começou a aprimorar a sua
técnica. Depois passou a usar o agar, o que permitia solidificar os meios de cultura à
temperatura ambiente, sem comprometer a viabilidade dos microrganismos com que
trabalhava.
Com este grande passo, Koch passou a isolar várias bactérias causadoras de
quadros infecciosos. Desenvolveu estudos com o bacilo do antraz, com o bacilo
causador de septicemia hemolítica e, em 1878, publicou os resultados onde, pela
primeira vez, demonstrou que a causa de seis diferentes doenças em animais eram
seis bactérias distintas. E que apenas uma forma de bactéria era encontrada em
cada doença.
Por estes estudos foi agraciado com um alto posto e um laboratório no
Departamento de Saúde Imperial, em Berlim, além de ganhar o apoio de dois
assistentes.
Sabe-se, hoje, que ainda em Wollstein, trabalhou no desenvolvimento do
microscópio, junto com Ernst Abbe e Carl Zeiss, tendo sido o primeiro cientista a ter
um microscópio equipado com o condensador de luz e a lente de imersão
desenvolvida pelos dois excepcionais peritos ópticos. Esta inovação foi de extrema
importância para o desenvolvimento dos trabalhos de Koch, por permitirem visualizar
estruturas bacterianas que nenhum outro instrumento permitia à época.
A partir daí, suas pesquisas puderam se desenvolver mais rapidamente. Novos
métodos de coloração e novas técnicas de isolamento vieram a permitir que
visualizasse o bacilo da tuberculose, pela primeira vez em 1882, a partir de culturas
desenvolvidas no sangue de carneiros.
Sua descoberta foi apresentada em Berlim, em 24 de março de 1882, em
reunião científica que deixou perplexa toda a platéia constituída pelos médicos mais
famosos da Alemanha.
Publicou, neste mesmo ano, os resultados obtidos na revista da Sociedade
Fisiológica de Berlim, onde incluiu também seus postulados para se considerar um
determinado agente como causador de uma dada doença infecciosa:
1. Que o microrganismo seja sempre encontrado na doença.
2. Que o microrganismo não seja encontrado em outras doenças, ou ainda na
saúde.
52 Publicou o livro Pathologische Untersuchungen, em 1840, onde reformula as idéias de seus
predecessores.
3. Que o microrganismo seja cultivado artificialmente e reproduza a doença em
questão, depois de inoculada uma cultura pura do agente em um animal
susceptível.
4. Que o microrganismo possa ser recuperado do animal assim inoculado.
Assim como Pasteur, era um patriota. Por diversas vezes os dois, junto com os
respectivos assistentes, disputaram o privilégio das descobertas da nova ciência
que ajudaram a criar.
No caso do cólera, Koch foi o vencedor. Em 1883, fazendo pesquisas em uma
epidemia que ocorreu no Egito, foi o primeiro a isolar o Vibrio cholerae.
Em 1888, Koch e sua mulher Emmy se separaram, devido à pouca atenção
que ele lhe dispensava. Voltou a se casar novamente em 1893, com uma jovem e
bela estudante de arte de 21 anos, Hedwig Freiburg, por quem se apaixonara ao
vê-la em um retrato pintado por um artista.
Seu maior fracasso, no entanto, ocorreu durante o X Congresso Médico
Internacional, em 1890, quando anunciou a tuberculina (o atual PPD) como a cura
da tuberculose. Apesar de ainda hoje ser utilizada como teste de avaliação da
imunidade ao bacilo, a tuberculina não poderia ser considerada como uma arma
terapêutica, conforme logo se demonstrou.
Em 1905 Koch recebeu o prêmio Nobel de medicina. Morreu em 1910 como um
dos fundadores da bacteriologia, junto com Pasteur.
As conseqüências dos avanços na bacteriologia, fisiologia e patologia
O surgimento da bacteriologia levou a uma nova era da medicina. O clínico e o
cirurgião foram forçados a fazer grandes mudanças na sua maneira de pensar e
de raciocinar sobre as doenças, suas causas, seus sintomas e seus planos de
tratamento.
Também a teoria da patologia celular contribuiu para as grandes mudanças
ocorridas na medicina durante o século XIX.
Influenciaram de forma importante os conceitos de etiologia, nosologia e
imunologia das doenças.
O estudo da célula nos deu a conhecer que era na esfera do mundo
microscópico que estariam as soluções para os problemas médicos mais
importantes.
As novas descobertas da fisiologia e da bioquímica (além de outras áreas
básicas) trouxeram a convicção que era nas pesquisas desenvolvidas nos
laboratórios, e não na clínica, que estaria a base do progresso da medicina.
Com o desenvolvimento considerável da ciência, houve a tendência à
especialização, já que se tornou cada vez mais difícil reter tantas, e cada vez mais
freqüentes novas informações, sobre tantos e tão variados campos do
conhecimento científico.
O clínico geral, que dominaria todos os campos da medicina, foi se tornando
cada vez mais raro.
Gregor Johann Mendel(Fundador da genética)
Filho de camponeses nasceu na Áustria, em 1822. Formou-se padre em 1847.
Quatro anos depois, foi para a universidade de Viena estudar física, matemática e
ciências naturais. De volta ao convento onde se formara, em Brünn, na República
Tcheca, começou a se dedicar às suas famosas experiências de cruzamento entre
diferentes variedades de ervilhas, por meio das quais conseguiu descobrir as
primeiras leis da hereditariedade.
Hoje se sabe que os caracteres encontrados nas diferentes variedades de
ervilhas são definidos por segmentos do ácido desoxirribonucleico (ADN), e
denominados de genes.
O gene é a unidade hereditária que é transmitida à prole por cada genitor, e
que será responsável pelo surgimento de um determinado caráter ou
característica no filho, junto com o gene do parceiro.
Em organismos superiores, os genes ocorrem em pares. Os genes são unidos
dentro de uma estrutura maior, o cromossomo. Existem alternativas de um gene,
que são chamados alelos. Os alelos ocupam a mesma posição em cromossomos
homólogos.
Leis de Mendel:
Lei da dominância: nos híbridos, um dos caracteres opostos, ou alelos, domina
mascarando em determinada proporção o outro, que é recessivo.
Lei da segregação dos caracteres: as características opostas dos ascendentes
se dissociam, nas gerações seguintes, segundo proporções fixas, ou seja, 25% de
dominantes puros, 50 % de dominantes híbridos e 25% de recessivos puros.
Lei da independência dos caracteres: no cruzamento de raças ou variedades
que diferem por mais de uma característica, cada característica se transmite de
maneira independente das demais.
Publicados em 1865, na revista da Sociedade de Naturalistas de Brünn, os
trabalhos de Mendel passaram despercebidos até 1900, quando os botânicos
Hugo de Vries, Carl Correns e Erik Tshermak von Seysenegg, de forma
independente, chegaram às mesmas conclusões que ele.
Mendel morreu no convento de Brünn, em 1884, sem ter recebido de seus
contemporâneos o reconhecimento que merecia.
Entre 1912 e 1926, Thomas H. Morgan, da Universidade de Columbia,
promoveu grande desenvolvimento da genética utilizando experiências de
cruzamento com moscas de frutas, da espécie Drosophila melanogaster.
O seu ciclo de vida é curto (em torno de doze dias) e fecundo (mil ovos em
média). As moscas podem ter olhos brancos ou vermelhos, sendo a característica
branca ligada ao cromossomo X, e de caráter recessivo, vindo a aparecer
principalmente em machos, de forma semelhante ao que ocorre com o
daltonismo em humanos.
Possuem quatro pares de cromossomos, incluindo um par de cromossomos
sexuais. Analisando os resultados dos cruzamentos das moscas, Morgan pôde
construir um mapa físico de cada cromossomo, mostrando a localização relativa
de cada gene.
Em 1933, Morgan veio a receber o prêmio Nobel de medicina, e um de seus
alunos, Muller, pelos trabalhos de indução de mutações, em Drosophila, com o
uso de raios X, veio a receber o mesmo prêmio em 1946.
Atualmente, sabemos que o ADN contido no total das 100 trilhões de células
do corpo humano, se estendido de uma ponta à outra, equivaleria a 40 vezes a
distância da Terra ao Sol, apesar de que em cada uma de nossas células o ADN
encontra-se condensado em um núcleo com cerca de 0,005 milímetros de
diâmetro.
A arte de curar no Brasil no século XIX
A vinda da família real portuguesa para o Brasil teve boas conseqüências
também para a evolução da medicina. Por insistência do Dr. José Corrêa Picanço,
primeiro cirurgião da corte, D. João VI criou, em 1808, em Salvador(18 de
fevereiro), e depois no Rio de Janeiro(2 de abril) as primeiras academias
médico-cirúrgicas do país. Antes, quem queria seguir esta carreira tinha que
estudar em Coimbra ou em outra faculdade européia.
Picanço, um dos dois brasileiros que lecionavam na faculdade de medicina de
Coimbra (o outro era José Francisco Leal, professor da cadeira de Matéria Médica
e Farmácia), tinha a cadeira de anatomia sob sua responsabilidade. Mais tarde
veio a se tornar barão de Goiana, como prêmio por sua contribuição à Coroa
portuguesa.
O curso durava cinco anos, tinha as disciplinas de anatomia, química,
fisiologia, higiene, etiologia, patologia, terapêutica, operações, obstetrícia e clínica
médica. Ao final do curso, o aluno recebia o título de cirurgião-aprovado.
Em 1832, D. Pedro II transformou as academias em faculdades de medicina, e
o curso passou a ser de seis anos, com um currículo mais aprimorado. As
matérias então ensinadas eram as seguintes:
1) Física médica.
2) Botânica médica e algumas noções de zoologia.
3) Química médica e algumas noções de mineralogia.
4) Anatomia geral e descritiva.
5) Fisiologia e higiene.
6) Patologia externa e clínica externa.
7) Patologia interna e clínica interna.
8) Anatomia topográfica, medicina operatória e aparelhos.
9) Matéria médica geral e, especialmente a brasileira, farmacologia e
terapêutica.
10) Medicina legal, aplicação das ciências médicas à legislação.
11) Partos, doenças de mulheres e de meninos.
12)História da medicina, metodologia ou exposição dos diversos sistemas
médicos e explicação dos aforismos de Hipócrates.
O internato ocorria nos dois últimos anos do curso, sendo que a história da
medicina era dada apenas durante o sexto ano.
Ao final do curso, depois de defender tese sobre tema clínico ou cirúrgico, o
aluno recebia diploma de doutor em medicina.
Os cursos eram eminentemente teóricos, com falta de material didático e de
instalações adequadas.
A partir do século XIX, a França passa a exercer maior influência sobre as
nossas ciências, assim como sobre a literatura, comércio e costumes em geral.
Esta ascendência predominou até a metade do século XX, quando a cultura
americana passou a exercer a liderança que mantém até os dias de hoje.
A criação dos laboratórios de saúde pública no Brasil
O exemplo de Pasteur com a criação do seu Instituto, em Paris, voltado para a
pesquisa de doenças infecciosas e parasitárias, teve desdobramentos em vários
países. Muitos pesquisadores foram formados naquele centro e, ao retornarem,
criaram institutos similares.
No Brasil, o Laboratório Bacteriológico, que depois viria a se chamar Instituto
Adolfo Lutz em homenagem ao seu primeiro diretor, foi criado em S. Paulo, em
1892. Lutz formou-se em medicina em Berna, na Suíça, tendo feito cursos de
aperfeiçoamento em várias cidades européias. De 1889 a 1892 foi responsável
pelo tratamento da hanseníase, no Havaí.
No Rio de Janeiro foi criado, na mesma época, o Instituto Soroterápico do Rio
de Janeiro, com sede na Fazenda de Manguinhos. Para dirigi-lo o prefeito indicou
o Barão de Pedro Afonso. Logo após assumir a direção, o barão viajou até Paris
com o propósito de contratar um cientista do Instituto Pasteur para ser o seu
responsável técnico.
Lá, ficou surpreso ao saber por Émile Roux, que sucedeu a Pasteur na direção
do Instituto, da existência, no Brasil, de um pesquisador que preenchia
totalmente as condições. Voltando ao Rio, o barão contratou o Dr. Oswaldo Cruz,
que havia permanecido de 1896 a 1899 no Instituto Pasteur, onde foi aperfeiçoar
seus conhecimentos, especialmente em bacteriologia.
A sede do Instituto foi concluída no ano de 1900. No famoso palácio em estilo
mourisco fica, ainda hoje, a administração da instituição.
Em 1902, Oswaldo Cruz assumiu a direção geral do instituto, que passou a
sofrer considerável expansão, contratando uma equipe de jovens pesquisadores
de grande capacidade, como Carlos Chagas e Adolfo Lutz. Lutz deixou São Paulo
em 1908 para trabalhar em Manguinhos, até morrer em 1940.
Em Belém foi fundado, em 1936, o Instituto de Patologia Experimental do
Norte. Em 1940 passou a se denominar Instituto Evandro Chagas, em
homenagem ao seu diretor à época, filho de Carlos Chagas, que assim como seu
ilustre pai foi um grande pesquisador de doenças tropicais, tendo morrido aos 35
anos de idade, em um acidente aéreo. O Instituto Evandro Chagas é hoje, em
virologia e outras áreas de medicina tropical, uma das principais referências da
América Latina.
Joseph Lister (A antissepsia e a assepsia em cirurgia)
-Meu marido ficará tão contente! – repetiu Agnes Lister, várias vezes, ao
visitante estrangeiro. Os colegas dele são de uma indiferença... Todos acreditam
que as condições vigentes nos hospitais vêm de Deus, ou da natureza, e que não
se deva mudar nada. Outros não vêem nenhum meio senão arrasar os hospitais,
como se estes fossem os culpados de toda a mortandade53.
O visitante era um cirurgião alemão, Henrich Hartmann, que soubera das
experiências de Lister, em 1865, adotadas logo após ter tido conhecimento dos
trabalhos de Pasteur sobre a putrefação causada pelas bactérias anaeróbicas.
Joseph era filho de um comerciante de vinhos da Inglaterra, Joseph Jackson
Lister, que usava suas horas de lazer para resolver problemas de óptica, sendo
dele vários aperfeiçoamentos das lentes acromáticas, lentes que transmitiam a
luz sem fragmentá-la em suas cores componentes, e que levaram a um grande
desenvolvimento dos microscópios.
Lister formou-se em medicina, em Londres, em 1852. Em 1856 casou-se com
Agnes, filha mais velha do Prof. James Syme, com quem aprendeu cirurgia em
Edimburgo, Escócia.
Naquele tempo acreditava-se que havia o pus saudável, depois das cirurgias.
Os cirurgiões acreditavam que a presença de secreção purulenta ajudava na
cicatrização das feridas.
Lister, no entanto, baseado em suas próprias estatísticas, estava
impressionado com as altas taxas de mortalidade. Nas cirurgias de amputação,
45% dos pacientes morriam, e em outros tipos de operações as taxas também
eram altíssimas. Abrir o tórax e o abdômen, então, era o mesmo que morte certa.
Começou, a partir daí, a procurar meios de diminuir este flagelo.
Em 1863, toma conhecimento dos trabalhos de um químico francês, Jules
Lemaire, que publicou um livro sobre o valor médico do ácoido carbólico (fenol) e
daí passou a vaporizar a sala cirúrgica com este desinfetante, ao mesmo tempo
em que o utilizava no campo operatório e o embebia nos curativos de linho que
aplicava após as cirurgias.
Também era extremamente exigente com a limpeza, desde as salas de
cirurgia até as enfermarias. Com o bisturi usava a flambagem (esterilização pelo
calor de uma chama), por sugestão do próprio Pasteur. Geralmente os cirurgiões
limpavam o bisturi no seu avental, além de usarem o mesmo bisturi para diversos
pacientes.
O que Lister não tinha, assim como os demais médicos de sua época, era o
conhecimento de que as bactérias causadoras das infecções cirúrgicas, na maioria
das vezes, eram da própria microbiota normal da pele dos pacientes. O uso do
fenol eliminava estes germes, atuando como antisséptico, e por isso as infecções
não se desenvolviam.
Os resultados de Lister foram muito satisfatórios, com queda acentuada da
taxa de mortalidade pós-operatória, sendo seus dados publicados em 1867, na
revista Lancet, com o título
On a new method of treating compound fractures,
abscess, etc., with observations on the conditions of suppuration.
Em 1869 sucedeu a seu sogro como professor de cirurgia, em Edimburgo. Em
1877, assumiu a cátedra de cirurgia na universidade de Londres e, em 1897,
tornou-se o primeiro médico a ter assento na Câmara dos Lordes.
Morreu em 1912, sendo os seus restos mortais mantidos até hoje na abadia
de Westminster, assim como Newton.
53 Thorwald, em O século dos cirurgiões.
Apesar de no início ter sido muito criticado, em alguns anos o seu método da
antissepsia e de assepsia passaram a ser adotados por todos os cirurgiões. Como
desdobramentos do trabalho de Lister, pode-se citar a introdução da esterilização
dos aventais cirúrgicos pelo calor úmido (autoclave), em 1886, pelo alemão Ernst
von Bergmann, e a introdução das luvas de borracha esterilizadas, em 1890, pelo
cirurgião americano William Halsted.
Halsted desenvolveu as luvas de borracha para proteger as mãos da
enfermeira que o assistia na sala de cirurgia, e que depois veio a se tornar sua
esposa. Ele também foi o primeiro a empregar a cocaína como anestésico local,
tendo se tornado viciado nesta droga, o que acabou por comprometer a sua
brilhante carreira de cirurgião. Em 1899 a droga foi substituída pela novocaína,
não tendo sido mais empregada com finalidades anestésicas.
O início da odontologia científica
Em 1563, Bartolomeus Eustachius publicou um livro com trinta capítulos,
contendo estudos anatômicos dos dentes, onde afirmava, pela primeira vez, que
os dentes permanentes tinham a sua própria origem, e não tinham as mesmas
raízes dos dentes de leite, como se acreditava à época.
Ambroise Paré, o famoso médico militar francês do século XVI, deu uma
importante contribuição para o desenvolvimento da cirurgia oral ao introduzir
próteses de ouro ou prata para o fechamento de defeitos do palato.
Até o século XVIII, a odontologia era praticada somente pelos cirurgiões-
barbeiros, cirurgiões diplomados e práticos de toda espécie. A atividade
profissional se resumia à extração de dentes cariados, quase exclusivamente.
A partir do livro do médico francês Pierre Fauchard,
O cirurgião dentista, em
1728, ficou clara a necessidade de uma formação específica para quem desejasse
atuar nesta área.
Phillip Pfaff, dentista do rei Frederico II da Prússia, publicou em 1756, na
Alemanha, outro livro que teve grande influência na prática da odontologia. Ele
descrevia como fazer modelos de gesso a partir de impressões em cera. As
próteses eram geralmente feitas em madeira, por artesãos, precursores dos
protéticos.
O cirurgião inglês John Hunter publicou, em 1771, outro importante livro para
o desenvolvimento da odontologia,
A história natural dos dentes humanos.
A odontologia moderna surgiu nos Estados Unidos, no século XIX, com a
primeira escola de odontologia do mundo fundada em 1839, o Colégio de Cirurgia
Dental de Baltimore.
A introdução da anestesia, por dois dentistas americanos, Wells e Morton,
contribuiu de forma importante para o progresso da odontologia, da mesma
forma que para a cirurgia. Em 1899 foi introduzida a novocaína, que passou a ser
utilizada como anestésico local.
A Sociedade de Cirurgiões Dentistas de Nova Iorque, criada em 1834, foi a
primeira sociedade científica de odontologia do mundo.
Em alguns países como Itália, Espanha e Portugal a odontologia ainda hoje é
uma especialidade médica. Para ser dentista é preciso, antes, fazer o curso de
medicina.
Na maioria dos países, no entanto, a odontologia é uma ciência independente,
devido ao seu alto grau de especialização e às diversas técnicas com que lida.
Billroth e a cirurgia experimental
Theodor Billroth desenvolveu o conceito de cirurgia experimental, trabalhando
seus novos conceitos primeiramente em laboratório, para só depois de testados e
aprovados passar a utilizá-los na sala de cirurgia.
Foi professor de cirurgia, em Viena, tendo realizado a primeira cirurgia
abdominal com sucesso, no dia 29 de janeiro de 1881, sob anestesia com
clorofórmio. A paciente, Thèrése Heller, submeteu-se a uma gastrectomia, devido
a um tumor. A operação durou 90 minutos e a paciente se recuperou sem
problemas.
Nessa época, as cirurgias abdominais equivaliam a uma sentença de morte.
Billroth e sua equipe realizaram ainda 41 ressecções devido a câncer de
estômago, com êxito em 19 casos.
Uma nova enfermagem
Até o final do século XVII, a enfermagem existiu mais como uma atividade
ligada às ordens religiosas, e de uma maneira precária. Também precários eram
os hospitais, embora houvesse ordem, disciplina e alguma higiene.
Deste período até a metade do século XIX passaram a contar com leigos
totalmente despreparados, exercendo de forma amadorística as suas funções.
Nesta época, os hospitais eram imundos e os pacientes morriam mais pelas
infecções lá adquiridas do que pelas doenças que os levavam a se internar.
Foi um pastor, Theodor Fliedner, que junto com sua mulher resolveu criar
uma escola de enfermagem em 1833, tendo transformado parte de sua
residência em asilo para prisioneiras libertadas. Em 1836 fundou a primeira escola
de enfermagem de religiosas da Alemanha. Florence Nightingale foi uma de suas
alunas.
Nascida em Florença, e filha de ingleses, teve um papel muito importante no
desenvolvimento da sua profissão.
A guerra da Criméia foi um conflito entre a Rússia e uma aliança da Inglaterra,
França, Turquia e Piemonte. Foi iniciada em 1853 e durou três anos. A situação
dos soldados aliados era péssima. Havia muitas mortes, que chegavam a mais de
40% entre os feridos.
Por solicitação do ministro da guerra inglês, Florence foi designada a
comandar um corpo de 38 enfermeiras em Scutari, bairro de Constantinopla, em
1854.
Lá, atuando em hospital improvisado - na verdade um quartel abandonado
onde se podiam acomodar mil soldados, mas onde se amontoavam quatro mil -
conseguiu promover grandes mudanças, que levaram a uma considerável
melhoria da sobrevida dos feridos, chegando alguns a relatar que a taxa de
mortalidade teria caído para 2%.
Logo que chegou, encontrou um local com o piso sujo, coberto de poeira, com
janelas sempre fechadas, onde não havia lavanderia e onde as portas, que se
fechavam todas as noites, só eram abertas pela manhã, para a retirada dos
mortos. Durante a noite ninguém ficava de plantão para cuidar dos doentes.
Cedo Florence procurou mudar a situação. Enfrentou de forma firme e
decidida a burocracia militar e modificou por completo a situação que havia
encontrado. Passou a administrar com mais eficiência as condições dos feridos,
cuidando da melhoria da alimentação que lhes era servida e do vestuário, para
protegê-los do frio, além de outras necessidades básicas de um hospital.
O trabalho de Florence logo teve amplo reconhecimento e, na sua volta à
Inglaterra, recebeu a importância de cinqüenta mil libras, que usou para fundar a
escola de enfermeiras do Hospital St. Thomas, em 15 de junho de 1860. Suas
alunas, depois de formadas, preenchiam todas as vagas existentes nos grandes
hospitais ingleses.
Nightingale definia a enfermagem simplesmente como tendo por objetivo
“ajudar o paciente a viver”. Também deu uma grande contribuição para o
surgimento de uma nova enfermeira, voltada para a saúde pública.
Em 1893, chamou a atenção para a necessidade da enfermagem sanitária e
insistiu em que a enfermeira, além de cuidar dos pacientes, deveria também ser
uma missionária da saúde, atuando como visitadora e dando orientação de saúde
nos lares, ou seja, combinando o papel de enfermagem com o de educadora em
saúde e de assistente social.
A medicina natural
A medicina natural emprega os procedimentos diagnósticos da medicina
tradicional, mas dela se distingue na sua interpretação da origem das doenças e nas
suas condutas terapêuticas.
Para os naturalistas, a doença é uma reação curativa e seus sintomas (febre,
diarréia, hemorragias, etc.) são apenas manifestações de defesa do organismo.
Para eles, a conduta terapêutica tradicional é errada porque não corrige o
desequilíbrio originado pela violação das leis naturais e, pelo contrário, ainda agrava
o mal.
Admite a existência de doenças causadas por microrganismos, mas acredita
que elas são produzidas após o organismo perder o equilíbrio natural, devido à
retenção de produtos tóxicos.
Entre as práticas desta medicina pode-se citar a aproximação com a natureza,
os exercícios físicos, a hidroterapia, a ingestão de alimentos não processados,
principalmente de origem vegetal, além de se procurar evitar os excessos
alimentares, as bebidas alcoólicas e o fumo. Com isso, a ingestão de medicamentos
deveria ser encarada apenas como último recurso terapêutico.
Em 1796, Cristoph Whilhelm Hufeland publicou
Macrobiótica, que ainda hoje é
considerado um clássico do naturalismo. Nele está contida a base da medicina
natural.
O naturalismo está diretamente relacionado ao regime vegetariano, sendo
baseado na ingestão de frutas, cereais, vegetais e leite. A doutrina vegetariana tem
sua origem na Alemanha, com Theodor Hahn (1824 a 1883), autor dos livros
O
paraíso da saúde e o
Manual da vida sadia.
O surgimento da Pediatria
A pediatria surgiu a partir do século XIX, como um ramo da medicina interna.
Anteriormente os médicos atendiam indistintamente adultos e crianças. Em 1850, a
mortalidade infantil na França estava em torno de 20%, tendo permanecido nesse
patamar até o final do século. O infanticídio era comum naquele tempo, assim como
o abandono de recém-nascidos. Essas crianças, deixadas nas portas das igrejas,
invariavelmente morriam. Como paliativo criaram-se as “rodas de abandono”,
instaladas próximas às portas dos conventos. Em 1830 havia 230 delas, sendo que,
apenas em 1833, treze mil crianças tinham sido abandonadas por esse meio. A
última “roda de abandono” foi fechada em 1868, devido à queda substancial dessa
deplorável prática.
O primeiro hospital pediátrico surgiu em 1802
, Les Enfants Malades, de Paris.
A pediatria seguiu, desde o início, dois cursos paralelos: a puericultura ou o
crescimento e desenvolvimento infantil e a especialidade responsável pelo
tratamento das doenças das crianças. Em 1815, um trabalho baseado em sete mil
casos, definiu a importância do conhecimento do peso da criança ao nascer e que
isso representava um bom indicador para o diagnóstico da prematuridade.
A primeira incubadora foi desenvolvida por Stéphane Tarnier, na Maternidade
de Port Royal, em 1880. Tarnier foi o primeiro a perceber que a sobrevivência dos
prematuros necessitava de isolamento, higiene extrema, alimentação apropriada por
intubação nasal e atmosfera úmida.
Uma importante causa de mortalidade infantil, que chegava até a 80%, era a
gastrenterite provocada pela contaminação das mamadeiras. Com a introdução das
novas técnicas de tratamento do leite, como a pasteurização, a mortalidade infantil
entre crianças amamentadas com mamadeiras ficou igual à daquelas que recebiam
leite materno.
Houve, ainda, considerável redução da mortalidade por doenças infecciosas.
Em 1884, a introdução do soro antidiftérico fez a mortalidade pela doença cair de
73% para 14%.
Cai o último inimigo da cirurgia
Os três inimigos históricos da evolução da cirurgia foram a dor, a infecção e a
hemorragia.
O primeiro foi vencido com a descoberta dos anestésicos inalatórios, por Wells
e Morton.
O segundo foi parcialmente superado54 por Pasteur, von Bergman e Lister, por
meio do desenvolvimento da técnica asséptica(uso de material esterilizado) e do
emprego de antissépticos em cirurgia.
Faltava resolver o problema da hemorragia, que levava o paciente, com
freqüência, ao choque (queda acentuada da pressão sanguínea) e à morte, em
seguida.
Antes da evolução da hemoterapia, foram tentadas transfusões entre espécies
diferentes(carneiro para o homem) e mesmo entre os da mesma espécie, com
resultados, muitas vezes, desastrosos.
Em 1900, Karl Landsteiner definiu o caminho a ser seguido para vencer a
hemorragia. Descobriu que o sangue humano é dividido em quatro grandes grupos
(A, B, AB e O), e que os acidentes de transfusão poderiam ser evitados se o sangue
do doador e do receptor fossem compatíveis, ou se não houvesse na circulação
anticorpos de um grupo contra o antígeno (proteína que induz a formação de
anticorpos) de outro grupo sangüíneo.
Em 1930, Landsteiner recebeu o prêmio Nobel de Medicina pela sua grande
contribuição ao tratamento das anemias e hemorragias.
Em 1940, junto com Wiener, Landsteiner descobriu outro grupo sanguíneo,
denominado fator Rh (Rh positivo e Rh negativo), chamado assim porque este fator
foi encontrado primeiramente em hemácias de macacos Rhesus.
Outra etapa importante no desenvolvimento da hemoterapia foi a descoberta
de que o sangue resfriado, e contendo um anticoagulante (citrato de sódio), podia
permanecer viável por várias semanas, o que facilitava a sua estocagem e a
possibilidade de ser utilizado a qualquer momento, mesmo em casos de emergência.
Mais tarde, com a descoberta do complexo de histocompatibilidade de
leucócitos, o sistema HLA, pelo pesquisador francês Jean Dausset, abriu-se o
caminho para o transplante de órgãos, devido à diminuição dos riscos de rejeição
entre pessoas com sistemas HLA semelhantes.
O início do diagnóstico por imagem
Wilhelm Konrad Röntgen nasceu em 1845, na Alemanha, e formou-se em
física, em Zurique. Foi professor da matéria em várias universidades européias.
Fazendo experiências sobre a condução da eletricidade nos gases, observou
que, em meio à escuridão, uma tela de papel coberta com platinocianeto de bário,
nas proximidades do tubo de vácuo (coberto com cartolina preta) com que
trabalhava, apresentava fluorescência.
Mais tarde veio a descobrir que se tratava da emissão de um tipo de radiação
desconhecida, que era capaz de penetrar em corpos densos, impenetráveis pelas
54 Somente com a introdução dos antibióticos, a partir da descoberta da penicilina, é que a
infecção foi superada.
ondas da luz visível, proporcionando a formação de imagens em uma tela
fluorescente e em um negativo de filme fotográfico.
Röntgen deu o nome de raios X a esta nova radiação por desconhecer a sua
origem.
Na verdade, os raios X são radiações eletromagnéticas de pequeno
comprimento de onda, que se propagam em linha reta, com a velocidade da luz,
ionizando a matéria, incluindo o ar, e podendo ultrapassar, serem absorvidos ou
serem refletidos pela matéria, dependendo do átomo utilizado. A radiação é
produzida em um tubo onde uma corrente elétrica estimula o pólo negativo (catódio)
a liberar elétrons, os quais são atraídos para o pólo positivo (anódio), onde se
chocam abruptamente, liberando energia. Dessa energia cinética, 99% dela
transformam-se em calor e somente 1% em raios X. Sem o estímulo elétrico não há
emissão de radiação.
A primeira radiografia de Röntgen foi tirada da mão esquerda de sua mulher,
onde se podiam ver os ossos e o anel de casamento. Era uma imagem pouco nítida,
mas em que se percebiam nitidamente os ossos dos dedos.
A partir do seu início, a radiologia permitiu um grande avanço no diagnóstico
de diversas doenças e lesões, como pneumonias, vários tipos de câncer e fraturas.
Em 1897, foi introduzido o bismuto como composto radiopaco, no estudo do
trato gastrintestinal de animais. Posteriormente foi também utilizado em humanos e,
a partir de 1904, foi substituído pelo bário.
Em 1929, o iodeto de sódio foi primeiramente usado como contraste em
arteriografias, o que ajudou bastante na localização de tumores e outras lesões
cerebrais.
Röntgen recebeu o primeiro prêmio Nobel de Física em 1901. Morreu em
1922, praticamente esquecido pelas novas gerações.
Harrison(Criador da cultura de tecidos)
Ross Granville Harrison nasceu na Pensilvânia, em 13 de janeiro de 1870.
Considerado brilhante pelos seus contemporâneos, cedo se interessou pelo estudo da
embriologia na Universidade John Hopkins.
Depois foi para a Alemanha, onde em 1899 formou-se em medicina. Em 1907,
trabalhando com células nervosas vivas, em condições assépticas, conseguiu mantê-
las por até quatro semanas. Seu trabalho foi publicado em 1907 no
American Journal
of Anatomy, com o título
Observations on the living developing nerve fiber.
Apesar de nunca ter recebido o prêmio Nobel, o trabalho de Harrison permitiu
que a medicina desse um grande salto, como quando os vírus passaram a ser
cultivados em culturas celulares. Com isso, propiciaram o desenvolvimento de várias
vacinas, como as da poliomielite, influenza e do sarampo. Seu trabalho muito
contribuiu, também, para a genética, que ainda hoje utiliza culturas celulares na
realização do mapeamento cromossômico.
Ehrlich(Fundador da quimioterapia moderna)
Filho de um zelador de hospedaria nasceu em 1854 e formou-se em medicina
em 1878. Desde cedo Paul Ehrlich interessou-se pela química, devido à influência de
um parente, primo de sua mãe, Carl Weigert, patologista que introduziu as técnicas
microscópicas de coloração, com derivados da anilina.
Desenvolveu uma série de pesquisas nas mais diversas áreas. Tinha
predileção por estudar os corantes. Acreditava que se eles eram capazes de corar os
micróbios, também poderiam (quando associados a moléculas capazes de causar
dano) levar à sua destruição.
Em 1889 foi trabalhar, como assistente, com Koch. Desenvolveu uma técnica
de coloração que permitia visualizar melhor o bacilo da tuberculose e que era
baseada na álcool-ácido resistência do Mycobacterium.
Junto com outro alemão, Emil von Behring, desenvolveu a produção passiva
de anticorpos (soroterapia) contra a difteria. Como Behring patenteou esta técnica, o
que o tornou muito rico, o relacionamento entre os dois tornou-se tenso e distante.
Desenvolveu a chamada teoria da cadeia lateral, que foi a precursora da
moderna teoria da formação dos anticorpos e também serviu de guia para o
desenvolvimento de novas drogas, a partir de um composto original.
Utilizou esta estratégia para procurar uma droga que viesse a curar as mais
diversas infecções e parasitoses.
A partir de uma substância orgânica, em anel, com uma cadeia lateral
contendo um átomo de arsênico (atoxil), passou a fazer modificações em sua
estrutura química, visando descobrir a tal droga capaz de eliminar todas as doenças.
Na versão de sua teoria relacionada à quimioterapia, Ehrlich acreditou que
poderia manipular o atoxil de forma a encontrar, por meio de reações químicas
controladas, novas cadeias laterais mais eficientes.
Em 1909, juntamente com um de seus assistentes mais brilhantes, o médico
Sahachiro Hata, encontrou um dos derivados do atoxil, de número 606, que se
mostrou capaz de curar a sífilis em animais de laboratório.
Este produto, a que foi dado o nome comercial de Salvarsan, foi anunciado
como a primeira droga capaz de tratar a doença, em 1910.
Em 1908 recebeu o prêmio Nobel de medicina, por sua teoria da imunidade. O
prêmio foi dividido com o russo Elie Metchnikoff, que desenvolveu estudos sobre a
fagocitose, mecanismo básico de defesa do organismo.
Ehrlich foi, ainda, o fundador da hematologia. Classificou os leucócitos de
acordo com a presença ou não de grânulos; diferenciou as leucemias; mostrou que a
leucocitose é uma resposta da medula óssea às infecções e outros estímulos;
estudou a anemia aplástica e deu as bases para a diferenciação citoquímica das
diversas células envolvidas com o sangue.
Seus trabalhos com corantes de ação antimicrobiana foram precursores do
descobrimento das sulfas, três décadas depois, por Gerhard Domagk.
Morreu em 1915, e poucos fizeram tanto como ele pelo desenvolvimento da
medicina. Paul Ehrlich foi, sem nenhuma dúvida, um dos maiores gênios da
humanidade.
Marie Curie (Uma grande cientista)
“A humanidade necessita de sonhadores, para quem o desenvolvimento
desinteressado de seu trabalho seja tão cativante que seja impossível para eles
dedicar alguma atenção a seu proveito pessoal”, foi o que disse Marie Curie, que
junto com seu marido, Pierre, isolou o rádio, elemento químico extraído da uraninita,
de potente capacidade radioativa.
Por sua descoberta, Pierre e Marie Curie receberam o prêmio Nobel de física
de 1903. Em 1906 Pierre morreu atropelado por uma carruagem. Marie continuou
trabalhando em suas pesquisas, e ainda veio a receber, mais tarde, o prêmio Nobel
de química.
Apesar de toda a sua capacidade, e mesmo tendo recebido tantos prêmios, a
Academia Francesa de Ciências vetou-a como sócia, devido à sua condição feminina.
Suas investigações foram continuadas por uma de suas filhas, Irène Curie
Joliot, que junto com o marido, Frédéric Joliot, descobriu que a radioatividade
poderia ser induzida em alguns átomos normais por meio da formação de isótopos.
Em 1935, também o casal Joliot recebeu o prêmio Nobel de química.
Entre os desdobramentos das descobertas desta brilhante família, pode-se
citar a radioterapia de tumores e o desenvolvimento de substâncias marcadas, ou
radioativas, empregadas para diagnóstico de doenças (como o radioimunoensaio).
Oswaldo Cruz (Nosso maior sanitarista)
“Desde o primeiro dia que nos foi facultado admirar o panorama encantador
que se divisa quando se coloca os olhos na ocular de um microscópio, sobre cuja
platina está uma preparação; desde que vimos, com o auxílio deste instrumento
maravilhoso, os numerosos seres vivos que povoam uma gota de água; desde que
aprendemos a lidar, a manejar com o microscópio, enraizou-se em nosso espírito a
idéia de que os nossos esforços intelectuais de agora em diante convergiriam para
que nos instruíssemos, nos especializássemos em uma ciência que se apoiasse na
microscopia”. Assim se expressou Oswaldo Gonçalves Cruz, no primeiro parágrafo de
sua tese de conclusão do curso de medicina,
A veiculação microbiana pelas águas,
em 1893.
Filho de médico, Dr. Bento Gonçalves Cruz, por quem nutria grande
admiração, Oswaldo Cruz perdeu o pai no dia em que apresentou sua tese à
faculdade.
Permaneceu no Rio de Janeiro por três anos, trabalhando em um laboratório
recebido de presente de casamento, de seu sogro.
Em 1896 viaja para Paris, junto com a família. Freqüenta o Instituto Pasteur,
onde aperfeiçoa seus conhecimentos de bacteriologia. Faz, também, estágio no
serviço de urologia do Prof. Félix Guyon. Permanece na França por três anos.
Após retornar ao Brasil, em outubro de 1899, é convidado pelo ministro da
saúde para, junto com Adolfo Lutz e Vital Brazil, investigar a origem de uma
epidemia que estava ocorrendo em Santos. Havia suspeitas de que poderia tratar-se
de peste bubônica.
Seu relatório, encaminhado em 12 de novembro, conclui que realmente
tratava-se de peste. Depois de Santos, a epidemia se estendeu a S. Paulo, Rio de
Janeiro, Niterói e outras cidades do país.
No Rio, o primeiro caso foi diagnosticado em 7 de janeiro de 1900. Tornou-se
então uma endemia, sendo que, em dezembro de 1905, 2.401 pessoas morreram
dessa doença na capital do país.
As medidas tomadas por Oswaldo Cruz para o combate a essa e outras
endemias brasileiras foram apresentadas em um relato feito na 3ª Convenção
Sanitária Internacional, realizada na cidade do México, em 1907, da seguinte forma:
Febre amarela - campanha contra o vetor (Aedes aegypti), por meio de uma força
constituída por um médico inspetor, dez inspetores auxiliares, setenta e cinco
estudantes de medicina e mil guardas sanitários.
O pessoal estava dividido em três grupos encarregados de:
1. Isolamento dos doentes e fumigação das casas.
2. Eliminação sistemática dos mosquitos, secando os depósitos temporários de água
ou lançando sobre os viveiros petróleo misturado com creolina, ou por meio de
peixes que comiam as larvas do mosquito.
3. Proteção das cisternas e outras fontes de água.
4. Fiscalização dos receituários médicos, verificação de óbitos e vigilância médica
das pessoas não imunes residentes nos focos.
Peste bubônica – desinfecção bactericida e parasiticida por meio de fenóis e cresóis,
visando a destruição do bacilo e da pulga transmissora (Pulex cheops), pela
vigilância dos domicílios ou por comunicação dos interessados.
Nesta desinfecção, as soluções eram usadas em temperatura elevada, e os
soalhos eram levantados para a desinfecção completa.
A guerra contra o rato era outra medida tomada e feita pela
impermeabilização do solo de todas as casas vizinhas dos focos e pela caça
sistemática aos roedores.
A inoculação preventiva do soro antipestoso era feita quando permitida. O
soro era produzido pelo Instituto Manguinhos.
O isolamento sistemático e indistinto de todos os doentes em um hospital, e a
desinfecção dos objetos que manipulavam, completava as medidas usadas.
Malária – guerra contra o mosquito nas cidades e profilaxia clínica com quinina, por
três dias, nos locais de maior incidência da doença.
Só para se ter uma idéia do que foi a epidemia de febre amarela no Rio de
Janeiro daquela época, basta dizer que no ano de 1892 houve 4.312 mortes pela
doença e, em 1909, após as medidas tomadas por Oswaldo Cruz, não houve mais
nenhum caso.
Quanto à varíola, tentou implantar a vacinação obrigatória no nosso país, mas
não conseguiu devido à forte reação popular e à forma como foi regulamentada a
vacinação.
Dirigiu o Instituto Manguinhos, que em 1908 passou a se chamar Instituto
Oswaldo Cruz.
Em 1912 foi eleito para a Academia Brasileira de Letras, passando a ocupar a
vaga do poeta Raimundo Correia.
Oswaldo Cruz morreu em 1917, mas deixou como principal legado o maior
instituto de pesquisas do país, referência internacional como instituição voltada para
a pesquisa e o desenvolvimento na área da saúde pública.
A revolta da vacina
No Rio de Janeiro, só em junho de 1904, apenas no Hospital de S. Sebastião,
haviam sido notificados mais de 1800 casos de internação por varíola.
No Brasil havia diversos focos endêmicos da doença e isso acarretava grande
preocupação para as autoridades, além de consideráveis perdas para a economia do
país.
Um projeto de lei que instituía a obrigatoriedade da vacinação contra a varíola
foi então apresentado ao Congresso pelo senador alagoano Manuel José Duarte.
Aprovado quatro meses depois, a regulamentação da obrigatoriedade da vacina,
elaborada por Osvaldo Cruz, e publicada em 9 de novembro de 1904, foi o que
desencadeou a revolta popular.
Por ser uma sociedade de moral consideravelmente recatada, a exposição por
estranhos de partes íntimas do corpo de suas mulheres, mães e filhas causava, em
muitas pessoas, grande revolta e indignação.
Por não ter tido qualquer preocupação em conscientizar e preparar
psicologicamente a população, de quem só se esperava total submissão, a revolta é
um belo exemplo de como não se deve realizar uma campanha de vacinação.
A revolta começou no dia seguinte à publicação das normas de aplicação da
vacina e só terminou no dia 16 de novembro, com a revogação, pelo governo, de sua
obrigatoriedade.
No período da revolta houve numerosos conflitos entre populares -
especialmente os das camadas mais pobres - e a força policial. Até o Exército e a
Marinha participaram da repressão. Houve numerosos mortos e feridos, além de
diversas pessoas terem sido presas e banidas para o Acre
Carlos Chagas(A tripanosomíase americana)
Em 1902, Carlos Justiniano das Chagas procurou o então diretor do Instituto
Manguinhos, Dr. Oswaldo Cruz, para que lá pudesse desenvolver sua tese de
doutoramento em medicina, sobre os estudos hematológicos da malária.
Com o aval do diretor, em dois anos concluiu a sua tese.
Impressionado com a capacidade de trabalho e com o conhecimento científico
demonstrados pelo jovem médico, Oswaldo Cruz convidou-o para trabalhar em
Manguinhos.
A partir de 1907, Carlos Chagas passa a desenvolver pesquisas junto com
Cruz, além de outros grandes cientistas nacionais e estrangeiros, como Arthur Neiva,
Rocha Lima, Gustav Giemsa, von Prowazeck e Max Hartmann, este um grande
especialista em protozoários, que teve muita importância no desenvolvimento
científico do jovem médico.
Em 1909, a pedido de Oswaldo Cruz, parte para o interior para investigar um
surto de malária que estava dificultando os trabalhos de construção da Estrada de
Ferro Central do Brasil, em trecho próximo a Pirapora, Minas Gerais, em um vilarejo
chamado Lassance.
Neste local, além da malária, Chagas encontra uma nova doença muito
freqüente, onde as pessoas acometidas se queixavam de um incômodo no peito, e
apresentavam arritmias, sinais de insuficiência cardíaca, além de ser comum haver
casos de morte súbita.
Além de combater o surto de malária, Chagas se debruçou na investigação
desta nova doença, quando soube, por um dos engenheiros da ferrovia, que nas
casas simples dos moradores da região (habitações de barro com muitas frestas,
onde os insetos se escondiam), havia uma grande quantidade de insetos
hematófagos.
À noite, estes insetos picavam a área descoberta do corpo das pessoas,
geralmente o rosto, daí porque eram conhecidos como “barbeiros”.
Examinando o tubo digestivo destes insetos, Chagas encontrou um novo tipo
de protozoário, que tinha características diferentes de todos os outros que conhecia.
Passou então a pesquisar a possível relação deste microrganismo com a
doença que acabara de conhecer.
Em 26 de outubro de 1910, a Academia Nacional de Medicina ouviu Carlos
Chagas falar sobre a tripanosomíase americana. Desta doença, foi o descobridor do
agente etiológico, o Trypanosoma cruzi; do vetor, o Triatoma infestans; e das
características da doença, tanto em sua forma aguda como crônica. Isso é, até hoje,
um caso excepcional na história da medicina.
Calcula-se que haja atualmente, no Brasil, em torno de 3,5 milhões de
pessoas infectadas pelo agente da doença descoberta por Carlos Chagas.
Por ser uma doença com forte envolvimento econômico e social, seu controle só será
efetivamente obtido quando a população rural do nosso país vier a ter melhores
condições de vida. Casas de boa qualidade e maior controle dos agentes
transmissores (barbeiros) por meio do uso de inseticidas mais eficientes que o DDT,
para o qual já existe muita resistência, é fundamental. Além disso, é crítico o
controle da qualidade do sangue para se evitar a transmissão por meio de
transfusão, como pode ocorrer caso o doador seja portador da doença.
Recentemente foram descritos ainda casos de transmissão da doença por
meio da ingestão de alimentos contaminados (caldo de cana, açaí, etc), o que pode
ser explicado pelo fato de que ao ser triturado durante a moagem o inseto
contaminado libera milhares de protozoários de seu intestino e que permanecem
viáveis por várias horas, podendo assim penetrar no organismo humano pelo trato
intestinal quando ingeridos junto a algum produto.
A descoberta da insulina
Em 1869, um estudante de medicina alemão, chamado Paul Langerhans,
observou que no pâncreas havia dois tipos de células, as células acinares, que
secretavam enzimas digestivas, e células aglomeradas em ilhas ou ilhotas, o que
sugeria uma possível nova função para elas.
Os primeiros relatos da retirada do pâncreas e do desenvolvimento do
diabetes mellitus foram registrados por von Mering e Minkowski, em um artigo
publicado em 1889. No entanto, somente em 1922 um trabalho publicado por
Frederick G. Banting fez o relato do resultado satisfatório obtido com o tratamento
de sete pacientes diabéticos pelo uso de extrato pancreático, contendo uma
substância denominada, por Banting, de insulina, devido à localização das células
produtoras do hormônio. Para ajudá-lo a descobrir a insulina, Banting contou com o
apoio considerável de um estudante do 4º ano do curso de medicina de Toronto,
chamado Charles Best.
Banting acreditava que só conseguiria extrair o hormônio envolvido no
diabetes se impedisse a sua degradação pela ação proteolítica do suco pancreático,
que era liberado através dos ductos do órgão. Fez, então, ligadura dos ductos, o que
levou à posterior degeneração dos tecidos acinares, permanecendo intactas as
células das ilhotas. Extraiu, posteriormente, o extrato pancreático com álcool e ácido,
que se mostrou efetivo em reduzir os níveis de glicose no sangue.
O primeiro paciente tratado por eles foi Leonard Thompson, um garoto de 14
anos, que chegou ao Hospital Geral de Toronto com glicemia de 500 mg% (a taxa
normal varia de 70 a 99 mg%) e com uma diurese diária de 3 a 5 litros. Apesar de se
submeter a uma dieta rígida (450 kcal por dia), seu diabetes estava totalmente
descontrolado e sua morte era iminente. Após a administração dos extratos de
Banting e Best, houve uma considerável mudança clínica e laboratorial. Sua glicemia
passou para níveis próximos a 100 mg% e o rapaz teve uma melhora significativa de
saúde. A suspensão do tratamento, por outro lado, revertia todo o processo, o que
demonstrava a importância da administração do novo tipo de tratamento.
Posteriormente, Banting conseguiu a adesão do professor de fisiologia,
Macleod, que levou à purificação e maior produção do hormônio. Em 1923, Banting e
Macleod dividiram o prêmio Nobel de Medicina e Fisiologia. Banting anunciou que iria
dividir a sua parte com Best, em consideração à sua contribuição nas pesquisas
iniciais da descoberta da insulina.
Em 1953, Frederick Sanger conseguiu determinar a seqüência completa da
molécula de insulina, tendo recebido por isso o prêmio Nobel de química, em 1958.
Fleming (A descoberta da penicilina)
Alexander Fleming nasceu na Escócia, em 1881. Formou-se em medicina e em
1922 descobriu que nas secreções, como muco nasal, saliva e lágrima havia uma
enzima que destruía as bactérias, chamada por ele de lisozima.
Em 1928, ao estudar variantes de uma bactéria chamada estafilococo, após
deixar uma placa vários dias sobre a bancada de seu laboratório no Hospital St.
Mary, em Londres, observou a presença de um fungo contaminante, da espécie
Penicillium notatum.
O fato interessante, que lhe chamou a atenção, era um halo de inibição do
crescimento bacteriano ao redor da colônia do fungo.
Pelos conhecimentos que adquirira estudando a lisozima, Fleming acreditou
que esta inibição seria conseqüência de algum tipo de substância semelhante,
produzida pelo Penicillium.
Passou então a trabalhar com o fungo em caldo de cultura, e pôde verificar
que ele produzia uma substância que provocava uma forte inibição no crescimento
de vários micróbios. Como o fungo pertencia ao gênero Penicillium, deu a esta
substância o nome de penicilina.
Em 1929, Fleming publicou o primeiro trabalho científico sobre a penicilina,
mas só em 1940 - com o apoio dos pesquisadores Howard Florey e Ernst Chain - foi
possível produzir a penicilina em sua forma mais purificada.
Em um teste, Florey e Chain injetaram cinqüenta camundongos com uma dose
letal de uma bactéria, o estreptococo. Vinte e cinco animais foram injetados com
penicilina a cada três horas, por um período de 45 horas. No final de dez dias, 24
dos 25 camundongos tratados tinham sobrevivido. Por outro lado, todos os 25
camundongos controle, que não receberam o antibiótico, morreram.
Estes resultados foram publicados em agosto de 1940, na revista Lancet,
sendo recebidos com muito entusiasmo por todos.
Estava inaugurada uma nova etapa das ciências da saúde. Por seus trabalhos
no desenvolvimento da penicilina, Fleming, Florey e Chain receberam o prêmio
Nobel de medicina, em 1945.
Freud e a criação da psicanálise
A psicanálise veio preencher um espaço surgido após o grande
desenvolvimento obtido pela neurologia e pela psiquiatria durante o século XIX.
O termo psicanálise está relacionado a um método de investigação para
estudo das regiões mais íntimas e ocultas do espírito; a uma teoria que se elabora
com os resultados desta análise e a uma técnica que tem por finalidade adotar o
método analítico no tratamento dos desequilíbrios da mente.
A psicanálise é a única ciência que exerce profundamente a auto-reflexão, ou
a reflexão sobre as motivações de ordem subconsciente, pessoal e emotiva que vão,
de maneira insensível, condicionando o conhecimento e formando a personalidade
de cada um.
Pinel, no final do século XVIII, havia implantado grandes mudanças no
tratamento das doenças mentais com a sua reforma hospitalar. O conjunto de
medidas não físicas que preservavam e melhoravam moralmente o doente mental,
além de evitar as freqüentes iatrogenias, constituíram o núcleo dessas reformas.
A psicoterapia passa a ter um caráter mais científico a partir das escolas de
Nancy, sob o comando de Hippolyte Bernheim (1840 a 1919) e de Paris, com Jean
Martin Charcot (1825 a 1893). A psiquiatria francesa estava dividida entre estas duas
escolas, que divergiam a respeito de algumas questões, como as relativas à histeria
e ao emprego da hipnose como meio semiótico.
Charcot acreditava que o estado de hipnose era essencialmente igual ao da
histeria, deduzindo que a facilidade de uma pessoa para se deixar sugestionar pela
hipnose significava uma histeria latente. Bernheim, por sua vez, discordava das
teorias de Charcot sobre a histeria e sobre a correspondência entre hipnose e
comportamento neurótico.
Enquanto isso, por meio dos estudos de Charles Bell, François Magendie,
Brown-Séquard, Paul Broca e Claude Bernard, a neurologia e a neurofisiologia deram
considerável apoio ao diagnóstico e à compreensão de uma série de doenças, antes
pouco conhecidas e de fundamento fisiopatológico nebuloso.
Sigmund Freud (1856 a 1939), nascido em Freiberg, pequena cidade da
Moravia, formou-se em medicina em 1881, em Viena. Depois estudou em Paris, de
1885 a 1886, com Charcot, com quem aprendeu as relações existentes entre a
histeria e a sexualidade. A tese de Charcot era a de que na base desses casos havia
sempre um trauma sexual, que sua lembrança era ocultada pela mente dos
histéricos.
Mais tarde desenvolveu junto com o médico austríaco Josef Breuer uma
técnica em que os pacientes podiam discutir seus problemas emocionais por livre
associação. O procedimento desencadeava poderosas forças, que arrastavam
pensamentos incontrolados na direção do conflito psíquico, acabando por resolver o
quadro neurótico então existente. Breuer criara assim o método catártico e
descobrira a íntima relação existente entre os sintomas histéricos e certos traumas
de infância. No livro que ambos publicam sobre histeria, em 1895, ressaltam o
significado etiológico da vida sexual nas neuroses.
Segundo sua doutrina, a memória de eventos passados joga um importante
papel na vida das pessoas e os conflitos mentais freqüentemente produzidos por tais
memórias podem ser removidos quando trazidos até a superfície (ao consciente).
Isso se o conflito for adequadamente compreendido por meio de um longo processo
de pesquisa a partir do inconsciente, que tem como uma de suas características
nunca esquecer o que nos acontece.
Mais tarde, Freud rompe com Breuer, e passa a desenvolver ainda mais o
método de livre associação de idéias. Isso o leva aos dois fundamentos que formam
a base da psicanálise, a resistência (mecanismo de defesa que o paciente apresenta
ao sentir que se revelam suas experiências recalcadas) e a transferência (o vínculo
emocional entre o paciente e o analista).
De forma resumida, pode-se ainda dizer que a psicanálise tenta compreender
a base do comportamento humano a partir de três conceitos fundamentais:
a) A existência de uma mente inconsciente, demonstrada por meio de
exemplos como os fornecidos pelos sonhos, esquecimentos seletivos
e eventos pós-hipnóticos.
b) O determinismo psíquico, que diz que nada ocorre por acaso, ou que
todos os eventos psíquicos são determinados por outros fatos ou
acontecimentos.
c) O mecanismo de repressão, que impede que eventos
demasiadamente dolorosos aflorem à consciência.
A Interpretação dos Sonhos é considerado o marco de fundação da
psicanálise. Freud foi o primeiro pesquisador a transformar o sonho em objeto de
ciência. Segundo ele, os sonhos não são produtos do acaso, mas conteúdos do nosso
inconsciente tentando chegar à consciência. Publicado em 1900, com tiragem de 600
exemplares, o livro teve apenas 351 unidades vendidas após dois anos de ter sido
editado. O próprio Freud queixou-se, em
História do Movimento Psicanalítico, de que
seu livro “nem sequer foi comentado na literatura especializada e, nos poucos casos
em que isto ocorreu, foi criticado com superioridade compassiva ou com sarcasmo”.
Enquanto a psicoterapia tradicional procura - através da sugestão, persuasão
ou outros métodos repressivos - agregar algo para modificar a imagem da
personalidade, a psicanálise trata de liberar a personalidade daquilo que a está
impedindo de tomar a sua forma autêntica.
Seguindo um modelo citado por Freud, a psicoterapia tradicional
corresponderia a pintar de cores uma tela vazia, enquanto a psicanálise agiria como
o escultor que trabalha o mármore até surgir a imagem que nele estava escondida.
O método que a psicanálise usa é uma forma de comunicação, verbal e não
verbal, que permite que o paciente resgate de seu inconsciente o trauma psicológico
que gerou o processo neurótico.
O analista atua como um espelho, que só reflete o que lhe é mostrado.
Descobrindo o inconsciente e suas leis, a pessoa analisada poderá resgatar
elementos de sua personalidade que ficaram adormecidos.
Para Freud, a natureza humana nada tem de generosa. A convivência entre os
homens dependeria da internalização da agressividade natural do ser humano, com
um desvio da direção do objeto externo e seu retorno para o próprio indivíduo.
Segundo Mac Lean55, o cérebro humano contém uma parte mais primitiva, o
paleocéfalo; uma intermediária, o mesocéfalo; e uma mais recentemente
desenvolvida, o córtex, que nos seres humanos é mais desenvolvido que nos outros
animais, sendo chamado de neocórtex. O paleocéfalo, herdeiro do cérebro dos
répteis, seria a fonte da agressividade e das pulsões. O mesocéfalo, oriundo dos
antigos mamíferos, estaria ligado à afetividade e à memória de longo prazo. Já o
neocórtex seria a sede dos pensamentos e raciocínio mais elaborados, característicos
da espécie humana. Nem sempre há harmonia entre esses três níveis de
complexidade mental. Ora predomina um, ora outro. A resultante desse eterno
conflito é a ação média de cada pessoa, ao longo de sua existência.
Vivemos sob a influência de duas pulsões básicas, ou tanáticas e eróticas, e a
renúncia a elas desenvolveria o nosso superego, ou a base da instância moral que
nos limita. O ser humano deve então aceitar a renúncia parcial à onipotência da
pulsão para poder conviver socialmente. A maturidade psíquica seria o resultado da
passagem gradativa do funcionamento mental marcado pelo prazer (como no
narcisismo infantil) para um outro influenciado pelo princípio da realidade, ou a
passagem gradativa à maturidade psíquica, onde há um amadurecimento da mente,
com um espaço maior para o altruísmo e a gratidão.
Jonathan Lear, professor de Filosofia da Universidade de Chicago, sustenta ser
a psicanálise essencial à convivência em uma sociedade democrática, por ser uma
técnica que permite que significados obscuros e motivações irracionais cheguem à
superfície da consciência, podendo ser adequadamente trabalhados. Com isso
possam tornar-se menos capazes de aflorar sob formas violentas e incompreensíveis,
como têm ocorrido inúmeras vezes, quando, por exemplo, indivíduos aparentemente
normais assassinam pessoas inocentes, que nada tinham a ver com suas angústias
ou frustrações. Ou, ainda, quando o fanatismo serve de justificativa para ações
violentas contra outros.
Segundo Freud, a psicanálise só se presta ao tratamento das neuroses. Tanto
os casos emergenciais, como as tendências suicidas em pacientes melancólicos,
como as psicoses são doenças que orbitam o espaço da psiquiatria.
Desde o seu surgimento, a psicanálise encontra resistência em vários setores
da sociedade, recebendo críticas provocadas por ser uma ciência nova e, também,
devido ao próprio objeto dessa ciência.
Segundo Freud, “a psicanálise quer elevar os materiais psíquicos recalcados ao
nível do reconhecimento consciente, e cada homem que a julga é ele próprio alguém
que possui tais recalques e que talvez só os conserve com grande esforço. A
psicanálise desperta nessas pessoas a mesma resistência que nos pacientes, e essa
resistência consegue facilmente revestir um disfarce intelectual e mobilizar
argumentos, do mesmo modo que os brandidos por nossos doentes, quando se
55 The triune brain, In The Neurosciences, Rockefeller University Press, 1970.
revoltam contra a regra fundamental da análise. Como os doentes, também nossos
adversários se caracterizam, muitas vezes, por uma sensível deterioração de sua
capacidade de julgamento, em decorrência de fatores afetivos. Há as mesmas
resistências nessas pessoas que nos doentes, os mesmos argumentos, afetos
travestidos de razões”.
A psicanálise é combatida ainda por ser uma fonte de humilhação para o
narcisismo do ser humano, por ter demonstrado que somos influenciados por
aspectos não controláveis do nosso inconsciente56, tendo repercussão semelhante à
ocorrida depois que Copérnico mostrou que a Terra não é o centro do universo, e
que Darwin repôs o homem no reino animal57.
A história natural das doenças
Logo após o início da bacteriologia, houve uma grande expectativa de que as
doenças seriam facilmente eliminadas a partir do conhecimento de suas respectivas
causas.
Com o tempo, verificou-se que, além do agente causador de cada infecção,
havia ainda diversos outros fatores que interagiam para que uma determinada
doença se desenvolvesse.
Assim, o fato de uma pessoa, por exemplo, entrar em contato com o bacilo da
tuberculose não necessariamente a torna tuberculosa.
Fatores como a presença ou não de desnutrição, condições de habitação,
contato freqüente com pacientes com a doença, exposição ao frio, ou condições
ligadas ao meio ambiente, também contribuem de maneira significativa para haver
ou não tuberculose, sob a forma de doença.
Esta interação – hospedeiro/agente/meio ambiente - é válida tanto para as
doenças infecciosas e parasitárias, como para os outros tipos de enfermidades.
Uma doença para ser detectada clinicamente, tem antes de desenvolver
alterações orgânicas preliminares, somente detectáveis por meio de exames
complementares. Existe, portanto, uma fase pré-clínica, que antecede a fase clínica
das doenças.
A conseqüência maior do conhecimento da história natural das doenças é o
fato de que, ao se tentar controlar ou prevenir um tipo de enfermidade, tem-se que
adotar uma abordagem multifatorial e não visar apenas o controle de uma de suas
causas, como habitualmente se pensa.
56 Freud, em Uma dificuldade no caminho da psicanálise.
57 Habermas, filósofo alemão contemporâneo, considera a Psicanálise o paradigma de uma
ciência crítica, que atua por meio da dissolução das estruturas patológicas que inibem a livre
comunicação do sujeito consigo mesmo e com os outros.
A educação médica nos EUA
A falta de regulamentos legais levou os Estados Unidos da América (EUA) a
chegarem a ter centenas de escolas de medicina, durante o século XIX. Várias delas
eram verdadeiras “fábricas de diplomas”, graduando profissionais sem nenhuma
qualificação.
Com a criação da Associação Médica Americana (AMA), em 1847, tentou-se
modificar esta situação procurando elevar o nível da profissão e impedindo que os
maus profissionais e charlatães pudessem continuar atuando.
Abraham Flexner nasceu em Lousville, Kentucky, em 13 de novembro de
1866, sendo o sexto filho de imigrantes europeus e formou-se em educação em
1886, na Universidade John Hopkins.
No início do século XX terminou o mestrado em educação, em Harvard.
Em 1908 publicou o livro
The American College: A Criticism, que lhe valeu
convite para trabalhar para a Fundação Carnegie, em uma pesquisa que examinasse
as condições de ensino da medicina nos EUA.
Após dois anos de visitas de inspeção, Flexner elaborou um relatório que
marcou o início de um movimento de reforma radical no ensino médico na América
do Norte.
O relatório,
Medical Education in the United States and Canadá, foi publicado
em 1910, e recomendava a redução do número de faculdades de medicina e o
número de alunos, devido a que estaria havendo uma produção de médicos que
excedia consideravelmente as necessidades do mercado.
Segundo ele, 31 boas faculdades de medicina poderiam fazer um trabalho
melhor que as 155 escolas de qualidade variável que tinha visitado ao longo de sua
pesquisa.
Foi sugerido que o repasse do dinheiro da Fundação Carnegie deveria ser feito
apenas para as melhores escolas médicas, de acordo com o relatório. Foram também
feitas propostas de reforma do currículo das faculdades.
As principais recomendações do relatório consistiam na criação de
departamentos, na criação do ciclo básico em ciências, no desenvolvimento da
pesquisa no âmbito das áreas básicas e na criação de hospitais-escola para serem
utilizados como principais cenários de treinamento clínico.
A partir de 1913, quando passou a atuar como secretário do Conselho Geral
de Educação da Fundação Rockefeller, Flexner conseguiu grandes doações
filantrópicas para o desenvolvimento das escolas de medicina dos EUA, o que gerou
um aporte de recursos da ordem de 600 milhões de dólares.
Em 1930, as escolas foram reduzidas a 76 instituições de elevado padrão de
ensino, o que contribuiu para tornar a medicina desenvolvida nos EUA em uma das
melhores do mundo.
A Fundação Rockefeller foi fundamental para tornar a atividade universitária
mais profissional. Sua atuação foi caracterizada pela ênfase nas ciências básicas, que
ocupavam o centro das pesquisas nas décadas de 1930 e 1940.
No Brasil, sua influência ocorreu principalmente por meio de financiamentos,
tendo sido especialmente relevante na Universidade Federal de S. Paulo e na de
Minas Gerais.
Apenas em 1964, a Escola Paulista de Medicina (EPM) recebeu 716 mil dólares
da Fundação Rockfeller, o que contribuiu para vir, três anos depois, a ser a sede da
Biblioteca Regional de Medicina, mais conhecida como BIREME, por meio de
convênio firmado entre a Organização Panamericana de Saúde, Ministério da
Educação, Ministério da Saúde e a EPM.
A BIREME inspirava-se na instituição modelo americana, a National Library of
Medicine (NLM), com acesso à base de dados MEDLARS, criada e sediada na NLM,
acesso à coleção de periódicos da mesma biblioteca e com a missão de desenvolver
a integração entre as bibliotecas associadas da América Latina.
A primeira universidade do Brasil surgiu durante o governo de Epitácio Pessoa,
na década de 1920, ao reunir a Escola Politécnica, a Faculdade de Direito e a Escola
de Medicina do Rio de Janeiro. Em seguida, a Universidade Federal de Minas Gerais
foi criada em 1927 e a de S. Paulo em 1934, que resultou da incorporação de
diversas faculdades como a de Direito, a Politécnica, a de Medicina, a de Farmácia e
Odontologia, o Instituto de Educação, a de Agricultura e a de Filosofia, Ciências e
Letras.
A criação das universidades atendia a um pensamento da nossa elite
intelectual que reivindicava o seu surgimento no país, visando a uma formação de
nível superior de forma integrada à sociedade.
Doenças mais importantes no início do século XX
Febre amarela
Foi primeiramente descrita em 1684 e, durante mais de dois séculos, provocou
considerável perda de vidas humanas, em grande parte do mundo.
A responsabilidade do mosquito como vetor da doença foi confirmada em
1900, pelo médico americano Walter Reed. Quem primeiramente levantou esta
hipótese foi o médico cubano Carlos Finlay, alguns anos antes.
O vírus foi isolado em 1927, e a vacina contra a febre amarela começou a ser
empregada em 1934.
Por ter reservatórios silvestres, como algumas espécies de macacos, além dos
mosquitos transmissores, a doença não pode ser extinta em florestas, como na
Amazônia e em partes da África e da Ásia tropical.
Pessoas não imunizadas que penetrem em áreas de reservatórios da doença
podem vir a adquirir a enfermidade, que leva a um quadro grave de hepatite e
insuficiência renal, com elevada taxa de mortalidade.
Gripe
Desde o século XVI têm sido descritas epidemias de doenças respiratórias
febris a cada um a três anos. A alta taxa de ataque, a natureza explosiva das
epidemias e a freqüência de tosse, calafrios, dores generalizadas e coriza
acompanhando os sintomas, permitem supor que se tratasse de surtos de gripe,
doença causada principalmente pelos vírus influenza A e B.
A origem do nome influenza é atribuída a médicos italianos e seria
conseqüência das doutrinas prevalentes no início da época moderna, que ligavam os
distúrbios físicos aos fenômenos astrológicos, como a relação que se fazia entre o
surgimento de epidemias e a aparição de cometas e meteoros, ou ainda a erupções
vulcânicas ou mesmo a bruscas mudanças metereológicas. Assim, tudo o que
acontecia em nosso planeta seria devido à influência das estrelas, o que motivou o
nome dado à doença.
A última pandemia de influenza do século XIX, ocorrida em 1889 e 1890, foi a
primeira na vigência da era bacteriológica. Logo depois, em 1892, o bacteriologista
alemão Richard Pfeiffer declarou ter encontrado, em amostras colhidas do trato
respiratório de doentes, uma bactéria que nomeara como
Haemophilus influenzae.,
Erroneamente, Pfeiffer considerou o micróbio como causador da gripe. No entanto, o
vírus influenza só foi descoberto em 1933. Sabe-se hoje que o bacilo descoberto por
Pfeiffer causa apenas um dos diversos tipos de pneumonias agudas bacterianas.
A influenza é uma doença viral que foi, possivelmente, adquirida por meio do
contato humano com animais domesticados, como aves e porcos.
Em termos de morbidade e mortalidade, nenhuma das pandemias se
aproximou da que ocorreu em 1918 e 1919, conhecida como gripe espanhola,
quando cerca de 40 a 100 milhões de pessoas morreram em todo o mundo.
Como os recursos terapêuticos e preventivos à época se restringiam à
quarentena e isolamento, pouco se pode fazer para impedir a disseminação da
doença, assim como seus elevados índices de letalidade.
Estudos sorológicos posteriores, realizados nos EUA, permitiram verificar que a
população mais atingida nessa pandemia foi a de 5 a 15 anos de idade.
O mesmo grupo etário foi também o mais afetado na pandemia de 1957, com
origem na China, e que foi causada pela vírus influenza tipo A, sorotipo H2 N2
(subtipos dos antígenos hemaglutinina e neuraminidase que servem para tipificar os
vírus influenza).
O vírus foi ainda isolado de porcos na China, sugerindo que a transmissão
para humanos tenha sido a partir da criação de animais domésticos na Ásia.
Devido ao fato dos vírus da gripe estarem sempre se modificando por meio de
freqüentes mutações, vários laboratórios de virologia, em diferentes países, exercem
vigilância constante a fim de detectar qualquer surgimento de um novo tipo desses
micróbios. Caso isto ocorra, imediatamente as autoridades sanitárias deverão ser
comunicadas, para que medidas profiláticas possam ser implantadas em curto
espaço de tempo de forma a evitar uma propagação rápida da doença.
Em 2003 um novo tipo de vírus assustou o mundo. Os coronavírus foram os
responsáveis pela Síndrome Respiratória Aguda Severa (SARS), que apresentou uma
mortalidade de até 50% em algumas faixas etárias mais elevadas. Foi considerada a
primeira pandemia do século XXI, demonstrando mais uma vez a necessidade de um
controle constante dos vírus causadores de doenças respiratórias, à semelhança do
que já é feito com os vírus influenza.
Já em 2009, surgiu uma nova pandemia pelo mesmo vírus A/H1N1,
descendente do responsável pela pandemia do início do século XX, e que tem
preocupado as autoridades sanitárias de todo o mundo.
Segundo dados da Organização Mundial de Saúde, até o início de novembro
de 2009, houve 503 mil casos de influenza pandêmica nos diversos continentes, com
pouco mais de seis mil óbitos e uma letalidade de 1,2%.
No Brasil, no mesmo período, houve 22,5 mil casos com 1,5 mil óbitos, ou
seja, uma letalidade próxima a 7%.
Os principais grupos de risco e os mais sujeitos a complicações para essa nova
pandemia são os extremos de idade (menores de dois anos e maiores de sessenta),
as gestantes, os tabagistas e os portadores de doenças crônicas, principalmente as
de origem pulmonar, cardiovascular e as imunossupressoras.
Entre a 1ª pandemia por vírus A/H1N1 e a atual há algumas diferenças que
poderiam explicar a menor letalidade existente na atual:
- Quando ocorreu a 1ª pandemia não havia, na comunidade internacional,
consciência de que a ameaça poderia ser tão significativa. Nesse caso a 1ª
epidemia pelo seu impacto em morbidade e mortalidade foi sem
precedentes na história da humanidade.
- Também não existia, por ocasião da 1ª pandemia, um sistema global de
vigilância epidemiológica dos vírus influenza. A OMS só foi criada em 1948.
- Hoje há disponibilidade de vacinas, antivirais e antibióticos, o que contribui
de forma significativa para também diminuir a morbimortalidade por vírus
influenza. Além disso, há atualmente testes laboratoriais para um
diagnóstico rápido e acurado, propiciando medidas de tratamento e de
isolamento mais rápidas e eficientes, contribuindo também para limitar a
propagação da doença.
- Não há um conflito como a I Guerra Mundial, que colaborou de forma
relevante para uma maior e mais rápida disseminação do vírus. Estudos
sugerem que a cepa pandemica tenha se originado de uma área rural do
estado de Kansas, depois se espalhado pelos EUA com a mobilização pela I
Guerra Mundial e em seguida se espalhado pela Europa junto com a Força
Expedicionária Americana.
A arte contemporânea de curarOs filósofos não podem isolar-se contra a ciência. Ela não apenas ampliou e
transformou enormemente nossa visão da vida e do universo, mas também
revolucionou as regras segundo as quais opera o intelecto.
Claude Lévi-Strauss
A descoberta do código genético
Em 1868, o médico suíço Miescher descreveu o primeiro relato de
nucleoproteínas a partir de células obtidas de bandagens cirúrgicas descartadas de
um hospital. Mais tarde, isolou uma substância semelhante do esperma de salmão, e
mostrou que a nucleoproteína consistia de uma proteína básica (protamina) e de um
ácido nucleico.
Posteriormente, Levene, químico russo radicado nos EUA, descobriu ,em 1909,
que havia dois tipos de ácido nucleico, o ADN (ácido desoxirribonucleico) e o ARN
(ácido ribonucleico). Achava, no entanto, que eram as moléculas de proteína que
armazenavam a informação genética nos cromossomos das células.
Foi o trabalho de um bacteriologista inglês, Frederick Griffith, que em 1928,
trabalhando com pneumococos, ajudou a elucidar o problema. Percebeu que uma
substância desconhecida, obtida a partir de bactérias mortas, era capaz de penetrar
em outros micróbios vivos e fazer a transferência de características da variedade
morta para a viva.
Em 1944, outro bacteriologista, Oswald Avery, demonstrou que era o ADN, e
não a proteína ou o ARN, o responsável pela transformação genética das bactérias.
Enquanto o ADN consiste no material genético responsável pela hereditariedade, o
ARN faz com que nossas células sigam perfeitamente as ordens contidas no ADN.
Tanto o ADN como o ARN é formado por açúcares (desoxirribose ou ribose) e
bases nitrogenadas como a adenina, guanina, citosina, timina e uracila (esta só
existente no ARN). O ADN tem cadeia dupla, enquanto o ARN tem cadeia simples,
como uma fita.
A maneira pela qual estas substâncias se juntavam, formando a molécula de
cada ácido nucléico, foi descoberta por Watson e Crick, em 1953, quando
demonstraram que as fitas de ADN são dispostas de modo antiparalelo e as bases
ficam pareadas ao longo de toda a extensão, formando uma dupla hélice. As duas
fitas sofrem pareamento por meio das bases nitrogenadas. A adenina pareia com a
timina e a citosina com a guanina.
Além de Watson e Crick, também desenvolveram trabalhos nesta área Maurice
Wilkins(com quem dividiram o prêmio Nobel, em 1962) e Rosalind Franklin. Por ter
morrido precocemente, aos 37 anos, Franklin não veio a ser agraciada com o prêmio
Nobel junto com os outros. Seus estudos de difração por raios X permitiram elucidar
a estrutura helicoidal do DNA. Sua fotografia de nº 51, da forma hidratada da
molécula, é que levou Watson e Crick a concluírem corretamente sua construção da
molécula de DNA.
Em 1964, o código genético foi decifrado por três bioquímicos do
National
Institute of Health, M.W. Nirenberg, J.H. Mathaei e P. Leder. Eles sintetizaram
pequenas moléculas de ARN, de composição conhecida, e observaram quais
aminoácidos eram incorporados na formação das proteínas. Testando as 64
possibilidades das quatro bases nitrogenadas do ARN, combinadas em grupos de
três, conseguiram identificar o código exato para cada aminoácido.
A importância deste conhecimento na replicação do ADN, e na síntese do ARN
de seqüências complementares, foi logo reconhecida.
Estava descoberto o idioma onde as informações genéticas são lidas e
executadas.
Em futuro próximo, é provável que o genoma passe a ser a fonte principal de
informações para que os diagnósticos e tratamentos sejam determinados, assim
como a terapia genética possa se transformar em uma realidade capaz de eliminar
uma série de doenças que ainda hoje são responsáveis por causar muitas mortes e
sofrimento.
As novas tecnologias e a evolução das ciências da saúde
A partir da segunda metade do século XX, uma série de novas tecnologias foi
se agregando às ciências da saúde, fazendo com que um novo mundo de
possibilidades de cuidados aos pacientes fosse introduzido na prática clínica e
cirúrgica.
A medicina laboratorial, que teve seu primeiro livro
Laboratory diagnosis for
the practioner publicado em 1906, pelo americano James C. Todd, tem nos dias de
hoje desenvolvimento considerável. Isso pode ser observado por meio da inclusão de
novas metodologias, como os ensaios imunoenzimáticos e imunoquímicos, as
reações em cadeia da polimerase, as contagens de subpopulações de células
sanguíneas, além de centenas de testes bioquímicos e de triagem de vários tipos de
doenças. Os testes de sensibilidade aos antimicrobianos, antes restritos às bactérias,
hoje também podem ser realizados para outros tipos de microrganismos, como
fungos e vírus.
Em 1911, o holandês Willem Einthoven, desenvolve o primeiro aparelho capaz
de registrar a atividade elétrica do coração, que permite o surgimento de uma nova
abordagem na investigação das doenças cardiovasculares.
Novos tipos de tratamento vão se agregando à prática clínica e cirúrgica,
permitindo que cada vez mais pessoas possam ser curadas de vários tipos de
enfermidades consideradas graves, antes responsáveis por níveis elevados de taxas
de mortalidade.
Quando o Dr. Christian Barnard, em 1967, no Groote Schuur Hospital, da
Cidade do Cabo, África do Sul, realizou o primeiro transplante de coração, ainda
havia grandes dificuldades para controlar o risco de rejeição. Com a evolução da
farmacologia e a introdução de novas drogas, como a ciclosporina, este risco foi
sendo controlado e hoje temos condições de realizar transplantes de vários tipos de
órgãos, como os de coração, pulmão, rim, pâncreas, fígado e medula óssea.
Com a introdução das pesquisas com células-tronco, em breve os problemas
de rejeição de órgãos irão desaparecer ou se tornar bem menos importantes do que
hoje.
Em 1978, os doutores Patrick Steptoe e Robert Edwards anunciaram o
nascimento de Louise Brown, primeiro bebê concebido pela técnica de fertilização “in
vitro”, fora do útero. A partir daí, a humanidade passou a contar com novas técnicas
de reprodução assistida, o que veio a melhorar consideravelmente as expectativas
dos casais com problemas de infertilidade, em torno de 15% da população mundial.
As especialidades cirúrgicas vêm tendo grande desenvolvimento ao longo dos
últimos 50 anos. Hoje as cirurgias de revascularização miocárdica são realizadas em
vários hospitais de todo o mundo, utilizando técnicas cada vez menos invasivas. Isto
também tem ocorrido com outras especialidades cirúrgicas, que têm utilizado, de
maneira crescente, as cirurgias por via endoscópica, com menores complicações e
menor tempo pós-operatório.
A informática e a evolução do diagnóstico por imagem fizeram com que
passássemos da era dos raios-X para uma outra onde surgiram novos equipamentos,
muito mais avançados, como os que permitiram o desenvolvimento de exames bem
mais sofisticados e sensíveis. A ecografia, a cintilografia, a tomografia helicoidal e a
ressonância magnética permitem, atualmente, um nível de possibilidades
diagnósticas nunca antes imaginado pelos médicos do passado.
A ética em pesquisa científica
A teoria nazista – e de alguns outros grupos radicais de direita - da
supremacia da “raça ariana”, mostrou-se totalmente falsa com a evolução científica.
Estudos genéticos recentes demonstram que as características físicas
responsáveis pelas diferenças de cor da pele são expressas em menos de dez genes,
ou seja, um percentual insignificante em relação aos cerca de 25 mil genes que
constituem o genoma humano.
Além disso, segundo a Paleoantropologia, todos os seres humanos descendem
de uma mesma população africana, que, formada a cerca de 100 a 200 mil anos
atrás, emigrou para outros continentes58.
Em consequência, a cor da pele constitui uma mera adaptação evolutiva a
diferentes níveis de radiação ultravioleta, não havendo qualquer justificativa para se
falar em raça como algo que nos possa separar.
Além das experiências nazistas feitas com prisioneiros de guerra, perseguidos
raciais e políticos e que tanto horrorizaram a humanidade, várias pesquisas foram
sendo desenvolvidas ao longo da história sem grandes preocupações éticas.
Em 1947, uma corte internacional reuniu-se na cidade de Nuremberg,
Alemanha, onde foram julgados os médicos nazistas responsáveis por vários crimes
contra a humanidade.
Além do julgamento, foi elaborado um conjunto de preceitos éticos para a
pesquisa clínica, que ficou conhecido como Código de Nuremberg. Apesar de ser
conhecido por todos, nem sempre as diretrizes éticas contidas no código foram
capazes de sensibilizar alguns pesquisadores.
58 Segundo Magnoli, em Uma gota de sangue.
Nos Estados Unidos da América, por exemplo, houve uma famosa pesquisa
sobre desenvolvimento da sífilis, que foi iniciada em 1932 e encerrada na década de
70. Ficou conhecida como “a pesquisa de Tuskegee”, por ser o nome da localidade
situada no Alabama onde morava a comunidade objeto da experiência.
No período da pesquisa 408 pacientes, todos negros e pobres, foram mantidos
sem tratamento da doença, e outros 192 (não sifilíticos) foram usados como grupo
controle. Nenhum foi alertado que estava sendo submetido a um ensaio. Ao
contrário, lhes informavam que iriam receber “um tratamento especial gratuito”.
O estudo, que durou 41 anos, levou à publicação de 13 trabalhos científicos.
Em um destes trabalhos publicado em 1954, os autores demonstraram que a
mortalidade entre os sifilíticos não tratados era maior do que entre os pacientes
presumivelmente não sifilíticos, além de terem a sua doença agravada com o passar
dos anos.
Os doentes continuaram sem receber tratamento, apesar de a penicilina estar
em uso desde a década de 1940. A própria comunidade científica, inexplicavelmente,
calou a respeito das questões éticas que envolviam essa pesquisa.
O estudo só veio a ser interrompido em 1972, quando foi denunciado por um
jornalista do Washington Star.
Em junho de 1964, durante a 18ª Assembléia Geral da Associação Médica
Mundial, realizada na Finlândia, foi divulgada a Declaração de Helsinki. Ainda hoje é
considerada a referência ética mais importante para a regulamentação de pesquisas
médicas envolvendo seres humanos, significando basicamente a aceitação, pelas
entidades médicas de todo o mundo, dos preceitos instituídos pelo Código de
Nuremberg.
No Brasil, as primeiras normas para a pesquisa em seres humanos foram
inicialmente estabelecidas pela Resolução nº1 de 18 de junho de 1988, do Conselho
Nacional de Saúde, do Ministério da Saúde. As normas nacionais tinham caráter de
orientação e de conscientização da sociedade sobre a importância da ética em
ciência. Toda a pesquisa em seres humanos deveria ser submetida, ainda em fase de
projeto, a um comitê de ética, recomendava a Resolução 1/88.
Em 10 de outubro de 1996 outras normas passaram a vigorar, após a sua
publicação no Diário Oficial da União, por meio da Resolução nº 196 do Conselho
Nacional de Saúde.
Ela incorpora os quatro referenciais básicos da bioética: autonomia ou
liberdade (os sujeitos das experimentações deverão dar o seu consentimento livre e
plenamente informado), não maleficência, beneficência e justiça. De forma
semelhante à Resolução nº1, toda pesquisa envolvendo seres humanos deverá ser
submetida à apreciação de um comitê de ética em pesquisa.
Na impossibilidade de constituir um comitê próprio, a instituição onde se
pretende realizar a pesquisa (ou o pesquisador principal) deverá submeter o projeto
à apreciação do comitê de outra instituição. Do projeto deve constar um termo de
adesão em que cada pessoa consente, de forma livre e consciente, em participar da
pesquisa. Tais exigências se aplicam a qualquer tipo de estudo, independente do
método utilizado.
No entanto, apesar de todas essas recomendações, ainda hoje ocorrem
desvios éticos nas pesquisas científicas realizadas em vários países, inclusive no
Brasil. Um dos principais problemas reside no uso de placebo, ou no uso de um falso
medicamento, sem a presença de princípio ativo, que é empregado para neutralizar
uma possível melhora de uma determinada doença apenas por razões psicológicas
ou sugestão.
Pela Declaração de Helsinki, placebo só poderia ser usado quando não
existisse tratamento efetivo para a doença. Isso nem sempre ocorre, como quando
são apresentadas várias pesquisas em que o placebo é utilizado em enfermidades
como hipertensão, enxaqueca e depressão, entre outras. Nestes casos, o uso de
placebo é totalmente injustificável, já que existem vários medicamentos de
reconhecida eficácia para o tratamento dessas doenças.
Dados recentes evidenciam ser o nosso país um dos que mais utilizam
voluntários humanos em pesquisas clínicas. Segundo a Comissão Nacional de Ética
em Pesquisa (CONEP), apenas em 2001, 645 mil brasileiros participaram de
pesquisas, a maioria deles usando medicamentos de laboratórios estrangeiros. Quase
todas essas pessoas eram pacientes pobres, atendidos pela rede pública de saúde.
Um olhar sobre a história
Segundo Hobsbawn (
On History, 1997), a ciência moderna sistemática e
deliberadamente negligencia a experiência histórica. O modelo atual é esperar uma
resposta definitiva, sobre qualquer assunto, de computadores cada vez mais
parecidos com um ser etéreo, de quem nada se espera a não ser a infalibilidade.
Além disso, a evolução científica tem levado a atual civilização a acreditar cada
vez mais no conhecimento científico e na tecnologia, considerando-a até capaz de
substituir ou mesmo superar a Deus59.
O materialismo histórico tinha como um dos seus objetivos trazer a história
para mais perto das ciências sociais, evitando as simplificações exageradas do
positivismo. Segundo Marx, as sociedades são sistemas de relações entre seres
humanos, existindo uma relação fundamental entre o ser social e a consciência.
Assim, não podemos desenvolver um profissional de saúde sem lhe dar uma
formação apoiada nas ciências sociais. A importância da falta desta visão pode ser
exemplificada pelo descaso com que a saúde pública ainda é tratada no Brasil. Isso
pode ser comprovado ao se observar doenças que antes estavam aparentemente
controladas, como a febre amarela, a cólera, a lepra e a tuberculose, voltando
novamente às manchetes dos jornais, além do surgimento de novas endemias, como
a dengue e a AIDS.
Esta situação pode ser atribuída a vários fatores, mas também ao
esquecimento da história sanitária da civilização. O que foi prioridade no passado,
passou a não ser mais no presente, como as campanhas desenvolvidas por Oswaldo
Cruz para o combate ao vetor da febre amarela, no início do século XX. As
conseqüências têm um alto custo econômico e social.
Sobre o potencial das nações, hoje não se valorizam tanto os recursos
minerais como no passado, mas o capital humano, este sim o grande propulsor do
desenvolvimento de um Estado. Como pensar em grandes transformações, se nosso
59 Doutrina do gnosticismo, citada por Jonh G. Gunnel, em Teoria Política.
povo continua à mercê das mesmas doenças e limitações, há muito abolidas nos
países desenvolvidos?
Por outro lado, o século XX produziu grandes mudanças e inovações
tecnológicas. Passamos a conviver com um grau de conforto, tecnologia e facilidades
que nossos ancestrais jamais imaginaram.
Mas será que mudamos tanto mesmo?
Hobsbawn nos ensina que, apesar de mais altos e pesados do que nossos
antepassados, que viviam nas cavernas, biológica e emocionalmente o homem é
quase o mesmo.
Ainda somos egoístas, invejosos e pouco propensos a pensar na humanidade
como uma grande família.
Talvez possamos sonhar, no futuro, com um mundo sem fronteiras, e com
maior solidariedade, em que não haja fome, miséria, guerra, doença ou qualquer
outro tipo de sofrimento para todos os habitantes desse planeta azul, primeira
morada do ser humano no universo infinito.
Doenças mais importantes no final do século XX
Câncer
O câncer não é uma doença única, mas um conjunto de mais de cem doenças
que têm como característica comum o surgimento de células anormais, que
perderam o controle sobre o crescimento e a reprodução celular.
Apesar de se ter conhecimento da existência de alguns tipos de câncer desde
a mais remota Antigüidade, como múmias egípcias com câncer ósseo, alguns tipos
da doença têm aumentado de forma considerável neste século, como é o caso do
câncer de pulmão, antes raramente diagnosticado.
Avanços nos conhecimentos de biologia molecular têm oferecido uma melhor
compreensão sobre o surgimento destas doenças. A divisão celular normal ocorre de
forma controlada pela atuação conjunta de fatores chamados de promotores, os
oncogenes, e de fatores restritivos ou limitadores, denominados gens supressores.
O aparecimento do câncer parece ser conseqüência ou da excessiva ativação
dos oncogenes, ou da perda da função dos supressores, ou ainda de ambos os
mecanismos, ao mesmo tempo.
Várias são as causas da modificação da atuação destes genes. A radiação, por
efeito direto sobre a estrutura do ADN celular, provocando rupturas da molécula e
facilitando o surgimento de mutações, é um dos mecanismos mais bem conhecidos.
Os agentes químicos constituem outro grande grupo de substâncias
carcinogênicas. Entre as mais conhecidas podem-se citar os derivados da anilina,
benzeno, óxido de etileno, destilados do petróleo, pesticidas e herbicidas.
O hábito do tabagismo tem grande responsabilidade sobre o surgimento de
vários tipos de câncer, mas, principalmente, o de pulmão. Entre as substâncias
cancerígenas que são absorvidas pelo organismo, ao fumar, algumas das mais
importantes são os hidrocarbonetos poliaromáticos, aminas, aldeídos, benzeno,
arsênico, níquel e chumbo.
Fatores irritantes do trato digestivo representam outro grupo de carcinógenos
como ingestão de defumados e comidas muito quentes.
Sabe-se, ainda, que a dieta rica em gorduras saturadas tem responsabilidade
sobre o desenvolvimento de alguns tipos de câncer, como o de mama e o de
próstata.
Também alguns tipos de micróbios são responsabilizados pelo surgimento de
neoplasias, como a bactéria Helicobacter pylori (câncer de estomago), o vírus da
hepatite B (câncer de fígado), o papilomavírus ou HPV (carcinoma de colo de útero),
o HTLV-II (leucemia de células T) e o HIV (alguns tipos de linfoma e o sarcoma de
Kaposi).
Antes considerado como uma doença incurável, o câncer, hoje, se
diagnosticado precocemente, apresenta mortalidade cada vez menor. Várias
abordagens têm sido utilizadas, desde as cirurgias, radioterapia, imunoterapia e
quimioterapia, com grandes chances de êxito.
Atualmente, com os novos avanços em termos de laboratório (exame
citopatológico, marcadores tumorais, enzimas, hormônios, etc.), de radioimagem e
mesmo de biologia molecular, a tendência é a prevenção do câncer se tornar cada
vez mais comum, com conseqüente queda de suas taxas de mortalidade.
Doenças cardiovasculares
As doenças cardiovasculares representam atualmente, em todo o mundo, a
maior causa de mortalidade, em torno de 30% de todos os óbitos.
Isto nem sempre foi assim. Até o início do século XIX, a média de vida do ser
humano era de 35 anos, e se morria, principalmente, de doenças infecciosas.
À medida que a reforma sanitária foi sendo implantada (melhoria da qualidade
da rede de água e de esgoto, controle de roedores, vacinações, etc.), houve uma
correspondência na queda da mortalidade pelas doenças transmissíveis. Ao mesmo
tempo em que a média de vida foi se elevando, também ocorreu um incremento das
doenças crônico-degenerativas, como as doenças cardiovasculares e os vários tipos
de câncer.
Entre as doenças cardiovasculares, as mais importantes são as coronariopatias
(ou cardiopatias isquêmicas), a hipertensão arterial e as doenças cerebrovasculares.
Estas patologias têm fatores de risco comuns, e também podem ocorrer
associadas.
O aumento do colesterol (principalmente o LDL colesterol), dos triglicerídeos,
a própria hipertensão, a depressão e a ansiedade, o tabagismo, o diabetes, a
obesidade, o stress, assim como o sedentarismo, são os principais fatores de risco
cardiovascular.
Para o desenvolvimento de uma vida sadia há que se diminuir a associação
desses fatores, procurando modificá-los ou aboli-los se necessário.
Uma importante contribuição foi dada pelas companhias de seguro, no século
XIX, para uma menor mortalidade por este grupo de doenças, ou seja, a introdução
das avaliações periódicas de saúde, ou check-up.
Evidentemente, não foram razões humanitárias que as levaram a agir assim,
mas razões econômicas. Quanto mais tempo estivesse vivo o segurado, melhor para
a seguradora, pois seu tempo de contribuição aumentaria.
Em 1861, Horace Dobell propôs o exame periódico de saúde como uma
maneira de se detectar as patologias em um momento anterior à doença clínica, o
que estava totalmente correto.
Síndrome da Imunodeficiência Adquirida (SIDA ou AIDS)
À semelhança da AIDS, a sífilis foi, desde a Idade Média e até a descoberta da
penicilina, uma endemia que causou milhões de mortes e levou o pânico à
sociedade. Desconhecida a sua causa, os sifilíticos chegaram a ser tão discriminados
quanto os leprosos, sendo que muitas vezes uma doença era confundida com a
outra.
Quando se percebeu que era através do contato sexual que a doença era
transmitida, as prostitutas passaram a sofrer forte perseguição, como nos mostra
esta pregação, feita por um dos maiores anatomistas da época, o francês Sylvius, em
1567:
“Aprende a odiar a libertinagem das prostitutas mais que a dos cães e das
serpentes. Odeia o seu olhar impudico, os seus gestos tentadores, as suas conversas
sedutoras, o sorriso dissimulado dos seus lábios, os seus seios erguidos para a
corrupção”.
Da mesma forma que no final do século XX - quando a AIDS gerou
preconceitos e até perseguições aos chamados grupos de risco (homossexuais,
bissexuais, hemofílicos, etc.) -, no início da epidemia a sífilis também gerou os
mesmos sentimentos de intolerância e irracionalidade.
O risco de contágio e, em conseqüência, de vir a morrer pela doença,
desencadeou uma nova moral, antes bastante liberal, tendo o mesmo ocorrido com a
AIDS, pelo menos até o surgimento de novos medicamentos mais eficazes do que o
primeiro lançado no mercado, o AZT.
De forma diversa ao ocorrido com a sífilis – cujo agente causador, a bactéria
Treponema pallidum, só foi descoberto em 1905, 500 anos após a sua chegada à
Europa, por Fritz Schaudin - o vírus HIV, causador da AIDS, foi identificado em
poucos anos por Montagnier, do Instituto Pasteur, de Paris, em 1983.
Hoje, a AIDS continua sendo um importante problema de saúde pública, mas
especialmente para os países subdesenvolvidos, como os da região central da África.
Pelo elevado custo do tratamento do aidético, por ser uma doença crônica que pode
levar a infecções oportunistas, algumas delas necessitando internação, o custo final
costuma ser tão elevado que tem acarretado repercussões muito sérias para a
economia destes países.
A projeção da Organização Mundial de Saúde era de, até o ano 2.000, haver
cerca de 30 milhões de portadores do HIV no mundo, com 10 milhões de casos de
AIDS, sendo 90% deles nos países subdesenvolvidos.
Segundo outra estatística, apresentada na XI Conferência Internacional sobre
AIDS, realizada em 1996, em Vancouver, Canadá, haveria, em todo o mundo, 22
milhões de adultos e crianças portadores do vírus HIV, sendo que 94% deles nos
países em desenvolvimento.
No Brasil, segundo o Ministério da Saúde, foram notificados 506 mil casos de
AIDS até junho de 2008, com 205 mil óbitos.
Até 1995 a taxa de letalidade era de 9,7 óbitos por 100 mil habitantes. Com a
introdução da política de acesso universal ao tratamento anti-retroviral, houve queda
gradual da mortalidade, com estabilização em 6,3 óbitos por 100 mil habitantes, a
partir do ano 2000.
É importante ressaltar, ainda, a freqüente associação de tuberculose com
AIDS, sendo que em torno de 20% a 30% dos casos de AIDS são notificados junto
com a micobacteriose, especialmente entre a população com menor nível de
escolaridade e de renda.
Estudos demonstram ainda que a co-infecção pelo bacilo de Koch e pelo HIV
pode elevar em até 25 vezes o risco do desenvolvimento da tuberculose, o que, por
sua vez, contribui significativamente para elevar a letalidade por AIDS.
Dengue
Atualmente a dengue é a mais importante doença viral transmitida por
mosquitos que acomete humanos. Sua distribuição global é comparável à da malária.
A doença é endemica na África, nas Américas e partes do Oriente Médio, Ásia e
Oeste do Pacífico.
A infecção é transmitida pelo Aedes aegypti, vetor de hábitos diurnos. O
mosquito é originário da África, mas se espalhou pelas regiões tropicais do planeta
durante os dois últimos séculos por meio do comércio internacional. Bem adaptado
ao meio urbano, cresce em áreas onde há água estocada ou onde possa se
acumular, como coleções de água parada, garrafas, vasos, panelas, recipientes de
plástico e pneus.
Trabalhos recentes têm demonstrado que a estratégia de combater a forma
adulta do mosquito pela pulverização com inseticida não é mais a melhor de combate
à doença. Várias populações do mosquito apresentam resistência aos inseticidas
organofosforados.
O combate ao transmissor deve ser feito, prioritariamente, para impedir a sua
multiplicação desde o início. Para isso é fundamental o apoio da população, assim
como ao trabalho realizado pelas equipes do Programa Saúde da Família.
A frequência da dengue e de suas complicações mais severas como a forma
hemorrágica e a síndrome do choque, tem crescido de forma acentuada desde a
década de 1980.
A dengue é uma doença viral causada por um de quatro sorotipos do gênero
Flavivírus. A infecção por um dos sorotipos não promove proteção a qualquer outro.
Quanto à forma clínica, a doença pode cursar desde uma síndrome viral
inespecífica até as formas mais severas.
A febre hemorrágica por dengue é uma condição de elevado risco de morte,
caracterizada por aumento da permeabilidade capilar que pode levar ao choque
hipovolemico e, em seguida, à morte. A forma hemorrágica se detecta,
laboratorialmente, por uma queda na contagem das plaquetas sanguíneas.
Para o desenvolvimento das formas severas da infecção, são importantes
fatores de risco o tipo de cepa e sorotipo do vírus, assim como a idade, estado da
imunidade, predisposição genética do paciente e contato prévio com outro sorotipo
anteriormente.
A recente epidemia de dengue do tipo 2 e do tipo 3, que acometeu
principalmente o Rio de Janeiro, produziu em todo o Brasil, nos primeiros três meses
de 2008, mais de 85 mil casos, com mais de 400 casos da forma hemorrágica, além
de dezenas de óbitos.
Não existe tratamento específico para a infecção pelos vírus da dengue, ou
seja, o tratamento é apenas sintomático e de apoio, especialmente nos casos de
suspeita das formas severas, como reidratação e controle do quadro hemorrágico.
Relíquias da arte de curar
Em toda questão relacionada à doença, a credulidade continua sendo um fato
permanente, sem a influência da civilização ou da educação. Sir William Osler
Receita de anticoncepcional (Egito 2200 a. C.)
Pontas de acácia bem esmagadas, juntamente com mel e tâmaras, em um chumaço
de fibras, para serem introduzidas profundamente no ventre.
Receita para saber o sexo do filho (Egito 2200 a. C.)
Encher duas bolsas, feitas de tecidos, com grãos de trigo e de cevada. A
gestante deverá regar as bolsas com sua urina todos os dias. Se os grãos de uma
das bolsas começarem a brotar, ela dará à luz. Se brotar a cevada, nascerá uma
menina. Se brotar o trigo, nascerá um menino. Se nem o trigo e nem a cevada
brotarem, não haverá parto.
Receita contra resfriado( Egito, 1500 a. C.)
“Defluxo, resfriado, filho do resfriado que quebra os ossos, destrói o crânio, de
modo que as sete aberturas na cabeça dos súditos de Rá, que agora se voltam em
orações a Thot. Veja que eu trouxe o medicamento contra ti. Leite de quem pariu
um menino, látex de agradável cheiro que te afasta. Siga para a terra, apodreça,
apodreça quatro vezes”.
Plantas usadas pela medicina chinesa tradicional
Yuzhizi: extraída da fruta seca, madura, da planta Akebia quinata. Tem como
principio ativo uma saponina. Tem ação diurética e antiinflamatória.
Zexie: extraída da raiz seca da Alisma orientalis. Tem como principio ativo o
alisol. Ação diurética, tratamento da hipercolesterolemia e inibição da agregação
plaquetária (menor possibilidade de trombose e infartos).
Alho: extraído da planta Allium satimm, também muito empregado pelos
egípcios. Tem como princípio ativo a alicina. Ação no tratamento de doenças
infecciosas (antibacteriano, antifúngico e antiviral). Antilipemico, especialmente por
levar à diminuição do colesterol ruim (LDL e VLDL colesterol). Aumenta a atividade
fibrinolítica do sangue e inibe a agregação plaquetária. Melhora o nível de tolerância
à glicose, colaborando para controlar o diabetes.
Anemona: extraída da planta Anemona raddeana. Tem como princípios ativos
as saponinas. Ação antireumática e antiinflamatória (antiflebite).
Angelica: extraída da planta de mesmo nome. Tem como princípio ativo a
angelicina. Ação analgésica, antipirética, antireumática e para o tratamento de
hemorragias uterinas.
Anisodus: extraída da planta chinesa Anisodus tanguticus. Tem como principio
ativo um alcalóide chamado anisodamina/anisodina. Ação antiespasmódica ao nível
de arteríolas, melhorando a microcirculação. Tem também ação antiasmática, pela
inibição da contração dos brônquios, quando provocada pela ação da histamina,
como nas alergias.
Artemisia: extraída do broto e folhas da Artemisia annua. Tem como principio
ativo a artemisinina. Tem potente ação antimalárica, contra várias espécies de
Plasmodium. Em um estudo com mais de dois mil pacientes com impaludismo, todos
ficaram curados com o uso da artemisinina, além dela ser efetiva no tratamento da
malária por Plasmodium falciparum resistente à cloroquina.
Yadanzi: extraída da fruta madura da planta Brucea gavanica. Tem como
principio ativo o quassinoide. Antigamente era usado como antimalárico, hoje é
empregado no tratamento de leucemias.
Cephalotaxus: extraída de oito espécies da planta Cephalotaxus. Tem como
princípios ativos alcaloides como o taxol e a cefalotaxina. Empregados na
quimioterapia de tumores(câncer).
Duzhong: extraída do caule da planta Eucommia ulmoides. Tem como
principio ativo a aucubina. Ação antihipertensiva sobre a musculatura lisa das
arteríolas, provocando vasodilatação.
Baigno: extraído das sementes maduras, raízes e folhas da planta Ginkgo
biloba. Tem como princípios ativos os gincolidos e fenóis. Ação antimicrobiana dada
pelos fenóis, melhoria da atividade cerebral do idoso e da irrigação vascular
periférica, por meio dos gincolidos.
Ginseng: extraído da raiz seca da planta Panax ginseng. Tem como princípios
ativos algumas saponinas. Ação bastante variada, incluindo efeitos cardiovasculares,
sobre o sistema nervoso, a imunidade, a atividade antitumoral e antidiabética. Sobre
o sistema cardiovascular sua ação é de aumentar a freqüência cardíaca e diminuir a
pressão arterial. Diminui os níveis de colesterol ruim no sangue e de triglicerídeos.
Aumenta os níveis do colesterol bom(HDL). Tem ação antidiabética por diminuir os
níveis de glicose no sangue e aumentar a formação de glicogênio no fígado.
Plantas usadas pelos mesopotâmios(700 a. C.)
Conheciam várias plantas medicinais como a papoula(fonte do ópio),
mandrágora, meimendro, louro, mirra, incenso, açafrão, tomilho, cominho, zimbro,
alho e cebola. A mais importante, no entanto, era a beladona, Atropa belladona. Seu
componente químico mais importante é a atropina, um alcalóide que atua inibindo o
sistema nervoso parassimpático e que pode até levar à morte, se administrado em
doses excessivas.
O cânhamo, Cannabis sativa, foi empregado desde a mais remota
Antigüidade, na China, Índia e Mesopotâmia. Era utilizado contra as dores, em casos
de bronquite, doenças da bexiga, reumatismo e insônia. Também foi empregado na
adivinhação e no exorcismo.
Receita contra a tosse (Mesopotâmia, 700 a. C.)
Desmanchar eufórbio60 em cerveja pura, mel e azeite refinado. Fazer o doente
engolir o líquido de uma vez. Em seguida, tomar cerveja fria e mel. Depois provocar
o vômito, com o auxílio de uma pena. Então o paciente deve comer pastéis com
creme e mel, e beber vinho doce.
Receita para eliminar cálculos renais (Mesopotâmia, 700 a. C.)
Reduzir o tamanho das pedras com óleo de terebintina e com cascas de ovo
pulverizadas, principalmente do ovo de avestruz.
Tratamento de pneumonias (Mesopotâmia 700 a. C.)
Fazer cataplasmas quentes de linhaça, combinando com o envolvimento em
panos, que devem ser mergulhados repetidamente em água quente ou em um chá
de erva-doce.
Sobre o ensino da cirurgia (Índia 400 a. C.)
“O mestre deverá procurar que seu aluno aprenda a prática cirúrgica, mesmo
que já tenha estudado as diversas partes da ciência médica geral. Por mais que
tenha lido, o estudante é incompetente como cirurgião, se não dominar a prática
cirúrgica. Aquele que conhece apenas os seus livros ficará desorientado e
amedrontado ao defrontar-se com a verdadeira doença, tal como um covarde no
campo de batalha”.
Sobre a ética médica(Índia 400 a.C.)
“Dedica-te inteiramente ao auxílio do doente, mesmo com a perda da tua
própria vida. Jamais prejudique o doente, nem mesmo em pensamentos. Esforça-te
constantemente para aprimorar teus conhecimentos. Não trates da mulher a não ser
na presença do marido. O médico deve observar todas as regras do bem trajar e do
bom comportamento. Quando estiver com um doente, não deve ocupar-se com
palavras ou pensamentos de qualquer outro assunto que não seja o caso daquele
que sofre. Fora da casa do paciente ele não poderá falar sobre os acontecimentos
dessa casa. Não poderá falar ao paciente sobre a possibilidade do seu falecimento,
quando isso prejudicar o próprio paciente ou qualquer outro. Diante dos deuses
deverás assumir esta responsabilidade. Que todos os deuses te auxiliem quando
60 Várias espécies de plantas pertencem às euforbiáceas. No Brasil, a seringueira é uma das mais importantes.
assim procederes. Caso contrário, que estejam contra ti. A isto os estudantes digam:
assim seja”.
Sobre a natureza das coisas (Tito Lucrécio Caro, 59 a . C.)
“A morte, em si, não é terrível; só os nossos temores do além a tornam assim.
Mas o além não existe. O inferno é aqui, no sofrimento que surge da ignorância, da
paixão, da belicosidade e da cobiça; e o céu é aqui, nos serenos templos da
sabedoria”.
Como lidar com as frustrações (Sêneca, 65 d.C.)
Suportamos melhor as frustrações para as quais nos preparamos e que
compreendemos, e somos atingidos principalmente por aquelas que menos
esperamos e que não conseguimos entender.
Ao encararmos racionalmente as conseqüências de um desejo não realizado,
teremos grande chance de perceber que as questões envolvidas costumam ser bem
mais modestas do que as ansiedades que geraram.
A filosofia deve procurar nos harmonizar com a percepção da realidade e
dessa forma nos poupar, senão da própria frustração, ao menos das emoções
perniciosas que costumam acompanhá-la, tais como raiva ou mesmo acessos de
fúria ou crises de tristeza.
A sabedoria está em distinguir corretamente as situações em que estamos
livres para moldar a realidade de acordo com nossos desejos, daquelas em que
somos obrigados a aceitar o que não podemos modificar com tranqüilidade e espírito
desarmado.
Receita para fumigação aromática (Inglaterra, 1655)
Tomar aroeira e olíbano, uma onça de cada, pílulas de cidra, raízes de poejo,
ervas secas e cravos, e de cada um três dracmas. Fazer tudo num pó grosso e ferver
em fogo brando, num pote perfumado com água de alfazema e vinho branco.
Recomendações de saúde (Escola de Salerno, século XVIII)
Respire um ar sereno, brilhante de pureza,
Do qual nenhuma exalação turve a clareza;
Evite os odores infectos e vapores deletérios,
Que sobem dos esgotos e empestam a atmosfera.
Quer prolongar o sucesso dos seus prazeres?
Evite o excesso do vício e da mesa.
Se o mal é insistente, cabe à arte reagir:
Mais que curar o mal, a arte deve prevenir.
O ar, o repouso e o sono, o prazer e a comida,
Preservam a saúde do homem, se saboreados com medida.
O abuso transforma em veneno esse bem inocente,
Destruindo o corpo e turvando a mente.
Receitas contra a tristeza (Portugal,1759)
“Plínio disse que os bons alimentos desterram a tristeza e sossegam as
paixões; e eu digo que a boa companhia da mesa ainda tem mais eficácia que as
mesmas iguarias que nela se comem”.
“Se Cícero chamou morte do homem à ociosidade, também com máxima
católica pode chamar de vida o emprego literário, porque a recreação dos livros é
uma política cristã para a conformidade dos males, e tolerá-los com semblante alegre
e heróica indústria para ser feliz, sem depender da fortuna”.
Diferença entre o verdadeiro e o falso médico (Inglaterra, 1840)
O falso apresenta o mesmo remédio em todas as doenças, muito embora elas
possam diferir largamente nos seus sintomas e caráter, ao passo que o verdadeiro
examina, no espírito da análise filosófica, todas as peculiaridades existentes no seu
paciente, bem como a sua discordância. Daí adapta com judiciosa discrição e com
um julgamento correto dos seus agentes medicinais, de tal forma que possa ser a
mais bem calculada para controlar e corrigir a doença do seu paciente.
Remédio para evacuação mensal (Brasil, 1843)
Toma-se um manípulo de caroços de algodoeiro, infunde-se em água
fervente, por 20 minutos, com volume suficiente para uma xícara, e se deverá tomar
de manhã, em jejum. Sendo tomado seis dias antes em que deveria aparecer a
evacuação mensal.
A verdade e a pesquisa (Claude Bernard, 1865)
“Quando estou em meu laboratório, começo por fechar a porta ao
materialismo e ao espiritualismo; observo somente os fatos, e procuro apenas
encontrar as condições sob as quais a vida se manifesta.”
“Quando você se encontra com um fato que se opõe a uma teoria
estabelecida, você deve aderir aos fatos e abandonar a teoria, mesmo que ela seja
apoiada por grandes autoridades e usualmente adotada”.
Sobre a ciência experimental (Louis Pasteur, 1884)
“A vontade é poderosa, enquanto que a ação e o trabalho geralmente seguem
a vontade e quase sempre o trabalho é acompanhado pelo sucesso. Estas três
coisas, vontade, trabalho e sucesso, preenchem a existência humana. A vontade
abre as portas do sucesso de forma brilhante e feliz; o trabalho passa por essas
portas e ao final da jornada o sucesso vem para coroar nossos esforços. E então, se
sua determinação for firme, sua tarefa será como puder ser feita, se já a tiver
iniciado; e você terá de caminhar em frente, se quiser concluí-la.
O cultivo da ciência, em sua expressão máxima, é talvez mesmo mais
necessário para a condição moral de uma nação do que para sua prosperidade
material.
Grandes descobertas, como as manifestações do pensamento na arte, na
ciência e nas letras, e em uma palavra o exercício desinteressado da mente em cada
direção e nos centros de instrução de onde se irradiam, introduzem a sociedade,
como um todo, no espírito filosófico e científico, no espírito de discernimento que
submete tudo ao raciocínio severo, condena a ignorância e descarta o erro e o
preconceito. “Elas elevam o nível intelectual e o senso moral, e por meio delas a
própria idéia divina é divulgada e intensificada”.
Ataque de nervos (França, 1909)
O ataque de nervos, também chamado de crise nervosa ou crise histérica, é
específico de algumas mulheres ou jovens nervosas e emotivas. Ele também pode
ocorrer em homens, porém mais raramente.
A crise é, algumas vezes, anunciada com antecedência de várias horas, ou
mesmo dias, através de bocejos, lágrimas ou risadas sem motivo, ou por uma
sensação da presença de uma bola que sobe desde o abdômen ou o tórax até o
pescoço.
A crise explode como conseqüência de uma emoção, contrariedade ou mesmo
sem motivo aparente, especialmente durante o período menstrual.
Abra as janelas e dê ar ao doente, retire suas roupas, deite-o em um sofá ou
em uma cama. Retire todas as pessoas desnecessárias ao seu redor. Se for uma
jovem, deixe apenas a sua mãe. Se for uma dama, deixe apenas o marido ao seu
lado.
Jogue água fria no seu rosto. Se a crise for forte, quem atende pode tentar
comprimir, com as duas mãos, fortemente, sobre o baixo ventre, na região dos
ovários, especialmente do lado esquerdo.
Não dê sais, nem odores fortes, vinagres, ou qualquer outra coisa que poderia
excitar a doente e prolongar a crise. Mas pode-se, com um lenço, fazê-la inalar um
pouco de éter ou água de colônia.
Os ataques terminam com lágrimas abundantes ou com um pouco de delírio.
Se eles se repetirem, deve-se consultar um médico que procurará encontrar as
razões primordiais destas crises e indicará o tratamento adequado a ser seguido.
Calvície (França, 1911)
Fazer massagens diárias do couro cabeludo com a seguinte solução: Amoníaco
– 4 gr.; Essência de terebintina – 13 gr.e Álcool canforado – 83 ml.
Diabetes(França, 1911)
Indicações terapêuticas:
Higiene corporal – Banhos mornos, duas vezes por semana, durante 20 minutos,
acompanhados de fricção suave com uma esponja.
Higiene alimentar - Restrição de açúcar, que deverá ser substituído por glicerina ou
sacarina. Restringir frutas, exceto pêssegos, damascos, maçãs, framboesas e melões,
todas em pequena quantidade. Restringir farináceos. São permitidas as verduras,
assim como as gorduras, manteiga, azeite, ovos, e queijos. Pão em pequena
quantidade. Carnes e peixes também são permitidos. Massas devem ser restringidas.
Álcool, nenhum.
Epilepsia (França, 1911)
Para a prevenção das crises, preparar uma solução de hidrato de cloral, que
deverá ser dada até três vezes a cada 24 horas, quando os acessos estiverem se
repetindo em intervalos curtos.
Modo de preparo da solução: Hidrato de cloral – 2 gr.; Brometo de potássio – 2 gr.;
Gema de ovo – 01. Água – 150 ml.
Também o clorofórmio poderá ser empregado (por via nasal), porém a sua
ação é mais incerta, o mesmo com o éter e com o brometo de etila. Deve-se manter
o doente em um quarto pouco iluminado, onde lhe será proibido falar ou se
movimentar.
Insônia (França, 1911)
Ao anoitecer, antes da última refeição, tome um banho com sais, de duração
de 45 minutos, a uma temperatura de 36/37 ºC.
Em seguida, faça uma refeição ligeira, sem álcool ou café. Vá se deitar após
duas horas e meia depois de concluída a refeição.
Psicoterapia (França, 1922)
A psicoterapia é uma verdadeira ciência da qual só daremos aqui algumas
indicações. Lembremos somente que:
Todo médico que goza da confiança de um doente exerce sobre ele uma ação
favorável, que contribui fortemente para o sucesso terapêutico.
Apesar de útil em todo o tempo e em todo lugar, esta ação é particularmente
indispensável e preciosa quando se procura tratar uma doença nervosa ou mental.
Em muitos casos, é indispensável que esta psicoterapia produza todo seu
efeito de isolar o paciente, de o subtrair ao meio familiar do qual o atendimento mal
feito agrava a maior parte das manifestações patológicas.
Esta psicoterapia, válida sobretudo nas afecções ditas funcionais do sistema
nervoso, está longe de ser desprovida de eficácia quando se tem uma doença
orgânica.
Ela necessita muita consistência por parte do médico, segurança, talento
psicológico e conhecimento aprofundado do caso a tratar.
Histeria (França, 1922)
Prevenção:
Levantar as crianças de forma conveniente, poupar-lhes emoções violentas,
desenvolver-lhes sobretudo a razão e a inteligência. Caso se trate de pessoas com
atividade neuropática, enviá-las para viver no campo e cuidar para que não vejam
um ataque histérico.
Tratamento:
1º Métodos psicoterápicos – o isolamento constitui, de longe, o melhor modo
de tratamento da histeria. Algumas pessoas ficam curadas só de pensar em entrar
numa casa de saúde. Para os outros, lembrar que o isolamento deve ser absoluto.
Que haja visitas freqüentes do médico, que deve cuidar e envidar esforços de forma
continuada e diminuindo o rigor até a cura do doente.
2º Métodos físicos – a eletricidade age, sobretudo, por sugestão. Então, ela
constitui uma das medicações mais preciosas, quando é bem manejada. Quanto à
hidroterapia, se a aplicarmos, recorrer, de preferência, às duchas mornas.
Amamentação do recém nascido (Alemanha,1922)
A criança não deve receber alimento algum no primeiro dia depois do parto. A
mãe tem necessidade de repouso, e, além disso, o recém nascido, em geral, não
manifesta sinais de fome. Se mostrar algum incômodo, pode-se dar simplesmente
algumas colheres pequenas de chá ralo, adoçado com um pouco de açúcar, ao qual
se junta uma pitada de sal.
No segundo dia (24 horas após o parto), a criança será levada ao seio pela
primeira vez. Para isso, a mãe, deitada, volta-se para o filho colocado ao seu lado.
Em seguida, com o bico do seio preso por ela entre o dedo indicador e o médio, será
introduzido na boca da criança de maneira tal que não sugue unicamente o mamilo,
mas consiga prender entre o maxilar e a mandíbula todo o vestíbulo aureolar. Tenha-
se, entretanto, cautela de deixar livre o nariz da criança que não deve ficar colado ao
peito, pelo risco de sufocar.
No primeiro dia inicia-se a amamentação levando o lactente ao seio mais ou
menos três vezes. No dia seguinte, quatro vezes, e daí por diante cinco vezes, com
pausas regulares de quatro horas, mantendo durante a noite um intervalo de oito
horas. Havendo inquietação da criança no decorrer da noite, pode-se dar um pouco
de chá nas primeiras semanas, até que se habitue à grande pausa noturna.
Muitas crianças, quando a secreção é abundante, contentam-se com quatro
mamadas por dia. O hábito de se nutrir a horas certas faz com que o lactente não
exija alimento nos intervalos. Mas, quando ocasionalmente manifestar fome um
pouco antes da hora marcada, ou estando dormindo ultrapassar o momento
prescrito para mamar, não há inconveniente em se afastar um pouco desse regime.
O tempo de cada mamada deve durar, aproximadamente, 20 minutos.
Quando a criança suga mal, ou por algum motivo sente dificuldades para mamar, o
tempo pode ser elevado para trinta minutos, durante a primeira semana de vida.
Após três dias do parto, a nutriz deve sentar-se no leito para amamentar o
filho.
A alimentação exclusiva da criança pelo leite materno deve ir até o sexto mês
de vida. A partir daí, deve-se substituir uma das mamadas por uma sopa (feita com
caldo de carne ou de legumes cozidos), à qual se junta um pouco de farinha
(cevadinha, etc.), até adquirir a consistência de pirão mole, do qual se dá à criança
de 150 a 200 gramas. Assim se vai passando, gradativamente, à alimentação
artificial, até ocorrer o desmame por volta do nono mês ou até o primeiro ano de
vida.
Tratamento da obesidade (França, 1922)
Todo obeso que quer emagrecer deve ter paciência e força de vontade, comer
só ou num sanatório apropriado, e pesar-se regularmente a cada semana.
Todos os regimes desejados repousam em um mesmo princípio: redução da
massa de alimentos e escolha de sua qualidade.
Alimentos a serem evitados: carnes gordurosas, molhos, manteiga, frios,
purê, doces e chocolates.
Bebidas a serem evitadas: cerveja, licores, álcool, vinho, champanhe e cidra.
Exemplos de regimes dietéticos:
1.Para o grande obeso – repouso na cama.
Primeira semana: 3 a 4 litros de leite por dia, e um ou dois ovos.
Segunda semana: 3 litros de leite, e um ovo por dia.
Terceira semana: 3 litros de leite por dia. O doente se levantará.
Quarta semana: 2 litros de leite por dia. Alguns exercícios, como caminhada.
2.Para o obeso médio.
Café da manhã: taça de chá morno, com um pouco de suco de limão.
Almoço: bife grelhado, salada com um pouco de óleo, vinagre e suco de
limão. Espinafre ou chicória. Uma fruta. Um pedaço de pão grelhado.
Jantar: frango ou pássaro ou caça, sem molho e em pequena quantidade.
Salada. Uma fruta. Um pedaço de pão grelhado.
Abster-se de cerveja, licores, açúcar, bolos, e colocar pouco sal nos alimentos.
Água à vontade.
Complemento à dieta, para pessoas sem outros problemas de saúde:
exercícios físicos (longas caminhadas, natação, patinação, etc.) praticados seguindo
um roteiro metódico. Banhos quentes, banhos a vapor e massagens.
Pessoas obesas e com complicações cardíacas: não proceder à cura de
emagrecimento a não ser com extrema prudência.
A defesa da homeopatia (França, 1922)
“A homeopatia, que poderíamos mais exatamente chamar de homeoterapia, é
um método terapêutico quase desconhecido pelos médicos modernos. Ela é,
entretanto, tão velha quanto o mundo. Hipócrates definiu o princípio como uma das
bases da medicina. Ela sempre foi empregada. Paracelso, Van Helmont, Sthal
fundaram sua terapêutica sobre ela, mas no dia em que ela foi erigida em doutrina
por Samuel Hahnemann parece que se passou a enxergá-la como uma jovem
herética excomungada. É necessário, ao menos, saber do que se trata:
O princípio da homeopatia é este: “os semelhantes são curados pelos
semelhantes”. Quando lemos os autores antigos, nos apercebemos que esta idéia
governava, quase sempre, sua terapêutica, e que eles recorriam à lei que assim
podemos enunciar: similia similibus curantur.
Definitivamente, o homeopata, diante de um doente, o analisa longamente,
procura todos os sintomas que ele apresenta e lhe administra o remédio que lhe
devolverá a saúde. Este princípio tendo sido posto, uma conseqüência decorre
necessariamente dele. É necessário conhecer a ação sobre o homem sadio dos
remédios nele aplicados. Hahnemann, e depois seus discípulos, estudaram
sistematicamente (sobre eles próprios e seus alunos) uma quantidade considerável
de substâncias, anotando cuidadosamente seus efeitos, sensações, mudanças
psíquicas e físicas, e dessa forma editaram uma imensa obra que eles chamaram de
“matéria médica pura”.
Uma segunda conseqüência da lei da similitude foi a atenuação das doses.
Não era uma idéia preconcebida. Hahnemann empregava, de início, doses muito
fortes de remédios, a tal ponto que seus compatriotas o chamavam de perigoso.
Pouco a pouco, ele percebeu que essas doses começavam, antes de curar, por
exagerar o estado mórbido, o que se concebe facilmente. Em seguida, notou que as
menores doses, não somente não agravavam, como curavam melhor e mais rápido.
Atenuando cada vez mais as doses, ele chegou a doses infinitesimais,
diariamente empregadas desde então por seus adeptos, se bem que não se conceba
mais, atualmente, a homeopatia como separável do emprego de doses infinitesimais.
Resumindo, a homeopatia é um método terapêutico que trata as doenças
pelos remédios que produzem sobre o homem os mesmos sintomas apresentados
pelo doente. E tem como corolário a necessidade do estudo dos efeitos produzidos
por esses remédios sobre o homem sadio e o emprego de doses infinitesimais.
Cefaléia e enxaqueca(França, 1925)
a) Evite a estafa cerebral, o sedentarismo, a imobilidade, a clausura; viva em
ambientes bem arejados, e faça exercícios físicos regularmente.
b) Faça refeições ligeiras, de preferência vegetarianas: ovos, cremes, sopas,
purês, frutas, saladas e pães. Beba bastante líquido. Evite os alimentos
que contenham chocolate.
c) Evite a constipação por meio de um regime laxativo, usando lavagens e
supositórios. Use compressas frias sobre o ventre.
d) Aja sobre a pele por meio de banhos quentes: mantenha a água, acima
dos ombros, em temperatura de 38 a 40ºC, todas as manhãs.
Sobre a escolha da medicina (Sigmund Freud, 1935)
“Embora vivêssemos em circunstâncias muito limitadas, meu pai insistiu que,
na escolha de uma profissão, eu deveria seguir minhas próprias inclinações. Nem
naquele tempo, nem, na verdade, no restante da minha vida, eu senti qualquer
predileção especial pela carreira de médico. Eu era movido mais por um tipo de
curiosidade, que era, entretanto, direcionada mais às inquietações humanas que na
direção de objetos naturais, nem tinha reconhecido a importância da observação
como uma das melhores maneiras de ser gratificado. Ao mesmo tempo, as teorias de
Darwin, então de grande interesse, atraíram-me fortemente, porque estendiam
nossas esperanças em um extraordinário avanço da nossa compreensão do mundo.
E ouvindo o belo ensaio de Goethe sobre a natureza, lido em voz alta em uma
conferência a que assisti pouco antes de deixar a escola, levaram a decidir-me por
estudar medicina”.
Sobre a história da ciência (George Sarton, 1941)
“A história da ciência, e em particular a história da medicina, não é
simplesmente um relato de descobertas. Seu propósito é explicar o desenvolvimento
do espírito científico, a história das reações do homem à verdade, a história da
gradual liberação de nossas mentes da escuridão e do preconceito”.
Sobre a complexidade da Natureza (John Barrow, 1994)
“Existe uma forma de caos que é causada pela ordem excessiva; por muitas
leis; por muita complexidade. Nossa confiança na simplicidade da Natureza
pode ser imerecida. A Natureza pode nos parecer simples somente porque ela
nos revelou muito pouco de seus segredos. À medida que vamos mais fundo
na estrutura microscópica da matéria e do espaço-tempo poderemos descobrir
um filão de grande complexidade criado pela interação simultânea de um
enorme número de fatores. Tal situação pode parecer como sem lei, como
puro caos”.
Epílogo (Sobre o presente e o futuro)Precisamos da história, mas não como dela precisam os ociosos que passeiam no
jardim da ciência. Vantagens e desvantagens da história para a vida
Friedrich Nietzche
O crescente desenvolvimento científico e tecnológico aplicado atualmente ao
diagnóstico e tratamento de vários tipos de doenças - e, principalmente, para as
doenças crônico-degenerativas (incluindo as doenças terminais) - tem levado a um
incontrolável aumento dos custos da assistência médico-hospitalar em todo o mundo,
inclusive nos países desenvolvidos.
Em regiões onde estes recursos são escassos, como no Brasil, o modelo
baseado fortemente em uma medicina curativa produz grandes distorções e terríveis
dilemas.
Ao mesmo tempo em que a mídia exalta os grandes avanços de uma ciência
cada vez mais apoiada em uma tecnologia cara e complexa, recursos a cada dia mais
escassos têm que ser administrados para fazer frente a um imenso desafio.
Como atender às populações mais carentes, sujeitas, ainda hoje, à falta de
saneamento básico, carências nutricionais de toda ordem, exposição a vários tipos de
endemias, acesso limitado a um sistema público eficiente, com carência de moradia
decente, sem acesso à informação, expostas diariamente a vários tipos de violência
física e psíquica, sem acesso ao lazer e sem uma formação profissional que lhe
permita obter uma renda digna?
O modelo atual, que privilegia o tratamento, gera um considerável consumo
do dinheiro público, além de transformar o Estado em mero repassador de recursos
do setor público para a iniciativa privada, em detrimento dos reais interesses da
ampla maioria da população.
Este modelo apresenta como uma manifestação de sua falência a não
correlação entre o aumento dos gastos em saúde e a mortalidade infantil e a
esperança de vida ao nascer61. O acesso à atenção médica tende a variar de forma
inversa às necessidades da população e na distribuição relativa entre os diversos
grupos sociais, conforme alguns indicadores sanitários.
Nos EUA, país mais rico do planeta, cerca de 45 milhões de pessoas não são
atendidas por nenhum sistema de saúde, especialmente parcelas da população
constituídas por pessoas pobres e de raça negra. No Brasil, até 1990, as regiões mais
pobres, como Norte e Nordeste, recebiam juntas apenas 21% dos recursos
repassados pelo Ministério da Saúde para atendimento ambulatorial, enquanto
apenas o Sul e Sudeste, regiões mais ricas, recebiam a maior parte, ou 72% dos
recursos62.
61 Nos últimos anos tem ocorrido queda nas taxas de mortalidade infantil devido,
principalmente, às ações dos agentes comunitários do programa Saúde da Família e de
organizações não governamentais como a Pastoral da Criança, entidade que acompanha 1,6
milhões de crianças e mais de 70 mil gestantes em mais de32 mil comunidades de todo o país.
62 Segundo Laura Camargo M. Feeuerwerker, em Mudanças na educação médica e
residência médica no Brasil.
Ainda sofremos com a cultura da hospitalização, além do fato das
universidades continuarem insistindo na formação de médicos com forte apelo
individualista. Eles são preparados apenas para atuar em hospitais com forte apoio
tecnológico, distanciados de cenários mais adequados para o ensino-aprendizagem.
O ensino na comunidade poderia ser uma alternativa, onde há diversas
oportunidades de tornar o aprendizado dos estudantes bem mais enriquecido, ao
mesmo tempo em que não é repetitivo em relação ao que é ensinado nas escolas e
nos hospitais universitários.
Como exemplo dessas atividades pode-se citar a participação em programas
de imunização, em inquéritos epidemiológicos, na busca ativa de pacientes com
doenças crônico-degenerativas (diabetes, hipertensão, etc.) ou doenças infecciosas
(como hanseníase e tuberculose), em vigilância sanitária, em educação para a saúde,
na participação em programas de desenvolvimento da comunidade, em escolas
públicas e em várias outras áreas e atividades de interesse social.
Por outro lado, o currículo médico sempre se caracterizou pela falta de
disciplinas da área de ciências humanas, limitando o conteúdo humanístico do ensino
médico formal a tópicos isolados de disciplinas afins, como a Ética Médica e a
Psicologia Médica. Isto é um erro, como para os que consideram a medicina o ponto
de encontro das ciências biológicas com as ciências humanas. Em conseqüência, o
preparo do médico é incompleto sem uma formação humanista.
Algumas faculdades do país têm se preocupado com estas questões e têm
procurado dar ao perfil do médico a ser graduado algumas características que
atendam a estas necessidades. Para estas faculdades os novos médicos devem, além
de uma excelente capacitação técnica, possuir as seguintes competências:
• Exercer a medicina com postura ética e humanística em relação ao
paciente, à família e à comunidade.
• Ter uma visão social do papel do médico.
• Saber atuar em equipe multiprofissional, relacionando-se com os
demais membros em bases éticas.
• Informar e educar seus pacientes, familiares e comunidade quanto à
promoção da saúde, além da prevenção, tratamento e reabilitação das
doenças, usando técnicas adequadas de comunicação.
• Estar estimulado e capacitado para a prática da educação permanente,
especialmente para a auto-aprendizagem, conseqüência da necessidade
de atualização constante, provocada pela crescente e contínua massa
de novas informações na área da saúde.
Outra questão é a falta de terminalidade no curso médico, fazendo com que a
residência médica torne-se essencial à formação do profissional, o que contribui para
elevar a formação de especialistas em detrimento de médicos generalistas, como
seria mais adequado para atender às necessidades maiores das populações mais
carentes do país.
Além disso, em sua maioria as faculdades não estão contribuindo para a
colocação, no mercado de trabalho, de profissionais adaptados às novas demandas
e desafios exigidos pelos problemas de saúde que serão prevalentes no século XXI.
Neste século, prevê-se o aumento das doenças psiquiátricas (principalmente a
ansiedade e a depressão), das doenças relacionadas ao tabagismo e as sexualmente
transmissíveis (ligadas ao sexo não seguro), além das patologias a elas associadas.
Também aumentará de importância a violência urbana (com suas conseqüências em
termos de saúde pública) e com a maior expectativa de vida maior número de
pessoas com idade avançada deverão necessitar de mais atenção dos serviços de
saúde.
As práticas de saúde se deslocarão das doenças agudas, em jovens, para as
doenças crônicas, em idosos. A atenção às famílias passará a desempenhar um papel
cada vez mais importante, assim como o atendimento domiciliar. Em conseqüência,
novas estruturas organizacionais deverão surgir em resposta às novas demandas,
passando-se a priorizar uma postura de prevenção das doenças e de promoção da
saúde.
Por sua vez, o Estado precisará investir mais na construção de redes de
saneamento básico e na melhoria da qualidade da água que é oferecida à população.
E ainda em sistemas de coleta e tratamento de lixo, em imunização (incluindo maior
diversificação das vacinas disponíveis), na construção de redes de drenagem de
águas pluviais e no combate aos vetores das doenças infecciosas e parasitárias.
Não podemos ainda esquecer a educação, que, em nosso país, ao elitizar o
saber - não propiciando um ensino leigo, gratuito e universal de qualidade - tem
impedido a maioria da população ao acesso a esse direito fundamental à construção
da cidadania, entendida como a expressão concreta do pleno exercício da
democracia.
Por outro lado devem-se melhorar ainda os programas de atendimento às
gestantes e nutrizes, de merenda escolar, além da informação para a saúde e em
outros programas sociais, se quisermos realmente transformar o país e prepará-lo
para os grandes desafios que vislumbramos para o futuro.
Introducao
Fala-se muito, hoje em dia, em inserir o ensino de um conceito matematico em
um contexto. Justamente porque muitos alunos consideram a Matematica por
demais abstrata, ouvimos muitos pedidos para que ela se torne mais concreta,
ligada ao quotidiano. Contudo, a Matematica e vista, ao mesmo tempo, como
um saber abstrato por excelencia. Diante disso, como seria possvel torna-la mais
concreta?
Estas questoes aparecem frequentemente na experiencia de ensinar matema-
tica, bem como nas discussoes sobre as dificuldades no ensino e na aprendizagem
desta disciplina. Em nossa formacao, ja ouvimos dizer que o aprendizado da Ma-
tematica e importante porque ajuda a desenvolver a capacidade de raciocnio e,
portanto, o pensamento logico coerente, que e um tipo de pensamento abstrato.
Muitas vezes, a Matematica lida com conceitos que nao parecem corresponder `a
experiencia sensvel, como e o caso dos numeros negativos, irracionais ou com-
plexos. Mesmo os conceitos geometricos basicos de ponto e reta sao abstratos,
uma vez que nao existem, no mundo real, grandezas sem dimensao, ou com
somente uma dimensao. Todos os objetos de que temos experiencia sao tridi-
mensionais. Mesmo o conceito de numero, apesar de ter sido definido a partir de
necessidades concretas, pode ser encarado como abstrato. Sendo assim, parece
estarmos diante de um paradoxo: como tornar a Matematica mais concreta
sem abdicar da capacidade de abstracao que o seu aprendizado proporciona? Nao
investigaremos a natureza desta aparente contradicao, o que demandaria definir,
de modo mais preciso, o que estamos chamando de concreto e de abstrato.
Acreditamos, contudo, que quando os alunos pedem para que a Matematica
se torne mais concreta, eles podem nao querer dizer, somente, que desejam
ver este conhecimento aplicado `as necessidades praticas. Talvez eles demandem
compreender seus conceitos em relacao com algo que lhes de sentido. Este pode
ser o papel mais importante da historia da Matematica para o ensino.
A Matematica pode ser ensinada de uma maneira mais concreta, caso
seus conceitos forem tratados a partir de um contexto. Isto nao significa ne-
cessariamente partir de um problema quotidiano, e sim saber com o que estes
conceitos se relacionam, como podem ser inseridos em uma rede de relacoes e
vii
viii INTRODUC AO
de significados  ainda que estas relacoes pertencam `a propria Matematica.
Entender os problemas que alimentam a Matematica de hoje e praticamente
impossvel, haja vista sua complexidade e a especificidade da linguagem e do
simbolismo nos quais eles se exprimem. Mas os conteudos que ensinamos, desde
o ensino fundamental ate o ensino superior, ja foram desenvolvidos ha muitos
seculos. Podemos, entao, analisar o momento no qual os conceitos foram criados
e como os resultados, que hoje consideramos classicos, foram demonstrados, con-
trabalancando a concepcao tradicional que se tem da Matematica como um saber
operacional, tecnico ou abstrato. Raramente entendemos o sentido dos conceitos
e das ferramentas que aprendemos no Ensino Basico. A historia da Matematica
pode tirar do esconderijo onde se encontram os problemas que constituem o
campo de experiencia do matematico, ou seja, o lado concreto do seu fazer.
Ha uma diferenca crucial entre a ordem logica da exposicao, o modo como um
texto matematico e organizado para ser apresentado, e a ordem da invencao, que
diz respeito ao modo como os resultados matematicos se desenvolveram. Muitas
vezes, e necessario reverter a ordem da exposicao, se queremos compreender o
sentido amplo das nocoes matematicas. Ao analisar a estrutura das revolucoes
cientficas, T. Kuhn ([103]) ja havia sinalizado que os cientistas, em seu trabalho
sistematico, estao continuamente reescrevendo (e escondendo) a historia real do
que os levou ate ali. Isto e natural, pois o objetivo destes pesquisadores e fazer
a ciencia avancar e nao refletir sobre seus resultados.
Esta diferenca entre o modo de produzir e de escrever os resultados e muito
presente na Matematica, que parece ter sido escrita de tras para a frente. As
definicoes, que precedem as conclusoes sobre os objetos de que se esta tratando,
explicitam, na verdade, os requisitos para que um enunciado seja verdadeiro, que
foram descobertos por ultimo, em geral, no trabalho efetivo do matematico. Este
encadeamento logico na apresentacao dos enunciados da a impressao de que a
Matematica e desconectada de seu contexto de descoberta.
Um dos fatores que contribuem para que a Matematica seja considerada
abstrata vem da forma como esta disciplina e ensinada, fazendo uso, muitas
vezes, da mesma ordem de exposicao presente nos textos matematicos. Ou seja,
ao inves de partimos do modo como um conceito matematico foi desenvolvido e
exibirmos as perguntas `as quais ele responde, tomamos este conceito como algo
pronto. Vejamos como a ordem logica sugere apresentar o teorema de Pitagoras.
Definicao1: Um triangulo e retangulo se contem um angulo reto.
Definicao2: Em um triangulo retangulo o maior lado e chamado hipotenusa e
os outros dois sao chamados catetos.
Teorema: Em todo triangulo retangulo o quadrado da medida da hipotenusa e
igual `a soma dos quadrados das medidas dos catetos.
ix
Problema: Desenho um triangulo retangulo de catetos 3 e 4 e pergunto o valor
da hipotenusa.
Temos primeiro as definicoes, depois os teoremas e as demonstracoes que
usam estas definicoes e, finalmente, as aplicacoes dos teoremas a alguma situacao
particular, considerada um problema. A partir desta apresentacao, podemos
demonstrar e aplicar o teorema de modo convincente. Ainda assim, diversas
perguntas permanecem sem resposta: Por que um triangulo retangulo merece
uma definicao especial? Por que estes nomes? O que e medir? Por que e
interessante medir os lados de um triangulo? Por que devemos conhecer a relacao
entre as medidas dos lados de um triangulo retangulo? As respostas a estas
perguntas permanecem escondidas por tras do modo coerente como enunciamos
o teorema e, sobretudo, do modo como utilizamos operacionalmente o resultado
que ele exprime.
A Matematica se desenvolveu, e continua a se desenvolver, a partir de pro-
blemas. O papel da historia da Matematica pode ser o de exibir estes problemas,
muitas vezes ocultos no modo como os resultados se formalizaram. Para alem
da reproducao esteril de anedotas que visam a motivar o interesse dos estu-
dantes, e possvel reinventar o ambiente problematico no qual os conceitos
foram criados. A nocao de problema usada aqui, bem como de problematico,
nao remete a uma ignorancia, `a falta de conhecimento que deve ser suplantada
pelo saber. Neste ultimo caso, o significado de um problema e o mesmo dos
exerccios de fixacao que pedimos para os alunos responderem, propostos apos
a exposicao de uma teoria para testar o seu conhecimento (como no exemplo
acima do problema sobre o teorema de Pitagoras).
As situacoes que motivaram os matematicos sao problemas em um sentido
muito mais rico. Podem ter sido problemas quotidianos (contar, fazer contas);
problemas relativos `a descricao dos fenomenos naturais (por que um corpo cai,
por que as estrelas giram?); problemas filosoficos (o que e conhecer, como a
Matematica ajuda a alcancar o conhecimento verdadeiro?); ou ainda, problemas
matematicos (como legitimar certa tecnica ou certo conceito?). Na historia da
Matematica, encontramos motivacoes que misturam todos estes tipos de proble-
mas. Ate o seculo XIX, problemas fsicos e ou de engenharia, bem como questoes
filosoficas, possuam um papel muito mais importante no desenvolvimento da Ma-
tematica do que possuem hoje. Entre os seculos XIX e XX, problemas relativos
`a formalizacao e `a sistematizacao da Matematica tornaram-se preponderantes.
Para tentar compreender como a Matematica se tornou o que e hoje, e
extremamente importante ler as producoes dos que praticaram Matematica ao
longo dos seculos. Em geral, esta tarefa e difcil, se quisermos ir diretamente
`as fontes. Ainda assim, e essencial ler os autores e nao somente teorizar sobre
suas obras. Felizmente, no caso da Matematica, ha antologias (sourcebooks)
x INTRODUC AO
de partes significativas de obras matematicas do passado, traduzidas para uma
lngua moderna e comentadas. Recomendamos, o uso frequente das organizadas
por Fauvel [59], Katz [95], Smith [136], Stedall [138], Struik [139] e Swetz [142] ,
entre outras. Chamamos a atencao, por sua qualidade e adequacao `as tendencias
historiograficas de nosso livro, para as duas mais recentes, as de Fauvel e Stedall1.
A Matematica que lemos nos livros ja foi produzida ha muito tempo, e re-
organizada inumeras vezes. Neste livro, procuraremos dar exemplos de alguns
momentos na historia da Matematica, aqueles que se relacionam mais de perto
com os conteudos ensinados nas escolas. Para reintroduzir os conceitos em seu
contexto nao basta relaciona-los com o ambiente em que foram criados, sem
investigar de perto o modo como as tecnicas e as ferramentas foram elaboradas.
Este e um dos princpios que nortearam este trabalho. A fim de entender o modo
como um conceito foi pensado ao longo da historia e importante entrar nos deta-
lhes tecnicos dos procedimentos a ele associados, a fim de exibir a particularidade
de um tipo de raciocnio ou sua relacao com outros argumentos. Procuraremos,
contudo, apresentar os desenvolvimentos matematicos do modo mais didatico
possvel, a fim de torna-los acessveis a alunos com um conhecimento basico de
matematica. Uma consequencia deste tipo de abordagem, que tambem julga-
mos interessante, e que o estudo da historia pode ser tambem uma ocasiao para
se aprender Matematica, ainda que seja uma Matematica distinta daquela que
praticamos hoje.
Os temas abordados aqui possuem grande relevancia na constituicao da ima-
gem que temos da Matematica, seja porque sao ensinados ou porque, ainda que
nao ensinados diretamente, podem ajudar a esclarecer alguns pressupostos ocul-
tos na maneira como a disciplina se apresenta. Quase todos os livros de historia
da Matematica disponveis em portugues, traduzidos de obras estrangeiras ja ul-
trapassadas, sao marcados por uma visao retrospectiva, que parte dos conceitos
tais como os conhecemos hoje para investigar sua origem. Deste ponto de vista,
surgem afirmacoes como o primeiro a descobrir esta formula foi o matematico
X; este resultado ja estava presente na obra de Y, ou na epoca Z. Este tipo
de informacao e considerada anacronica pelos pesquisadores mais recentes, ou
seja, ela indica uma postura de se olhar o passado a partir do ponto de vista
atual. Outro objetivo deste trabalho, ainda que secundario, e apresentar as novas
contextualizacoes fornecidas pela pesquisa recente em historia da Matematica,
que desmistificam a visao tradicional. Iniciaremos cada captulo com um resumo
sobre o contexto historico da epoca tratada. Todas estas secoes, bem como
grande parte do material usado ao longo de todos nos captulos, foram retiradas
1Alem disso, a Matematica foi construda, aos poucos, por homens, que viveram em uma
certa epoca e lugar. Uma boa visao, resumida e integrada, das muitas sociedades que forjaram
praticas as quais, aos poucos, constituram a Matematica como a conhecemos hoje, encontra-se
em McNeill [107].
xi
do livro Uma Nova Historia da Matematica ([128]). Aos leitores interessados
em um maior aprofundamento historico sobre os temas abordados aqui indica-
mos este trabalho, bem como muitos outros listados na bibliografia e citados ao
longo do texto2.
No captulo 1, falaremos dos registros numericos nas civilizacoes mesopotami-
ca e egpcia. Alem disso, mostraremos as caractersticas principais dos sistemas
de numeracao empregados e como as operacoes matematicas intervinham em
procedimentos de resolucao de problemas, descritos em forma de receitas. A
Matematica desta epoca e vista como essencialmente pratica, marcada pelo uso
de receitas e algoritmos de calculo. Veremos, contudo, que o modo de enunciar
estes procedimentos pode indicar um tipo distinto de generalidade, diferente do
que concebemos como tal. A visao tradicional da historia da Matematica as-
socia os procedimentos numericos dos mesopotamicos a operacoes aritmeticas,
ou mesmo algebricas. E frequente sermos informados, por exemplo, de que os
mesopotamicos ja sabiam resolver equacoes do segundo grau. Esta afirmacao,
contudo, reflete um grande anacronismo, sobretudo se levarmos em conta as
dificuldades de se lidar com as fontes do perodo que, alem de extremamente
fragmentadas, podem ser interpretadas de muitos modos. Em contraposicao
`a interpretacao algebrica dos procedimentos de resolucao de problemas meso-
potamicos, pesquisadores mais atuais propuseram que os algoritmos numericos
podem ter sido enunciados a partir de tecnicas geometricas, baseados em pro-
cedimentos de cortar e colar figuras para obter outras com a mesma area. Isto
sugere que a divisao em disciplinas, como algebra ou geometria, e inadequada
para analisar epocas nas quais a Matematica nao era uma disciplina, como e
hoje, contendo subareas bem delimitadas. Exibiremos, ao final, procedimentos
de medida que poderamos chamar de geometricos, com o cuidado de entender
esta palavra em um sentido muito especfico.
O captulo 2 comeca por descrever brevemente o mundo grego antes de
Euclides. Normalmente, fala-se da transicao do tipo de Matematica realizada
pelos mesopotamicos e egpcios, marcada por calculos e algoritmos, para a Ma-
tematica teorica, praticada pelos gregos, fundada em argumentacoes consistentes
e demonstracoes. Nao ha, contudo, uma documentacao confiavel que possa es-
2Os livros de historia da Matematica mais conhecidos no Brasil sao os de Carl Boyer, Historia
da Matematica, e Howard Eves, Introducao `a Historia da Matematica. Qualquer trabalho que
mencione um fato ou um personagem historico da Matematica cita, obrigatoriamente, uma
destas obras. Quando muito, podem ser mencionados os livros de Dirk Struik, Historia Concisa
da Matematica([141]), disponvel em portugues; alem de obras em ingles, como a de Morris
Kline, Mathematical Thought from Ancient to Modern Times ([98]). Tratam-se todas, sem
excecao, de obras ultrapassadas e amplamente questionadas pela pesquisa mais recente em
historia da matematica, a qual, infelizmente, temos pouco acesso em portugues. O objetivo
de [128] e justamente o de suprir, parcialmente, esta deficiencia.
xii INTRODUC AO
tabelecer tal transicao. Alem disso, mesmo no seio da Matematica grega, nao
podemos afirmar que as praticas de que temos notcia pertenciam a um corpo
unificado de conhecimento que poderamos designar como Matematica grega,
ao menos ate a epoca de Euclides. Um de nossos objetivos sera desconstruir
o mito da crise provocada pela descoberta dos irracionais que, na verdade, e a
descoberta da possibilidade de existirem segmentos incomensuraveis. Falar de
descoberta dos irracionais ja indica uma visao retrospectiva, pois a questao
dos incomensuraveis se inseria em um contexto geometrico, que nao tinha nada
a ver com a existencia de numeros irracionais. Para compreender o conceito de
numero dos pitagoricos, e mostrar que a incomensurabilidade nao foi descoberta
no contexto desta escola, analisaremos alguns aspectos de seu pensamento. Alem
disso, procuraremos dar uma ideia, a partir das pouqussimas fontes disponveis,
do contexto geometrico dos seculos V e IV a.E.C.. Analisaremos, em particu-
lar, um metodo que parece ter sido usado para comparar grandezas, inclusive
as incomensuraveis, chamado metodo da antifairese. Em seguida, passamos
`a analise de alguns livros dos Elementos de Euclides. Discutiremos, brevemente,
as possveis motivacoes do modo particular de expor os enunciados nesta obra,
enfatizando a separacao entre o tratamento das grandezas e dos numeros, que,
esta sim, pode ter sido uma consequencia da descoberta dos incomensuraveis.
Voltamo-nos, em seguida, para alguns desenvolvimentos da Matematica grega
apos Euclides. No captulo 3, falaremos de Arquimedes e da tradicao dos proble-
mas geometricos na Matematica grega, contrastando o aspecto formal, normal-
mente enfatizado, com o pragmatismo na resolucao de problemas geometricos,
que parece ter sido o real motor da geometria da epoca. Exporemos alguns
metodos de calculo de areas, em particular aqueles que ficaram conhecidos como
metodo de exaustao, cujos procedimentos evitam processos infinitos, passa-
gens ao limite. Explicaremos estas tecnicas nos termos da epoca, sem recorrer `a
linguagem atual de limites. Alem disso, daremos exemplos de como problemas
classicos da geometria grega, como o da trissecao do angulo, eram resolvidos
por meio de curvas mais gerais que a reta e o crculo, os instrumentos de cons-
trucao geometrica associados `a geometria euclidiana. As exigencias relativas `a
formalizacao e `a sistematizacao da Matematica se inserem, provavelmente, no
contexto filosofico do perodo helenstico, que se desenvolveu em Alexandria de-
pois da morte de Euclides e Arquimedes. Veremos, com o exemplo de Apolonio
e de sua definicao das conicas, o modo como a tradicao de Euclides parecia
vigorar em uma epoca um pouco posterior `a de Arquimedes. Saltando para um
momento ainda mais tardio, no qual a Matematica grega parecia ser pouco in-
fluenciada por Euclides, daremos exemplos das tecnicas aritmeticas de Diofanto
e da trigonometria grega.
O captulo 4 se organiza, sobretudo, em torno dos procedimentos para a reso-
lucao de equacoes. Analisaremos alguns trabalhos indianos e arabes a partir dos
xiii
seculos VIII e IX, explicando seus metodos, predominantemente retoricos, para
resolver problemas que, hoje, podem ser expressos por equacoes. Veremos que a
formula de resolucao de equacoes de segundo grau, conhecida como formula de
Bhaskara nao pode ter sido conhecida por este matematico indiano, nem pelos
arabes, apesar de ambos saberem resolver equacoes (de seus respectivos mo-
dos). Falaremos das praticas algebricas no perodo do Renascimento, sobretudo
no contexto italiano. As tecnicas de resolucao de problemas com quantidades
desconhecidas introduziram, aos poucos, simbolismos que podem ser vistos como
um passo na constituicao de metodos algebricos. A relacao entre estas praticas
algebricas e suas justificativas geometricas sera analisada de perto, pois e util
para a compreensao de um movimento, iniciado no seculo XVI, que buscava pra-
ticar Matematica com base no metodo analtico. Em contraposicao ao metodo
sintetico, a chamada arte analtica, defendida por Francois Vi`ete, pretendia re-
solver problemas geometricos e aritmeticos por meio de ferramentas algebricas.
Ao final do captulo, discutimos a importancia de uma Matematica pratica, para
expor a invencao dos logaritmos por Neper.
No seculo XVII a Matematica sofrera uma transformacao importante, fre-
quentemente associada `a obra de Rene Descartes, que analisaremos no captulo
5. A separacao entre teoria e pratica, forjada para avaliar os acontecimentos
tratados no captulo anterior, continuou hegemonica na historia deste perodo,
levando a historia da Matematica a negligenciar o contexto mais geral de pro-
blemas ligados `a construcao de instrumentos praticos para a compreensao de
fenomenos fsicos. A Matematica de Descartes tambem pode ser encarada a
partir desta perspectiva. O desenvolvimento da algebra, mas, sobretudo, as no-
vas concepcoes sobre o movimento e sobre a ideia de curva influram nas trans-
formacoes da geometria na epoca. Costumamos atribuir a Descartes a criacao
do que conhecemos hoje como geometria analtica. Investigaremos de perto
seus metodos, descrevendo os desenvolvimentos que julgamos mais esclarecedo-
res para mostrar que esta afirmacao e retrospectiva e ilusoria, pois as praticas
de Descartes, apesar de conterem algumas inovacoes, nao estavam em ruptura
com a Matematica e a ciencia de seu tempo. Outro heroi do seculo XVII
e Pierre de Fermat, conhecido pelo famoso teorema, mas que participava das
discussoes sobre os metodos mais eficazes a serem usados na geometria, que se
articulavam em torno da figura do padre Marin de Mersenne. Falaremos, resumi-
damente, das contribuicoes de Fermat para a geometria. O estudo do movimento
e das curvas, incluindo a deducao de propriedades com significado fsico, como o
calculo de tangentes, era uma parte fundamental dos problemas geometricos tra-
tados por diversos matematicos da primeira metade do seculo XVII. As mesmas
questoes continuaram a motivar os pensadores da segunda metade desse seculo,
nao somente na Franca, mas em outros pases, levando `a proposta de tecnicas
infinitesimais para tratar problemas com sentido fsico, como os que envolviam
xiv INTRODUC AO
o calculo de tangentes a curvas e de areas definidas por elas. Estas tecnicas
comecaram a ser sistematizadas nas ultimas decadas do seculo XVII, em par-
ticular por Gottfried Wilhelm von Leibniz e Isaac Newton, conhecidos como os
fundadores do que chamamos hoje de calculo infinitesimal. Mas as tecnicas in-
finitesimais usadas neste contexto foram questionadas por alguns pensadores da
epoca, o que gerou uma longa discussao a respeito da legitimidade dos metodos
do calculo, que faziam intervir infinitesimais, ou seja, quantidades infinitamente
pequenas. A busca de uma exposicao que pudesse fornecer maior legitimidade
`as tecnicas do calculo infinitesimal levou `a introducao de metodos algebricos,
determinante para o tipo de Matematica que sera praticada no seculo XVIII. A
partir das contribuicoes de Leonhard Euler e Joseph-Louis Lagrange a nocao de
funcao, identificada `a sua expressao analtica, passou a ser o objeto fundamental
da matematica.
O captulo 6 sera o ultimo, enfocando, de modo bastante parcial, alguns as-
pectos da historia da Matematica do seculo XIX que contriburam para formar
a imagem que temos atualmente. Pretendemos mostrar que a propria nocao
de rigor possui uma historia, expressa pelo modo como nocoes fundamentais
da Matematica basica, como as de funcao e de numero, foram discutidas e re-
definidas ao longo da historia. As nocoes de numeros irracionais, negativos e
complexos  chamados durante seculos de numeros impossveis, falsos, ab-
surdos, imaginarios  comecaram a ganhar cidadania Matematica no incio
do seculo XIX. Veremos como as tentativas de representar geometricamente os
numeros negativos e imaginarios, nos trabalhos de Argand e Gauss, tambem fa-
ziam parte do esforco para que estes numeros pudessem adquirir o estatuto de
objetos matematicos aceitaveis. Tudo isso se deu paralelamente ao movimento
que passou a encarar a Matematica como um saber abstrato, que nao precisava
mais se justificar pela geometria ou pela intuicao. Tambem tiveram um papel
importante nestas transformacoes as discussoes sobre a definicao mais geral do
conceito de funcao, ligada `as tentativas de mostrar que uma funcao qualquer
pode ser representada por uma serie trigonometrica. Na Franca, a legitimacao
de um novo modo de se fazer Matematica esta relacionada `as transformacoes do
ensino frances depois da Revolucao Francesa, as quais deram origem `a fundacao
da Ecole Polytechnique. Veremos que esta instituicao teve um papel determi-
nante na incorporacao de um novo tipo de rigor, expresso de modo exemplar
pelos trabalhos de Cauchy. Uma nova etapa na constituicao da Matematica
abstrata partiu da necessidade de definir os objetos fundamentais desta teoria,
muitos deles usados sem justificativa. Este e o caso da nocao de numero real,
usado ate este momento como contrapartida natural da nocao intuitiva de quan-
tidade. A consciencia de que a Matematica trabalha sobre objetos que precisam
ser definidos, como os de funcao e numero, tratados aqui, se tornou dominante
a partir do final do seculo XIX e incio do XX e teve um papel fundamental na
xv
constituicao do que passamos a chamar, ate hoje, de Matematica pura.
Os captulos sao divididos em secoes e, ao final de cada uma, ha uma lista de
exerccios sobre o conteudo daquela secao. Estes primeiros exerccios tem cunho
historico e visam a explorar ou complementar o conteudo exposto na secao. Ao
final de cada captulo, acrescentamos tambem exerccios suplementares, que se
relacionam de modo indireto com os desenvolvimentos historicos e, muitas vezes,
buscam incentivar a reflexao sobre o conhecimento matematico relacionado `a
epoca tratada.

Captulo 1
Sistemas de numeracao,
problemas e medidas na Babilonia
e no Antigo Egito
1.1 Contextualizacao historica
Nao e difcil imaginar que sociedades muito antigas tenham possudo uma nocao
de quantidade. Um registro relacionado com contagens, e cuja interpretacao
suscita discussoes entre os especialistas, e o osso, mostrado na Figura 1.1, en-
contrado em Ishango, na Africa, e datado entre vinte mil e dez mil anos a.E.C.
Figura 1.1 O osso de Ishango
Normalmente, associa-se a historia dos numeros `a necessidade de contagem,
relacionada a problemas de subsistencia. Quando lemos sobre a origem da conta-
gem, o exemplo que encontramos com mais frequencia e o de pastores de ovelhas
que teriam sentido a necessidade de controlar o rebanho por meio da associacao
de cada animal a uma pedra. Em seguida, ao inves de pedras, teria se tornado
mais pratico associar marcas, escritas na argila, e estas marcas estariam na ori-
gem dos numeros. Mas esta versao nao e segura. As fontes para o estudo das
civilizacoes muito antigas sao escassas e fragmentadas.
1
2 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Os primeiros registros, que podem ser concebidos como um tipo de escrita,
datam aproximadamente do quarto milenio antes da era comum e sao proveni-
entes da Baixa Mesopotamia, onde atualmente se situa o Iraque. O surgimento
da escrita e o surgimento da Matematica, nesta regiao, estao intimamente rela-
cionados. As primeiras formas de escrita foram motivadas pela necessidade de se
registrar quantidades e nao foi somente o controle de rebanhos a maior motivacao
para a criacao dos numeros, e sim o registro de quantidades de insumos relaciona-
dos `a sobrevivencia, mas - sobretudo - `a organizacao da sociedade. Nesta epoca,
houve um crescimento populacional consideravel, particularmente na regiao Sul
do Iraque, o que motivou o desenvolvimento de cidades e o aperfeicoamento das
tecnicas de administracao da vida comum. O surgimento de registros de quan-
tidades associados `as primeiras formas de escrita esta diretamente relacionado a
esta nova conjuntura.
A invencao da escrita nao seguiu um percurso linear, nem a sua historia. Por
volta dos anos 1930, comecaram a ser elaboradas novas teses sobre a origem
da escrita, com a descoberta de novos tabletes, provenientes da regiao de Uruk,
datados de aproximadamente 3000 a.E.C. Centenas de tabletes arcaicos indica-
vam que a escrita ja existia no quarto milenio, pois continham sinais tracados ou
impressos com um tipo de estilete. Este material mostrava que, na fase inicial
da escrita, as figuras que representavam algum objeto concreto eram excecao.
Diversos tabletes traziam sinais comuns que nao procuravam representar um ob-
jeto: o sinal para designar uma ovelha nao era o desenho de uma ovelha, mas
um crculo com uma cruz.
A continuacao das escavacoes trouxe ao conhecimento dos estudiosos tabletes
ainda mais enigmaticos, mostrando que esta forma arcaica de escrita consistia de
figuras como cunhas, crculos, ovais e triangulos, impressos em argila. Nos anos
1990, Denise Schmandt-Besserat propos a tese inovadora de que a forma mais
antiga de escrita tem origem em um dispositivo de contagem. Ela observou que
as escavacoes traziam, de modo regular, pequenos tokens  objetos em argila
de diversos formatos: cones, esferas, discos, cilindros, etc (Veja a Figura 1.2).
Estes objetos serviam `as necessidades da economia, pois permitiam manter o
controle sobre produtos da agricultura, e foram expandidos, na fase urbana, para
controlar tambem os bens manufaturados. Com o desenvolvimento da sociedade,
aperfeicoaram-se metodos para armazenar estes tokens. Um deles empregava
involucros de argila, como uma bola oca, dentro dos quais eles eram guardados
e fechados. Estes involucros escondiam os tokens e, por isso, em sua superfcie,
eram impressas as formas contidas em seu interior.
O numero de unidades de um produto era expresso pelo numero correspon-
dente de marcas na superfcie. Uma bola contendo sete ovoides, por exemplo,
possua sete marcas ovais na superfcie, `as vezes produzidas por meio dos proprios
tokens pressionados contra a argila ainda molhada. A substituicao destes tokens
1.1. CONTEXTUALIZAC AO HIST ORICA 3
Figura 1.2 Exemplos de tokens
por sinais foi o primeiro passo para a escrita. Os contadores do quarto milenio
devem ter percebido que o conteudo dos involucros se tornava desnecessario em
vista das marcas superficiais. Estes sinais nao consistiam de figuras representando
os produtos em si, mas os tokens usados para conta-los.
Tratava-se de uma maneira de contar bem diferente da nossa. Nao se repre-
sentavam os numeros, como 1 ou 10, mas usavam-se instrumentos particulares
para contar cada tipo de insumo: jarras de oleo eram contadas com ovoides,
pequenas quantidades de graos, com esferas. Os tokens eram usados em corres-
pondencia um a um com o que contavam: uma jarra de oleo era representada
por um ovoide; duas jarras, por dois ovoides e assim por diante. Besserat afirma
que este procedimento traduz um modo de contar concreto, anterior `a invencao
de numeros abstratos. Isto quer dizer que o fato de associarmos um mesmo
smbolo, no caso 1 ou um cone, a objetos de tipos distintos, como ovelhas e jar-
ras de oleo consiste em uma abstracao que nao estava presente no processo de
contagem descrito acima. Este sistema deu origem `a representacao cuneiforme
dos numeros. As marcas impressas nos involucros passaram a incluir impressoes
com estiletes. Alem disso, uma vez que o registro na superfcie tornava des-
necessaria a manipulacao dos tokens, os involucros nao precisavam ser usados
enquanto tais e as impressoes podiam ser feitas sobre tabletes planos de argila.
Os primeiros numerais nao eram smbolos criados para representar numeros
abstratos, mas sinais impressos indicando medidas de graos. Em um segundo
momento, as marcas representando as quantidades passaram a ser acompanhadas
de ideogramas que se referiam aos objetos que estavam sendo contados. Este
foi um passo em direcao `a abstracao, pois o registro das quantidades podia
servir para coisas de natureza distintas, tanto que surgiu a necessidade de se
indicar o que estava sendo contado. Na verdade, ha registros de que estas
sociedades possuam uma vida economica ativa e a variedade dos objetos com os
quais estes povos tinham que lidar podia ser muito grande. Neste caso, o modo
de representacao que emprega smbolos distintos para quantidades (iguais) de
4 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
objetos distintos pode ser restritivo.
Os registros eram usados para documentar atividades administrativas e exi-
biam um sistema complexo para controlar as riquezas, apresentando balancos de
produtos e contas. Os tabletes mostram que eram usados diferentes sistemas de
medidas e bases, dependentes do assunto tratado nos balancos. Neste momento,
os smbolos nao eram numeros absolutos, mas significavam diferentes relacoes
numericas dependentes do que estava sendo contado. No entanto, as listas mos-
tram um interesse crescente pelas propriedades dos numeros em si mesmas. Com
isto, desenvolveu-se a escrita cuneiforme, em forma de cunha, ao longo do ter-
ceiro milenio. Presume-se que o sistema de contagem que agrupava animais, ou
outros objetos discretos, em grupos de 10, 60, 600 ou 3600 foi o primeiro a ser
traduzido para a representacao cuneiforme.
Apesar das evidencias nao permitirem um conhecimento linear dos registros
numericos, pode-se conjecturar que o sistema evoluiu de um estagio no qual um
unico contador era impresso varias vezes a uma fase mais economica, na qual
era possvel diminuir a quantidade de impressoes dos contadores de tamanhos e
formas diferentes. Esta e a essencia do sistema posicional: um mesmo smbolo
serve para representar diferentes numeros, dependendo da posicao que ocupa na
escrita. Este e o caso do smbolo em forma de cunha, que serve para 1, 60 e
3600. Uma simplificacao analoga e usada em nosso sistema de numeracao, no
qual o smbolo 1 tambem serve para representar os numeros 10 e 100. O sistema
sexagesimal posicional, usado no perodo babilonio, surgiu da padronizacao deste
sistema numerico, antes do final do terceiro milenio.
Conforme a metrologia foi sendo racionalizada pelo poder administrativo,
tambem foram se multiplicando as funcoes da representacao dos numeros, como
e o caso de praticas pedagogicas. Ha evidencias de que, mais ou menos em
meados do terceiro milenio a.E.C., as propriedades dos numeros passaram a ser
investigadas por si mesmas, transformacao que pode ser associada ao incio de
uma Matematica mais abstrata. Neste momento, o domnio da escrita nao era
universal, ou seja, nem todos manejavam estas tecnicas. Desenvolveu-se, assim,
a atividade dos escribas, que tinham funcoes ligadas `a administracao e eram res-
ponsaveis pelos registros. Aos poucos esta elite intelectual foi adquirindo outras
atribuicoes ligadas ao ensino. Na verdade, presume-se que muitos dos table-
tes que nos permitem ter algum conhecimento sobre a Matematica cuneiforme
tinham funcoes pedagogicas.
Veremos adiante como algumas operacoes aritmeticas eram realizadas neste
sistema. Mas ao mesmo tempo em que uma parcela da sociedade comecou a se
dedicar especificamente `a Matematica, as praticas que podem ser designadas por
este nome passaram a incluir tambem procedimentos para resolucao de problemas
numericos, tratados como algebricos pela historiografia tradicional. Historia-
dores conhecidos, como O. Neugebauer ([111]) e B.L. van der Waerden ([146]),
1.1. CONTEXTUALIZAC AO HIST ORICA 5
postularam que os babilonios ja possuam um tipo de algebra e as traducoes pro-
postas pelo primeiro pressupunham esta interpretacao. No entanto, esta versao
comecou a ser desconstruda por J. Hyrup, nos anos 1990, com base em novas
traducoes dos termos que aparecem nos registros. Ele mostrou que a algebra
dos babilonios estava intimamente relacionada a um procedimento geometrico
de cortar e colar, que descreveremos em detalhes. Logo, esta pratica nao
poderia ser descrita como uma algebra, sendo mais adequado falar de calculos
com grandezas. Tanto os mesopotamicos quanto os egpcios realizavam uma
especie de calculo de grandezas, ou seja, efetuavam procedimentos de calculo
sobre coisas que podem ser medidas (grandezas), e esta era uma das principais
caractersticas de sua pratica matematica. Podemos falar de Matematica ba-
bilonia, ou egpcia, mas tendo em mente que se trata de um conjunto de praticas
muito distintas daquelas atualmente designadas por este nome.
Falaremos aqui somente destas duas civilizacoes antigas, as da Mesopotamia
e do Antigo Egito. Por volta do final do quarto milenio a.E.C., os egpcios re-
gistravam nomes de pessoas ou de lugares, bem como bens materiais e suas
quantidades. As evidencias disponveis sao mais numerosas para a Matematica
mesopotamica do que para a egpcia, provavelmente devido `a maior facilidade
na preservacao da argila do que do papiro. As fontes indicam que, quando a
Matematica comecou a ser praticada no Egito antigo, ela tambem estava as-
sociada a necessidades administrativas. A quantificacao e o registro de bens
levaram ao desenvolvimento de sistemas de medida, empregados e aperfeicoados
pelos escribas, ou seja, pelos responsaveis pela administracao da sociedade. Es-
tes profissionais eram importantes para assegurar a coleta e a distribuicao dos
insumos disponveis, mas tambem pela formacao de novos escribas. Os papiros
matematicos, aqui tambem, fazem parte desta tradicao pedagogica, e contem
problemas e solucoes preparados pelos escribas para antecipar as situacoes que os
mais jovens poderiam encontrar em sua pratica futura. Os textos matematicos
eram escritos em hieratico e datam da primeira metade do segundo milenio antes
da era comum (a.E.C.), apesar de haver registros numericos anteriores.
Temos notcia da Matematica egpcia por meio de um numero limitado de
papiros, como o de Rhind, escrito em hieratico e datado de cerca de 1650 a.E.C.
O nome se deve ao escoces Alexander Henry Rhind que o comprou, por volta
de 1850, em Luxor, no Egito. Este documento tambem e chamado papiro de
Ahmes o escriba egpcio que o copiou, e encontra-se no Museu Britanico. A
Figura 1.3 mostra um dos problemas deste papiro.
Analisaremos algumas diferencas e semelhancas entre os sistemas de nu-
meracao empregados na Babilonia e no Antigo Egito, examinando o modo como
os calculos eram realizados em cada cultura. Isto nos levara a concluir que as
tecnicas usadas dependiam intimamente da natureza dos sistemas de numeracao.
Por isso, calculos considerados difceis em um sistema, podiam ser considerados
6 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Figura 1.3
mais faceis no outro. Logo, a referencia `as necessidades praticas de cada um
destes povos nao basta para explicar a criacao de diferentes sistemas de nu-
meracao, contendo regras proprias e bem distintas umas das outras. E preciso
relativizar, portanto, a interpretacao frequente de que a Matematica nesta epoca
se constitua somente de procedimentos de calculo voltados para a resolucao de
problemas quotidianos.
Mesmo o desenvolvimento do conceito de numero, apesar de ter sido impul-
sionado por necessidades concretas, implica em um tipo de abstracao. Contar
e concreto, mas usar um mesmo numero para expressar quantidades iguais de
coisas distintas e um procedimento abstrato. A Matematica antiga nao era pura-
mente emprica, nem envolvia somente problemas praticos. A Matematica evolui
pelo desenvolvimento de suas tecnicas, o que permite que certos problemas sejam
colocados, e outros nao.
Mencionaremos, ao final, alguns problemas que podem ser chamados de
geometricos, em um sentido particular, o que nos leva a questionar, uma
vez mais, algumas teses da historia tradicional. Havia ou nao geometria no
Antigo Egito? E anacronico e temerario querer enquadrar as praticas de Ma-
tematica de povos antigos em nossa classificacao atual das areas do saber ou
dos campos da Matematica. Por exemplo, mesmo atualmente os significados que
atribumos aos termos algebra e geometria tem mudado radicalmente. A con-
cepcao da algebra no incio do seculo XIX e muito diferente daquela do fim do
mesmo seculo. De modo semelhante, a geometria, ao longo dos seculos, mudou
de significado, paradigmas, tecnicas e objetivos. Tanto os egpcios quanto os
babilonios tinham procedimentos sistematicos para resolver problemas que hoje
chamaramos de geometricos, envolvendo medidas. Por vezes, estes procedimen-
tos estao ancorados em uma maneira conceitualmente diferente de conceber os
conceitos geometricos1.
1Como e o caso do crculo na Matematica babilonia, segundo Robson [125].
1.2. O SISTEMA SEXAGESIMAL POSICIONAL NA ANTIGA BABIL ONIA 7
Querer comparar as praticas geometricas dos antigos egpcios com o enca-
minhamento dado `a geometria pelos gregos, mais tarde, e colocar uma alterna-
tiva que nao faz sentido. Os preconceitos que cercam nossa visao da Matematica
egpcia impediram, ate recentemente, que ela fosse apreciada tal como se apre-
senta nos registros disponveis. Mesmo estudiosos que sempre valorizaram a Ma-
tematica egpcia, como Gillings, nao escapam da comparacao com a Matematica
grega:
Sejamos, no entanto, muito claros quanto ao semi-cilindro e ao
hemisferio. Em nenhum dos casos foi estabelecida uma demons-
tracao [. . . ] pelo escriba egpcio [. . . ]. Tudo o que podemos dizer
e que, neste caso especfico, as operacoes efetuadas mecanicamente
[pelo escriba] sao consistentes com as que alguem que conhece as
formulas efetuaria, embora com ordem e notacao diferentes. Nao
temos como saber se os escribas encontraram, por acaso, uma boa
aproximacao ou se seus metodos sao o resultado de estimativas feitas
ao longo de seculos de aplicacoes praticas. [68]
Um conhecido historiador da Matematica, Morris Kline, chega a desdenhar
dos egpcios ([97], p. 14), ao afirmar que que [. . . ] suas contribuicoes `a
Matematica foram quase insignificantes e, comparada com a dos gregos, [a
Matematica ] dos egpcios e dos babilonios e como as garatujas de criancas que
estao aprendendo a ler, comparadas com a boa literatura.
Nao pensamos deste modo e procuraremos mostrar, por meio de poucos
exemplos, que os babilonios e egpcios faziam Matematica, em um sentido dife-
rente do nosso. Para enxergar esta possibilidade, e preciso considerar que nao
ha somente uma Matematica, que evoluiu ao longo do tempo para aquela que
conhecemos hoje. Varias praticas, ao longo da historia, podem ser chamadas
de matematicas, ainda que se assemelhem de maneira vaga com o que hoje
concebemos como tal.
1.2 O sistema sexagesimal posicional na antiga
Babilonia
Enfocaremos somente o sistema de numeracao utilizado pelos escribas babilonios
que habitaram a Mesopotamia por volta de 2000 a 1600 a.C, durante o perodo
Babilonio Antigo, sem nos preocuparmos com seus antecedentes, que remontam
a epocas bem mais remotas.
Os smbolo para o numero um pode ser visto na Figura 1.4. Ele era repetido
para formar os numeros maiores do que um, como dois, tres, e assim por diante
8 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
ate chegar a dez, representado por um smbolo diferente, que tambem pode ser
visto na Figura ReHORTO.
O processo aditivo descrito acima prosseguia da mesma forma apenas ate
o numero sessenta, quando se voltava a empregar o smbolo o mesmo smbolo
usado para o numero um. Continuando a contar, ao chegar a 602 = 3.600,
emprega-se novamente o mesmo smbolo, e assim sucessivamente.
Figura 1.4
Como podemos observar na Figura 1.4, o numero sessenta era representado
pelo mesmo smbolo usado para representar o numero um. O sistema dos antigos
babilonios usa uma notacao posicional de base sessenta. Ou seja, e um sistema
sexagesimal, . Na verdade, eles usavam uma combinacao de base sessenta e de
base dez, pois os smbolos ate cinquenta e nove mudam de dez em dez.
Ainda hoje, o sistema que usamos para representar as horas, minutos e segun-
dos e um sistema posicional sexagesimal. Assim, 1h 4min 23s e igual a 1x3600
(60x60) + 4x60 + 23 = 6023s.
Nosso sistema de numeracao tambem e posicional. Temos smbolos diferentes
para os numeros de 1 a 9, e o dez e representado pelo proprio 1, mas em uma
posicao diferente. Por isso dizemos que nosso sistema e um sistema posicional
de numeracao de base dez.
Uma grande vantagem dos sistemas posicionais, que e utilizada em nosso
sistema decimal, e que os mesmos smbolos sao suficientes para escrever qualquer
numero, inteiro ou fracionario. Os chamados algarismos, 0,1,2,3,4,5,6,7,8,9
nos permitem escrever qualquer numero, desde a massa de um proton ate o
numero de partculas atomicas do universo. Os egpcios, os gregos e os romanos,
por exemplo, nao adotavam sistemas posicionais. Seus sistemas eram aditivos,
isto e, somavam-se os valores de cada smbolo usado na representacao de um
numero para se ter este numero (o sistema romano era aditivo-subtrativo, com
uma regra que especificava quando somar e quando subtrair valores). Outra
1.2. O SISTEMA SEXAGESIMAL POSICIONAL NA ANTIGA BABIL ONIA 9
grande vantagem de um sistema posicional, como o nosso, e que neles e possvel
desenvolver algoritmos eficientes para realizar operacoes.
Em nosso sistema de numeracao, no numero decimal 125, o algarismo 1
representa 100, o 2 representa 20 e o 5 representa 5. Assim, podemos escrever
que 125 = 1102 +2101 +5100. O mesmo e valido para um numero que, alem
de uma parte inteira, contenha tambem uma parte fracionaria. Por exemplo, no
numero 125, 38 os algarismos 3 e 8 representam 3  101 + 8  102.
Generalizando, podemos representar um numero racional qualquer, r, na base
10, escrevendo
r = an10n + an110n1 + . . . + a0100 + a1101 + . . . + at10t, n, t  N.
Isto significa que an10n + an110n1 + ... + a0100 e a parte inteira e a1101 +
. . . + at10t e a parte fracionaria deste numero.
Suponhamos agora que queiramos escrever o numero racional r em um sis-
tema de numeracao posicional cuja base e um numero natural b diferente de 1.
Para isso, escrevemos
r = anbn + an1bn1 + . . . + a0b0 + a1b1 + ... + atbt. (1.1)
Isto significa que anbn + an1bn1 + . . . + a0b0 e a parte inteira e a1b1 + . . . +
anbn e a parte fracionaria deste numero. Logo, o numero sera escrito, na base
b, como anan1 . . . a0, a1 . . . at.
Qual a vantagem de se utilizar a base sessenta, ou seja, um sistema sexa-
gesimal? A divisibilidade por inteiros pequenos e uma importante caracterstica
a ser levada em conta no momento de escolhermos a base para um sistema
de numeracao. A base 12 esta presente ate hoje no comercio quando usamos a
duzia, justamente pelo fato do numero 12 ser divisvel por 2, 3 e 4. Uma das
vantagens do sistema sexagesimal e que o numero sessenta e divisvel por todos
os inteiros entre 1 e 6, o que facilita o calculo dos inversos multiplicativos dos
numeros expressos nesta base, como veremos adiante.
A Figura 1.5 mostra alguns exemplos de numeros escritos no sistema sexa-
gesimal usado pelos babilonios.
Observamos que a leitura mais facil deve ser feita da direita para a esquerda
e que este sistema da margem a algumas ambiguidades. Por exemplo, usando
duas cunhas, que representam cada uma delas o numero um, temos o numero
2 ou o numero 61. Na representacao do numero 2, este problema e resolvido
unindo-se bem os dois smbolos. Mas como diferenciar 1 de 60? Neste ultimo
caso, houve uma epoca em que se usava o smbolo de 1 com tamanho diferente
para representar 60. Este habito talvez esteja na origem do sistema posicional.
10 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Figura 1.5
Quando os smbolos se tornaram padronizados, para facilitar os registros, a di-
ferenciacao entre o numero 1 e as potencias de 60 dependia do contexto, que
permitia determinar a ordem de grandeza dos numeros com que se estava lidando
em cada problema.
E como escrever os numeros decimais 3, 601 e 7, 200? No sistema dos ba-
bilonios estes numeros seriam escritos tambem como . Algumas vezes era
deixado um espaco entre os dois smbolos para marcar uma coluna vazia. Esta
solucao nao era estendida `a expressao de uma coluna vazia no fim do numero,
logo nao seria possvel diferenciar 7.200 de 2 e de 120. No entanto, o contexto
do problema permitia distinguir com que numero se estava lidando.
Um perodo babilonio de que temos bastante evidencia e a epoca do Imperio
Seleucida, que se estabeleceu por volta do ano 300 a.E.C., no qual a astronomia
estava bastante desenvolvida e empregava tecnicas matematicas sofisticadas. Os
astronomos seleucidas, talvez pela necessidade de lidar com numeros grandes,
chegaram a introduzir um smbolo para designar um zero, ou melhor, uma coluna
vazia. No caso de 3.601 escrevia-se 1; separador; 1. O separador era simbolizado
por dois tracos inclinados.
O smbolo usado como separador pode ser considerado como um tipo de
zero, dada sua funcao no sistema posicional; no entanto, ele nao era usado
para diferenciar 1, 60 e 3.600, ou seja, nao podia ser usado como ultimo alga-
rismo, nem podia ser resultado de um calculo. Este separador, portanto, nao era
exatamente o que chamamos de zero, pois nao era um numero.
Exerccios
1.2. O SISTEMA SEXAGESIMAL POSICIONAL NA ANTIGA BABIL ONIA 11
1.1. Como determinar os coeficientes an, an1, . . . em (1.1)?
1.2. Escreva, no sistema de base 60, o numero representado em nossa base
decimal por 234, 572.
1.3. Escreva, em nosso sistema decimal, os numeros seguir, representados,
em base 60, por 2
1. 23; 15, 4; 17; 9; 45.
2. 1; 1; 1, 1; 1; 1;
3. Como voce escreveria, em nosso sistema, o numero sexagesimal
1; 1; 1; 1; 1; 1 ?
4. Como os babilonios representariam o numero, dado em nosso sis-
tema, por 0, 4321? (Lembre-se de que os babilonios nao conheciam
o zero).
1.4. Mostre que, na base sessenta, os zeros nao aparecem com tanta fre-
quencia quanto no sistema decimal.
1.5. Exprima um numero n na base dez. Faca o mesmo para a base ses-
senta e veja porque ha mais fracoes finitas na base dez do que na base
sessenta. Esta e uma das razoes pelas quais os astronomos, desde os
gregos, como Ptolomeu, ate Kepler e Copernico sempre preferiram a
base sessenta.
1.6. Multiplique por 60 o numero cuja representacao sexagesimal e
a1, b1; b2; b3; . . . , bn.
1.7. Divida por 60 o numero cuja representacao sexagesimal e
a1, b1; b2; b3; . . . ; bn.
2Usaremos o smbolo ; como separador dos algarismos dentro da parte inteira ou da
parte fracionaria; e o smbolo , para a separacao entre a parte inteira e a parte fracionaria.
Muitos historiadores estrangeiros fazem o contrario, ou seja, usam o ponto e vrgula para
separar a parte inteira da parte fracionaria e a vrgula para separar os algarismos dentro da
parte inteira ou da parte fracionaria. Decidimos inverter esta representacao uma vez que, no
Brasil, a vrgula e usada normalmente para separar a parte inteira da parte fracionaria e ja
estamos habituados a esta utilizacao do smbolo ,.
12 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
1.3 Calculos e problemas matematicos babiloni-
os
Como os babilonios faziam contas? Eles sabiam somar, subtrair, multiplicar,
dividir e extrair razes quadradas e mostraremos, a seguir, como eles efetuavam
algumas destas operacoes, e como resolviam problemas.
Em primeiro lugar, eles dispunham de tabletes com a mesma funcao de nossas
tabuadas. A maioria das operacoes realizadas pelos babilonios usava direta-
mente estes tabletes. No caso da multiplicacao, elas eram fundamentais. Basta
observar que os calculos elementares, ou seja, aqueles que sao os corresponden-
tes `a nossa tabuada, incluem multiplicacoes ate 59  59! Isso torna necessaria a
presenca de tabletes com tabuadas, mesmo para os escribas mais experientes.
Vejamos, inicialmente, um exemplo de uma tabuada de multiplicacao por
25. Nos tabletes, os textos entre parenteses ficam subentendidos, so sao escritos
os multiplicadores (1, 2, 3, . . .) e os resultados da multiplicacao, (25, 50, . . .):
1 (vezes 25 e igual a) 25
2 (vezes 25 e igual a) 50
3 (vezes 25 e igual a) 1; 15
4 (vezes 25 e igual a) 1; 40
5 (vezes 25 e igual a) 2; 05
6 (vezes 25 e igual a) 2; 30
7 (vezes 25 e igual a) 2; 55

As tabelas de multiplicacao fornecem os multiplos de um numero. Em geral,
dado o numero p, a tabela dos multiplos de p nao mostra os produtos 1  p,
2  p, . . . , ate 59  p. Sao dados os produtos 1  p, 2  p, . . . , ate 20  p e, deste
numero em diante, somente os produtos 30  p, 40  p, 50  p. Para calcular, por
exemplo, 37  p, e suficiente somar 30  p com 7  p.
A adicao e feita de maneira inteiramente analoga `a nossa adicao usual em
base 10. Isso nao e de espantar pois nosso algoritmo se baseia nas propriedades
associativa, distributiva e comutativa da adicao, e as mesmas podem ser utili-
zadas em um sistema cuja base seja qualquer numero natural, b, maior do que
1.
Os exemplos mostrados abaixo tem finalidade puramente didatica, nao re-
produzem a maneira como os babilonios efetuavam operacoes. Em verdade, a
adicao e a subtracao sao simples, e seus resultados eram indicados sem mais
sobre como foram encontrados.
Exemplo 1.1. Vejamos exemplos de operacoes feitas no sistema sexagesimal
babilonio.
1.3. C ALCULOS E PROBLEMAS MATEM ATICOS BABIL ONIOS 13
1. 1; 30, 27; 50 + 0; 29, 38; 13 = 2; 0, 6; 3.
Temos, montando o algoritmo de maneira exatamente igual `a nossa:
601 600 601 602
1 1 1
1 30 27 50
0 29 38 13
2 00 06 03
2. 2; 30, 4; 38  40, 5; 15 = 1; 49, 59; 23.
O algoritmo tambem e analogo ao que usamos em base 10.
601 600 601 602
1 1 1
2 30 4 38
40 5 15
2 00 06 03
3. 11; 32  25.
Podemos desenhar 4 colunas indicando o multiplicando e a ordem de grandeza
do resultado (Figura 1.6). 3
Figura 1.6
Em seguida, procuro na tabua de multiplicacao por 25 o correspondente `a
multiplicacao por 2 (50) e reproduzo o valor encontrado na coluna das unidades
(Figura 1.7).
Agora, apago o 2 na coluna do multiplicando e escrevo o valor correspondente
a 30 na tabua de multiplicacao por 25 (12; 30) (Figura 1.8).
Apago o 30 da coluna do multiplicando e procuro na tabua de multiplicacao
por 25 o valor correspondente a 11 (4; 35). Como 11 e de uma ordem superior
3Frisamos que este exemplo tem finalidades puramente didaticas. Ele nao reproduz exata-
mente como uma multiplicacao era feita pelos babilonios.
14 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Figura 1.7
Figura 1.8
`a utilizada ate este ponto, escrevo 4 na coluna das 3.600 e 35 na coluna das
sessentenas (Figura 1.9).
Figura 1.9
Podemos, agora, apagar o 11 e so resta simplificar cada coluna para obter o
resultado (Figura 1.10).
Assim, o resultado e 4; 48; 20.
As divisoes eram feitas com o auxilio de tabletes de inversos multiplicativos,
que listavam numeros e seus inversos multiplicativos. Esses inversos hoje seriam
escritos como fracoes do tipo 1
n . A divisao de m por n era efetuada pela mul-
tiplicacao de m pelo inverso multiplicativo de n, ou seja, em nossa linguagem
moderna, desconhecida para os babilonios, m
n = m  1
n . Havia, no entanto, um
1.3. C ALCULOS E PROBLEMAS MATEM ATICOS BABIL ONIOS 15
Figura 1.10
problema com os numeros cujo inverso nao possuem representacao finita em base
sessenta, como 7 ou 11. Nos temos o mesmo problema com o numero 3, pois o
desenvolvimento decimal de 1
3 e infinito.
Exemplo 1.2. Mostraremos que os inversos de 7 e de 11 nao tem representacao
finita em base sessenta.
Com efeito, o numero 1
k tem representacao finita em base sessenta se pode
ser escrito como 1
k = 0, a1a2 . . . an = a1
60 + a2
602 + . . . + an
60n . Multiplicando e dividindo
todas as parcelas por 60n, temos
1
k = (a160n1 + . . . + an600)/60n = a
60n .
em que o numerador e um inteiro. Disso, segue-se imediatamente que
ak = 60n = 22n  3n  5n.
Entao, pelo teorema fundamental da aritmetica, o produto ak so pode conter
os fatores primos 2, 3 e 5. Logo, a so pode ter estes fatores. Isso nao acontece
para 7 e 11.
O fato de nao se poder representar de modo finito os inversos de 7 e 11, em
base sessenta, nao significava que nao fosse possvel realizar multiplicacoes do
tipo 22  1
11 . Da mesma forma, ainda que 1
3 nao possua representacao finita na
base dez, 6  1
3 possui, pois o resultado aqui e igual a 2. No caso dos babilonios,
estas divisoes eram escritas em tabletes, assim como a solucao de problemas
analogos que aparecem na extracao de razes.
Este procedimento de divisao nos leva a concluir que a utilizacao dos tabletes
nao servia apenas `a memorizacao de tabuadas, o que seria um papel acessorio.
Para que a tecnica utilizada na divisao fosse rigorosa, havia uma necessidade
intrnseca de se representar em tabletes as divisoes por numeros cujo inverso nao
possuem representacao finita em base sessenta. Isto porque, no caso de 1
n nao
16 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
(a) (b)
Figura 1.11 YBC 7289
possuir representacao finita, o resultado da divisao de m por n tem que estar
registrado em um tablete. Se esta operacao fosse realizada pelo procedimento
usual, ou seja, multiplicando-se m por 1
n , o resultado obtido nao seria correto.
1.3.1 O calculo da raiz quadrada
Alem das operacoes de adicao, subtracao, multiplicacao e divisao, os babilonios
sabiam tambem calcular potencias e razes quadradas, que eram registradas em
tabletes.
O exemplo mais famoso de calculo de razes quadradas pelos babilonios
encontra-se na tablete YBC 7289, de que mostramos uma imagem e um de-
senho, o qual permite ler, com mais clareza, os numeros que constam do tablete
(Figura 1.11), de entre os anos 2.000 e 1.600 a.E.C., produzido em um con-
texto escolar. O tablete, de forma grosseiramente circular, tem um diametro de
aproximadamente 7 cm. Proximo a um dos lados do quadrado vemos o numero,
escrito no sistema sexagesimal babilonio, 30. Proximo a uma das diagonais,
encontram-se os numeros 1, 24; 51; 104 e 42; 25; 35. 5
Ora, 30  1, 24; 51; 10 = 42; 25; 35. Segundo Fowler e Robson ([64]), a cons-
tante 1, 24; 51; 10 encontra-se em uma tabela de coeficientes,6 o tablete YBC
7243, e e chamado a diagonal do quadrado. Assim, a conclusao inevitavel e
4A posicao da ,, que separa a parte inteira da parte fracionaria, e feita pelo contexto do
problema. Observando a Figura 1.11, ve-se que a consideracao desse contexto era essencial
para determinar a ordem de grandeza dos numeros com os quais se estava lidando.
5Lembre-se que usamos , para separar a parte inteira da parte fracionaria e ; para
separar os algarismos.
6As tabelas de coeficientes eram essenciais na Matematica da Babilonia. Elas eram tabletes
de referencia que continham numeros que ocorrem em varios tipos de problemas. Elas sao
listas de constantes.
1.3. C ALCULOS E PROBLEMAS MATEM ATICOS BABIL ONIOS 17
que a diagonal d do quadrado e igual a l  1, 24; 51; 10, em que l e o lado do
quadrado, no nosso caso 30 (1/2 em nosso sistema de numeracao decimal). Ve-
mos portanto que os escribas babilonios sabiam que l/d  1, 24; 51; 10. De fato,
(1, 24; 51; 10)2 = 1, 24; 51; 10, o que da uma boa aproximacao de 2.
Apresentamos a seguir a proposta de Katz ([94], p. 28) para explicar como os
babilonios chegaram a esta raiz quadrada. O metodo era bastante interessante,
uma vez que permitia obter valores aproximados para razes que sabemos hoje
serem irracionais. Escrito em linguagem atual, o procedimento para calcular a raiz
de um numero k se baseava, segundo Katz, no resultado geometrico explicado a
seguir.
Na figura 1.12, se o segmento AE e cortado em um ponto B, o quadrado
sobre AE e igual ao quadrado sobre AB mais o quadrado sobre BE mais duas
vezes o retangulo formado por AB e BE. Se AB medir a e BE medir c,
trata-se da versao geometrica da igualdade que escrevemos hoje em dia como
(a + c)2 = a2 + c2 + 2ac.
k
Figura 1.12
Calcular a raiz de k e achar o lado de um quadrado de area k. Logo, podemos
tentar colocar no interior deste quadrado o maior quadrado possvel cujo lado
conhecemos e usar o resultado geometrico acima para encontrar o resto. Ou
seja, se a e o lado do quadrado conhecido, obtemos que a raiz de k, k, e
igual a a + c. Para achar uma raiz melhor do que a, vamos procurar uma boa
aproximacao para c, o que pode ser feito observando a area da regiao poligonal
BEGKDC (Figura 1.12).
A area da regiao poligonal e obviamente igual a k  a2. Por outro lado, ele
pode ser decomposto em dois retangulos de lados a e c e em um quadrado de
lado c. Assim,
2ac + c2 = k  a2.
Se c for bem pequeno, podemos desprezar c2, e obtemos
18 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
c  k  a2
2a .
Faca
a = a + k  a2
2a = 1
2 (a + k
a ) . (1.2)
Entao, a  a + c e uma aproximacao de k melhor do que a, como pode
ser visto imediatamente pela interpretacao geometrica que apresentamos. Isso
decorre tambem do do fato que se a < k, entao k/a > k, e se a > k, entao
k/a < k.
Com efeito, como estamos lidando com numeros positivos nao-nulos,
a < k  ak < kk = k  k < k
a .
A segunda parte da afirmacao e demonstrada de maneira analoga.
1.3.2 Problemas do segundo grau na Babilonia
Alem de tabletes de resultados de operacoes, existem tambem outras que contem
procedimentos, como se fossem exerccios resolvidos. Estes exerccios correspon-
dem a problemas que resolveramos hoje por meio de equacoes. Analisaremos
alguns destes procedimentos com detalhes, a fim de mostrar, contudo, o quanto
seria anacronico considerar que os babilonios soubessem resolver equacoes. Du-
rante bastante tempo, ate recentemente, os historiadores realmente acredita-
vam, erroneamente, que os babilonios sabiam resolver equacoes, tinham uma
algebra, que mais tarde seria expressa geometricamente pelos gregos.
Os dois exemplos a seguir encontram-se na colecao do British Museum, no ta-
blete BM 13901. O primeiro e o problema #1, traduzido usualmente da seguinte
maneira:
Exemplo 1.3. Procedimento: Adicionei a area e o lado de um quadrado: obtive
0,45. Qual o lado?
Solucao:
1. tome 1
2. fracione 1 tomando a metade (:0,30)
3. multiplique 0,30 por 0,30 (:0,15)
4. some 0,15 a 0,45 (:1)
1.3. C ALCULOS E PROBLEMAS MATEM ATICOS BABIL ONIOS 19
5. 1 e a raiz quadrada de 1
6. subtraia os 0,30 de 1
7. 0,30 e o lado do quadrado
Cada passo do procedimento acima era executado com a ajuda de um tablete,
por exemplo, a etapa (3) exigia a consulta a um tablete de multiplicacao ou de
quadrados e a etapa (5), evidente neste caso particular, era resolvida em geral
pela consulta a um tablete de razes quadradas.
Neste mesmo tablete, BM 13901, ha um problema parecido, o #3, traduzido
como segue:
Exemplo 1.4. Procedimento: Subtra o terco da area e depois somei o terco
do lado do quadrado `a area restante: 0, 20
Solucao:
1. tome 1; 0
2. subtraia o terco de 1; 0, ou seja 0, 20, obtendo 0, 40
3. multiplique 0, 40 por 0, 20 obtendo 0, 13; 20
4. encontre a metade de 0, 20 ( 0, 10)
5. multiplique 0, 10 por 0, 10 ( 0, 1; 40)
6. adicione 0, 1; 40 a 0, 13; 20 ( 0, 15)
7. 0, 30 e a raiz quadrada
8. subtraia 0, 10 de 0, 30 ( 0, 20)
9. tome o recproco de 0, 40 (1, 30)
10. multiplique 1, 30 por 0, 20 ( 0, 30)
11. 0, 30 e o lado do quadrado
Atualmente, os problemas dos Exemplos 1.3, 1.4 e 1.5, o qulal ainda sera
visto, poderiam ser resolvidos por uma equacao do segundo grau. Obviamente, na
epoca de que tratamos nao se escrevia uma equacao geral do tipo Ax2 +Bx+C =
20 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
0, pois nao havia smbolos para designar os coeficientes e as incognitas. Logo,
nao havia sequer um sentido para aquilo que concebemos como equacao.
Resolvemos problemas como os acima, hoje, criando regras gerais que podem
ser aplicadas a exemplos particulares. Os exemplos particulares sao vistos como
casos de um tipo de problema generico. Os babilonios obtem os mesmos
resultados construindo uma lista de exemplos tpicos, empregando-os em seguida
para resolver novos problemas e nao possuam uma linguagem para expressar
estes casos de modo generico. No entanto, isto nao significa que esta Matematica
nao fosse dotada de um certo tipo de generalidade. Na verdade, os primeiros
passos do problema 3 servem para reduzir seu enunciado ao do problema 1, sendo
possvel interpolar o procedimento ja enunciado para este problema, considerado
um exemplo tpico.
O modo de enunciar o procedimento babilonio para o caso geral de uma
equacao de tipo Ax2 + Bx = C levou alguns historiadores a conjecturarem
que a Matematica babilonia seria de natureza primordialmente algebrica. Entre
eles destaca-se O. Neugebauer, um dos principais responsaveis pelas primeiras
traducoes de textos matematicos babilonios.
Com efeito, dada uma equacao do tipo Ax2 + Bx = C, o procedimento acima
pode ser traduzido algebricamente no roteiro descrito abaixo para encontrar a
raiz L = (

( B
2 )2 + AC  B
2 )  1
A .
1) Multiplique A por C (obtendo AC)
2) Encontre metade de B (obtendo B
2 )
3) Multiplique B
2 por B
2 (obtendo (B
2 )2
4) Adicione AC a (B
2 )2(obtendo ( B
2 )2 + AC )
5) A raiz quadrada e (

(B
2 )2 + AC)
6) Subtraia B
2 da raiz acima
7) Tome o recproco de A (obtendo 1
A )
8) Multiplique 1
A pela raiz para obter o lado do quadrado
9) O lado do quadrado e (

(B
2 )2 + AC  B
2 )  1
A
Este paralelo, no entanto, decorre das traducoes tendenciosas propostas pe-
los historiadores mais antigos, que pressupunham, implicitamente, a natureza
algebrica da Matematica babilonia. Temos hoje disponveis trabalhos historicos,
como os de J. Hyrup, mostrando que estas traducoes nao eram fieis ao es-
tilo da Matematica praticada na epoca. A partir da, novas traducoes foram
propostas, que podem nos levar a conclusoes bastante distintas sobre a natu-
reza da Matematica nesta cultura. Traduzimos para o portugues, com algumas
1.3. C ALCULOS E PROBLEMAS MATEM ATICOS BABIL ONIOS 21
simplificacoes, a nova transcricao proposta em [87].
Exemplo 1.5. (nova traducao).
Procedimento: A superfcie e a minha confrontacao acumulei: obtive
0, 45 (Estaria suposto que o objetivo era encontrar a confrontacao  o lado)
Solucao:
1. 1 e a projecao
2. quebre 1 na metade (obtendo 0, 30) e retenha 0, 30, obtendo 0, 15
3. agregue 0, 15 a 0, 45
4. 1 e o lado igual
5. retire do interior de 1 os 0, 30 que voce reteve
6. 0, 30 e a confrontacao
Esta versao motiva uma nova interpretacao do procedimento, de natureza
geometrica. Em primeiro lugar, faz-se uma projecao de 1, que permite inter-
pretar a medida do lado procurado, que chamaremos de l, concretamente como
um retangulo de lados 1 e l. Os babilonios transformavam, por meio de uma
projecao, esta linha de comprimento l em um retangulo com lados medindo, res-
pectivamente, l e 1l. Ou seja, eles projetavam o lado l para que se tornasse o
lado de um retangulo com area igual a l. (Figura 1.13).
ll
Figura 1.13  Passo (I): Projecao do lado l
Na figura 1.14, temos um retangulo de lados 1 e l e um quadrado de lado
l. Esta figura sera cortada e coladaa fim de se estabelecer uma equivalencia
entre medidas de areas que resolva o problema.
No passo (II), ilustrado na Figura 1.15, quebramos 1 na metade, o que
divide o retangulo inicial em duas partes. Rearrumando as duas metades do
retangulo, obtemos a figura 1.15, cuja area e igual `a area dada inicialmente
(0, 45).
Os lados quebrados, na figura em forma de l da Figura 1.15, delimitam um
quadrado de lado 0, 30 que retenho, ou seja, multiplico por ele mesmo, obtendo
22 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
1
l
l
confrontacao superfcie
Figura 1.14  Enunciado: A superfcie e a minha confrontacao acumulei
0,30 0,30
0,30
0,30
l
l
l
l
l
Figura 1.15  Passo (II): quebre l no meio
a area de um novo quadrado (0, 15). Esta area pode ser agregada ao conjunto,
completando o quadrado e formando um quadrado maior de area 1 (Figura 1.16).
Como 1 e o quadrado de 1, 1 e o lado igual. Deste lado, retiro o lado do
quadrado menor (0,30). Obtemos, assim, que o lado procurado e 1 - 0,30 = 0,30.
E importante observar que este lado e chamado confrontacao e o enunciado do
problema pede para acumular uma area e uma confrontacao. Ou seja, queremos
somar a area de um quadrado com o seu lado, que seria a confrontacao da area.
Para efetuar esta operacao, vimos que os babilonios transformavam esta linha
em um retangulo, por isso o lado e uma confrontacao (da area).
Este lado e chamado confrontacao e o enunciado do problema pede para
acumular uma area e uma confrontacao. Ou seja, queremos somar a area de um
quadrado com o seu lado, que seria a confrontacao da area. Para efetuar este
procedimento, os babilonios transformavam, esta linha, digamos de comprimento
l, em um retangulo com um lado dado por l e o outro medindo 1. Sendo assim,
eles projetavam o lado l na direcao oposta `a do quadrado, obtendo um retangulo
cuja area possui medida igual `a do lado em questao.
Este procedimento e interessante, pois, como veremos mais tarde, desde a
epoca grega, e pelo menos ate o seculo XVII, a geometria teve que respeitar
a homogeneidade das grandezas. Isto quer dizer que nao era permitido somar
uma area com um segmento de reta. O procedimento babilonio mostra que eles
nao experimentavam nenhuma dificuldade deste tipo, uma vez que possuam um
procedimento concreto para transformar um segmento de reta em um retangulo:
1.3. C ALCULOS E PROBLEMAS MATEM ATICOS BABIL ONIOS 23
0,30
0,30
0,30
0,30
l
l
Figura 1.16  Passos (III) e (IV): Retenha 0, 30 e agregue o resultado a 0, 45. O
quadrado maior tem area 1 e lado 1
aquele que foi traduzido aqui como projecao. Hyrup mostra que houve uma
fase da Matematica babilonia em que eram considerados segmentos com es-
pessura, que foram substitudos pelos retangulos descritos acima em escritos
posteriores, pertencentes a uma tradicao de formacao de escribas. Exemplos
como este, envolvendo operacoes de cortar e colar figuras geometricas pare-
cem ter sido comuns na epoca. Hyrup caracteriza estas praticas como um tipo
de geometria ingenua.
Apesar de ser bastante plausvel a hipotese de que os procedimentos ba-
bilonios usavam raciocnios geometricos, seria precipitado concluir que, ao inves
de possurem uma algebra, eles fizessem geometria. Como ja sinalizamos, de-
vemos ter cuidado ao aplicar as definicoes disciplinares que usamos hoje para
caracterizar a Matematica dos povos antigos.
Exerccios
1.8. Verifique, trabalhando no sistema sexagesimal dos babilonios, que o pro-
duto de 37; 28 por 19 e igual a 11; 51; 52.
1.9. Encontre os resultados das operacoes indicadas, USANDO O SISTEMA
SEXAGESIMAL DOS BABIL ONIOS, sem converter os numeros para a
base 10!
1. 59; 27 + 59; 40 = 1; 59; 7.
2. 48; 32  3 = 2; 25; 36.
3. 48; 32  3, 2 = 2; 27; 12, 64.
4. 2; 1; 1  1; 2; 2 = 58; 59.
5. 23; 18  3 = 7; 40; 6.
6. 1, 30  3 = 0, 30.
1.10. Trabalhando no sistema sexagesimal, ache o inverso multiplicativo de
1
45 .
24 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
1.11. Usando o sistema sexagesimal, divida 30 por 45.
1.12. Os numeros racionais que tem representacoes sexagesimais finitas sao
exatamente aqueles cujos denominadores sao produtos de potencias dos
numeros 2, 3 e 5. Nos outros casos, os desenvolvimentos sexagesimais
sao infinitos. Calcule, aproximadamente, com cinco casas sexagesimais,
5
42 .
1.13. Escreva o procedimento seguido no Exemplo 1.3 em linguagem atual
e o compare com nosso metodo de resolucao.
1.14. Interprete, o seguinte problema, e o resolva de maneira analoga `a do
Exemplo 1.5.
Retirei meu lado quadrado de dentro da area, de maneira que [o resul-
tado] fosse 14; 30. Voce escreve 1, a projecao. Voce quebra metade de
1. Voce combina 0, 30 e 0, 30. Voce adiciona 0, 15 a 14; 30. 14; 30, 15
quadrados 29, 30. Voce adiciona 0, 30 que voce tinha combinado com
29, 30, de maneira que o lado quadrado e 30.
Sugestao: Neste caso, e dada a diferenca entre a area e o lado do qua-
drado, o qual deve ser calculado. E necessario remover uma projecao
do quadrado. Entao, a diferenca entre os dois lados e dividida em duas
partes iguais e rearrumada em forma de gnomon.
1.15. Considere o seguinte problema do tablete VAT 6598, da Biblioteca do
Vaticano:
Se o portao tem altura 0, 40 (cubitos) e diagonal 0, 41; 15, qual sua
largura? Voce: tome 0, 40, a altura, de 0, 41; 15, a diagonal. O resto
e 0, 01; 15. Duplique 0, 01; 15. Voce vera 0, 02; 30. Multiplique 0, 40,
o comprimento, por 0, 02; 30 o fator que voce viu. Voce vera 0, 01; 40.
Qual e a raiz quadrada? 0, 10 e a raiz quadrada. A largura e 0, 10. O
metodo.
Como voce formularia o procedimento do escriba usando nossa simbo-
logia algebrica moderna?
1.16. Forneca uma interpretacao de porque, no tablete YBC 7289, o lado do
quadrado tem comprimento 1/2 e nao, como parece mais natural para
nos, 1.
1.17. Represente, em base 10, o numero sexagesimal 1, 24; 51; 10. Qual o
erro cometido se tomarmos esse numero como aproximacao de 2?
1.4. SISTEMAS DE NUMERAC AO NO ANTIGO EGITO 25
1.18. No procedimento proposto por Katz, que reencontraremos no algo-
ritmo de Hierao (Veja a pagina 141), e tambem no metodo de Newton
para o calculo de razes quadradas, qual teria sido a aproximacao inicial
escolhida pelo escriba para obter o resultado 1, 24; 51; 10?
1.19. Tome 1, 41 como aproximacao inicial de 2 no algoritmo proposto por
Katz. Qual aproximacao de 2 voce obtem? E se tomarmos esta nova
aproximacao e aplicarmos a ela o mesmo algoritmo, qual e o resultado
obtido? E se dermos mais um passo, ou seja, se usarmos esta segunda
aproximacao no algoritmo babilonio, qual sera o resultado encontrado?
A iteracao do algoritmo e a ideia do algoritmo de Hierao, o qual permite
o obtermos aproximacoes sucessivas, cada vez melhores, para a raiz
quadrada de um numero.
1.4 Sistemas de numeracao no Antigo Egito
Figura 1.17
Segundo os estudiosos, os egpcios desenvolveram um sistema de numeracao e
uma escrita mais ou menos na mesma epoca que os babilonios, ou seja, por volta
do ano 3000 a.E.C. Como em nosso sistema de numeracao, os antigos egpcios
empregavam um sistema decimal. Mas, diferente dos babilonios, o sistema de
numeracao no Egito nao era posicional, era aditivo.
O numero 1 era representado por uma barra vertical e os numeros consecu-
tivos de 2 a 9 eram obtidos pela soma de um numero correspondente de barras.
Em seguida, os numeros sao multiplos de dez e, por esta razao, dizemos que o
sistema e decimal. O numero dez e uma alca; cem, uma espiral; mil, a flor de
lotus; dez mil, um dedo; cem mil, um sapo e um milhao, um deus com as maos
levantadas (Veja a Figura 1.17).
26 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Para pensar
O sistema de numeracao egpcio nao e pratico para escrever numeros muito
grandes. Por exemplo, como voce escreveria, no sistema egpcio, o numero
1  10255 Quantos deuses seriam necessarios? Qual a caracterstica de nosso
sistema de numeracao que permite vencer esta dificuldade?
A convencao para escrever e ler os numeros e simples: os numeros maiores
vem escritos na frente dos menores e, se ha mais de uma linha de numeros,
devemos comecar de cima. Sendo assim, para escrevermos um numero, basta
escrevermos, seguindo esta convencao, todos os smbolos, e a soma fornece o
numero desejado. Por exemplo, qual o numero representado na Figura 1.18?
Figura 1.18
Como o sistema e aditivo, e os numeros sao obtidos pela soma de todos os
numeros representados pelos smbolos, basta entao escrevermos:
1.000 + 1.000 + 1.000 + 100 + 100 + 10 + 10 + 10 + 10 + 1 + 1 + 1 + 1 = 3.244.
1.4.1 Fracoes
Ate aqui falamos apenas de como os egpcios representavam os numeros inteiros.
E os numeros fracionarios? Eles usavam um conceito que, para nos, equivale `as
fracoes unitarias, da forma 1
n . Uma fracao, com numerador diferente de 1 a ter
uma representacao no sistema egpcio era a fracao 2
3 , e a fracao 1
2 era por vezes
representada por um smbolo especial. A Figura 1.19 mostra como os egpcios
escreviam algumas fracoes.
As outras fracoes eram representadas escrevendo os numeros inteiros com
uma elipse em cima, significando parte. Por exemplo, 1
7 seria escrito com a
elipse sobre sete barras verticais (Veja a Figura 1.20).
O smbolo oval colocado acima do numero nao possui o mesmo sentido
daquilo que chamamos hoje de numerador. Nosso numerador indica quantas
partes estamos tomando de uma subdivisao em um dado numero de partes. Na
designacao egpcia, o smbolo oval, que exprime a palavra parte nao possui
1.4. SISTEMAS DE NUMERAC AO NO ANTIGO EGITO 27
Figura 1.19
Figura 1.20
um sentido cardinal, mas ordinal. Ou seja, ele indica que, em uma distribuicao
em n partes iguais, tomamos a n-esima parte, aquela que conclui a subdivisao
em n partes. e como se estivessemos distribuindo algo por n pessoas e 1/n e o
quanto a ultima pessoa ira ganhar. Logo, e um certo abuso de linguagem dizer
que, na representacao egpcia, as fracoes possuem numerador 1.
Por que os egpcios podem ter se restringido a fracoes deste tipo? Sera
que esta representacao e mesmo uma limitacao da Matematica egpcia? Sera
que o sistema egpcio possui alguma razao de ser? A resposta e sim e um dos
sentidos desta representacao esta ligado justamente ao procedimento de divisao.
Podemos imaginar um exemplo para entender a que modo de raciocnio esta
representacao se relaciona.
Exemplo 1.6. Como repartir a quantidade de graos contida em 5 sacos de feijao
por oito pessoas.
Comecamos por imaginar que, se tivessemos 4 sacos, cada pessoa deveria
receber a metade de cada saco. Sendo assim, como sao cinco sacos, cada pessoa
deve receber, no mnimo, a metade de cada saco, ou seja, 1
2 . Fazendo isso,
sobrara um saco, que podera ser dividido pelas oito pessoas, cada uma recebendo
mais 1
8 deste saco. Sendo assim, podemos dizer que o resultado da divisao de 5
por 8 e 1
2 + 1
8 . Este resultado expressa diretamente o modo como a divisao foi
realizada.
Em nosso modo de representar fracoes, este resultado equivaleria a 5
8 o que
significa que cada meio saco sera dividido em quatro com o unico objetivo de
que a adicao de fracoes seja homogenea, ou seja, para que somemos fracoes
de mesmo denominador. Poderamos perguntar se esta divisao de cada meio
28 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Figura 1.21
saco por quatro nao e, de certo modo, artificial, e se ela nao serve apenas para
justificar a nossa tecnica particular de somar fracoes.
Podemos entender as vantagens da representacao egpcia a partir do problema
de se representar uma divisao, por exemplo de 58 por 87. Se quisermos distribuir
58 coisas por 87 pessoas teremos que dividir primeiramente cada coisa em dois,
obtendo 116 (58  2) metades. Daremos entao uma metade para cada pessoa,
restando 29 (116  87) metades. Devemos em seguida dividir cada metade por
tres obtendo 87 (29  3) metades divididas por tres, ou seja, 87 sextos. O
resultado e quanto cada um vai receber do todo. E este raciocnio que esta
expresso no fato de que a representacao egpcia de 58/87 e 1/2 + 1/6.
Para pensar
Qual seria uma vantagem da representacao egpcia em relacao ao nosso sis-
tema? Para responder, tente decidir, usando a representacao egpcia e a nossa,
qual a maior fracao: 58/87 ou 5/8?
Veremos, no exemplo seguinte, como converter uma fracao qualquer em uma
soma de fracoes egpcias distintas? Isto e sempre possvel?
Exemplo 1.7. Expressar 3/7 como uma soma de fracoes com numerador 1.
Em primeiro lugar, e necessario saber qual a maior fracao com numerador
1 menor que 3/7.
1. Inverto 3/7 obtendo 7/3;
2. tomo o maior inteiro mais proximo da fracao obtida (como 2 < 7/3 < 3,
o maior inteiro e 3);
3. 1/3 < 3/7 e a maior fracao com numerador 1 menor que 3/7;
4. faco 3/7  1/3 = 2/21, logo 3/7 = 1/3 + 2/21;
5. repito o algoritmo para 2/21.
1.4. SISTEMAS DE NUMERAC AO NO ANTIGO EGITO 29
(a) inverto 2/21 obtendo 21/2;
(b) 10 < 21/2 < 11, o maior inteiro e 11)
(c) 1/11 < 2/21 e a maior fracao com numerador 1 menor que 2/21;
(d) faco 2/21  1/11 = 1/231, logo 2/21 = 1/11 + 1/231;
(e) 3/7 = 1/3 + 1/11 + 1/231.
A escrita de uma fracao qualquer em fracoes unitarias deu origem a varios
problemas, alguns deles muito difceis. Por exemplo, em 1948 os matematicos
Paul Erdos e Ernst Straus conjecturaram que, qualquer que seja o numero
natural n > 5, entao existem numeros naturais a, b e c, distintos entre si, tais
que
4
n = 1
a + 1
b + 1
c .
Ate hoje nao se conseguiu provar esta afirmativa. Sabe-se, experimental-
mente, que ela e verdadeira para n < 1024, mas nao se conhece uma demons-
tracao para o caso geral.
Exerccios
1.20. Qual o numero representado na Figura 1.22?
Figura 1.22
1.21. Como escreveramos o numero 3.568.327 no sistema egpcio?
1.22. Encontre a resposta para o exemplo 1.7 usando o algoritmo de divisao
dos saquinhos e compare as respostas.
1.23. A representacao de uma fracao como uma soma de fracoes com nume-
rador 1 e unica?
1.24. Divida, como no Exemplo 1.6, 13 paes por 12 pessoas.
1.25. Qual a maior fracao? 58/87 ou 5/8? Resolva este problema escrevendo
as duas fracoes como somas de fracoes unitarias.
1.26. Prove que qualquer fracao tem infinitas representacoes como soma de
fracoes unitarias.
30 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
1.5 Operacoes e problemas no Antigo Egito
Vejamos como os egpcios efetuavam operacoes com numeros, e examinemos
alguns dos problemas encontrados em textos matematicos egpcios. No que
segue, a fracao 1/n sera denotada por n. Assim, 5 representa 1
5 , e 37 repre-
senta 1
37 . Uma expressao do tipo a n representa a+ 1
n . Como ja dissemos, alem
das fracoes unitarias, os egpcios usavam a fracao 2
3 . Nos a representaremos
por 3. Observe que 2  3 = 3 e que 3 dividido por 2 e igual a 3.
Exemplo 1.8. Multiplique, usando o metodo egpcio, 7 por 5. Ou seja, tome 5
vezes o numero 7.
Veremos que multiplicar 7 por 5 e tomar 5 vezes o numero 7, e N AO tomar
7 vezes o numero 5. Hoje, quando escrevemos 7  5 desaparece totalmente a
assimetria existente ao escrevermos multiplique 7 por 5. Isto nao quer dizer
que os egpcios nao conhecessem a propriedade comutativa do produto, eles
a utilizavam para simplificar calculos, mas o algoritmo que empregavam para
multiplicar estava baseado na distincao entre multiplicando e multiplicador.
Os egpcios procediam por duplicacoes sucessivas do multiplicando, 7.
/1 7
2 14
/4 28
Apos fazer isso, marcavam com um smbolo, /, os numeros da coluna
da esquerda que somados dao 5, e somavam os numeros correspondentes na
coluna da direita. No nosso caso, a resposta e 35.
Este processo egpcio repousa sobre o resultado geral, bem conhecido, que
todo numero natural pode ser escrito como soma de potencias de 2. Ou seja,
se n  N, entao existe k, numero natural tal que,
n =
k

0
ak2k = a020 + a121 + a222ak2k.
Exemplo 1.9. Multiplique, como os egpcios, 27 por 15, ou seja, tome 15 vezes
o numero 27.
Temos:
/1 27
/2 54
/4 108
/8 216
16 432
1 + 2 + 4 + 8 = 15  27  15 = 27 + 54 + 108 + 216 = 405.
1.5. OPERAC OES E PROBLEMAS NO ANTIGO EGITO 31
Uma maneira mais rapida de resolver este problema, tambem usada pelos
egpcios, e a seguinte:
1 27
/10 270
/5 135
(Da segunda para terceira linha, os numeros de cada coluna
foram divididos por 2).
Entao,
10 + 5 = 15  27  15 = 270 + 135 = 405.

Os escribas egpcios dispunham de muitas tabelas, e usavam livremente
seus resultados ou os que eles ja conheciam por serem usados frequentemente
em problemas. Assim, por exemplo, encontramos no Papiro Ahmes, o calculo
de como reduzir 2
n a uma soma de partes, para n mpar entre 5 e 101. Entre
estes resultados, encontra-se o seguinte
2
5 = 3 15. (1.3)
Vejamos agora como os egpcios efetuavam divisoes. Eles transformavam
o problema de dividir a por b em achar um numero x tal que b vezes x = a.
Assim, dividir a por b significava, para eles, por quanto devo multiplicar b
para obter a.
Exemplo 1.10. Os tres problemas a seguir, do papiro Ahmes, mostram como
os egpcios efetuavam divisoes, transformando-as no problema inverso da multi-
plicacao.
1. Divida 19 por 8, ou seja, por quanto se deve multiplicar 8 a fim de obter
19.
Temos
1 8
/2 16
2 4
/ 4 2
/ 8 1
A resposta e 2 4 8. 
2. Calcule, como no papiro Ahmes, 2
5 . Ou seja, por quanto devo multiplicar
5 para obter 2.
O escriba escreveu:
32 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
5 de 5 e 1 3, 15 de 5 e 3
1 5
3 3 3
/ 3 1 3
/ 15 3
Assim, a resposta sera 3 15.
(Este resultado sera usado no Exemplo 1.11)
3. Estudemos o problema 21 do papiro Ahmes:
E dito a voce para completar 3 15 para obter 1.
Aplicado a 15 3 e 10 e 15 e 1, fazendo 11. O resto e 4. Multiplique 15
para obter 4.
1 15
10 1 2
/ 5 3
/ 15 1
Total 4.
O que fez o escriba? Em linguagem moderna, o problema e resolver a
equacao
1 = 3 + 15 + x.
Multiplicando ambos os lados por 15, obtemos
15 = 10 + 1 + 15x  15x = 4.
Assim, devemos dividir 4 por 15, e foi exatamente isso que o escriba
fez: Multiplicou 15 ate achar 4.
1.5.1 A regra de falsa posicao.
Considere a equacao ax = b. Uma maneira de resolve-la ate recentemente,
usando somente aritmetica, antes dos procedimentos algebricos se tornarem
praticamente universais para resolver problemas desse tipo, era a seguinte:
Escolha um valor arbitrario x0 e calcule entao o valor de ax0, que chama-
remos de b0. Na pratica, x0 e escolhido a fim de facilitar as contas. Assim,
1.5. OPERAC OES E PROBLEMAS NO ANTIGO EGITO 33
por exemplo, se a e uma fracao com denominador 53, e conveniente escolher
x0 = 53. Isso eliminara os denominadores, tornando os calculos mais simples.
Considere entao a igualdade
ax0 = b0.
Por quanto devo multiplicar os dois membros da igualdade acima para
termos, do lado direito, b? Claramente por b
b0 . Fazendo isso, temos:
ax0  b
b0
= b0  b
b0
.
Ou seja,
a  (x0  b
b0
) = b0  b
b0
= b.
Assim,
x0  ( b
b0
)
e solucao de ax = b.
O processo descrito acima e conhecido como regra da falsa posicao, e foi
muito usado, ao longo da Historia, em varias civilizacoes, ate recentemente.
Exemplo 1.11. Considere, agora, o seguinte problema do papiro de Ahmes
(Problema 24).
Uma quantidade, com 1/7 dela adicionado, torna-se: 19.
Em primeiro lugar, resolvamos o problema como nos o faramos hoje.
O problema se transforma em resolver a equacao
x + 1
7 x = 19  8
7x = 19  x = 19  7
8 = 133
8 .
Uma outra solucao seria usar a regra de falsa posicao, procedendo como
segue:
Se a quantidade procurada fosse igual a 7, teramos que ela mais 1/7
dela seria igual a 8. Como a resposta deve ser 19, multiplicaremos os dois
membros da igualdade
7 + 1
7  7 = 8
por 19
8 , obtendo
34 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
(7  19
8 ) + 1
7  (7  19
8 ) = 19  19
8 = 19.
Assim, 7  19
8 = 133
8
e a raiz procurada.
Chegaremos ao mesmo resultado procedendo como segue, usando notacao
algebrica para tornar os passos do processo de falsa posicao mais transparen-
tes:
Faca x0 = 7. Temos, entao, que
x0 + 1
7 x0 = 8.
Multipliquemos os dois lados dessa igualdade por 19
8 :
19
8 x0 + 19
8
1
7 x0 = 19
8  8 = 19
8 x0 + 1
7
19
8 x0 = 19.
Como x0 = 7, e colocando 19
8 em evidencia, vemos facilmente que
19
8 x0
e realmente a solucao do problema. Guarde este resultado a fim de com-
para-lo com o que obtivermos resolvendo o mesmo problema como no papiro
Ahmes. Salientamos que o procedimento imediatamente acima, que utiliza
notacao algebrica, e estranho `a regra de falsa posicao. E somente uma ex-
plicacao, em linguagem algebrica moderna, de porque ela funciona.
Vejamos agora a solucao apresentada no papiro:
/1 7 faca como mostrado
/ 7 1
1 8 A quantidade
/2 16 7 2 4 8
2 4 pedido 19
/ 4 2 Total
/ 8 1
/1 2 4 8
/2 4 2 4
/4 9 2
A solucao apresentada pelo escriba esta disposta em tres blocos, com 2,
5 e 3 linhas, respectivamente. Analisemos cada um deles.
1.5. OPERAC OES E PROBLEMAS NO ANTIGO EGITO 35
O primeiro bloco simplesmente faz x0 = 7, e calcula x0 + 1
7 x0 = 8. Percebe-
se aqui a conveniencia dessa escolha para x0.
O segundo bloco divide 19 por 8, chegando ao resultado 2 4 8. Esse resul-
tado e igual exatamente a 19
8 .
O terceiro bloco multiplica 2 4 8 por 7, obtendo
2 4 8 4 2 4 9 2 = 15 + 1
4 + 1
8 + 1
2 + 1
4 + 1
2 = 16 2 8 = 133
8 ,
que e o resultado procurado.
Por vezes e afirmado que os egpcios resolviam problemas com a regra de
falsa posicao. Essa afirmacao pode dar a impressao de que ela era o metodo
que os egpcios usavam sistematicamente para resolver problemas como o
discutido acima. Isso nao e verdade. Por vezes eles usavam a regra, por
vezes utilizavam outros metodos.
Exerccios
1.27. Divida, como os egpcios, 27 por 15, ou seja, por quanto devo multi-
plicar 15 para obter 27?
1.28. Multiplique 1 2 por 13. Ou seja, tome 13 vezes o numero 1 2.
1.29. Como e calculado, no papiro Ahmes, 2
5 ? Ou seja, por quanto devo
multiplicar 5 para obter 2 ? Explique o procedimento usado pelo es-
criba.
1.30. Resolva, usando os metodos descritos nesta secao, o problema 26 do
papiro de Ahmes:
Uma quantidade e seu 1/4 e igual a 15. Qual e a quantidade?
1.31. Resolva, usando os metodos egpcios mostrados nesta secao, o pro-
blema 28 do papiro de Ahmes:
Uma quantidade e somada com seus 2/3, e subtraido 1/3 do resultado
e resta 10. Qual e a quantidade
1.32. (Problema 30 do papiro de Ahmes) Qual a quantidade de que 2/3 +
1/10 sao iguais a 10?
1.33. O problema 40 de papiro de Ahmes e particularmente interessante.
Trata-se obviamente de um problema sem aplicacoes praticas, proposto
a fim de testar a competencia matematica dos escribas egpcios:
36 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Divida 100 paes entre 5 homens, de maneira que as porcoes estejam
em progressao aritmetica e que 1/7 das tres maiores porcoes seja igual
`a soma das duas menores porcoes. Qual a diferenca entre as porcoes?
Resolva este problema por nossos metodos algebricos atuais e discuta a
solucao apresentada no papiro de Ahmes. Suponha, como fez o escriba,
que as porcoes de pao estao em progressao aritmetica:
Eis como e feito. A diferenca de porcoes sendo 5 2. Faca voce a
multiplicacao: 1 2/3.
/ 1 23
/ 1 17 2
/ 1 12
/ 1 6 2
/ 1 1
60
Total
/ 1 60
/ 3 40
23 38 3
/4 9 2
a tantas vezes isso se torna:
17 2 29 6
12 20
6 2 103 6
1 1 ddot3
60 100
Total Total
1.34. O primeiro problema do papiro de Berlim e o seguinte:
Um quadrado e um segundo quadrado, cujo lado mede 3/4 do lado
do primeiro quadrado, tem conjuntamente area 100. Mostre-me como
calcular isso.
1. Resolva este problema usando nossas tecnicas algebricas moder-
nas.
2. Resolva o problema usando a regra da falsa posicao, o que foi feito
na solucao que se encontra no papiro.
1.6. CONHECIMENTOS GEOM ETRICOS NA BABIL ONIA E NO EGITO 37
1.35. Resolva, usando a regra de falsa posicao, o problema 27 do papiro
Ahmes:
Uma quantidade e seu quinto se torna 21. Qual e a quantidade?
1.6 Conhecimentos geometricos na Babilonia e
no Egito
A geometria dos babilonios e egpcios era essencialmente uma geometria
metrica, isto e, preocupada em calcular comprimentos, areas e volumes, para
o que utilizavam algumas propriedades geometricas de figuras planas e de
solidos geometricos, sem que saibamos como chegaram a estes resultados.
Como ainda hoje acontece na Matematica escolar, os exemplos de problemas
babilonios e egpcios `as vezes sao bem artificiais, modelos simplificados de
situacoes reais propostos para exercitar ou verificar as habilidades de calculo
dos escribas.
1.6.1 Calculo de areas na Babilonia
Encontram-se, entre os muitos tabletes achadas em stios arqueologicos na
Mesopotamia, alguns que contem problemas de geometria. Uma dos mais
famosos e o YBC 7289, que ja discutimos ao estudar como os babilonios
achavam razes quadradas.
Vejamos agora o tablete YBC 7302, mostrada na Figura 1.23, na qual
encontramos os numeros, em representacao sexagesimal, 3 (a circunferencia
do crculo), 9 e 45 (a area do crculo).
Como defendido por Robson ([125]), baseada no estudo do tablete YBC
7302, entre outros, a maneira como os babilonios consideravam o crculo era
fundamentalmente diferente da nossa. Conceitualmente, para nos, o crculo
e obtido tracando-se uma circunferencia com um compasso (Axioma 3 de
Euclides). Para os babilonios, ele era concebido como a figura limitada por
uma circunferencia. Mesmo quando conheciam o diametro do crculo, eles
calculavam sua area usando o comprimento da circunferencia.
Se A e a area do circulo de circunferencia S e raio r, entao, A = r2,
S = 2r. Assim,
r = S
2 ,
A =   S2
42 = 1
4 S2.
38 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Se fizermos  = 3, teremos
A = 1
12S2.
Como, no sistema sexagesimal, 1/12 = 5, veremos que, de fato, a area do
crculo do tablete foi encontrada desta maneira. Com base nesta traducao,
afirma-se frequentemente que a aproximacao  = 3 era padrao, para os ba-
bilonios ou que, em casos especiais, eles usavam 3, 07; 30 (o que, em nosso
sistema, e igual a 3 + 1/8). No entanto, esta interpretacao e anacronica.
Conceitualmente, ha uma grande diferenca entre o que fazemos e os proce-
dimentos dos babilonios.
Para nos,  e uma constante de proporcionalidade, que relaciona a area e o
quadrado do raio de um crculo qualquer, ao passo que os babilonios tinham
um processo para calcular a area de crculos no qual dividiam o quadrado
da circunferencia do crculo por 12. Veremos, no proximo exerccio, o que
significa a multiplicacao pela constante 3 no procedimento babilonio.
Figura 1.23 YBC 7302
Os babilonios calculavam volumes de varios solidos, como, por exemplo,
o de um cilindro circular reto e de prismas retos, com bases retangulares ou
triangulares. Os problemas que envolvem estes calculos de volume sao con-
textualizados em situacoes agrcolas, construcoes civil ou militar, ou outras
atividades. Sao calculados os volumes de muros, muralhas e barragens e o
numero de operarios necessarios para constru-los ([94], p. 20).
Exemplo 1.12. Procedimento para um tronco (cilndrico) com 0, 05 de diametro
(Haddad 104).
Em primeiro lugar, calculava-se a area de uma secao transversal, de forma
circular:
1.6. CONHECIMENTOS GEOM ETRICOS NA BABIL ONIA E NO EGITO 39
Triplique a linha divisoria 0, 05 tal que 0, 15 aparecera. A circunferencia do
tronco e 0, 15. Combine (faca o quadrado) de 0, 15 tal que 0, 03; 45 aparecera.
Multiplique 0, 03; 45 por 0, 05 e teras 0, 00; 18; 45, a area, aparecera.
Em seguida, basta multiplicar esta area da base circular pela altura. A altura
era considerada implicitamente como igual ao diametro.
Vimos que deve-se multiplicar o diametro por 3 para obter a circun-
ferencia (ou o permetro) da base do tronco. Lembramos que a formula usada
atualmente para o permetro da circunferencia e d (onde d e o diametro).
Podemos dizer que o metodo dos babilonios nao esta muito longe do nosso,
usando 3 como valor aproximado de .
Mas o objetivo do problema nao e calcular o permetro e sim a area da
circunferencia. Para calcular a area a partir do permetro, temos que elevar
ao quadrado e depois dividir o resultado por 4 (basta verificar na nossa
formula que a area r2 = 2d2
4 ). Mas considerando que os babilonios usavam
3 como constante, em base sessenta, dividir por 4 e equivalente a multiplicar
por 0, 5 (pois 1/12 e 0, 5 em base 60). Isto explica a multiplicacao por esta
constante no final do procedimento.
Aqui, o calculo da area da circunferencia tambem faz intervir uma cons-
tante, no caso o sexagesimal 0, 5 (= 5/60 na base 107) utilizado na ultima
etapa. Esta e uma constante relativa ao crculo empregada em qualquer pro-
cedimento de calculo de area de circunferencia. No entanto, o 3 pelo qual
devemos multiplicar o diametro, nao e exatamente uma constante, e sim uma
operacao, indicada por um verbo (triplique).
Se usarmos a formula da area que conhecemos atualmente e fizermos
A =   r2 = (8
9 d)2 = ( 8
9  2)2 r2, obteremos que os babilonios aproximavam 
por 3. No entanto, seria um tremendo anacronismo dizer que estes povos ja
possuam uma estimativa para , pois multiplicar por tres era uma operacao,
e nao era um numero considerado como constante universal, como e o caso
de nossa concepcao atual sobre . Veremos na proxima secao que o mesmo
porde ser dito sobre os egpcios.
Voltemo-nos agora para o tablete YBC 7290 (Figura 1.25), que mostra
um trapezio. Vemos que sua base maior e um dos lados sao iguais a 2, 20 (no
sistema sexagesimal), e que a base menor e igual a 2. O escriba supoe que o
trapezio e reto e, entao, sua area e calculada fazendo (sem os smbolos)
A = 2, 20  [1
2  (2, 20 + 2)] .
7Este e um exemplo de fracao cujo desenvolvimento na base sexagesimal e finito, e infinito
na base decimal.
40 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Figura 1.24
Encontram-se a exerccios sofisticados, como o de calcular as areas das
figuras que formam a configuracao mostrada na Figura 1.24 (Veja [95], p.
99).
Figura 1.25 YBC 7290
As propriedades dos triangulos retangulos sao exploradas no exerccio do
tablete IM 55357 (ver [95], p. 100). Os comprimentos BF , AB e AF sao
iguais, respectivamente, a 1, 0, 45 e 1, 15, escritos em notacao sexagesimal.
A area do triangulo ABF e 0, 22; 30. As areas dos triangulos ABC,CDE,
DEF sao, respectivamente, 0, 08; 06, 0, 05; 11; 02; 24, 0, 03; 19; 03; 56; 09; 36 e
0, 05; 53; 53; 39; 50; 24. Pede-se para calcular os comprimentos BC, CD e DE
(Figura 1.26).
1.6.2 A geometria no Antigo Egito
O que significa falar de geometria no Egito antigo? Significa falar de pro-
cedimentos de calculo de areas e de volumes. Por exemplo, a area de um
1.6. CONHECIMENTOS GEOM ETRICOS NA BABIL ONIA E NO EGITO 41
E
D
C
A
FB
Figura 1.26 IM 55357
retangulo era calculada multiplicando sua base por sua altura. O problema
no 6 do Papiro de Moscou ilustra bem o procedimento empregado:8
Exemplo 1.13. Metodo para calcular um retangulo
Se lhe e dito, um retangulo de area 12 2 4 do comprimento
Para o comprimento. Calcule 2 4 ate obter 1. Resultado 1 3.
Calcule com estes 12, 1 3 vezes. Resultado 16.
Calcule [sua raiz quadrada]. Resultado 4 para o comprimento.
2 4 e 3 para a largura.
Em linguagem moderna, teramos
A = lb e b = (2 4)  l  (2 4)l = 12.
Assim,
l  l = 12  (2 4) = 12  1 3 = 16.
Segue-se entao que o comprimento l e igual a 4 e que 2 4 da largura
(altura) e 3.
Vemos que, neste problema, a area de um retangulo e calculada. Mas ha
divergencias, entre os estudiosos, sobre a maneira como os egpcios calcula-
vam a area de um triangulo. Mais precisamente, discute-se se eles calculavam
a area tomando a metade da base vezes a altura ou se tomavam metade da
base vezes um lado. No segundo caso, o resultado esta certo somente se o
triangulo for reto. O Exemplo 1.6.2 mostra o calculo, pelos egpcios, da area
de um triangulo.
Os egpcios sabiam achar o volume de um paraleleppedo reto (um bloco
retangular) e de um cilindro circular reto. O Exemplo 1.6.2 discute como
interpretar o calculo da area do crculo pelos egpcios.9
8Seguimos, neste exemplo, a apresentacao de [68].
9Isso tambem e discutido cuidadosamente em [94], pp. 18-19.
42 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Ao discutir a geometria no Egito antigo, e inevitavel perguntar o que era
conhecido, entao, sobre a geometria da piramide. A resposta, baseada nos
documentos matematicos egpcios que chegaram ate nos, e decepcionante.
Segundo Gillings ([68], pp. 185 - 186), as unicas coisas que sabemos, com
certeza, sobre seus conhecimentos deste assunto sao as seguintes:
1. A inclinacao dos lados de uma piramide.
2. O volume de um tronco de piramide.
3. O volume de uma piramide.
O item 2) consta do problema 14 do Papiro de Moscou, pelo que se deduz
que 3) tambem era conhecido. Os problemas 56, 57, 58, 59 e 60 do Papiro
Ahmes lidam com o item 1).
Encontramos, no papiro Rhind, problemas geometricos, como, por exem-
plo, o problema 51:
Exemplo 1.14. Exemplo de um triangulo de terreno. Suponha que lhe e dito,
qual a area de um triangulo de lado 10 khet e base 4 khet?
Resolva o problema da seguinte maneira:
1 400
1/2 200
1 1000
2 2000
Sua area e 20 setat.
Retire 1
2 de 4, a fim de obter seu retangulo. Multiplique 10 vezes 2; isso e a
area.
Analisaremos agora um exemplo de exerccio que pedia o calculo do vo-
lume, em graos, de uma caixa de forma cilndrica. Insere-se neste problema
a discussao sobre a existencia de uma possvel aproximacao para  na Ma-
tematica egpcia.
Exemplo 1.15. Fazer um celeiro (ou um cilindro) redondo de 9 por 10.
A primeira parte do problema consiste em calcular a area da base, em
forma de circunferencia, cujo diametro e 9, e a segunda parte em calcular o
volume em graos se a sua altura e 10 (para simplificar o problema, evitamos
aqui entrar em detalhes sobre as unidades de medida utilizadas).
O procedimento empregado para resolver a primeira parte e o seguinte:
Subtraia 1/9 de 9 de 9: 1. Resta: 8. Multiplique 8 por 8; obtendo 64.
1.6. CONHECIMENTOS GEOM ETRICOS NA BABIL ONIA E NO EGITO 43
A area da circunferencia de base seria, portanto, 64. Mas de onde veio
esta subtracao de 1/9 do dado? Ela nao esta relacionada ao fato de o lado
ser 9. Este valor, 1/9, e uma constante que devia ser aprendida e utilizada
pelos egpcios sempre que quisessem calcular a area de uma circunferencia
(multiplicando esta constante pelo diametro). Sempre que fosse necessario
calcular esta area, o diametro deveria ser multiplicado por 1/9 do lado e
subtrada na primeira etapa do procedimento citado (podemos imaginar o
quanto a consideracao de um lado diferente de 9 iria complicar os calculos).
Mais uma vez, usando a formula da area que conhecemos, obteremos
aproximadamente 3, 16 para o valor de  no procedimento egpcio. Mas
o valor de 1/9 usado pelos egpcios era uma constante multiplicativa, que
devia ser operada com o diametro, e nao um numero. Logo, nao se trata
exatamente de uma aproximacao para !
Exerccios
1.36. Calcule, trabalhando no sistema sexagesimal, a area do trapezio do
tablete YBC 7290.
1.37. Resolva o problema proposto no tablete IM 55357. Suponha, como fez
o escriba, que o triangulo ABF e retangulo, BC e perpendicular a AF ,
DC e perpendicular a BF e que DE e perpendicular a AF .
1.38. Um antigo exerccio da Matematica babilonia (ver Figura 1.27) trata
do calculo da area de um terreno de forma quadrangular. Neste exerc-
cio, a area e calculada tomando as medias dos comprimentos dos lados
opostos e multiplicando-as. Traduzindo em nossa notacao, se a, b, c e
d sao os comprimentos dos lados do terreno, entao (Figura 1.28)
S = (a + c)
2  (b + d)
2 .
Em que casos esta formula fornece resultados exatos?
1.39. O seked era a unidade usada para medir inclinacoes. Ele se baseava
na medida de comprimento chamada de cubito real. Cada cubito era
dividido em 7 palmos e cada palmo, por sua vez, era dividido em 4
dedos. A inclinacao era medida como o numero de palmos e dedos
percorridos horizontalmente para subir um cubito real.
O problema 56 do papiro de Ahmes pede o calculo da inclinacao da
face de uma piramide:
44 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
Figura 1.27
Figura 1.28
Se uma piramide tem 250 cubitos de altura e o lado de sua base mede 360
cubitos, qual e seu seked?
Tome 1/2 de 360; faz 180. Multiplique 250 para obter 180, faz 2 5 50
de um cubito. Um cubito e [sic] 7 palmos. Multiplique 7 por 2 5 50.
1 7
2 3 2
5 1 3 15
50 10 25
O seked e igual a 5 25 palmos.
Resolva este problema usando nossos metodos e compare sua solucao
com o metodo usado pelo escriba.
1.40. O problema 44 do papiro de Ahmes calcula a quantidade de graos
contida em um celeiro:
Exemplo do calculo de um celeiro retangular, seu comprimento sendo 10,
sua largura 10 e sua altura 10. Qual a quantidade de grao [sic] que vai
nele?
1.7. EXERCICIOS SUPLEMENTARES 45
Resolva o problema usando nossa simbologia matematica moderna e
compare sua solucao com a do escriba, exposta a seguir:
Multiplique 10 por 10; faz 100. Multiplique 100 vezes 10; faz 1000.
Adicione seu 2; faz 1500, sua capacidade em khar. Tome 20 de 1500;
faz 75 sua capacidade em hekat quadruplos, ou seja, 7500 hekat de
graos.
Os calculos:
1 10
10 100
1 100
10 1000
1 1000
2 500
1 1500
10 150
20 75
Prova:
1 75
10 750
/20 1500
10 de 1500 150
10 de 10 15
3 de 10 de 10 10
1.7 Exerccios suplementares
1.41. No papiro Ahmes, sao calculados os desenvolvimentos das fracoes 2/n,
para n = 5 . . . 101. Pode-se observar que nao ha uma maneira geral,
uniforme, no papiro, para achar estes desenvolvimentos. Uma maneira
de calcula-los todos, sistematicamente, seria usando o fato de que
2
2i + 1 = 1
i + 1 + 1
(i + 1)(2i + 1).
Mostre que esta identidade se verifica sempre, para i um numero natu-
ral.
46 CAPITULO 1. A MATEM ATICA NA BABIL ONIA E ANTIGO EGITO
1.42. Seja uma fracao a
b . Mostre que o desenvolvimento decimal desta fracao
e finito se e somente se seu numerador e da forma b = 2t5s, com t e s
numeros inteiros nao negativos.
1.43. Consideremos fracoes a
b , em um sistema de base k, com k um numero
natural maior do que 1. Como saber se o desenvolvimento decimal
desta fracao tera somente um numero finito de algarismos diferentes de
zero?
1.44. Usando o fato de que R e um corpo ordenado completo, mostre que e
possvel atribuir um valor (em R), a qualquer desenvolvimento decimal,
finito ou infinito.
1.45. Mostre que um numero real e racional se e somente se seu desenvol-
vimento decimal e finito (isto e, tem um numero finito de algarismos
diferentes de zero) ou periodico (uma dzima periodica).
1.46. Como ja foi explicado neste captulo, os egpcios usavam somente
fracoes unitarias, ou seja, fracoes com numerador igual a 1.
1. Demonstre que qualquer fracao ordinaria a
b pode ser decomposta
em uma soma de um numero finito de fracoes unitarias distintas.
(Sugestao: Dada a fracao a
b , ache a maior fracao 1
n menor do que
a
b . Considere entao a fracao a
b menos a fracao unitaria que voce
encontrou e repita sucessivamente o processo.)
2. Prove que o processo descrito acima termina em um numero finito
de passos e que as fracoes unitarias obtidas sao diferentes entre si.
3. O processo descrito acima e o unico que funciona? Tente encontrar
outros processos para decompor uma fracao arbitraria em uma
soma de um numero finito de fracoes unitarias distintas.
1.47. Escreva as fracoes abaixo como soma de fracoes unitarias distintas:
1. 3
4 .
2. 17
45 .
3. 19
7 .
1.48. Demonstre que todo numero natural pode ser escrito como soma de
potencias de 2.
1.7. EXERCICIOS SUPLEMENTARES 47
1.49. Os chineses usavam a regra de dupla falsa posicao, chamando-a de
metodo de excesso e de falsa. Resolva o seguinte problema, usando nos-
sas tecnicas algebricas modernas e pelo metodo de dupla falsa posicao:
Um certo numero de pessoas comprou galinhas. Se cada pessoa tivesse
contribudo com 9 unidades monetarias para a compra, sobrariam 11
u.m. Se cada pessoa tivesse contribudo com 6 u.m., faltariam 16 u.m.
para a compra. Determine o numero de pessoas e o preco de cada
galinha.

Captulo 2
O nascimento do metodo
dedutivo e a geometria de
Euclides
2.1 Contextualizacao historica
E muito comum ouvirmos que a geometria surgiu `as bordas do Nilo, devido
`as enchentes e `a necessidade de medir a area das terras a serem redistribudas
entre aqueles que haviam sofrido prejuzos. Esta hipotese tem sua origem nos
escritos de Herodoto:
[Quando das inundacoes do Nilo,] o rei Sesostris enviava pes-
soas para inspecionar o terreno e medir a diminuicao dos mesmos
para atribuir ao homem uma reducao proporcional de impostos.
A esta, creio eu, a origem da geometria que migrou, mais tarde,
para a Grecia.(Herodoto, Oeuvres compl`etes II 109, p.183).
Por outro lado, Aristoteles afirma que a Matematica surgiu
[. . . ] em lugares nos quais as pessoas dispunham de lazer.
Esta e a razao de a Matematica ter surgido primeiro no Egito;
pois a a casta dos sacerdotes tinha permissao para desfrutar de
lazer. (Aristoteles, Metafsica, 981b20-25, apud [75], pp. 258-
259.)
A historia tradicional nos conta que um dos primeiros matematicos gre-
gos foi Tales de Mileto, que teria vivido nos seculos VII e VI a.E.C. e sido
influenciado pelos mesopotamicos e egpcios. Diz-se que um de seus feitos
49
50 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
teria sido, justamente, o calculo da altura de uma das piramides do Egito,
a partir da semelhanca entre, por um lado, a relacao desta altura com sua
sombra e, por outro, a relacao de sua propria altura com sua propria sombra.
A Matematica pitagorica, datada da primeira metade do seculo V a.E.C.,
teria feito a transicao entre as epocas de Tales e Euclides.
E verdade que os povos mesopotamicos e egpcios, de que tratamos no
captulo anterior, realizavam calculos com medidas de comprimentos, areas
e volumes. Contudo, estas praticas sao bem diferentes da geometria grega.
Nas praticas de medida, os problemas geometricos sao transformados em
problemas numericos. A escolha de uma unidade de medida basta para
converter um comprimento, uma area ou um volume em um numero. Sem,
duvida, os primeiros matematicos gregos praticavam uma geometria baseada
em calculos de medidas, como os povos antigos. Nao ha, contudo, uma
documentacao confiavel que possa estabelecer a transicao entre a Matematica
mesopotamica e egpcia e a Matematica grega.
Tambem influenciado pela Matematica egpcia, Pitagoras teria introdu-
zido um tipo de Matematica abstrata na Grecia. A narrativa historica tradi-
cional enfatiza a transicao do tipo de Matematica realizada pelos babilonios
e egpcios, profundamente marcada por calculos e algoritmos, para a Ma-
tematica teorica, praticada pelos gregos, fundada em argumentacoes consis-
tentes e demonstracoes.
O tipo de pensamento que se expressa nesta Matematica tem relacao
com o contexto grego da epoca, tal como se desenvolveu a partir do seculo
V a.E.C. Por volta do seculo VII a.E.C., o crescimento populacional e a
dispersao dos gregos pela bacia do Mediterraneo deram origem `a mais im-
portante instituicao da antiguidade grega, que foi determinante para a or-
ganizacao poltica, administrativa, religiosa e militar da Grecia durante os
seculos V e IV a.E.C. Trata-se da polis  a cidade-estado grega.
A polis surgiu ao mesmo tempo em que o cidadao passou a ter direito
de reger sua cidade. Para isto, eram necessarios parametros, o que alimen-
tava um gosto pela discussao. A controversia movimentava a polis grega e,
como contribua para vencer o debate, a persuasao tornou-se uma habilidade
bastante valorizada. Em seus estudos sobre as origens historicas da razao
grega, Jean-Pierre Vernant mostra que este universo e marcado pela ligacao
ntima entre logos, razao e atividade poltica. Tratamos de um perodo no
qual a vida publica adquiriu suma importancia para os antigos gregos, o que
se refletiu no debate poltico na agora, nas trocas comerciais, na laicizacao
e na expansao das formas de religiosidade ao espaco externo (ate entao as-
sunto privado, restrito ao interior do templo) e na organizacao racional e
geometrica do territorio. O pensamento racional foi se constituindo neste
contexto e ganhou impulso neste novo tipo de organizacao. Surgiu entao, na
2.1. CONTEXTUALIZAC AO HIST ORICA 51
Grecia, a ideia de que quem soubesse persuadir sempre poderia convencer
os outros de que sua tese era verdadeira. Em sentido oposto, no entanto,
essa tentacao ao ceticismo deu origem a um esforco para mostrar que ver-
dade e verossimilhanca sao coisas diversas. A partir do final do seculo V
a.E.C., Platao e Aristoteles buscaram propor maneiras de selecionar os tipos
de afirmacao que alguem pode fazer, distinguindo os raciocnios falsos dos
corretos e estabelecendo criterios de verdade.
Em um mundo no qual as opinioes se multiplicavam, era necessario se-
lecionar os argumentos, estabelecer criterios para decidir quem tinha razao.
Este novo tipo de pensamento, para Platao, devia se fundar em definicoes
claras, que distinguem os seres inteligveis de suas copias no mundo sensvel.
Nos discursos de Socrates esta presente este modo de argumentacao, cha-
mado dialetica, que se servia das ideias para ultrapassar as opinioes. A
distincao entre retorica e dialetica ira marcar a educacao do cidadao livre.
Mais tarde, Aristoteles desenvolvera uma logica, na qual os criterios de ver-
dade estarao mais ligados `a pura coerencia, ao rigor da demonstracao. Ou
seja, em uma cadeia de conclusoes, tudo deve decorrer daquilo que antes foi
dito, sem que haja contradicao no interior do raciocnio. Platao e Aristoteles
se serviram da Matematica para constituir este novo ideal de pensamento.
Mas, na verdade, que Matematica era esta?
Grande parte do conhecimento de que dispomos hoje sobre a Matematica
da epoca e indireto, proveniente de escritos como os de Platao, Aristoteles,
Euclides e Proclus. Alem destas obras, ha outras evidencias em alguns pou-
cos fragmentos atribudos a Eudemo de Rodes, que viveu no seculo IV. a.E.C.
Presume-se que o catalogo dos geometras, contido no comentario de Pro-
clus, e provenienete dos escritos deste pupilo de Aristoteles, que mencionava
proposicoes e construcoes que teriam sido realizadas por Tales. No final do
seculo VII a.E.C., diversas realizacoes tecnologicas podem ter contribudo
para o desenvolvimento da Matematica. Alguns termos de geometria ja apa-
reciam, por exemplo, na arquitetura. Ha escritos tecnicos do seculo VI a.E.C.
tratando de problemas relacionados `a astronomia e ao calendario. Neles in-
tervinham alguns conceitos geometricos, como crculos e angulos. Ao menos
um destes livros ainda estava em circulacao na epoca de Eudemo, e os enun-
ciados geometricos a contidos podem ter ficado conhecidos como sendo de
Tales.
No entanto, e difcil estabelecer as bases factuais destas afirmacoes. O
papel de Tales foi objeto de algumas controversias historicas, descritas por
W. Burkert ([21]). Parece ser fato que, por volta do seculo V. a.E.C., seu
nome era empregado em conexao com resultados geometricos. Alem disso,
Aristoteles menciona Tales, na Metafsica, como o fundador da filosofia. Esta
honra, somada `a circulacao da referencia a seu nome como geometra, pode ter
52 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
levado a se atribuir ao filosofo de Mileto importantes descobertas geometricas.
Entre Tales e Euclides, a historiografia da Matematica costuma analisar as
contribuicoes da escola pitagorica do seculo V a.E.C.. Alem disso, e frequente
encontrarmos referencias a Pitagoras como um dos primeiros matematicos
gregos. Mas ambas as afirmacoes sao hoje largamente questionadas. As
evidencias mostram que havia uma Matematica grega antes dos pitagoricos.
Parecia ser comum a construcao de solucoes para problemas geometricos e a
comparacao de grandezas geometricas por meio de razoes. Presume-se que
no seculo V. a.E.C., em Atenas, a geometria era ensinada, apesar de nao
sabermos exatamente como. Podemos deduzir, das poucas evidencias, uma
intensa pratica geometrica na primeira metade do seculo IV a.E.C.
Nao ha sinais de que a Matematica desenvolvida na Grecia durante os
seculos V e IV a.E.C. empregasse qualquer precaucao no uso de procedi-
mentos heursticos e informais. Ha evidencias, todavia, de que no meio dos
filosofos os metodos usados pelos matematicos eram questionados. Por volta
do ano 375 a.E.C., Platao comeca a criticar os geometras por nao emprega-
rem criterios de rigor desejaveis nas praticas matematicas. Nao por acaso,
o trabalho de Eudoxo se desenvolveu no seio da Academia platonica. Sendo
assim, ainda que nao possamos dizer que a transformacao dos fundamentos
da Matematica grega e devida a Platao, ele expressa o descontentamento dos
filosofos com os metodos empregados e articula o trabalho dos pensadores `a
sua volta para que se dediquem a formalizar os conceitos e tecnicas utilizadas
indiscriminadamente na Matematica da epoca.
Os membros da Academia debatiam o modo de descrever as disciplinas
matematicas, o que pode ter tido um papel na legitimacao deste saber em
sua forma abstrata e na consolidacao da posicao da Matematica como uma
disciplina do pensamento puro. No seculo V a.E.C., o pensamento geometrico
e tecnico ja estava desenvolvido, mas nao temos como saber se os pitagoricos
contriburam para isto. A geometria grega comecou antes deles e continuou
depois; como mostra Burkert ([21]), esta escola nao parece ter tido um papel
significativo na transformacao da Matematica de seu tempo.
Quase todos os livros de historia da Matematica a que temos acesso em
portugues reproduzem a lenda de que a descoberta dos incomensuraveis pro-
vocou uma crise nos fundamentos da Matematica grega. Alguns chegam a
afirmar que esta crise so foi resolvida com a definicao rigorosa dos numeros
reais, proposta por Cantor e Dedekind no seculo XIX. Este mito possui con-
sequencias importantes para o modo como a historia da geometria grega se
estrutura.
A descoberta das grandezas incomensuraveis, frequentemente atribuda a
um pitagorico, deve ter tido outras origens. Esta descoberta contribuiu para
a separacao entre a geometria e a aritmetica, a primeira devendo se dedicar
2.1. CONTEXTUALIZAC AO HIST ORICA 53
`as grandezas geometricas e a segunda, aos numeros. Esta separacao e um
dos tracos marcantes da geometria grega, ao menos na maneira como ela se
disseminou com Euclides.
Apesar de questionarmos a validade da tese historiografica a respeito da
crise dos incomensuraveis, e inegavel que a descoberta de que duas grande-
zas podem nao possuir uma medida comum teve consequencias importantes.
Uma delas pode ajudar a explicar o carater formal e abstrato da geometria,
tal como exposta nos Elementos de Euclides. O fato de que duas grandezas
podem ser incomensuraveis desafia o testemunho dos sentidos e foi, talvez, o
que motivou um novo modo de fazer geometria.
A consequencia da descoberta dos incomensuraveis que mais gostaramos
de enfatizar neste trabalho e a separacao do universo das grandezas do uni-
verso dos numeros. A necessidade de demonstracao surge com os gregos a
partir deste momento chave da historia da geometria. A descoberta dos inco-
mensuraveis nos leva a desconfiar dos sentidos, uma vez que eles nao permi-
tem enxergar a possibilidade de dois segmentos nao serem comensuraveis.
E necessario, portanto, demonstrar, fundar a geometria sobre bases mais
solidas do que aquelas que podem ser fornecidas pela intuicao. Com esta
transformacao, ganha destaque o espaco abstrato sobre o qual fundamos, ate
hoje, a Matematica.
Com Euclides, a Matematica na Grecia parece ter adquirido uma confi-
guracao particular, passando a empregar enunciados geometricos gerais, que
nao envolvem somente procedimentos de medida. Os Elementos de Euclides
representam, neste contexto, o resultado dos esforcos de formalizacao da Ma-
tematica para apresentar uma geometria consistente e unificada que valesse
para grandezas quaisquer, fossem elas comensuraveis ou incomensuraveis.
Trataremos a seguir de alguns resultados, dentre os mais significativos que
se encontram nos Elementos. O papel desta obra na Matematica nao pode
ser superestimado. Em primeiro lugar, ela expoe, de maneira organizada,
a Matematica elementar que os gregos da epoca classica tinham criado e
desenvolvido. Assim, muito do que sabemos da Matematica grega deve-se a
esta obra de Euclides. Em segundo lugar, como os Elementos constituem a
mais antiga exposicao organizada de Matematica que nos chegou, eles muito
influenciaram seu desenvolvimento posterior.
Antes de analisar os Elementos com mais detalhes, comecaremos por des-
crever a concepcao particular de numero da escola pitagorica, bem como
alguns princpios basicos de sua filosofia. Nosso objetivo sera mostrar que,
se existiu uma Matematica pitagorica, tratava-se de uma pratica bastante
concreta. Mesmo o famoso teorema de Pitagoras, em sua compreensao
geometrica como relacao entre medidas dos lados de um triangulo retangulo,
nao parece ter sido particularmente estudado por Pitagoras e sua escola.
54 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Outro objetivo deste captulo e desconstruir os mitos envolvidos na cha-
mada crise dos incomensuraveis. Veremos que esta tese tem origem em
obras ja ultrapassadas, que constituem um exemplo paradigmatico de um
modo de fazer historia da Matematica, hoje bastante contestado, caracteri-
zado por pressupostos modernos sobre a natureza da Matematica.
2.2 A Matematica grega antes de Euclides
2.2.1 A nocao de numero dos pitagoricos e a geometria
pre-euclidiana
Pitagoras e frequentemente citado como o pai da Matematica grega, mas sua
teoria dos numeros era concreta, baseada em manipulacoes de numeros figu-
rados. Sua aritmetica era indutiva e nao continha provas. Era possvel obter,
graficamente, generalizacoes sobre sequencias de numeros, mas as regras para
obtencao de tais sequencias, como as dos numeros quadrados, cubos e ou-
tros, eram desenvolvidas para uso pratico. A diferenca estava na reverencia
que os pitagoricos cultivavam pelos numeros, empregados nao apenas para
fins praticos. Associadas a forcas cosmicas, as propriedades dos numeros nao
podiam ser consequencias logicas de sua estrutura, o que banalizaria suas
propriedades.
A concepcao de Pitagoras sobre a natureza parte da ideia de que ha uma
explicacao global que permite simbolizar a totalidade do cosmos, e esta ex-
plicacao e dada pelos numeros. Isto levou os pitagoricos a considerarem que
as coisas sao numeros, elas consistem de numeros. Uma das caractersticas
principais das coisas reside no fato de elas poderem ser organizadas e dis-
tinguidas. Sendo assim, as propriedades aritmeticas das coisas constituem o
seu ser propriamente dito, e o ser de todas as coisas e o numero.
Os numeros figurados dos pitagoricos eram constitudos de uma multipli-
cidade de pontos que tambem nao eram pontos matematicos, mas remetiam
a elementos discretos: pedrinhas dispostas em uma certa configuracao.
O primeiro exemplo de numero figurado e dado pelos numeros triangu-
lares, em que os pontos formam figuras triangulares (os numeros pitagoricos
sao apenas as colecoes de bolinhas, a cifra escrita embaixo e a traducao de
cada um em linguagem atual. Veja a Figura 2.1).
Os numeros triangulares representados acima podem ser associados aos
nossos numeros 1, 3, 6, 10, 15 e 21, que possuem respectivamente ordem
n = 1, 2, 3, 4, 5 e 6. Em linguagem matematica atual, o numero triangular
de ordem n e dado pela soma da progressao aritmetica 1+2+3+. . .+n = n(n+1)
2 .
Em seguida, temos os numeros quadrados, que atualmente podem ser escritos
2.2. A MATEM ATICA GREGA ANTES DE EUCLIDES 55
Figura 2.1
Figura 2.2
como n2 (Figura 2.2) e os numeros pentagonais para n = 1, n = 2, n = 3 e
n = 4 (Figura 2.3).
Figura 2.3
Destas configuracoes numericas, os pitagoricos tiravam, de forma visual,
diversas conclusoes aritmeticas como:
a) Todo numero quadrado e a soma de dois numeros triangulares suces-
sivos (Veja a Figura 2.4).
b) E possvel passar de um numero quadrado ao numero quadrado imedi-
atamente maior adicionando-se a sequencia dos numeros mpares. Na figura,
os numeros mpares sao dados pelos contornos em forma de L, os gnomons
dos pitagoricos (Figura 2.5).
Poderamos exprimir, em linguagem matematica atual, os enunciados
56 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Figura 2.4
Figura 2.5
acima respectivamente como:
a) n2 = n(n+1)
2 + (n1)n
2
b)
12 + 3 = 22
22 + 5 = 32
32 + 7 = 42
. . .
n2 + (2n + 1) = (n + 1)2
O problema que chamamos hoje de triplas pitagoricas e o de achar
dois numeros quadrados cuja soma seja tambem um numero quadrado. Estas
triplas sao constitudas por numeros inteiros, que podem ser associados `as
medidas dos lados de um triangulo retangulo1.
Provavelmente, os pitagoricos chegaram a estas triplas por meio do gno-
mon que era sinonimo dos numeros mpares, formados pelas diferencas entre
numeros quadrados sucessivos. Os gnomons forneciam uma tecnica para rea-
lizacao de calculos. Observando a figura acima, podemos calcular a sequencia
dos quadrados por meio de um deslocamento do esquadro, equivalente a so-
mar a sequencia dos numeros mpares. Por exemplo, para obter o 4 a partir
do 1, adicionamos o gnomon de tres pontos; para obter o 9 a partir do 4,
1Alguns historiadores da Matematica defendem que no tablete babilonico Plimpton 322 ha
um indcio de que os babilonios povo ja estudavam as triplas pitagoricas, o que mostraria que
a relacao atribuda a Pitagoras ja seria conhecida. Esta tese e refutada por E. Robson, em
artigo sobre Plimpton 322 ([122]).
2.2. A MATEM ATICA GREGA ANTES DE EUCLIDES 57
Figura 2.6
adicionamos o proximo gnomon, que e o proximo numero mpar, 5. Se con-
tinuarmos este procedimento, chegaremos a uma figura na qual o gnomon
tambem e um quadrado, constitudo por nove pontinhos. Obtemos assim a
igualdade 16 + 9 = 25, que da origem `a primeira tripla pitagorica: (3, 4, 5).
Observamos que, no metodo pitagorico, as triplas eram obtidas por pro-
cedimentos aritmeticos. Ou seja, a formula de Pitagoras pertence ao con-
texto dos numeros figurados. Na tradicao, poucas triplas sao mencionadas
e (3, 4, 5) tem um papel especial, pois 3 e o macho, 4 e a femea e 5 e o
casamento que os une no triangulo pitagorico.
Nao se conhece nenhuma prova do teorema que tenha sido fornecida por
algum pitagorico e a possibilidade de que ela exista parece pouco provavel.2
Alem disso, o teorema de Pitagoras dos pitagoricos nao deveria ser um
resultado geometrico.
Um pouco depois de Pitagoras, desenvolveu-se efetivamente alguma geo-
metria na Grecia pre-euclidiana, mas os indcios sao de que este estudo nao
teria relacao com o crculo pitagorico. Um dos geometras que conhecemos
melhor, antes de Euclides, e Hipocrates de Quios e Democrito (ambos da
segunda metade do seculo quinto a.E.C.). Em particular, temos as chama-
das lunulas de Hipocrates que fornecem o primeiro exemplo de figuras limi-
tadas por linhas curvas cujas areas foram encontradas. Seu estudo parece
ter surgido do problema de se encontrar a quadratura do crculo. Para os
matematicos gregos, fazer a quadratura de uma regiao limitada do plano
significa construir um quadrado igual 3 `a regiao.4
Hipocrates de Quos atacou este problema a partir de um caso mais sim-
2Algumas provas mais simples do que a de Euclides foram sugeridas, por exemplo, por
Heath, em seus comentarios da demonstracao contida nos Elementos de Euclides (Ver pagina
75).
3Para os matematicos gregos, a palavra igual podia significar tanto ter a mesma area,
quanto ser congruente.
4A quadratura do crculo e um dos tres problemas classicos da Matematica grega. Os
outros dois eram duplicar o cubo, ou seja, construir um cubo com volume duplo de um cubo
dado e trissectar um angulo dado..
58 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
ples, que seria o de encontrar a quadratura das lunulas. Uma lunula e uma
figura plana limitada por dois arcos circulares de raios diferentes, como exem-
plificado na Figura 2.7.
E
A
C
B
D
Figura 2.7
Textos de Hipocrates sobre a quadratura das lunulas sao os mais anti-
gos documentos matematicos gregos que nos chegaram, embora de maneira
fragmentada. Hipocrates e tambem conhecido por ter sido o primeiro ma-
tematico grego de que temos notcia a redigir um texto organizado na forma
de elementos. Mas esta obra se perdeu.
Exerccios
2.1. Mostre que o numero hexagonal de ordem n e igual a 2n2  n.
2.2. Hipocrates percebeu que, para fazer a duplicacao do cubo, e suficiente
construir duas meias proporcionais entre dois segmentos a e b. Mais
precisamente, dados a e b, procuram-se segmentos x e y tais que, em
linguagem algebrica moderna,
a
x = x
y = y
b .
Mostre que, fazendo a = 1 e b = 2, entao x3 = 2, ou seja, x e a aresta do
cubo de volume 2, duas vezes o volume do cubo de raio 1.
2.3. Hipocrates estudou varios tipos de lunulas, em suas tentativas para
fazer a quadratura do crculo. Uma delas e a seguinte (Veja a Figura
2.8): Seja a circunferencia com centro O e raio OE. Prolongue OE
a fim de obter o diametro AE. Seja BD o diametro perpendicular a
EA. Trace uma circunferencia com centro em A e raio AB. A regiao
limitada pelos arcos BCD e BED e uma lunula. Demonstre que a area
desta lunula e igual `a area do triangulo retangulo de vertices D, E e
B.
2.4. Outra lunula estudada por Hipocrates esta mostrada na Figura 2.9.
Os centros das tres circunferencias estao sobre os lados do triangulo
retangulo ABC, respectivamente. Mostre que a area do triangulo e
igual `a area das duas lunulas indicadas na Figura.
2.2. A MATEM ATICA GREGA ANTES DE EUCLIDES 59
Figura 2.8
Figura 2.9
2.2.2 O problema da incomensurabilidade
Antes de iniciarmos a discussao historica sobre o problema da incomensura-
bilidade, gostaramos de explicar a principal dificuldade colocada pela con-
tradicao da ideia intuitiva de que dois segmentos devem sempre possuir uma
unidade de medida comum. Ainda que cada segmento possa ser divido em
partes muito pequenas, o fato de dois segmentos nao serem comensuraveis
significa que nao e possvel encontrar uma parte que caiba um numero in-
teiro de vezes em ambos. Esta descoberta contradiz o que se pode esperar
por meio do testemunho dos sentidos.
Sabemos que, para medir, o primeiro passo e escolher uma unidade de
medida. Duas medidas da mesma natureza devem possuir uma unidade de
medida comum. Cada grandeza e identificada, assim, ao numero inteiro de
unidades de medida que a compoem. A medida torna possvel, portanto,
a correspondencia entre qualquer grandeza e um numero natural, ou uma
relacao entre numeros naturais.
Como medir significa, essencialmente, comparar, precisamos, na mai-
60 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
oria das vezes, subdividir uma das grandezas a serem comparadas para obter
uma unidade de medida que caiba um numero inteiro de vezes em ambas as
grandezas a serem comparadas. Suponhamos, por exemplo, que queiramos
comparar dois segmentos A e B. Como B nao cabe um numero inteiro de
vezes em A, podemos dividir B em 3 e tomar a unidade como sendo um
terco de B. Como esta unidade cabe 4 vezes em A, a comparacao de A
com B nos fornece a razao 4  3. e deste tipo de comparacao que surgem as
medidas expressas por relacoes entre numeros inteiros, que chamamos hoje
de racionais (justamente por serem associados a uma razao).
A 
B 
Em geral, o problema e o seguinte: Dadas duas grandezas A e B (seg-
mentos, figuras planas, solidos geometricos, entre outras), e sempre possvel
subdividir uma delas, por exemplo B, em um numero finito de partes, de
modo que uma destas partes caiba um numero inteiro de vezes em A? In-
tuitivamente, se pensamos em grandezas fsicas, podemos imaginar que sim.
Ou seja, se as partes de B puderem ser tornadas muito pequenas, sempre
poderemos encontrar um segmento que caiba em A um numero inteiro de
vezes, ainda que seja um numero muito grande. A descoberta das grande-
zas incomensuraveis mostra que isto nao e verdade, logo nossa intuicao nos
engana.
Ha muitas lendas sobre a descoberta dos incomensuraveis e, em particu-
lar, sobre a crise que isso teria provocado. A descoberta de que a comparacao
das medidas de dois segmentos nao pode ser realizada por meio de numeros
teria provocado um escandalo e, ate mesmo, levado um pitagorico a ser per-
seguido. Estes mitos vem sendo profundamente questionados pela historia
da Matematica nas ultimas decadas.5
Ja vimos que a aritmetica dos pitagoricos nao era abstrata, mas se baseava
em numeros figurados, descritos por uma configuracao espacial de pedrinhas,
consideradas unidades com magnitude, manuseadas e arrumadas em padroes
visveis. Burkert ([21]) mostra que este tipo de aritmetica e o problema
da incomensurabilidade sao mutuamente exclusivos e seria mais plausvel
considerar que a incomensurabilidade tenha sido descoberta no campo da
geometria.
Alem de duvidar que a possibilidade de grandezas incomensuraveis tenha
sido vislumbrada no seio da escola pitagorica, alguns pesquisadores, como
5Para uma discussao detalhada em portugues ver [70].
2.2. A MATEM ATICA GREGA ANTES DE EUCLIDES 61
Burkert e Knorr, contestam ate mesmo que esta descoberta tenha repre-
sentado uma crise nos fundamentos da Matematica grega. Nao encontra-
mos alusao a um escandalo em nenhuma passagem dos escritos a que temos
acesso e que citam o problema dos incomensuraveis, como os de Platao ou
Aristoteles.6.
O problema da incomensurabilidade parece ter surgido no seio da propria
Matematica, mais precisamente, da geometria, sem a relevancia filosofica
que lhe e atribuda. Diversos argumentos sao elencados em favor desta tese:
ninguem que nao fosse suficientemente instrudo em Matematica poderia ficar
impressionado pela descoberta da incomensurabilidade; a conexao entre este
problema e a filosofia pitagorica e duvidosa; nao e certa nem mesmo a relacao
entre a descoberta dos irracionais e a aplicacao do teorema de Pitagoras
(que nos permitiria concluir que ha um lado de um triangulo retangulo cuja
medida e 2), uma vez que os babilonios e chineses ja conheciam o teorema
e nem por isso chegaram aos numeros irracionais.
Uma opiniao bastante difundida e a de que a incomensurabilidade foi
descoberta pela geometria grega antiga, na segunda metade do seculo V a.C,
mais precisamente entre 430 e 410 a.E.C..
Um dos primeiros exemplos a apresentar a possibilidade de duas gran-
dezas incomensuraveis teria sido o problema de se usar o lado para medir a
diagonal de um quadrado, 7 o que exige conhecimentos simples de geometria.
Autores do seculo IV a.E.C., como Platao e Aristoteles, tratam do problema
da incomensurabilidade no contexto da comparacao entre o lado e o diametro
de um quadrado e citam matematicos como Teodoro e Teeteto.
Um dos procedimentos que pode estar ligado ao estudo das grandezas
incomensuraveis e o da antifairese, ou subtracoes recprocas.8 Os matematicos
gregos que trabalhavam com aritmetica no final do seculo V a.E.C. conhe-
ciam o procedimento da antifairese, bem como o modo de emprega-lo no tra-
tamento de alguns segmentos incomensuraveis. No entanto, estes resultados
nao eram percebidos como uma prova da incomensurabilidade destes seg-
mentos. O objetivo da antifairese era o de aproximar razoes entre segmentos
incomensuraveis e, ainda assim, os exemplos de seu uso nao sao abundantes.
6Alias, Aristoteles nao cita o problema dos incomensuraveis nem mesmo em sua crtica aos
pitagoricos.
7O problema das diagonais do pentagono regular, que constituem o famoso pentagrama
e algumas vezes relacionado `a descoberta dos incomensuraveis, sobretudo por von Fritz (Ver
[149]). A descoberta da incomensurabilidade por Hpaso teria se dado justamente a partir
deste exemplo. No entanto, os historiadores que seguimos aqui contestam esta reconstrucao,
uma vez que ela implica o uso de fatos geometricos elaborados, que so teriam se tornado
conhecidos posteriormente.
8Um indcio do emprego deste metodo pode ser encontrado no tratado peripatetico
(atribudo a Aristoteles) De lineis insecabilibus (970a 15-19).
62 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
A antifairese permite definir e comparar razoes sem a necessidade do con-
ceito de numero racional, ou de fracao, e independentemente da razao estar
inserida em uma relacao de proporcao.9 A definicao de razoes e proporcoes a
partir da antifairese permite evitar o problema de lidar com grandezas inco-
mensuraveis. No caso geometrico, duas grandezas estariam na mesma razao
quando possuem a mesma antifairese. Se tentarmos encontrar a razao entre
a diagonal e o lado do quadrado por este procedimento, obteremos uma vez,
duas vezes, duas vezes, duas vezes,. . . . Nao e difcil mostrar, com argumen-
tos da Matematica grega, que esta sequencia continua indefinidamente, o que
bastaria para concluir pela incomensurabilidade.
Uma outra hipotese sobre a descoberta da incomensurabilidade, desta vez
no contexto da aritmetica, tem sua origem em um resultado encontrado nos
Elementos de Euclides. No final do quarto seculo a.E.C., em sua exposicao
sobre a tecnica de raciocnio por absurdo, Aristoteles se refere `a prova da
incomensurabilidade dizendo que
[. . . ] se o lado e o diametro sao considerados comensuraveis
um em relacao ao outro, pode-se deduzir que os numeros mpares
sao iguais aos pares; esta contradicao afirma, portanto, a inco-
mensurabilidade das duas grandezas (Primeiros Analticos, I.23,
41a29).
Esta afirmacao e interpretada frequentemente como uma evidencia de que
os gregos conheciam uma demonstracao mostrando como a suposicao de que
o lado e a diagonal do quadrado sao comensuraveis leva `a contradicao de que
um numero deve ser par e mpar ao mesmo tempo. Muitas vezes, contudo, a
demonstracao apresentada para este fato faz uso de uma linguagem algebrica
que nao poderia ter sido usada pelos gregos antigos. Em um apendice ao
Livro X dos Elementos de Euclides, provavelmente interpolado em uma epoca
posterior, encontramos uma prova geometrica levando `a contradicao de que
um numero mpar seria igual a um par.
Em qualquer dos casos, podemos afirmar que a descoberta da incomen-
surabilidade nao provocou uma crise dos fundamentos da Matematica, mas
foi uma descoberta interessante que motivou novos desenvolvimentos mate-
maticos.
A antifairese entre a diagonal e o lado de um quadrado
Seja o quadrado ABCD de lado AB e diagonal AC (Figura 2.10). Suponha-
mos que AB e AC sejam comensuraveis, logo existe um segmento AP que
9Por tras dos livros II e X dos Elementos, haveria um interesse em estudar a antifairese de
razoes quadraticas.
2.2. A MATEM ATICA GREGA ANTES DE EUCLIDES 63
mede AB e AC. Em primeiro lugar, queremos construir um quadrado menor
que ABCD cujo lado esteja sobre a diagonal AC e cuja diagonal esteja sobre
o lado AB.
Seja B1 um ponto em AC tal que B1C = AB. Marcando um ponto C1
sobre AB (com B1C1 perpendicular a AC), podemos construir um quadrado
AB1C1D1 de lados AB1 = B1C1 e diagonal AC1 sobre AB. Isto e possvel
porque C AB = B1 AC1 e metade de um angulo reto e A B1C1 e reto, logo
A C1B1 e metade de um angulo reto e o triangulo AB1C1 e isosceles com
AB1 = B1C1.
Figura 2.10
Mas como, por construcao, BC = B1C, o triangulo BCB1 e isosceles e
temos que B1 BC = B B1C  B1 BC1 = B B1C1 (pois C BC1 e C B1C1 sao
retos). Isto significa que o triangulo B1C1B tambem e isosceles e podemos
concluir que BC1 = B1C1.
Temos assim um novo quadrado, AB1C1D1 e podemos escrever que
AB1 = AC  B1C = AC  AB
AC1 = AB  BC1 = AB  B1C1 = AB  AB1 = AB  AC + AB = 2AB  AC
Por esta igualdade, se AB e AC sao comensuraveis com relacao `a unidade
de medida AP , AB1 e AC1 tambem o serao.
Para concluir a demonstracao, precisamos mostrar que, do mesmo modo
que construmos AB1C1D1 sobre o lado e a diagonal de ABCD, podemos
construir novos quadrados, menores, desta vez sobre o lado e a diagonal do
quadrado pequeno AB1C1D1. Supondo que o lado e a diagonal do novo
quadrado sao, respectivamente, AB2 e AC2, temos que mostrar que estes
segmentos podem ser tornados menores do que qualquer quantidade dada.
Isto e, repetimos o procedimento acima ate obter um quadrado de lado ABn
e diagonal ACn, cujos comprimentos serao menores do que a unidade de
medida AP , ainda que esta possa ser tornada muito pequena.
64 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Continuando o processo indefinidamente, para qualquer que seja a escolha
inicial do segmento AP , podemos obter um quadrado de lado ABn e diagonal
ACn, comensuraveis em relacao a AP , tal que ABn < ACn < AP , o que e uma
contradicao. Se escolhessemos AP menor do que a escolha inicial, obteramos
o mesmo resultado, logo nao e possvel encontrar uma medida comum entre
o lado e a diagonal: eles sao incomensuraveis.
Mas para concluir esta demonstracao, faltou provar que AB1 e AC1 po-
dem ser tornados menores do que qualquer quantidade dada. No exerccio 9
fornecemos um roteiro para completar esta parte da demonstracao, usando
o lema de Euclides.
Exerccios
2.5. As demonstracoes feitas pelos pitagoricos parecem ter se baseado na
evidencia visual fornecida pelos numeros figurados.
1. Desenhe os quatro primeiros numeros triangulares, quadrados e
pentagonais, respectivamente.
2. Sejam Tn, Qn e Pn, respectivamente, os numeros triangulares, qua-
drados e pentagonais de ordem n. Mostre, sem utilizar aritmetica
ou algebra, simplesmente reorganizando diagramas de numeros
figurados, que
Pn = Sn + Tn1.
2.6. Mostre, sem utilizar aritmetica ou algebra, simplesmente reorganizando
diagramas de numeros figurados, que oito vezes um numero triangu-
lar mais um e igual a um numero quadrado. Se o numero triangular
tem ordem n, qual a ordem do numero quadrado obtido pelo processo
acima?
2.7. Demonstre que, em linguagem atual, o metodo usado pelos pitagoricos
para achar ternas pitagoricas consiste em obter os numeros a21
2 e a2+1
2
que satisfazem a relacao
a2 + (a2  1
2 )
2
= ( a2 + 1
2 )
2
.
2.8. A contradicao obtida no procedimento da antifairese exposto em 2.2.2
pode ser interpretada em linguagem atual do modo como segue: se o
lado e a diagonal sao comensuraveis podemos escrever AB = pAP e
AC = qAP , e teramos AB1 = (q  p)AP e AC1 = (2p  q)AP . A que
2.2. A MATEM ATICA GREGA ANTES DE EUCLIDES 65
resultado sobre a quantidade de numeros inteiros entre 0 e p (ou entre
0 e q) equivaleria a conclusao da demonstracao?
2.9. Conclua a demonstracao, iniciada em 2.2.2, de que a diagonal e o lado
do quadrado sao incomensuraveis. Para mostrar que AB1 e AC1 podem
ser tornados menores do que qualquer quantidade dada (Figura 2.10)
usamos o lema de Euclides, a proposicao X.I dos Elementos (que sera
demonstrada na pagina 88 e parece ter sido conhecida antes de Eucli-
des). Este lema afirma que se as quantidades sucessivamente retiradas
forem sempre menores do que a metade dos restos precedentes, estes
restos podem ser tornados menores do que qualquer quantidade dada.
Para satisfazer a condicao deste lema, usando seus conhecimentos de
geometria, prove que:
AB1 < 1
2 AB. (2.1)
AC1 < 1
2AC. (2.2)
2.10. Mostre aritmeticamente que o lado e a diagonal de um quadrado sao
incomensuraveis. Em linguagem moderna, se o lado do quadrado tem
comprimento 1, demonstre que 2 e um numero irracional. (Sugestao:
suponha que 2 e um numero racional e chegue `a contradicao de que
um numero pode ser par e mpar simultaneamente.)
2.11. Considere o pentagono regular de lado l inscrito em uma circunferencia
(Veja a Figura 2.11), mostrado com suas diagonais.
 Prove que o lado do pentagono e sua diagonal sao incomensuraveis.
(Sugestao: No pentagono ABCDEF da Figura 2.11, as diagonais
formam um novo pentagono, F GHKL. Suponha que o lado e a
diagonal do pentagono sao comensuraveis e conclua que o mesmo
tem que acontecer com o lado e a diagonal do pentagono F GHKL.
Repita o processo sucessivamente e chegue a uma contradicao.
 Se a diagonal mede x, prove que
x = x
1 = 1
x  1 .
 Suponha que o lado do pentagono mede 1. Demonstre que sua
diagonal tem comprimento igual a
66 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
(1 + 5)
2 .
Figura 2.11 O pentagono e suas diagonais
2.3 Os Elementos de Euclides
Os Elementos 10 sao formados por treze livros, escritos por volta do ano
300 a.E.C., que expoem resultados de tipos diversos, organizados sistema-
ticamente, muitos deles atribudos a outros geometras, alguns anteriores a
Euclides. Apesar disso, os Elementos nao podem ser vistos apenas como
uma compilacao, pois, alem de conterem resultados originais, propoem um
tratamento sistematico e uniforme da Matematica grega basica. Assim, os
Elementos nao contem resultados de Matematica grega avancada, como as
conicas, sobre as quais o proprio Euclides escreveu um livro, hoje perdido.
Euclides viveu em torno de 300 a.E.C. Nao se conhecem as datas de seu nas-
cimento e morte. Os Elementos constituem seu trabalho mais importante,
mas ele escreveu tambem varias outras obras, algumas das quais se perderam.
O que eram elementos para os gregos? Os elementos de uma ciencia
constituam as proposicoes fundamentais, a partir das quais seria possvel
deduzir as outras. Ou seja, nao tinham que ser enciclopedicos, mas mostrar
uma escolha judiciosa do que sera apresentado. Por exemplo, nos Elementos
de Euclides, nao esta demonstrado que as tres alturas de um triangulo se
encontram em um ponto, mas este teorema pode ser deduzido a partir de
outros, mais basicos, demonstrados por Euclides.
10O texto completo dos Elementos encontra-se, atualmente, disponvel gratuitamente, no
site www.dominiopublico.gov.br. Recentemente, Irineu Bicudo publicou uma edicao completa
dos Elementos traduzida diretamente do grego ([14]).
2.3. OS ELEMENTOS DE EUCLIDES 67
Os Elementos de Euclides tem sido exaustivamente estudados; procura-se
saber que teoremas sao devidos ao proprio Euclides e quais sao de matemati-
cos anteriores; analisa-se o encadeamento logico das proposicoes; procura-se
reconstruir o texto original, visto que nao nos chegou nenhuma edicao prove-
niente da epoca do autor. Cada epoca tem um ponto de vista predominante,
segundo o qual faz sua leitura dos Elementos.11 Cada uma dessas diferentes
maneiras de se encarar os Elementos faz com que nossa compreensao deste
livro se transforme.
Alguns historiadores e filosofos da Matematica mais atuais tem anali-
sado de perto o papel dos primeiros princpios na estrutura dedutiva dos
Elementos. Estes estudos mostram que algumas definicoes podem ter sido
interpoladas depois de Euclides, em publicacoes posteriores dos Elementos.
E mais, dependendo do editor, um postulado pode estar entre os axiomas.
E o caso do postulado V o qual, em alguns manuscritos, e considerado um
axioma, uma nocao comum.
A obra se compoe de 13 livros, ou seja, 13 captulos ou partes, cujos
conteudos descreveremos agora, seguindo Artmann [5]. Aos 13 Livros, foram
adicionados, posteriormente, mais dois. Os Elementos se dividem em tres
grandes partes:
1. Geometria plana  Livros I-VI;
2. Aritmetica  Livros VII-IX;
3. Geometria espacial  Livros XI-XIII.
Apresentaremos, neste trabalho, alguns dos resultados mais significativos
dos Livros I, II, V, VII-IX e XII. Obviamente, a descricao acima e global, e
portanto nao permite distinguir exatamente o que e tratado em cada livro.
Um dos principais objetivos dos primeiros livros dos Elementos seria o de
mostrar que diversas construcoes podem ser efetuadas somente com regua
(nao graduada) e compasso. O porque desta restricao ainda nao e consenso
entre os historiadores.
Euclides adota, nos Elementos, o metodo axiomatico-dedutivo, no qual,
a partir de alguns fatos aceitos como evidentes e intuitivos (chamados de
definicoes, postulados e axiomas), demonstram-se consequencias (teoremas)
ou se constroem figuras baseadas nos postulados, axiomas e resultados ja
demonstrados (problemas). Os primeiros princpios encontram-se no Livro I
dos Elementos.
11Veja, por exemplo, Saito (1998).
68 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
DEFINIC OES:
I. Ponto e o que nao tem partes.
II. Reta e o que tem comprimento sem largura.
III. As extremidades da linha sao pontos
IV. Linha reta e aquela que esta posta igualmente entre as suas
extremidades.
V. Superfcie e o que tem comprimento e largura.
VI. As extremidades da superfcie sao linhas.
(. . . )
X. Quando uma linha reta incidindo sobre outra linha reta fizer com
esta dois angulos iguais, cada um destes angulos iguais se chama
angulo reto e a linha incidente se diz perpendicular `a outra linha sobre
a qual incide.
XI. Um angulo e obtuso se e maior que um angulo reto.
XII. E um angulo e agudo se e menor que um angulo reto.
(. . . )
XV. Crculo e uma figura plana, fechada por uma so linha, a qual
se chama circunferencia, de maneira que todos as linhas retas que,
de um certo ponto existente no meio da figura, se conduzem para a
circunferencia, sao iguais entre si.
Observamos que a definicao III mostra que o termo reta designava o
que hoje chamamos de segmento de reta. Neste captulo, como Euclides,
usaremos reta tambem com este sentido. 12 Apos as definicoes, temos os
axiomas, enunciados a seguir.
12Por vezes, no entanto, Euclides usa o termo reta com nosso sentido atual.
2.3. OS ELEMENTOS DE EUCLIDES 69
AXIOMAS
I. As coisas que sao iguais a uma terceira sao iguais entre si.
II. Se a coisas iguais se juntarem outras iguais, os todos serao iguais.
III. Se de coisas iguais se tirarem outras iguais, os restos serao iguais.
IV. Se a coisas desiguais se juntarem outras iguais, os todos serao
desiguais.
V. Se de coisas desiguais se tirarem coisas iguais, os restos serao
desiguais.
VI. Quantidades que perfazem cada uma o dobro de outra quantidade
sao iguais.
VII. Quantidades que sao metades de uma mesma quantidade sao
tambem iguais.
VIII. Duas quantidades, que se ajustam perfeitamente uma com a
outra sao iguais.
XIX. O todo e maior do que qualquer das suas partes.
X. Duas linhas retas nao compreendem um espaco (uma superfcie).
Por ultimo, sao apresentados os postulados.
70 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
POSTULADOS
I. Pede-se que se desenhe uma reta de um ponto qualquer ate outro
ponto qualquer.
II. E que se produza uma linha reta finita continuamente em uma
linha reta.
III. E que com qualquer centro e qualquer distancia se descreva um
crculo.
IV. E que todos os angulos retos sejam iguais.
V. E que, se uma linha reta cortando duas linhas retas torna os angulos
interiores
do mesmo lado menores que dois retos, as linhas retas, se continua-
das indefinidamente, se encontrem deste lado no qual os angulos sao
menores que dois retos.
Atualmente, a distincao dos primeiros princpios entre definicoes, postula-
dos e axiomas nao e utilizada, mas e imprescindvel lembrar que a Matematica
se faz sempre a partir de primeiros princpios, admitidos como validos sem
demonstracao. Todas as proposicoes contidas nos Elementos de Euclides sao
consequencia da aplicacao do metodo axiomatico aos primeiros princpios.
2.3.1 Equivalencia de areas nos Livros I e II
As proposicoes nos Elementos sao divididas em problemas e teoremas. Os
primeiros lidam com construcoes e transformacoes dos seres geometricos:
construir figuras, secciona-las, subtra-las ou adiciona-las umas `as outras.
Ja os teoremas enunciam e demonstram propriedades inerentes aos seres
geometricos.
A primeira proposicao que decorre dos axiomas e um problema 13:
Proposicao I.1 Sobre uma determinada reta construir um triangulo equila-
tero
13A notacao I.4, por exemplo, designa a Proposicao 4 do livro I dos Elementos.
2.3. OS ELEMENTOS DE EUCLIDES 71
Figura 2.12
Construcao: Seja a linha reta AB de um comprimento dado. Com o
centro A e com a distancia AB descrevemos o crculo BCD (Postulado III);
e com o centro B e a distancia BA descrevemos o circulo ACE. Do ponto C,
no qual os crculos se cortam reciprocamente, tracamos (Postulado I) pelos
pontos A e B as retas CA e CB. Podemos afirmar que o triangulo ABC sera
equilatero, pois, sendo o ponto A o centro do crculo BCD,14 AC e igual a
AB (Definicao XV) e, sendo o ponto B o centro do crculo CAE, BC e igual
a BA. Lembrando que CA e igual a AB, temos que tanto CA como CB sao
iguais a AB. Mas as coisas que sao iguais a uma terceira sao iguais entre si
Axioma I. Sendo assim, CA e igual a CB e as tres retas CA, AB e BC sao
iguais, logo o triangulo ABC construdo sobre a reta AB e equilatero, como
queramos fazer.
Vemos que esta proposicao e, na verdade, um problema de construcao
que faz uso dos primeiros princpios: definicoes, postulados e axiomas. Sua
prova e frequentemente citada como exemplo de demonstracao em que e
usado um resultado nao includo no enunciado enunciado ou garantidas pelos
axiomas e postulados. Mais precisamente, Euclides usa o fato de que as duas
circunferencias tem um ponto em comum.
As tentativas de construir um conjunto de axiomas completo 15 para a
geometria plana foram coroadas de sucesso em 1899 por David Hilbert, em
seu livro fundamental Fundamentos da Geometria, no qual apresentou um sis-
tema de 21 axiomas para a geometria euclidiana plana, mais tarde reduzidos
a 20.
Nos Elementos de Euclides, o primeiro teorema aparece na quarta propo-
14Chamamos assim porque um crculo e determinado por tres pontos.
15Um conjunto de axiomas para uma teoria matematica e completo se todos os teoremas da
teoria puderem ser deduzidos a partir dos axiomas. Os axiomas do conjunto sao independentes
se nenhum deles puder ser deduzido, como teorema, a partir dos outros. E e consistente se
nele nao houver axiomas contraditorios.
72 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
sicao:
Proposicao I.4 Se dois triangulos tiverem respectivamente dois lados iguais
a dois lados e se os angulos compreendidos por estes lados forem tambem iguais,
as bases serao iguais, os triangulos serao iguais e os demais angulos que sao
opostos a lados iguais, serao tambem iguais
Figura 2.13
Ao passo que a solucao de um problema consiste em algo que precisa ser
feito, ou construdo, um teorema precisa ser demonstrado. E interessante
notar que a demonstracao da proposicao acima emprega um procedimento
de superposicao. Dada a igualdade entre, por um lado, AB e DE e, por
outro, AC e DF , bem como a igualdade entre BAC e EDF , Euclides coloca
o triangulo ABC sobre DEF e conclui da a coincidencia entre AC e DF .
Para os nossos padroes, este metodo nao e valido.16 Mas ainda que se diga
que Euclides evitava pensar em termos de movimento, nao ha evidencias de
que ele tenha achado este procedimento problematico.
Uma parte importante do Livro I e a teoria das paralelas de Euclides.
Ha evidencias de que, a teoria das paralelas era muito discutida antes de
Euclides. Por exemplo, Aristoteles comenta que esta teoria continha um
problema de raciocnio circular. 17 Euclides teria percebido a necessidade
de introduzir um postulado na teoria das paralelas e apresentar um postulado
eficiente que lhe permitiu organizar a teoria de maneira economica e elegante,
nas proposicoes 27 a 32 dos Elementos. Uma grande vantagem da formulacao
dada por ele e que ela fornece um criterio para determinar se duas linhas
retas se encontrarao ou nao quando forem prolongadas.
Um dos objetivos mais importantes dos primeiros livros dos Elementos
e realizar operacoes com areas, problema que passaremos a descrever em
seguida.
16Isto levou Hilbert a introduzir um novo axioma, que consiste em uma versao mais fraca
da proposicao I.4.
17Analtica ant. II.16, 65a4.
2.3. OS ELEMENTOS DE EUCLIDES 73
Raciocnios baseados em transformacoes de figuras planas, mantendo suas
areas, ja eram usados, como vimos, pelos babilonios, para resolver problemas
que hoje chamaramos de 2o. grau, ou seja, problemas que se reduzem a
equacoes do 2o. grau. Nao sabemos se ha influencia destes procedimentos
na Matematica grega, mas ha diversos resultados nos Elementos que teriam
por objetivo sistematizar procedimentos relativos `a equivalencia de areas.
Embora estes desenvolvimentos sejam bastante anteriores a Euclides, nos os
apresentaremos aqui na forma como se encontram nos Elementos.
Na Matematica grega classica, como exposta nos Elementos, nao se me-
dem areas da maneira como fazemos hoje. Nao se encontra, nos Elementos,
nenhum resultado do tipo a area de um triangulo e um meio do comprimento
da base vezes o comprimento da altura. Certamente, na pratica, agrimen-
sores, arquitetos, agricultores, cobradores de impostos, etc, sabiam calcular
areas, mas isso nao acontecia na Matematica pura dos gregos. Como pro-
cediam para lidar com comprimentos, ou, mais geralmente, com grandezas?
Eles as comparavam.
Por exemplo, dadas duas regioes planas S1 e S2, elas sao transformadas
em quadrados equivalentes Q1 e Q2, respectivamente. E entao facil saber se
as areas dessas regioes sao iguais, ou qual e a que tem menor area, ou se a
area de uma delas e multipla da area da outra.
Este processo de transformar uma regiao poligonal em um quadrado equi-
valente denomina-se fazer a quadratura da regiao. Da vem a expressao
fazer a quadratura do crculo, que significa construir um quadrado com
area igual `a do crculo dado.
Mostraremos a seguir como e possvel, somente com regua e compasso,
efetuar a quadratura de qualquer superfcie poligonal dada. Euclides faz isso
nos Livros I e II, antes de ter `a sua disposicao a teoria das proporcoes de
Eudoxo, exposta somente no Livro V dos Elementos. Assim, em todas as
construcoes que faremos a seguir, nao sao utilizados argumentos baseados
em proporcoes.
O ponto de partida de Euclides sao os criterios de congruencia de tri-
angulos (Proposicoes I.4, I.8, I.26), que omitiremos, para nao prolongarmos
demasiadamente esta exposicao. Em seguida, Euclides demonstra o seguinte
resultado importante, que tambem nao demonstraremos:
Proposicao I.34: Em um paralelogramo, os lados e os angulos opostos sao
iguais e o paralelogramo e dividido pela diagonal em duas partes iguais.
Apos isso, na linha de nosso objetivo, Euclides demonstra que
Proposicao I.35: Paralelogramos que estao postos sobre a mesma base e
entre as mesmas paralelas, sao iguais.
74 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Como provaramos este teorema hoje? Os paralelogramos tem a mesma
base e alturas iguais, logo, como a area de um paralelogramo e igual ao
comprimento da base vezes o comprimento da altura, o resultado segue-se
imediatamente. A fim de mostrar como os matematicos gregos trabalhavam,
demonstraremos a proposicao da maneira exposta nos Elementos.
Ha tres casos a considerar mas, como usual, Euclides demonstra somente
um caso, deixando os outros a cargo do leitor. Aqui, apresentaremos somente
o primeiro caso. Forneceremos esta demonstracao por ser um exemplo tpico
dos raciocnios sobre equivalencia de areas.
Figura 2.14 Elementos I.35
Sejam os paralelogramos ABCD e EF CB sobre a mesma base BC, en-
tre as mesmas paralelas AF , BC (Figura 2.14). Digo que o paralelogramo
ABCD e igual ao paralelogramo EBCF .
No paralelogramo ABCD a reta AD e igual `a reta BC, e no paralelogramo
EBCF a reta EF e igual `a reta BC. Logo sera AD igual a EF . Ajunte-se a
ambas a mesma reta DE. Sera entao AE = DF , isto e, o todo igual ao todo.
Mas a reta AB e igual `a reta DC. Logo as duas retas EA, AB sao iguais `as
duas retas F D, DC, cada uma a cada uma. Mas o angulo externo F DC e
igual ao interno EAB. Sera entao o triangulo EAB igual ao triangulo F DC.
Do trapezio ABCF tire-se o triangulo F DC; e do mesmo trapezio tire-se o
triangulo EAB. Logo os paralelogramos ABCD, EBCF , que sao os restos,
serao iguais entre si.
De posse deste resultado, e facil provar que
Proposicao I.36: Paralelogramos que tem bases iguais e situados entre
paralelas sao iguais.
Consequencias imediatas desses resultados sao as duas proposicoes se-
guintes:
Proposicao I-37: Triangulos situados sobre a mesma base e entre as mesmas
paralelas sao iguais entre si.
Proposicao I-38: Triangulos que tem bases iguais e estao entre as mesmas
paralelas sao iguais entre si.
Reunindo estes resultados, podemos resolver o seguinte problema:
2.3. OS ELEMENTOS DE EUCLIDES 75
Dado um triangulo, construir um retangulo com a mesma area.
Isso pode ser feito seguindo o roteiro abaixo.
1. Dado um triangulo ABC, complete-o para obter um para-
lelogramo ABCD cuja area e igual a duas vezes a area do
triangulo.
2. Construa um retangulo F GHK equivalente ao paralelogramo
obtido no item anterior.
3. Usando o retangulo F GHK, construa um retangulo equiva-
lente ao triangulo ABC.
E como construir um retangulo equivalente a uma regiao plana poligonal?
Basta dividir esta regiao poligonal em triangulos e, depois de transformar
cada um em um retangulo, somar os retangulos. Precisamos, portanto, de um
procedimento para somar retangulos. Para isto, transforma-se os retangulos
em quadrados e soma-se os quadrados por meio do teorema  de Pitagoras.
Tal e a importancia deste resultado para a geometria grega. Veremos como
ele e demonstrado no final do Livro I, antes de exibirmos como transformar
um retangulo em uma quadrado (o que so sera feito por Euclides no Livro
II).
Um dos mais importantes teoremas da geometria euclidiana, o teorema
de Pitagoras, diz respeito justamente ao modo como os gregos, nesta epoca,
faziam operacoes com areas, tema desta secao.
Proposicao I.47: Em um triangulo retangulo, o quadrado sobre o lado
oposto ao angulo reto e igual `a soma dos quadrados sobre os lados que formam
o mesmo angulo reto.
Demonstracao: Seja o triangulo retangulo ABC (Figura 2.15), cujo
angulo reto e BAC. Digo que o quadrado sobre o lado BC e igual aos
quadrados sobre os lados BA, AC, que formam o angulo reto BAC.
Com efeito, construa sobre BC o quadrado BDEC, e sobre BA, AC,
os quadrados de lados AB e AC respectivamente. Pelo ponto A trace AL,
paralela a BD ou CE e trace tambem as retas AD, F C.
Entao, como os angulos BAC, BAG sao retos, segue-se que as duas retas
AC, AG, que nao estao no mesmo lado da reta AB, formam com AB, em
A, angulos adjacentes iguais a dois angulos retos; portanto CA esta em linha
reta com AG.
Pela mesma razao BA esta em linha reta com AH.
76 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Figura 2.15 Elementos I.47  O teorema de Pitagoras
Os angulos DBC, F BA, por serem retos, sao iguais. Adicione a cada um
o mesmo angulo ABC; logo, o total DBA sera igual ao total F BC.
E como DB e igual a BC, e F B a BA, os dois lados AB, BD sao iguais
aos dois lados F B, BC respectivamente, e o o angulo DBA e igual ao angulo
F BC; portanto a base AD e igual `a base F C, e o triangulo ABD e igual ao
triangulo F BC.
Ora, o paralelogramo de lados BD e DL e o dobro do triangulo ABD,
porque tem a mesma base BD, e estao entre as mesmas paralelas BD, AL.
E e o quadrado de lado BA e o dobro do triangulo F BC, porque tem a
base comum F B, e estao entre as mesmas paralelas F B, GC.
Mas os dobros de quantidades iguais sao iguais.
Logo, o paralelogramo de lados BD e DL e tambem igual ao quadrado
de lado AB. Do mesmo modo, tracadas as retas AE, BK se demonstra que
o paralelogramo de lados EC e EL e igual ao quadrado de lado AC; logo, o
quadrado inteiro BDEC, de lado BC oposto ao angulo reto BAC, e igual
aos dois quadrados de lados AB e AC, de lados BA, AC, que fazem o mesmo
angulo reto BAC. 
Observe que nesta demonstracao nao se usa proporcionalidade. Todos os
passos sao dados utilizando equivalencia de areas. As demonstracoes que se
encontram atualmente, baseadas em semelhanca e nas propriedades metricas
em um triangulo retangulo, transformam o teorema de Pitagoras em um
simples fato algebrico,a2 = b2 + c2, escondendo inteiramente seu carater
geometrico e que ele e um resultado de equivalencia de areas.
Esta demonstracao e estatica, mas seria facil conjecturar como Euclides
2.3. OS ELEMENTOS DE EUCLIDES 77
a descobriu. Ele poderia ter formalizado cuidadosamente um raciocnio do
seguinte tipo:
Deslocando-se o ponto B sobre a reta BH, paralela a CK, vemos que o
triangulo BCK e igual, no sentido grego, ao triangulo CKH (que nao esta
mostrado na figura), o qual por sua vez e metade do quadrado ACKH.
Agora, girando o triangulo BCK em torno do ponto C, ate que CB
coincida com CE, obtemos o triangulo AEC, igual a BCK. Deslocando em
seguida o ponto A sobre a reta AL, ate chegar ao ponto de intersecao de
AL com BC, obtenho um triangulo cuja area e metade do retangulo LC.
Procedendo semelhantemente com o triangulo F BC chega-se `a conclusao
desejada.
Continuando em direcao ao nosso objetivo, que e mostrar como fazer a
quadratura de qualquer regiao poligonal, mostraremos agora como transfor-
mar um retangulo em um quadrado com mesma area. Para isso necessita-
mos de outro resultado dos Elementos, cuja importancia vai muito alem da
aplicacao que aqui faremos do mesmo.
Proposicao II.5: Se uma linha reta for dividida em duas partes iguais,
e em outras duas desiguais, o retangulo compreendido pelas partes desiguais,
juntamente com o quadrado da parte entre as duas secoes, sera igual ao quadrado
da metade da linha proposta.
Figura 2.16 Elementos II.5
Ou seja, se RET AD, DB , QUADCD e QUADCB designam, respectiva-
mente, o retangulo com lados AD e DB, o quadrado de lado CD e o o
quadrado de lado CD, entao
RET AD, DB + QUADCD = QUADCB .
Necessitamos de um ultimo resultado para podermos fazer fazer a qua-
dratura de qualquer polgono, ou seja, construir um quadrado de area igual
`a area do polgono dado.
Proposicao II.14 Construir um quadrado igual a um retangulo dado.
78 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Figura 2.17 Elementos II.14
Os resultados acima permitem fazer a quadratura de qualquer regiao po-
ligonal.
A algebra geometrica GREGA
A designacao algebra geometrica foi criada por Paul Tannery e Zeuthen,
no fim do seculo XIX (Veja, por exemplo [152]). Difundiu-se muito devido `a
adesao de Heath, em sua influente traducao de Heiberg (Ver [76], [77], [78])
e tambem em sua historia da Matematica grega ([79], [80]). Ela foi adotada
e difundida tambem por van der Waerden ([146]). Recentemente, principal-
mente devido aos trabalhos de Unguru, 18 ele vem caindo em descredito. 19
Para os defensores da algebra geometrica, os gregos assimilaram os
conhecimentos algebricos dos babilonios e os transformaram, principalmente
nos Elementos de Euclides, em resultados que sao simples traducao, para a
linguagem geometrica, de fatos algebricos. 20 Uma interpretacao alternativa
a essa foi proposta por Fowler ([63]).
O Livro II tem sido motivo de controversias entre os historiadores. Boa
parte de seus resultados tem sido interpretados, pelos que acreditam em uma
algebra geometrica grega como simples expressoes geometricas de resulta-
dos algebricos. Tomemos como exemplo, a proposicao II.1, cujo enunciado
e:
Proposicao II.1: Se tivermos duas retas e uma delas e dividida em um
numero qualquer de partes, o retangulo formado pelas duas retas e igual aos
retangulos formados pela reta que nao foi dividida por cada um dos segmentos.
(Figura 2.18).
18Veja [65] para uma discussao ampla do assunto. Um texto acessvel e resumido sobre o
assunto e Schubring [135].
19Um tratamento equilibrado da controversia sobre a algebra geometrica pode ser encontrado
na traducao dos Elementos por Vitrac [52], pp. 366-376.
20A tentativa de algebrizar a Matematica grega nao se limita aos Elementos. Zeuthen
([152]), por exemplo, fez o mesmo com Apolonio.
2.3. OS ELEMENTOS DE EUCLIDES 79
Os defensores desta interpretacao algebrica dos Elementos afirmam que
este resultado e uma versao geometrica do seguinte resultado algebrico.
Se fizermos AE = HC = GD = F B = a, e AC = b, CD = c, DB = d, entao,
a proposicao afirma simplesmente que a(b + c + d) = ab + ac + ad.
Figura 2.18
A controversia sobre a algebra geometrica e particularmente ilustrativa no
caso das proposicoes II.5 e II.6. Para os que algebrizam a Matematica grega,
elas mostram simplesmente como os gregos sabiam resolver geometricamente
equacoes do segundo grau que os babilonios resolviam algebricamente.
Figura 2.19 Proposicao II.5
Figura 2.20 Proposicao II.6
No entanto, os oponentes dessa visao algebrizante da Matematica grega
apontam a importancia de II.5 e II.6 em varias construcoes geometricas,
nao somente nos Elementos, como tambem apresentam o seguinte argumento
contra a interpretacao algebrica dessas duas importantes proposicoes dos
Elementos. Na figura relativa a II.5, faca x = CB = AC, y = CD. Entao,
AD = x + y e DB = x  y. Assim, algebricamente, a proposicao exprime
simplesmente que
80 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
(x + y)(x  y) + y2 = x2  (x + y)(x  y) = x2  y2.
Agora, na Figura relativa a II.6, faca x = CD, y = AC = CB. Entao,
((x + y)(x  y) + y2 = x2  (x + y)(x  y) = x2  y2.
Ora, os oponentes da teoria da existencia de uma algebra geometrica
grega perguntam: por que Euclides, tao cioso da forma de seus Elementos,
usa duas proposicoes para provar o mesmo fato? Esse e um argumento de
peso contra a teoria da algebra geometrica grega. E mais, esses mesmos
oponentes apontam as inumeras aplicacoes dessas proposicoes nos Elementos
no contexto da propria geometria, como, por exemplo, a equivalencia de
areas.
2.3.2 O Livro V  Uma nova teoria das razoes e proporcoes
Antes de expormos a teoria das proporcoes, atribuda a Eudoxo e inserida no
Livro V dos Elementos de Euclides, gostaramos de tecer alguns comentarios
sobre a nocao de razao apresentada por Euclides, que nao e organizada de
modo cronologico. Acredita-se que os livros VII a IX  os livros aritmeticos
dos Elementos, atribudos aos pitagoricos  sejam os mais antigos. Como Fo-
wler observa, os livros I a IV nao usam nenhuma ideia de proporcao, ou seja,
nao empregam a versao de igualdade de razoes. Isto poderia ser um indcio
de que eles teriam sido escritos depois da descoberta dos incomensuraveis.
Veremos mais adiante, na secao dedicada `a teoria euclidiana dos numeros,
que o criterio para a proporcionalidade de dois numeros e dado pela definicao
VII.20: Numeros sao proporcionais quando o primeiro e o mesmo multiplo, ou
a mesma parte, ou as mesmas partes, do segundo que o terceiro e do quarto.
A proposicao VII.19 afirma explicitamente, sem empregar nossa nota-
cao simbolica, a condicao moderna de que a relacao de proporcionalidade
a  b  c  d e equivalente `a igualdade a  d = b  c.
Na proposicao 16 do livro VI e dado um criterio para a proporcionalidade
de quatro segmentos de reta: Se quatro retas sao proporcionais, o retangulo
formado pelos extremos e igual ao retangulo formado pelos meios (e reciproca-
mente).
A partir destes enunciados, poderamos deduzir que a nocao de propor-
cionalidade apresentada nos Elementos e equivalente `a nossa. Mas qual a
motivacao das definicoes complexas que aparecem no livro V, de que trata-
remos aqui?
No caso comensuravel, as diferentes definicoes de proporcao, para gran-
dezas e numeros, serao reconciliadas pela proposicao 5 do livro X: Grandezas
2.3. OS ELEMENTOS DE EUCLIDES 81
comensuraveis tem uma para a outra a razao a qual um numero tem para um
outro numero. Mas no caso incomensuravel, as definicoes de proporcao pela
igualdade de razoes nao serao mais aceitaveis como definicoes e passarao a
ser validas apenas para o caso particular de grandezas comensuraveis.
Como dissemos, a consequencia mais importante da descoberta da in-
comensurabilidade e o fato de ter produzido um divorcio entre o universo
das grandezas e o universo dos numeros. Logo, a possibilidade de existirem
grandezas incomensuraveis tornou necessaria uma nova teoria das razoes e
proporcoes e um novo conceito de proporcionalidade independente da igual-
dade entre numeros. Alguns pesquisadores, como Fowler (Ver [64]), afirmam
que o livro V dos Elementos trata de resultados mais recentes do que os ou-
tros, contendo definicoes de razoes e proporcoes validas para todos os casos,
que evitam a identificacao de grandezas com numeros.
A teoria das proporcoes entre quatro grandezas apresentada aqui e atri-
buda ao matematico grego Eudoxo, discpulo de Platao, nascido em torno
do ano 400 a.E.C. Esta teoria abstrata das razoes e proporcoes servira para
o estudo das proposicoes geometricas do livro VI.
Os enunciados do livro V nao atribuem nenhum significado `as razoes a  b
e c  d separadamente, mas apenas ao fato de elas estarem em uma relacao
de proporcionalidade a  b  c  d.21 Logo no incio deste livro encontramos as
seguintes definicoes:
Definicao V.3 Uma razao e um tipo de relacao que diz respeito ao tamanho
de duas grandezas do mesmo tipo.
Definicao V.4 Diz-se que duas grandezas possuem uma razao entre elas
se estas grandezas, quando multiplicadas, podem se ultrapassar mutuamente.
Definicao V.5 Diz-se que grandezas estao na mesma razao, a primeira
para a segunda e a terceira para a quarta, quando, se quaisquer equimultiplos da
primeira e da terceira, e outros quaisquer equimultiplos da segunda e da quarta,
sao tais que os primeiros equimultiplos ultrapassam, um a um, os segundos, ou
sao iguais a estes, ou sao menores, que os ultimos equimultiplos considerados na
ordem correspondente aos primeiros.
Definicao V.6 Grandezas que possuem a mesma razao sao chamadas pro-
porcionais.
A definicao 3 deixa claro que o conceito de razao e aplicado a grandezas
homogeneas. Ou seja, importa observar a natureza da grandeza, nao podendo
haver razao entre um comprimento e uma area. Ainda que a razao diga
respeito `a quantidade, ela nao sera sempre calculavel como um numero. A
definicao 4 fornece um criterio operatorio para determinar se duas grandezas
possuem uma razao entre elas: para que duas grandezas a e b possuam uma
21Le-se a esta para b assim como c esta para d.
82 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
razao entre elas, e preciso que haja ao menos um par de inteiros m e n tal
que ma>b e nb>a.
A definicao 5 fornece justamente o criterio de comparacao de duas razoes
de grandezas. Em nossa linguagem simbolica atual, ela pode ser escrita como
segue
Sejam a, b, c e d grandezas homogeneas. Dizemos que elas sao
proporcionais se e somente se, para todo par de inteiros positivos
m e n, temos um dos casos abaixo:
(i) se ma < nb entao mc < nd.
(ii) se ma = nb entao mc = nd.
(iii) se ma > nb entao mc > nd.
O segundo caso so e possvel se a e b, por um lado, e c e d, por outro, forem
comensuraveis. Como a razao entre duas grandezas incomensuraveis nao
podia ser associada `a razao de suas medidas, Eudoxo introduziu a nocao de
razao de grandezas, na qual o conceito de razao tem uma natureza puramente
geometrica. Uma razao entre grandezas nao e identica a uma razao entre
numeros, ainda que a primeira inclua a segunda como caso particular (quando
as grandezas forem comensuraveis).
Observe que nao podemos escrever
a
b = c
d  ad = bc,
pois a, b, c, d sao grandezas, e nao existe divisao e multiplicacao de grandezas.
No caso comensuravel, podemos comparar a definicao 5 com um exemplo
numerico: mostrar que 6 esta para 10 assim como 9 esta para 15. Observamos
que 2 esta contido tres vezes em 6 e cinco vezes em 10 e 3 esta contido tres
vezes em 9 e cinco vezes em 15, logo os numeros 6, 10, 9 e 15 sao proporcionais,
logo temos o resultado que queremos. Isto porque, para todo m e n, 6m = 10n
implica que 9m = 15n, basta fazer 3m = 5n. Logo, (ii) valera para quaisquer
m, n inteiros positivos.
A proporcionalidade de quatro grandezas comensuraveis duas a duas e
estabelecida de modo analogo. Vejamos o exemplo da proposicao 1 do livro
VI.
Proposicao VI.1 - Triangulos (e paralelogramos) de mesma altura estao
entre eles como as suas bases.
Considere a Figura 2.21. Queremos comparar as areas dos triangulos
ABC e ADE. Se existe uma unidade de medida comum contida p vezes em
um segmento BC e q vezes em um segmento DE, ou seja se pBC = qDE,
2.3. OS ELEMENTOS DE EUCLIDES 83
e se sabemos que triangulos de mesma altura que possuem bases iguais sao
iguais, conclui-se facilmente que, na figura, q vezes a area do triangulo ADE
e igual a p vezes a area do triangulo ABC. Sendo assim, tomando m e n
inteiros positivos tais que qm = pn temos, pela igualdade (ii), que ABC esta
para ADE assim como BC esta para DE. A partir de um raciocnio deste
tipo, quando as bases sao comensuraveis, podemos demonstrar este teorema.
Mas e se as bases nao sao comensuraveis? Neste caso o item (ii) acima
nao seria valido e devemos utilizar o metodo de Eudoxo (contido nos itens (i)
e (iii) da definicao 5). Se queremos comparar as areas dos triangulos ABC e
ADE, podemos usar o seguinte raciocnio:
Figura 2.21
Construmos, `a esquerda de BC, m1 segmentos BiBi1 iguais a BC, que
juntamente com BC perfazem m segmentos. `A direita de DE, construmos
n1 segmentos Ej Ej+1 iguais a DE. Fazemos, em seguida, com que cada um
destes segmentos seja a base de um triangulo com a mesma altura de ABC
e ADE. Por construcao, temos que BmC = mBC e DEn = nDE. Alem
disso, como as alturas de todos os triangulos sao iguais, ABmC = mABC
e ADEn = nADE. Nao sabemos se BmC > DEn ou se BmC < DEn. O
que importa nesta definicao e podermos verificar que, para qualquer par de
inteiros positivos m e n temos:
BmC = mBC > DEn = nDE  ABmC = mABC > ADEn = nADE.
BmC = mBC < DEn = nDE  ABmC = mABC < ADEn = nADE.
Portanto, pela definicao 5,
BC
DE = ABC
ADE .

Note que, uma vez que BC e DE sao incomensuraveis, sua razao nao se
identifica `a razao de suas medidas, logo as razoes acima nao sao numeros e
a igualdade destas razoes nao e uma igualdade entre numeros.
84 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
2.3.3 Teoria dos numeros  Livros VII, VIII e IX
Nos Elementos de Euclides, o tratamento dos numeros (arithmos) e sepa-
rado do tratamento das grandezas (megethos). Tanto as grandezas quanto os
numeros sao simbolizados por segmentos de reta. No entanto, os numeros sao
agrupamentos de unidades que nao sao divisveis e as grandezas geometricas
sao divisveis em partes da mesma natureza (uma linha e dividida em linhas,
uma superfcie em superfcies, etc.). A medida esta presente nos dois ca-
sos, dos numeros e das grandezas, mas mesmo quando uma proposicao sobre
medidas possui enunciados semelhantes para numeros e grandezas, ela e de-
monstrada de maneiras diferentes nestes dois casos. As primeiras definicoes
do livro VII apresentam a nocao de numero e o papel da medida:
Definicao VII.1 A unidade e aquilo segundo o que cada uma das
coisas existentes e dita uma.
Definicao VII.2 O numero e uma multiplicidade composta de uni-
dades.
Definicao VII.3 Um numero e uma parte de um numero, o menor
do maior, quando ele mede o maior.
Os numeros servem para contar, mas antes de contar e preciso saber
qual a unidade de contagem. No caso das grandezas, a unidade de medida
deve ser tambem uma grandeza mas, neste caso, a unidade nao e numero
nem grandeza. A unidade, na definicao de Euclides, e o que possibilita a
medida, mas nao e um numero. Sendo assim, e inconcebvel que a unidade
possa ser subdividida. Este ponto de vista, que afirmamos ser o de Euclides,
foi explicitado por Aristoteles:
O Uno nao tem outro carater do que servir de medida a al-
guma multiplicidade, e o numero nao tem outro carater do que
o de ser uma multiplicidade medida e uma multiplicidade de me-
didas. e tambem com razao que o Uno nao e considerado um
numero, pois a unidade de medida nao e uma pluralidade de me-
didas. (Metafsica, N I 1088a).
Vemos assim que o Um nao e considerado um numero.
As tecnicas de medida que ocupam um lugar preponderante nas praticas
euclidianas sobre os numeros eram realizadas pelo metodo da antifairese,
que no caso dos numeros e conhecido hoje como algoritmo de Euclides.
Veremos como este metodo era utilizado para encontrar a medida comum de
dois numeros (ou seja, o mdc entre eles):
2.3. OS ELEMENTOS DE EUCLIDES 85
Proposicao VII.1 Dois numeros desiguais estando dados, o menor sendo, a
cada vez, continuamente retirado do maior, se o numero que resta nunca mede
o que o precede ate que se chegue `a unidade, entao dizemos que os numeros de
origem sao primos entre si.
Proposicao VII.2 Encontrar a maior medida comum entre dois numeros
que nao sao primos entre si.
Na verdade, o enunciado desta proposicao emprega uma linguagem de
grandezas. Os dois numeros dados sao segmentos A e B dos quais queremos
encontrar a maior medida comum. Se B nao mede A, entao, quando o menor
dos numeros A e B e retirado continuamente do maior, sobra algum numero
que mede o precedente. Construmos geometricamente as diferencas entre
restos sucessivos, por exemplo das grandezas A e B mostradas na Figura
2.22. Retiramos duas vezes B de A, obtendo R1. Em seguida, retiramos
uma vez o resto R1 de B obtendo R2. E depois, tres vezes R2 de R1, e assim
por diante. . .
Figura 2.22
Esta antifairese equivale a fazer A = n0B + R1, em seguida B = n1R1 + R2,
depois R1 = n2R2 + R3 e assim por diante. O procedimento pode dar 0,
ou seja, pode chegar ao fim, ou nao. Se os dois numeros nao sao primos
entre si, o mesmo procedimento dara um resto, diferente da unidade, que
mede o precedente (logo, se retiramos este resto do numero precedente um
certo numero de vezes, obtemos zero). Este resto e a maior medida (divisor)
comum entre os dois numeros. Um numero e primo quando nao e medido
por nenhum numero, somente por 1, que nao e considerado um numero.
Exemplo 2.1. Encontre, por este metodo, o mdc de 119 e 85.
Comeco por retirar 85 uma vez de 119, obtendo R1 = 34 como resto. Em
seguida retiro 34 duas vezes de 85, obtendo o segundo resto R2 = 17. Agora
retiro 17 duas vezes de 34 obtendo 0. Logo 17 e o maior divisor de 119 e 85.
Podemos exibir o processo da seguinte maneira
(119, 85)  (34, 85)  (34, 51) 
 (17, 34)  (17, 17)  (17, 0).
86 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Note que, se os dois numeros fossem relativamente primos, este procedi-
mento chegaria ao par (1, 0). Ou seja, a medida comum dos dois numeros
seria 1, a unidade, que nao era um numero para Euclides.
No caso de dois segmentos, se um resto mede o precedente, o algoritmo
termina e obtemos o mdc de dois segmentos. Este caso e enunciado pela
proposicao 3 do livro X que e equivalente `a proposicao VII-2. Esta proposicao
X-3 pode ser vista como uma versao da proposicao VII-2 para grandezas,
em que pedimos para, dadas duas grandezas comensuraveis, encontrar sua
maior medida comum. Portanto, podemos concluir que o caso de grandezas
comensuraveis e analogo ao dos numeros que nao sao primos entre si, pois
podemos obter uma maior medida comum.
No entanto, no caso de grandezas, nao existe uma grandeza menor do
que todas as outras e pode ser que o algoritmo de Euclides nao termine
(note que o fato de afirmarmos que nao existe uma grandeza menor do que
todas as outras e equivalente a assumir o argumento de que as grandezas sao
infinitamente subdivisveis).
Quando o algoritmo nao termina, as grandezas sao incomensuraveis, caso
que sera tratado na proposicao X.2 dos Elementos de Euclides:
Proposicao X.2 Se, quando a menor de duas grandezas e continuamente
subtrada da maior, a que resta nunca mede a precedente, as grandezas sao
incomensuraveis.
Alguns autores afirmam que o objetivo do livro X seria distinguir numeros
que tem uma boa antifairese dos que tem uma ma antifairese, ou seja, identi-
ficar quando o procedimento termina. Mas, no caso de grandezas, como saber
antecipadamente que o algoritmo nao termina, antes de realizar o numero
infinito de passos necessarios `a verificacao deste fato?
Vimos um exemplo de como proceder na demonstracao geometrica da
incomensurabilidade entre a diagonal e o lado de um quadrado, na qual ob-
servamos a repeticao da mesma situacao que se repetira tantas vezes quanto
queiramos. E exatamente o procedimento geometrico da antifairese que foi
usado nesta demonstracao. Deste modo, podemos concluir se duas grande-
zas sao comensuraveis ou incomensuraveis apenas de modo geometrico, sem
precisar recorrer aos numeros e ja vimos o papel que esta conclusao exerce
sobre a concepcao grega da geometria. Para assegurar a autonomia das gran-
dezas frente aos numeros, e necessario conceber uma teoria das proporcoes
que dispense o recurso ao numero, que e o papel da teoria de Eudoxo.
Muitas outras proposicoes do livro VII, envolvendo a antifairese, possuem
correspondentes no livro X, que trata das grandezas incomensuraveis. Pode-
mos observar, por meio destas proposicoes, o paralelismo entre numeros que
nao sao primos entre si e grandezas comensuraveis, e consequentemente entre
2.3. OS ELEMENTOS DE EUCLIDES 87
numeros primos entre si e grandezas incomensuraveis. Podemos mencionar,
por exemplo, a proposicao X-2, versao para grandezas da proposicao VII-1
citada anteriormente.
Entre os resultados importantes dos livros aritmeticos devemos citar as
proposicoes VII.31 e VII.32. A primeira prova que qualquer numero nao
primo tem um fator primo:
Proposicao VII.31. Todo numero composto e medido por algum numero
primo.
A segunda e uma consequencia facil da primeira:
Proposicao VII.32: Qualquer numero e primo ou e medido por algum numero
primo.
O Livro VIII trata dos numeros em proporcao continuada, ou seja, em lin-
guagem moderna, numeros em progressao geometrica. Entre as proposicoes
do Livro IX encontra-se o importante resultado de que ha infinitos numeros
primos, notavel pela simplicidade de sua demonstracao:
Proposicao IX.20. Os numeros primos sao mais numerosos do que qual-
quer multidao de numeros primos proposta.
Euclides supoe que existe um numero finito de numeros primos, p1, p2,
. . . , pk e forma o numero n = p12  . . . k +1, que e diferente de todos os primos
dados e e primo, o que e uma contradicao.
O ultimo resultado do Livro IX, a proposicao 36, da um metodo para
construir numeros perfeitos, aqueles que sao iguais `a soma de seus divisores
proprios. Por exemplo, 6 e um numero perfeito, pois 6 = 1 + 2 + 3. Ou seja,
aqueles que sao iguais `a soma de seus divisores proprios. Por exemplo, 6 e
um numero perfeito, pois 6 = 1 + 2 + 3. Euclides mostra que se a soma
1 + 2 + 22 +  + 2n = p
for um numero primo, entao, 2np e um numero perfeito.
2.3.4 Livro XII  Areas e volumes. O metodo de exaustao
de Eudoxo
Neste livro, Euclides estuda piramides, cilindros, cones e esferas. Para isso,
ele comeca por demonstrar que dois crculos estao entre si como os quadrados
de seus diametros, na proposicao XII.2, usando o metodo da exaustao de
Eudoxo.
Um passo essencial para isso e um resultado do Livro X, a proposicao
X.I, geralmente conhecida como Lema de Euclides.
88 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Lema de Euclides:(Proposicao X.1) Sejam a e b duas grandezas de
mesma especie (isto e, por exemplo, dois comprimentos, ou duas areas, ou
dois volumes). Se de a tirarmos uma parte maior do que ou igual a sua
metade, do restante tirarmos uma parte maior ou igual `a metade do restante,
e assim sucessivamente, entao, apos um certo numero de repeticoes desse
processo, obteremos uma grandeza menor do que b.
Sejam AB = a e b grandezas da mesma especie, com a > b.
Euclides prova que se de a tirarmos uma parte maior ou igual a sua
metade, do restante tirarmos uma parte maior ou igual `a metade do restante,
e assim sucessivamente, entao, apos um certo numero de repeticoes desse
processo, obteremos uma grandeza menor do que b.
Figura 2.23 O lema de Euclides, Elementos X.I
E importante notar que neste resultado nao ha mencao de processos infi-
nitos, nao e necessario repetir o processo indefinidamente. Ele e repetido
um numero finito de vezes.
Em verdade, este lema esta demonstrado por Euclides no decorrer da
propria XII.2. Nos o apresentamos antes por razoes didaticas.
Seja AB o lado de um polgono regular de n lados inscrito em uma cir-
cunferencia e M o ponto medio do arco AB, como mostra a Figura 2.24. Seja
RS tangente a circunferencia, por M. E claro que AM = BM e o lado do do
polgono regular de 2n lados inscrito na circunferencia.
Figura 2.24
A area do triangulo AMB e metade da area do retangulo ARSB, logo
e maior do que a metade da area do segmento circular AMB. Sendo as-
sim, subtraindo do segmento circular AMB o triangulo AMB, retiramos
2.3. OS ELEMENTOS DE EUCLIDES 89
uma figura com area maior do que a metade da area do segmento circular.
Repetindo o mesmo procedimento, por exemplo, para um triangulo ANM,
formado por dois lados de um polgono inscrito com o dobro do numero de
lados do polgono precedente, podemos sempre retirar da area que resta uma
area maior do que a metade da area do segmento circular original. Sendo as-
sim, a diferenca entre a area do crculo e a area do polgono pode ser tornada
menor do que qualquer quantidade dada.
Podemos agora demonstrar XII.2.
Proposicao XII.2: Crculos estao entre si como os quadrados se seus dia-
metros.
Como a demonstracao de Euclides e longa, e complexa, nos a apresenta-
mos de maneira simplificada, utilizando nosso simbolismo algebrico atual.
Sejam a e A, d e D respectivamente as areas e os diametros dos crculos
c e C da Figura 2.25. Queremos mostrar que
a
A = d2
D2 .
Figura 2.25
Suponhamos, em primeiro lugar, que a/A > d2/D2 e que existe um po-
lgono regular inscrito em c, com area p tal que p/A > d2/D2. Na verdade,
buscaremos uma contradicao para esta segunda desigualdade.
Utilizando o resultado mostrado acima, temos que a  p e menor do que
qualquer quantidade dada. Sabemos, entao que, como a/A > d2/D2, te-
mos tambem que p/A > d2/D2. Sendo P a area do polgono inscrito em
C e semelhante a p, sabemos, por uma propriedade dos polgonos inscri-
tos, que p/P = d2/D2 (usando semelhanca de triangulos). Sendo assim,
p/A > d2/D2 = p/P e conclumos que P > A. Mas P e a area do polgono ins-
crito na circunferencia C de area A, logo P nao pode ser maior do que A. De
maneira analoga, podemos mostrar que a suposicao de que a/A < d2/D2 (ob-
tida de a/P < d2/D2) leva a uma contradicao, o que mostra que a/A = d2/D2.

90 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Exerccios
2.12. Demonstre as proposicoes I.4, I.8 e I.26 dos Elementos os criterios
de congruencia de triangulos. Compare suas demonstracoes com as
originais dos Elementos.
1. Proposicao I.4: Se em dois triangulos um deles tem dois lados
iguais, respectivamente, a dois lados do outro, e tambem os angu-
los compreendidos entre estes lados sao iguais, entao eles terao os
terceiros lados iguais, e os dois triangulos serao iguais 22 e seus ou-
tros angulos serao dois a dois iguais, mais precisamente os angulos
opostos aos dois lado considerados.
2. Proposicao I.8: Se em dois triangulos um deles tem dois lados
iguais, respectivamente, a dois lados do outro, e tambem os ter-
ceiros lados sao iguais, os angulos compreendidos entre os dois
lados de cada um serao iguais.
3. Proposicao I.26: Se em dois triangulos um deles tem dois angulos
iguais, respectivamente, a dois angulos do outro, e o primeiro tem
um lado igual a um do outro, mais precisamente, ou lados adjacen-
tes, respectivamente, aos angulos iguais, ou lados que sao opostos,
respectivamente, aos angulos iguais, entao os outros lados serao,
respectivamente, iguais, e o terceiro angulo do primeiro sera igual
ao terceiro angulo do segundo.
Compare o tratamento dado, por Euclides, `a congruencia de triangulos
com o que e feito em um livro moderno, por exemplo [8].
2.13. Demonstre, usando somente as ferramentas disponveis no Livro I dos
Elementos, as proposicoes I.34, I.36, I.37 e I.38.
1. Proposicao I.34: Os angulos e os lados opostos de um paralelo-
gramo sao iguais, e a diagonal divide ao meio o paralelogramo, ou
seja, o divide em duas partes iguais.
2. Proposicao I.36: Paralelogramos sobre bases iguais e entre as mes-
mas paralelas sao iguais.
3. Proposicao I.37: Triangulos sobre a mesma base e entre as mesmas
paralelas sao iguais.
22Lembramos que, para Euclides, iguais pode significar congruentes ou ter a mesma
area. Neste caso, obviamente, temos a segunda acepcao.
2.3. OS ELEMENTOS DE EUCLIDES 91
4. Proposicao I.38: Triangulos sobre bases iguais e entre as mesmas
paralelas sao iguais.
2.14. Sejam A e B dois quadrados, com A maior do que B. Ache, utilizando
somente regua e compasso, um quadrado igual `a diferenca dos dois.
2.15. Demonstre, usando somente as ferramentas disponveis nos Livros I e
II dos Elementos, as proposicoes II.5 e II.6.
1. Proposicao II.5: Se uma linha reta 23 for dividida em partes iguais,
e tambem em partes desiguais, o retangulo contido pelas partes
desiguais, juntamente com o quadrado sobre a reta entre os pontos
de corte e igual ao quadrado sobre metade da reta (Veja a figura
na pagina 77).
2. Proposicao II.5: Se uma linha reta for dividida ao meio e prolon-
gada ate um ponto qualquer, o retangulo contido por toda a reta
assim prolongada, e a parte que a prolongou, juntamente com o
quadrado sobre a metade seccionada da reta, e igual ao quadrado
sobre a reta que e igual `a metade com a parte prolongada (Com-
parando o enunciado desta proposicao com o de II.5, tente voce
mesmo fazer a figura).
2.16. Seja P uma regiao poligonal plana. Mostre como, usando os exerccios
anteriores e o teorema de Pitagoras (proposicao I.47), e possvel fazer
a quadratura de P , ou seja, construir um quadrado de area igual `a de
P .
2.17. Demonstre a proposicao VI.2, o teorema de Tales: Se uma reta e
tracada paralelame3nte aos lados de um triangulo, ela cortara os outros
lados, os seus prolongamentos, proporcionalmente; e se os lados, ou
seus prolongamentos sao cortados proporcionalmente, a reta que une
os pontos de corte, sobre os lados, sera paralela ao lado restante do
triangulo.
Sugestao: use a proposicao VI.1, da pagina 82. No triangulo ABC, em
que DE e paralela ao lado BC, considere os triangulos BDE e CDE
e aplique a proposicao VI.1 aos mesmos (Figura 2.26).
2.18. Demonstre a proposicao VI.3: Se o angulo no vertice de um triangulo e
dividido em dois por uma a reta que tambem corta a base do triangulo,
23Lembramos que, para Euclides, linha reta significa segmento de reta ou toda a reta. Neste
caso, obviamente, temos a primeira acepcao.
92 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Figura 2.26
os segmentos que essa bissetriz determina na base estao entre si como
os dois outros lados do triangulo. E se os segmentos determinados na
base por uma reta que passa pelo vertice do triangulo estao entre si
como os dois outros lados, entao a reta divide o angulo do vertice em
duas partes iguais.
Sugestao: No triangulo ABC da Figura 2.26, trace CE paralela `a bis-
setriz do angulo A, com E sobre o prolongamento de BA. Entao, use
VI.2.
2.19. Sejam a e b dois numeros naturais. Pelo algoritmo da divisao, existem
q1 e r1 tais que
a = bq1 + r1,
com r1 < b.
Por sua vez, existem q2 e r2 tais que
b = q2r1 + r2,
com r2 < r1.
Este processo pode ser continuado, obtendo-se quocientes e restos par-
ciais, respectivamente iguais a q1, q2, q3, . . . e r1, r2, r3, . . . .
2.4. A TRANSMISS AO DOS ELEMENTOS 93
a = bq1 + r1
b = r1q2 + r2
r1 = r2q3 + r3

 Demonstre que este processo chega ao fim, ou seja, existe N tal
que rN = 0.
 Demonstre que, entao, qN e o maximo divisor comum de a e b.
2.20. Demonstre a proposicao IX.36 dos Elementos: Se a soma
1 + 2 + 22 +  + 2n = p
for um numero primo, entao, 2np e um numero perfeito.
2.21. Demonstre, geometricamente, sem usar algebra, o lema de Euclides, a
proposicao X.I (Veja a pagina 88).
2.22. Demonstre X.I usando nossos metodos modernos, com o emprego de
limites.
2.23. No lema de Euclides, o que acontece se a quantidade retirada for 1/3
da original? A quantidade restante tende para zero? Por que o Lema
de Euclides afirma que a quantidade retirada deve ser sempre maior do
que ou igual `a metade da quantidade restante?
2.24. Um dos pontos altos dos Elementos de Euclides e a proposicao XII.2
(Veja a pagina 89), a qual emprega o metodo da exaustao. Nessa
demonstracao, Euclides utiliza a proposicao XII.1: Polgonos seme-
lhantes inscritos em circunferencias estao entre si como seus diametros.
Demonstre-a.
2.4 A transmissao dos Elementos e as edicoes
em lngua portuguesa
Os Elementos de Euclides constituem uma das obras mais importantes da
tradicao matematica e cultural do Ocidente. Eles marcaram profundamente
a constituicao da Matematica, bem como seu ensino. Um exemplo disso
94 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
e que no movimento de renovacao curricular conhecido como Movimento da
Matematica Moderna, que teve lugar em meados do seculo XX, uma das pala-
vras de ordem pronunciadas por um dos lderes do movimento, o matematico
frances Jean Dieudonne, foi abaixo Euclides!
Durante muitos seculos, quando se falava em geometria, tinha-se em
mente a geometria tal como exposta nos Elementos de Euclides. Mesmo
a nocao do que e Matematica, do que e rigor em Matematica e de como ela
deve ser exposta se baseou nos Elementos durante muito tempo. Assim, por
exemplo, Isaac Newton deduziu muitos dos resultados de seu Philosophi
Naturalis Principia Mathematica (Princpios matematicos da filosofia natural)
usando metodos de calculo infinitesimal mas suas demonstracoes seguiam o
modelo euclidiano, geometrico.
Nos Elementos de Euclides nao se encontram aplicacoes, exerccios, mo-
tivacoes. A exposicao e seca, direta, implacavel. O fato de que eles foram
usados ate recentemente no ensino de jovens em alguns pases, como a Ingla-
terra, muito contribuiu para que algumas pessoas passassem a considerar a
Matematica como um saber arido. Em outros pases, como a Franca, muito
cedo se comecou a discutir a adequacao dos Elementos para o ensino de jovens,
e isso deu origem a livros classicos, como os de Arnauld, Lacroix, Legendre,
Hadamard, entre outros.
Ha inumeras edicoes dos Elementos em diversas lnguas, mas nao nos che-
gou nenhum manuscrito da epoca de Euclides. Nao sabemos o que Euclides
escreveu e comprovadamente sua obra sofreu acrescimos, modificacoes, mu-
tilacoes. Na Idade Media lhe foram acrescentados dois livros espurios. Varios
editores introduziram proposic`oes nos Elementos, na tentativa de torna-lo
mais facil, ou suprimiram partes que consideravam muito difceis ou sem
aplicacoes.
No seculo IV d.C., Theon de Alexandria publicou uma edicao dos Ele-
mentos que foi muito usada, e deu origem a toda uma longa serie de edicoes
posteriores. Esta linhagem de edicoes constitui os chamados manuscritos the-
oninos.
Enquanto os Elementos desapareceram do Ocidente, os arabes os preser-
varam. O califa Harun Al-Rashid ( 763 - 809) encomendou uma traducao
baseada em um manuscrito de Proclo. Um pouco mais tarde, em torno de
900 d.C., um manuscrito grego foi copiado em (Bizancio) Constantinopla.
Em torno de 1120 d.C., Adelard de Bath ( 1080 -  1152) traduziu os
Elementos para o latim, a lngua culta da Europa de entao, usando um ma-
nuscrito arabe. Um pouco depois, em 1260, Campanus de Novara ( 1220
- 1296) editou os Elementos. De seu trabalho, originou-se a primeira edicao
latina impressa, em 1482, feita por Erhard Ratdolt, em Veneza. Tambem de
Veneza provem a primeira edicao dos Elementos em grego, feita por Bartolo-
2.4. A TRANSMISS AO DOS ELEMENTOS 95
meo Zamberti, em 1505.
Em 1533, Simon Grynaeus publicou a editio princeps dos Elementos, a
qual, como sua propria alcunha indica, embora de baixa qualidade, foi a
fonte para inumeras edicoes posteriores.
Em 1756, o matematico escoces Robert Simson (1687 - 1768) publicou
uma edicao extremamente influente de Euclides, que foi republicada durante
muitos anos e influenciou diversas outras edicoes.
Um acontecimento importante na historia da transmissao dos Elementos,
foi a edicao de Peyrard, em grego, latim e frances, publicada entre 1814 e
1818. Como resultado das campanhas dos exercitos de Napoleao na Italia,
Peyrard teve acesso a manuscritos da biblioteca do Vaticano, nao descenden-
tes do manuscrito de Theon de Alexandria e os utilizou para preparar esta
nova edicao.
Johan Ludvig Heiberg (1854 - 1928), filologo e historiador dinamarques,
publicou, conjuntamente com Heinrich Menge, entre 1883 e 1916, as obras de
Euclides, entre elas a importantissima edicao dos Elementos, que deu origem
a praticamente todas as edicoes modernas de Euclides. Ela se difundiu enor-
memente devido `a traducao para o ingles, com extensos comentarios, feita
por Thomas Little Heath (1861 - 1940), originalmente publicada em 1908, e
que e amplamente utilizada, embora seus comentarios estejam em desacordo
com as mais recentes interpretacoes da Matematica grega.
Para sua edicao, Heiberg comparou manuscritos da linhagem theonina
com os que Peyrard tinha localizado no Vaticano e propos uma reconsti-
tuicao do texto euclidiano considerada definitiva durante o seculo XX. 24
Recentemente, Knorr ([102]) sugeriu que manuscritos arabes podem ser uma
fonte mais confiavel para a reconstituicao do texto euclidiano.
Em 1735, o Padre Jesuta Manoel de Campos, publicou, em Lisboa, para
uso da Aula da Esfera do Colegio de Santo Antao, seu Elementos de geometria
plana e solida, segundo a ordem de Euclides. Este livro e a primeira edicao
de Euclides em lngua portuguesa. Ele inspirou-se em outro Jesuta, Andre
Tacquet, 25 que publicara, em 1725, sua edicao dos Elementos.
Ainda em Portugal, em 1768, doze anos apos a edicao de Simson, foram
publicados os Elementos de Euclides, dos Seis Primeiros Livros, do Undecimo e
Duodecimo, da Versao Latina de Frederico Comandino, adicionados e ilustrados
por Robert Simson e traduzidos em Portugues para uso do Real Colegio de Nobres
por Joao Angelo Bruneli. Publicado em Lisboa, nas oficinas de Miguel Menescal
da Costa. Esta edicao e incompleta, pois nao inclui os livros aritmeticos.
24Detalhes sobre isso podem ser vistos em [52] e [76].
25Andre Tacquet (1612 - 1660) foi um jesuta belga que fez trabalhos importantes em
Matematica e Fsica.
96 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Onze anos depois, em 1792, a Universidade de Coimbra passou a publicar esta
traducao da edicao de Simson. Ela foi reeditada varias vezes em Portugal.
No Brasil, em 1944 e 1945 ela foi reeditada, com ortografia atualizada, pela
Editora Fundo de Cultura, de Sao Paulo.
Por fim, em 2009, a lingua portuguesa ganhou sua primeira edicao com-
pleta dos Elementos de Euclides, quando Irineu Bicudo ([14]) os traduziu
diretamente do grego.
2.5 Exercicios suplementares
2.25. Afirma-se, tradicionalmente, mas sem evidencia historica, que os pi-
tagoricos introduziram as medias na Matematica grega. De qualquer
maneira, elas ja eram conhecidas na epoca de Platao. Entre as medias,
as mais conhecidas sao a aritmetica (mA), a harmonica (mH ) e a geome-
trica (mG). Hoje, elas sao definidas como segue: Dados dois numeros
a e b,
mA = a + b
2 .
mH = 2ab
a + b .
mG = ab.
Para nos, hoje, estas medias sao definidas para numeros reais quaisquer.
Suas definicoes originais, para os gregos, eram as seguintes:
 Dadas tres numeros naturais, a, b e c, tais que a < c < b, c e a
media aritmetica de a e b se
c  a = b  c.
 Dados tres numeros naturais, a, b e c, tais que a < c < b, c e a
media harmonica de a e b se
(a  c)  (b  c)  a  c.
2.5. EXERCICIOS SUPLEMENTARES 97
 Dados tres numeros naturais, a, b e c, tais que a < c < b, c e a
media geometrica de a e b se
(c  a)  (b  c)  a  c.
1. Dados dois numeros a e b, a < b, mostre que suas medias aritmetica,
geometrica e harmonica sao tais que:
mG = mA  mH .
2.26. Na Figura 2.27, ab = A, bc = b, a semi-circunferencia tem centro em
O, ponto medio de AC, BD e perpendicular ao diametro AC e F B e
perpendicular ao raio OD. Prove que OE e a media aritmetica de a e
b, BD e sua media geometrica e F D e sua media harmonica. Deduza
que
mA > mG > mH .
Figura 2.27
Figura 2.28
98 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
2.27. Considere o triangulo ABC da Figura 2.28. Usando esta figura, de-
monstre o teorema de Pitagoras.
Esta demonstracao encontra-se, sem nenhum comentario, em tratados
indianos, dos Sulbasutras (em torno do seculo VIII a.E.C.) e na China,
nos comentarios de Liu-Hui sobre o classico da Matematica chinesa os
Nove captulos. Trata-se do que chamamos hoje de uma prova sem
palavras.
2.28. A construcao geometrica a seguir encontra-se em textos rituais religio-
sos, da India, redigidos em torno do VIII seculo a.E.C., e que proveem
de uma tradicao oral anterior a 2000 anos a.E.C. Estes textos continham
instrucoes cuidadosas para a construcao de altares para cerimonias re-
ligiosas. A construcao destinava-se a transformar um retangulo em um
quadrado de mesma area.
IMPORTANTE: Utilize somente equivalencia de areas e transforma-
coes dos retangulos e quadrados envolvidos. Nao utilize resultados
algebricos, como, por exemplo, usar que em um triangulo retangulo
com hipotenusa a e catetos b e c, a2 = b2 + c2.
Figura 2.29 Transformacao de um retangulo em um quadrado
Seja ABCD o retangulo dado. Sobre BC, marque E tal que AB = BE
e construa o quadrado BEMA. Divida o segmento EC em duas partes
iguais e construa os retangulos EF GM e GF CD.
Construa o retangulo AMKL congruente ao retangulo CDG (ou seja,
transporte o retangulo F CGD para a posicao do retangulo AMKL,
obtendo a Figura LBF GMK).
Prolongue os segmentos LK e F G ate se encontrarem em H. Com
centro em L e raio LH trace o crculo que corta AD no ponto P .
Demonstre que AP e o lado do quadrado procurado.
Sugestao: Aplique o teorema de Pitagoras.
2.5. EXERCICIOS SUPLEMENTARES 99
2.29. A passagem do sensvel ao abstrato pode ser percebida na seguinte
situacao.
Na Figura 2.30 e facil ver como transformar o paralelogramo ADCB
em um retangulo:
Figura 2.30
Recorte o triangulo EDC do paralelogramo e o coloque na posicao
F AB, obtendo assim o retangulo desejado. Alias, essa operacao fsica,
que pode ser concebida mentalmente, e o que se faz hoje nos livros
didaticos do ensino fundamental para provar que e possvel transfor-
mar um paralelogramo em um retangulo com a mesma area.
Mas o que acontece se o paralelogramo dado for ADCB da Figura 2.31?
Figura 2.31
Neste caso, sera talvez necessario gastar bastante papel e cola, para ser
convencido que ele e igual ao retangulo GHJL.
Prove que, neste caso, sao necessarios tres cortes para transformar o
paralelogramo no retangulo.
2.30. Examine a Figura 2.32 e demonstre que, usando-a, e possvel demons-
trar o teorema de Pitagoras. Nela, os triangulos ACD e CGE sao
congruentes.
2.31. Mostre, usando equivalencia de areas, que a expressao S = bh/2, que
calcula a area de um triangulo de base b e altura h, fornece sempre o
100 CAPITULO 2. A MATEM ATICA GREGA AT E EUCLIDES
Figura 2.32
mesmo resultado, qualquer que seja o lado do triangulo escolhido como
base.
2.32. Diz a tradicao que os pitagoricos trabalharam com os numeros amigos.
Dois numeros sao amigos se cada um deles e igual `a soma dos divisores
proprios do outro. Assim, por exemplo, como
284 = 1 + 2 + 4 + 5 + 10 + 11 + 20 + 22 + 44 + 55 + 110,
e
220 = 1 + 2 + 4 + 71 + 142,
os numeros 284 e 220 sao amigaveis. Este e o menor par de numeros
amigos.
Para cada numero natural n, defina Kn = 3  2n  1.
Demonstre que se Kn, Kn1 e 3K2n1 + 2 forem numeros primos, entao
o par
(2n  Kn  Kn1, 2n  (3  K2n1 + 2))
e formado por numeros amigos.
Isso se verifica somente para n = 2, n = 4 e n = 7. Os pares correspon-
dentes sao (220, 284), (17296, 18416) e (9363584, 9437056).
2.33. Prove a proposicao IX.39 dos Elementos: Se a soma
1 + 2 + 22 +  + 2n = p
2.5. EXERCICIOS SUPLEMENTARES 101
for um numero primo, entao, 2np e um numero perfeito.

Captulo 3
A Matematica grega apos
Euclides
3.1 Contextualizacao historica
E lugar comum afirmarmos que as figuras geometricas aceitas na geometria
grega deviam ser construdas com regua e compasso. De fato, isto e verdade
se temos em mente as construcoes realizadas nos Elementos de Euclides. Dizer
que o mesmo e verdade para toda a geometria grega significa considerar que
o conjunto das praticas gregas seguia o padrao de rigor estabelecido por
Euclides, o que nao acontecia.
As construcoes com regua e compasso nao permitem resolver todos os
problemas tratados pelos matematicos gregos antes e depois de Euclides, os
quais nao se furtavam a utilizar outros metodos de construcao, ou a empregar
outras curvas. Com o auxlio destas curvas, foram resolvidos os problemas
classicos: a trisseccao do angulo, a quadratura do crculo e a duplicacao do
cubo. Veremos aqui algumas das solucoes destes problemas, retiradas de
obras fundamentais da beometria grega, que nem sempre se restringiam aos
padroes euclidianos.
Pappus, um dos maiores comentadores dos trabalhos matematicos de seus
antecessores gregos, e que viveu no seculo III E.C., classificou os problemas
geometricos do seguinte modo:
Os antigos consideravam tres classes de problemas ge-o-me-
tri-cos, chamados planos, solidos e lineares. Aqueles que po-
dem ser resolvidos por meio de retas e circunferencias de crculos
sao chamados de problemas planos, uma vez que as retas e cur-
vas que os resolvem tem origem no plano. Mas problemas cujas
solucoes sao obtidas por meio de uma ou mais secoes conicas sao
103
104 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
denominados problemas solidos, uma vez que superfcies de fi-
guras solidas (superfcies conicas) precisam ser utilizadas. Resta
uma terceira classe, que e chamada linear porque outras linhas,
envolvendo origens diversas, alem daquelas que acabei de descre-
ver, sao requeridas para sua construcao. Tais linhas sao as es-
pirais, a quadratriz, a conchoide, a cissoide, todas com muitas
propriedades surpreendentes. ([147], pp. 38-39).
O livro no qual encontramos este comentario, A Colecao matematica, e
uma das fontes principais que nos permite conhecer muitos trabalhos gregos
cujas fontes originais se perderam.
O criterio usado nesta classificacao dos problemas baseia-se nos tipos de
linhas necessarias `a construcao, uma vez que os problemas envolvem sem-
pre construcao. Por exemplo, a conchoide e uma curva construda de modo
mecanico pelos gregos, da seguinte maneira.
Sejam um ponto fixo, K, e uma reta AB, tambem fixa. A conchoide e o
lugar geometrico dos pontos P tais que o comprimento entre P e S, ponto
de interseccao de KP com a reta AB, e constante (Ver Figura 3.1).
Figura 3.1 Conchoide de Nicomedes
No entanto, a divisao dos problemas em tres tipos so foi explicitada no
comentario de Pappus, no terceiro seculo da Era Comum, e podia ser de
ordem descritiva, mais do que normativa.
A partir de Arquimedes, podemos estudar metodos que marcaram a geo-
metria grega e se distinguem dos procedimentos euclidianos. Ele nasceu mais
ou menos no momento em que Euclides morreu, em torno da segunda decada
do seculo III a.E.C. Era de se esperar, portanto, que o trabalho de Euclides
tivesse uma influencia marcante em sua obra. Mas nao foi bem assim, mos-
traremos que Arquimedes nao pode ser visto como um sucessor de Euclides;
e seu trabalho nao se inscreve, por assim dizer, em uma tradicao euclidiana.
Um exemplo disso e a utilizacao de metodos mecanicos de construcao, como
veremos ser o caso da espiral de Arquimedes. Segundo a tese defendida por
Knorr ([100]), Arquimedes exprimiria uma tradicao alternativa aos Elementos
de Euclides, ligada aos metodos desenvolvidos por Eudoxo.
3.1. CONTEXTUALIZAC AO HIST ORICA 105
Arquimedes, um dos mais conhecidos matematicos gregos, chegou a de-
fender um metodo que permitisse entender certas realidades matematicas
usando a mecanica, ainda que este metodo possibilitasse apenas a desco-
berta de propriedades que deveriam ser, em seguida, demonstradas geome-
tricamente. Sabemos hoje que alguns dos resultados demonstrados dessa
maneira por Arquimedes eram obtidos de modo puramente mecanico. Have-
ria, portanto, uma distincao entre metodos de descoberta, que poderiam
ser mecanicos, e metodos de demonstracao, que deveriam ser puramente
geometricos.
No incio de sua obra sobre a Quadratura da Parabola ([81], pp. 233 - 252),
em uma carta a Dositeu, Arquimedes afirma que pretende comunicar
[U]m certo teorema geometrico que nao foi investigado antes
e que foi agora investigado por mim e que eu descobri, primeira-
mente, por meio da mecanica e que exibi, em seguida, por meio
da geometria.
Este tipo de procedimento fica ainda mais claro na obra, encontrada
apenas em 1899, O Metodo dos Teoremas Mecanicos ([81]), carta escrita a
Eratostenes, na qual Arquimedes explica:
(. . . ) [P]ensei que seria apropriado escrever-lhe neste livro
sobre um certo metodo por meio do qual voce podera reconhecer
certas questoes matematicas com ajuda da mecanica. Estou con-
vencido de que ele nao e menos util para encontrar provas para
os mesmos teoremas. Algumas coisas, que se tornaram claras
para mim, em primeiro lugar, pelo metodo mecanico, foram pro-
vadas geometricamente em seguida, uma vez que a investigacao
pelo referido metodo nao fornece de fato uma demonstracao. No
entanto, e mais facil encontrar a prova quando adquirimos previ-
amente, pelo metodo, algum conhecimento das questoes, do que
encontra-la sem nenhum conhecimento previo.
Arquimedes empregava uma balanca abstrata que deveria equilibrar fi-
guras geometricas. Nao nos determos sobre este trabalho, do qual podemos
encontrar uma analise em [39].
O final do seculo III a.E.C. foi o perodo de maior popularidade dos
tres problemas classicos. Estes problemas constituem o ponto comum dos
trabalhos de diversos geometras da epoca, como Eratostenes, Nicomedes,
Hppias, Diocles, Dionisodorus, Perseus e Zenodorus. Apesar da maioria
das fontes que contem estes trabalhos nao ter sido preservada, ha evidencias
106 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
de aplicacoes da geometria a problemas de astronomia, otica, geografia e
mecanica. Alem disso, estes geometras parecem ter sofrido influencia direta
de Arquimedes, o que pode ser constatado pelo uso de metodos mecanicos,
como a espiral (e outras curvas geradas por movimentos mecanicos) e diver-
sos tipos de neuses1. Contudo, nota-se tambem que estes matematicos se
distanciaram um pouco do estilo de Arquimedes, uma vez que se dedicaram
`a procura de metodos alternativos em suas construcoes. Esta busca poderia
indicar uma necessidade de ir alem dos procedimentos disponveis na epoca.
Os escritos de Euclides ofereciam uma alternativa, mas sua exploracao de-
mandava tecnicas de natureza muito distinta, o que talvez ultrapassasse as
possibilidades desta geracao imediatamente posterior a Arquimedes.
Na verdade, a busca de novos metodos de construcao, inspirados no para-
digma euclidiano serviu de motivacao para os trabalhos de Apolonio, desen-
volvidos na virada do seculo III para o seculo II a.E.C. Acredita-se que ele
tenha comecado a redigir seu livro mais conhecido, o Conicas, por volta do ano
200 a.E.C. Nesta obra, Apolonio define as secoes conicas do modo mais geral
possvel, como secoes de cones, usando metodos muito caractersticos dos Ele-
mentos de Euclides. Em particular, aqueles que dizem respeito `a aplicacao de
areas, que deram origem aos nomes dos diferentes tipos de conicas: parabola,
hiperbole e elipse. O estilo deste livro tambem e muito similar ao de Eucli-
des, pois Apolonio segue o estilo formal dos Elementos ate nos detalhes do
enunciado de certas proposicoes. Seus resultados parecem exprimir a tenta-
tiva de estender e tornar rigorosos os metodos antigos empregados no estudo
de conicas, desenvolvidos por Euclides (em sua obra sobre as conicas) e Ar-
quimedes.
Uma das preocupacoes de Apolonio era apresentar solucoes por meio de
conicas para os problemas classicos, como a duplicacao do cubo e a tris-
seccao do angulo, a fim de eliminar as solucoes por neuses e por curvas
especiais usadas por Arquimedes e outros. A diversidade de metodos empre-
gados na resolucao de problemas geometricos ate o seculo III a.E.C. mostra
que, neste estagio do desenvolvimento da Matematica, o importante era re-
solver os problemas por qualquer tecnica disponvel. Este leitmotiv marca
a tradicao grega de resolucao de problemas geometricos. Com Apolonio,
este panorama comeca a se transformar. Mesmo que tenha fornecido, ele
mesmo, uma construcao da duplicacao do cubo por meio da neusis, Apolonio
preferia claramente solucoes usando conicas, com um estilo bem euclidiano,
e que dependiam de resultados centrais dos Elementos. Por exemplo, as
1A neusis (plural  neuses) e um metodo de construcao que usa o ajuste com uma regua
graduada, o que nao e considerado um procedimento euclidiano. Veremos uma construcao por
este metodo mais adiante.
3.1. CONTEXTUALIZAC AO HIST ORICA 107
solucoes da trisseccao do angulo por meio da espiral de Arquimedes e da neu-
sis nao eram consideradas satisfatorias, e Apolonio propos uma construcao
com a hiperbole. Os trabalhos de Arquimedes apresentam uma diversidade
de aplicacoes do metodo da neusis em construcoes que tambem podiam ser
realizadas com regua e compasso.
A popularidade destas construcoes por neuses demonstra a vasta presenca
de metodos nao-euclidianos nos trabalhos de Arquimedes e seus seguidores.
Alem destas tecnicas, a enfase de Arquimedes na investigacao dos procedi-
mentos de Eudoxo contrasta com o tipo de pesquisa caracterstico de Euclides
e Apolonio, marcado pelo estudo de lugares geometricos e pelo uso de conicas.
Os metodos de resolucao de problemas usados por Euclides foram conso-
lidados por Apolonio no perodo seguinte, ao passo que os procedimentos de
Arquimedes so encontrariam seguidores bem mais tarde, por volta dos seculos
XVI e XVII. Pode datar da transicao entre os seculos III e II a.E.C. a ten-
tativa de regularizacao dos metodos para resolver problemas geometricos,
quando os matematicos teriam buscado construir, somente por metodos pla-
nos (ou seja, com regua e o compasso), ou por metodos solidos (usando secoes
conicas) construcoes ja efetuadas por outros meios.
Na epoca de Apolonio, o campo da geometria estava desenvolvido a tal
ponto que pode ter se tornado interessante regularizar os metodos de re-
solucao de problemas e tornar as tecnicas de construcao mais formais. A
consideracao de classes distintas de problemas  como a dos problemas pla-
nos, solidos e lineares  ajudava a compreender o escopo dos metodos usados
para trata-los. Isso explicaria o esforco para reduzir outros tipos de cons-
trucao a um destes tres. Assim, descrever os tipos de problema existentes
podia ser conveniente para organizar a pesquisa.
O incio do seculo II a.E.C. foi marcado por um declnio na atencao dos
matematicos aos problemas geometricos avancados, o que nao representou
uma decadencia do campo matematico, mas um deslocamento de interesse
em direcao a outras areas, como a trigonometria e os metodos numericos.
W. Knorr ([101]) taxa a escola de Alexandria, nos tempos de Arquimedes, de
academicista. Mesmo a composicao dos Elementos de Euclides, para ele,
se relaciona aos ideais da epoca e, sobretudo, aos seus objetivos pedagogicos.
Esta abordagem privilegiava uma exposicao sintetica, que torna inacessvel
o procedimento heurstico da descoberta e menosprezava toda consideracao
concreta ou pratica. Ele contrasta esta tendencia com outras obras alexan-
drinas mais tardias, como as Metricas de Hierao, o Almagesto de Ptolomeu,
e a Aritmetica de Diofanto.
A exposicao de Euclides nao da nenhuma pista sobre a aplicacao de seus
teoremas a problemas praticos. A abordagem teorica, de inspiracao eucli-
diana, seria caracterstica do ensino nas escolas filosoficas, pois o estudante
108 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
devia aprender Matematica por meio da contemplacao, e nao pela pratica.
Knorr ([101]) chega a atribuir a paralisacao do trabalho produtivo da geome-
tria grega aos efeitos esclerosantes desta pedagogia, tpica da orientacao es-
colastica dos pensadores da Alexandria antes do incio da era comum. Logo,
a divisao, proposta por Pappus, entre problemas planos (construdos com
regua e compasso) e outros, solidos ou mecanicos, nao provem do tempo
de Euclides. A resolucao de problemas era a parte essencial da atividade
geometrica na epoca de Euclides, Arquimedes e Apolonio, e a compilacao do
saber na forma de um conjunto de teoremas, uma atividade auxiliar.
Exporemos em seguida algumas construcoes nao-euclidianas, bem como
problemas de aproximacao que empregam o chamado metodo de exaustao.
Analisaremos depois a utilizacao de metodos euclidianos para a definicao das
conicas por Apolonio.
3.2 Arquimedes
Ja vimos que fazer a quadratura de uma area limitada por uma curva plana
significa construir um quadrado cuja area seja igual `a da figura. O metodo
da exaustao foi empregado em muitos problemas de quadratura de figuras
limitadas por linhas curvas, ou seja, que nao sao limitadas por poligonais
fechadas. Trataremos aqui, em particular, do exemplo da quadratura da
parabola, como apresentado por Arquimedes.
3.2.1 A quadratura da parabola
Para Arquimedes, uma parabola era definida pela secao de um cone circular
reto, obtido girando-se um triangulo retangulo em torno de um dos lados que
formam o angulo reto. A parabola e obtida quando seccionamos este cone
por um plano perpendicular `a hipotenusa do triangulo que foi girado.
Esta definicao e equivalente `a fornecida por Euclides em seu livro perdido
sobre as conicas. O ponto no qual o plano intercepta esta hipotenusa e
chamado vertice da parabola, sua intersecao com a base do cone e a base
e obtemos o diametro, ou eixo, da parabola, ligando o vertice ao ponto
medio de sua base.
A quadratura da parabola e um problema de comparacao da area deter-
minada por uma parabola e por um segmento de reta com a area de um
triangulo tendo este segmento de reta como base. Mais precisamente, quere-
mos mostrar que a area S entre a parabola e o segmento Qq e 4/3 da area
do triangulo P Qq (Veja a Figura 3.2). Para isto, precisamos de algumas
proposicoes, que Arquimedes supoe conhecidas (Veja [81], pp. 234-236).
3.2. ARQUIMEDES 109
Proposicao 1. Se por um ponto P de uma parabola tracarmos uma reta P V
que e o proprio eixo da parabola ou e paralela a esse eixo, e se Qq e uma corda
paralela `a tangente `a parabola por P e que corta P V em V , entao: QV = V q.
Reciprocamente, se QV = V q, a corda Qq sera paralela `a tangente em P (Veja
a Figura 3.2).
Figura 3.2
Proposicao 2. Se, em uma parabola, QQ for uma corda paralela `a tangente
em P , e se uma linha reta que passa por P for o eixo ou paralela ao eixo, e que
corta QQ em V , e a tangente `a parabola por P em T , entao P V = P T (Figura
3.3).
VPT
Q'
Q
Figura 3.3
Proposicao 3. Se por um ponto da parabola tracarmos uma reta que
e o eixo ou e paralela ao eixo da parabola, como P V , e se por dois outros
pontos da parabola Q e R tracamos retas paralelas `a tangente `a parabola por
P e que cortam P V respectivamente em V e W , entao P V  P W  (QV )2 
(RW )2.(F igura3.4)
Observamos que a equacao da parabola, dada em linguagem atual por
y = kx2, pode ser deduzida desta ultima propriedade. Com efeito, considere
o eixo que faz um angulo reto com a tangente no vertice P , os segmentos
110 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
Figura 3.4
P V medindo y, P W medindo y, QV medindo x e RW medindo x. Pela
proposicao 3 temos que
P V  P W  (QV )2  (RW )2.
Logo
y
y = x2
x2 ,
ou seja, y = kx2.
Esta relacao e o sintoma da parabola considerado, anacronicamente, um
antecedente grego da equacao de uma curva. No entanto, para Arquimedes
o ponto P nao precisa ser o vertice e os eixos nao sao fixos. Na deducao do
sintoma, os eixos sao escolhidos do modo mais conveniente. Quando falarmos
de Apolonio, veremos com mais detalhes o que e um sintoma para os gregos.
As provas das tres proposicoes precedentes nao sao fornecidas por Ar-
quimedes e, para suas demonstracoes, ele remete `a obra sobre conicas de
Euclides, que se perdeu.
Passamos agora `as proposicoes essenciais para a quadratura da parabola.
Proposicao 19. Sejam P o vertice e Q um ponto qualquer sobre a parabola
e R o ponto no segmento parabolico no qual a tangente e paralela a P Q, e seja
M o ponto em que a paralela ao eixo da parabola por R corta Qq, paralela `a
tangente em P . Entao, P V = (4/3)RM (Ver a Figura 3.5).
Demonstracao: Sabemos que a paralela a Qq por R corta P V em W .
Entao, pela proposicao 3, temos que
3.2. ARQUIMEDES 111
Figura 3.5
P V  P W = (QV )2  (RW )2. (3.1)
Mas, por construcao, RW = MV e temos assim que
P V  P W = (QV )2  (MV )2 = (2MV )2  (MV )2 = 4  1. (3.2)
Lembramos que QV = 2MV pois, pela proposicao 1, RM (paralela ao
eixo P V ) corta P Q (paralela `a tangente em R) no ponto medio Y . Mas o
triangulo P QV e semelhante a Y QM e como RM corta P Q em seu ponto
medio, deve cortar QV tambem em seu ponto medio. Logo, P W = (1/4)P V .
Assim,temos
P V = P W + W V = (1/4)P V + RM, (3.3)
logo RM = (3/4)P V e temos que P V = (4/3)RM.
Proposicao 21. Sejam Qq a base e P o vertice de um segmento parabolico
P Qq. Seja R o ponto no segmento parabolico no qual a tangente e paralela a
P Q (Figura 3.5). Entao:
P Qq = 8P RQ.
Demonstracao: Seja P V a paralela ao eixo que corta Qq em seu ponto
medio V (pela proposicao 1, pois Qq e paralela `a tangente em P ). A reta
paralela ao eixo por R corta P Q em seu ponto medio Y (ainda pela proposicao
1), logo esta mesma reta corta QV em seu ponto medio M(considerando o
triangulo P QV semelhante a Y QM, como na proposicao 19). Em seguida,
tracamos o segmento P M.
Pela Prop. 19, P V = (4/3)RM . E temos que P V = 2Y M , pois os
triangulos P QV e Y QM sao semelhantes e QV = 2QM . Logo, como
112 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
2Y M = 4 (RY + Y M )
3 , (3.4)
temos que Y M = 2RY .
Podemos mostrar, assim, que
 P QM = 2 P RQ,
pois
 P QM =  Y QM +  P Y M ,
 P RQ =  RQY +  P RY ,
e Y QM tem a mesma altura (ate Q) que Y RQ e duas vezes a base (YM
= 2RY), logo YQM = 2 YRQ; de modo analogo,  P Y M tem a mesma
altura (ate P ) que  P RY e duas vezes a base, logo  P Y M = 2 P RY .
Como  P QM = 2 P RQ, podemos mostrar que  P QV = 4 P RQ,
pois  P QM =  P MV uma vez que tem a mesma altura (ate P ) e bases
iguais (QM = MV ). Logo,
 P QV =  P QM +  P MV = 2 P QM = 4 P RQ.
Mas, como V divide Qq em dois, segue-se que  P Qq = 8 P RQ .
Mas, se o segmento RW e tracado de modo a encontrar a parabola nova-
mente em r, temos que RW = rW , pois RW = MV = V m = rW , e a mesma
prova mostra que P Qq = 8P rq. 
Mostremos agora como Arquimedes efetua a quadratura da parabola,
usando o metodo da exaustao.
Suponhamos que a area do triangulo  P Qq e T . Como
T =  P Qq = 8 P RQ
e
T =  P Qq = 8 P rq,
decorre
 P RQ +  P rq = T
4 .
(Note que os triangulos P RQ e P rq sao construdos sobre os lados de
P Qq).
3.2. ARQUIMEDES 113
Podemos continuar o mesmo processo e construir triangulos na diferenca
entre a parabola e o polgono obtido pela uniao dos triangulos  P Qq,
 P RQ e  P rq, o que fornecera triangulos de areas T /42, T /43, e assim
por diante. A area do segmento parabolico seria a soma das areas de todos
estes triangulos.
Um passo essencial para a quadratura da parabola e dado pela proposicao
23, que permite a Arquimedes evitar a soma de uma serie infinita.
Proposicao 23: Dada uma sucessao finita de areas, A, B, C, D, . . . , Z,
das quais A e a maior, e cada uma das outras e quatro vezes sua sucessora,
entao,
A + B + C + D + Z + 1
3 Z = 4
3 A.
a demonstracao deste resultado e feita da seguinte maneira
Sejam b, c, d, . . . areas tais que
b = 1
3 B
c = 1
3 C
d = 1
3 D

Segue-se entao, facilmente, que
B + b = 1
3 A.
De maneira analoga,
C + c = 1
3B

Entao
B + C + D +  + Z + b + c + d +  + z = 1
3 (A + B + C +  + Y ) .
Por outro lado,
b + c + d +  + y = 1
3 (B + C + D +  + Y ).
114 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
Entao, por subtracao
B + C + D +  + Z + z = 1
3 A,
ou seja,
A + B + C +  + Z + 1
3 Z = 4
3 A.
Arquimedes aplica este resultado aos triangulos obtidos sucessivamente a
partir do triangulo P Qq (Figura 3.5) e obtem
T + 1
4 T + 1
42 T +  + 1
4n1 T + 1
3
1
4n1 T = 4
3 T.
Agora Arquimedes esta pronto para demonstrar a proposicao 24:
Proposicao 24: Qualquer segmento limitado por uma parabola e uma
corda Qq e igual a quatro tercos do triangulo que tem a mesma base que o
segmento e mesma altura que ele (Veja a Figura 3.5, pagina 111).
Arquimedes demonstra este resultado pelo metodo da exaustao, provando
que a area area S do segmento parabolico nao pode ser nem menor nem maior
que 4
3 T (soma das areas dos triangulos). Logo S = 4T /3. Lembramos que
este e o procedimento classico do metodo da exaustao. Para provar que duas
grandezas A e B sao iguais, mostra-se que nao se pode ter A > B e A < B,
do que decorre, forcosamente, que A = B.
Suponhamos que S > 4
3 T . Devem existir entao n triangulos tais que a
soma das suas areas
T + 1
4T + 1
42 T +  + 1
4n1 T = A
seja inferior a S e superior a 4
3 T (argumento geometrico). Mas como
A = 4
3T  1
3
1
4n1 T,
A seria inferior a 4
3 T , o que seria contraditorio com a hipotese de que A e
superior a 4
3 T , o que leva a uma contradicao.
Suponhamos agora que S < 4
3 T e consideremos a diferenca 4
3 T  S. Pelo
Lema de Euclides, deve haver um inteiro m tal que a area Tm = 1
4m1 T seja
inferior a esta diferenca. Mas por outro lado,
Tm > 1
3 Tm = resto = 1
3.4m1 T = 4
3 T  T (1 + 1
4 +  + 1
4m1 )
e
3.2. ARQUIMEDES 115
4
3 T  S > Tm > 4
3 T  T (1 + 1
4 +  + 1
4m1 ) ,
(pela desigualdade anterior). Logo,
S < T (1 + 1
4 +  + 1
4m1 ) ,
o que contradiz a evidencia geometrica, uma vez que
T (1 + 1
4 +  + 1
4m1 )
e a area de um polgono inscrito no segmento parabolico. 
3.2.2 A area do crculo
Mostraremos, nesta secao, como Arquimedes fez a quadratura do crculo,
usando o metodo da exaustao.
Esta proposicao e uma maneira de determinar a area do crculo encon-
trando uma figura retilnea, um triangulo no caso, com area igual `a area do
crculo. Observamos que esta e uma das primeiras ocasioes em que se utiliza
o permetro de uma curva no contexto da geometria grega (antes, apenas
os permetros de polgonos estavam em jogo).Salientamos que o Lema de
Euclides e essencial nesta demonstracao.
Proposicao 1. A area de um crculo e igual `a do triangulo retangulo no qual
um dos lados que formam o angulo reto e igual ao raio e o outro lado que forma
o angulo reto e a circunferencia deste crculo.
r
r
Figura 3.6
Demonstracao. A ideia principal da demonstracao e aproximar a area
do crculo pelas areas de polgonos inscritos e circunscritos cujos lados sao
sucessivamente duplicados.
Sejam C e T as areas do crculo e do triangulo, respectivamente. Ar-
quimedes inscreve no crculo um quadrado, um octogono regular, e assim
116 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
por diante, passando sucessivamente do polgono regular inscrito de 2n lados
para o de 2n+1 lados pelo processo bem conhecido (Veja a Figura 3.7). Alem
disso, Ele circunscreve ao crculo um quadrado, um octogono regular, etc.,
passando sucessivamente do polgono regular circunscrito de 2n lados ao de
2n+1 lados. A Figura 3.7 mostra o quadrado inscrito inicial, ABCD, e os la-
dos AL e LB do octogono regular inscrito, obtido pela duplicacao do numero
de lados do quadrado. Ela mostra tambem o quadrado circunscrito original,
EF GH, e o lado KL do octogono regular circunscrito obtido a partir do
quadrado EF GH.
Figura 3.7
Sejam In e Cn, n  2, os polgonos de 2n lados respectivamente inscritos
e circunscritos na circunferencia.
Mostraremos que nao podemos ter C > T e C < T . Isso acarreta que
C = T .
Suponhamos, inicialmente, que C > T . Neste caso, podemos obter uma
quantidade d tal que d = C  T > 0.
De maneira geral, dado um polgono regular inscrito em um crculo (Fi-
gura 3.8), sua area e o produto de seu apotema, OG, por seu semi-permetro.
Aplicando isso ao polgono In, vemos que ele tem area igual `a do triangulo
retangulo no qual os catetos sao iguais, respectivamente, ao apotema e ao
permetro do polgono regular de 2n lados inscrito no crculo. Como os
apotemas e os permetros dos polgonos inscritos sao sucessivamente me-
nores que o raio e a circunferencia do crculo, ou seja, menores do que os
lados correspondentes do triangulo de area T , podemos concluir que a area
de In < T para todo n. Logo, a area de In < T < C.
Como a area de In e menor do que C, podemos obter uma quantidade
kn = C  area (In). Usando o Lema de Euclides, quando aumentamos o
numero de lados do polgono esta quantidade pode ser tornada menor do que
qualquer quantidade dada. Logo, para n suficientemente grande, podemos
obter kn < d. Mas, como
3.2. ARQUIMEDES 117
Figura 3.8
area de In < T < C, d = C  T < C  area (In) = kn,
chegamos a uma contradicao.
Voltando `a nossa demonstracao, isto implica que podemos tomar kn me-
nor do que d no raciocnio anterior. Para finalizar a demonstracao, supomos
agora que C < T e teremos novamente uma contradicao. Se C < T , temos
d = T  C > 0. O argumento e analogo, usando polgonos circunscritos.
Isso termina a demonstracao da proposicao de Arquimedes.
Mas, como calcular ?
Para fazer isso, Arquimedes, inicialmente, inscreveu e circunscreveu he-
xagonos regulares em uma circunferencia de crculo de raio 1. Em seguida,
ele duplicou sucessivamente seus numeros de lados. Assim, ele inscreveu
os polgonos regulares com 3  2n1 lados, cujos semipermetros sao bn e
circunscreveu polgonos regulares com 3  2n1, cujos permetros sao an. As
sequencias bn e an sao respectivamente decrescentes e crescentes e temos que
bn < 2 < an.
Os Exerccios 5 e 6 desta secao mostram como podemos chegar a uma
boa aproximacao de  por este metodo.
3.2.3 A espiral de Arquimedes e a trissecao do angulo
Estudaremos, agora, a espiral de Arquimedes, curva importante, e que permite
resolver dois dos problemas classicos da geometria grega, a trisseccao do
angulo e a quadratura do crculo.
Transcrevemos a definicao de espiral proposta por Arquimedes (Ver [81],
p. 154):
118 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
Se uma linha reta tracada em um plano se move uniforme-
mente em torno de uma extremidade fixa e retorna `a sua posicao
de partida, e se ao mesmo tempo em que a reta se move (uniforme-
mente), um ponto partindo da origem se move (uniformemente)
sobre a reta, este ponto ira descrever uma espiral no plano.
Por esta definicao, baseada na nocao de proporcionalidade, temos que a
espiral e uma curva gerada por um ponto que se move sobre um segmento
de reta com velocidade constante ao mesmo tempo em que este segmento
de reta se move, tambem com velocidade constante, circularmente com uma
extremidade fixa e a outra sobre uma circunferencia. A partir desta definicao
mecanica, Arquimedes define a propriedade fundamental da espiral:
Consideremos a espiral com extremidades em O e R e o crculo corres-
pondente de raio OR (Veja a Figura 3.9). Entao, Arquimedes mostra que
se dois segmentos de reta, OO2 e OO1, sao tracados da origem O ate dois
pontos sobre a espiral e se estes segmentos, prolongados, cortam o crculo
respectivamente em R2 e R1, temos que estes segmentos estarao entre si na
mesma razao que os arcos de circunferencia correspondentes.
Figura 3.9
Ou seja,
OO2  OO1  arco RR2  arco RR1.
Com efeito, quando a reta OR gira, os pontos Ri se movem com veloci-
dade uniforme sobre a circunferencia enquanto os pontos Oi se movem com
velocidade uniforme sobre o segmento de reta OR. Sendo assim, quando R
chega a R1, o ponto O chega a O1 e quando R chega a R2 o ponto O chega
a O2. 
3.2. ARQUIMEDES 119
Como ja mencionamos, o problema de dividir um angulo em tres partes
iguais era um dos problemas importantes da geometria grega. Sabemos di-
vidir um angulo em duas partes iguais com regua e compasso, mas muitas
foram as tentativas frustradas de encontrar um procedimento analogo para
o caso da trisseccao do angulo. Uma aplicacao da Espiral de Arquimedes e
justamente permitir achar uma solucao para este problema. Isso e feito como
segue.
Seja o angulo P OQ que desejamos dividir em tres. Marque os pontos
Q1 e Q2 de modo que dividam OQ em tres partes iguais. Tracamos, entao,
dois arcos de circunferencia com centro em O e com raios OQ1 e OQ2 que
cortarao o trecho de espiral que vai de O a Q em dois pontos O1 e O2. Entao,
as retas OO1 e OO2 trissectam o angulo P OQ.
Figura 3.10
Com efeito. Tracemos uma circunferencia de raio OT0, que define a es-
piral, e marquemos os pontos T1 e T2 sobre a mesma, prolongando OO1 e
OO2. Sejam os pontos T0 e T os pontos de encontro dos prolongamentos de
OP e OQ com a circunferencia de raio OT0 respectivamente. Pela propri-
edade da espiral, o arco de circunferencia T0T1 esta para o arco T0T assim
como o segmento OO1 esta para o segmento OQ. Mas, mas por construcao,
OO1 = OQ1 = OQ/3, o que demonstra que o segmento OO1 trissecta o angulo
P OQ. Isto porque o arco T0T1 divide T0T em tres. O mesmo raciocnio pode
ser feito para o segmento OO2. 
Este procedimento permite dividir um angulo em um numero, n, de par-
tes: e suficiente dividir o segmento OQ em n partes.
Observe que a solucao para o problema da trisseccao e mecanica, pois e
gerada por dois movimentos combinados, e leva em consideracao a velocidade.
Assim, ela nao seria aceita como uma solucao genuinamente geometrica pelos
padroes euclidianos. Mas esta limitacao nao impediu que os matematicos da
epoca explorassem construcoes deste tipo em problemas nao elementares.
A principal propriedade da espiral, que e bastante util para problemas
120 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
de construcao, esta no fato de associar uma razao entre arcos (ou angulos) a
uma razao entre segmentos. A espiral estabelece uma proporcionalidade entre
uma distancia em linha reta e uma medida angular, o que permite reduzir
o problema de dividir um angulo em partes iguais ao problema simples de
dividir um segmento de reta em partes iguais. A distancia entre a origem e
um ponto sobre a espiral e proporcional ao angulo formado pela reta inicial e
pela reta que compoe este angulo. Esta e exatamente a propriedade expressa,
em linguagem atual, pela equacao polar da espiral, que pode ser escrita na
forma r = a,  0.2.
A espiral de Arquimedes tambem pode ser usada para resolver o problema
da quadratura do crculo, como indicado a seguir. Como exerccio, deixamos
ao leitor completar os detalhes da demonstracao.
Sejam O o ponto inicial da espiral e P o ponto quando ela completa
a primeira volta (ou seja, quando  = 2). Trace a tangente `a espiral no
ponto P , e seja T o ponto em que esta tangente intercepta a perpendicular
a OP , pelo ponto O. Entao, na proposicao 19 de seu livro sobre as espirais,
Arquimedes prova que OT e o comprimento da circunferencia de centro O e
raio OP .
Como Arquimedes demonstrou, em sua obra Sobre a medida do crculo,
que a area de um crculo e igual `a area do triangulo retangulo cujos catetos
medem, respectivamente, o raio e a circunferencia do crculo, segue-se que a
area do crculo de raio OP e igual `a area do triangulo OP T .
Exerccios
3.1. Identifique claramente em que passos da demonstracao da proposicao
23, sobre a quadratura da parabola (pagina 113), Arquimedes usa o
lema de Euclides e como o emprega.
(Sugestao: Utilize a Figura 3.11.)
3.2. Como voce demonstraria a proposicao 23 usando series infinitas? Como
voce garante que as series empregadas sao de fato convergentes?
3.3. Demonstre, com detalhes, a segunda parte da proposicao 1 de Arqui-
medes, sobre a quadratura do crculo, ou seja, faca a demonstracao
completa da etapa em que Arquimedes emprega polgonos circunscri-
tos.
2A quadratriz, outra curva estudada pelos geometras gregos, permite tambem associar me-
didas lineares com medidas angulares, e portanto possibilita, tambem, a trisseccao do angulo.
Veja Carvalho,[28], para uma exposicao desta e de varias outras curvas criadas pelos gregos
para resolver problemas geometricos.
3.2. ARQUIMEDES 121
Figura 3.11
3.4. Euclides demonstrou, em XII.2, que crculos estao entre si como os qua-
drados de seus diametros. Chamando de A1 e de A2, respectivamente
a area dos dois crculos, cujos raios sao r1 e r2, e cujas circunferencias
sao C1 e C2, entao
A1
A2
= (r1)2
(r2)2 .
1. Prove que existe uma constante de proporcionalidade, k, tal que
A1
(2r1)2 = A2
(2r2)2 .
Por outro lado, como acabamos de ver, Arquimedes demonstrou
que
2A1 = C1  r1,
2A2 = C2  r2.
2. Prove que a constante k, e tal que
k = C1
2r1
= C2
2r2
.
Ou seja, demonstramos que a mesma constante de proporcionalidade
relaciona a area de um crculo com seu raio e a circunferencia do mesmo
crculo com seu raio. Hoje esta constante e chamada de de . Assim,
A = r2,
122 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
e
C = 2r.
3.5. Dada a formula para o permetro de um polgono regular com n lados,
obtenha a formula para o permetro do polgono com 2n lados (Figura
3.12). Note inicialmente que todo hexagono regular e inscritvel e que
seu lado e igual ao raio do crculo circunscrito. Use entao a seguinte
proposicao (proposicao VI.3 dos Elementos de Euclides): Se o angulo
de um triangulo e bissectado por uma reta que divide o lado oposto em
dois segmentos, a razao entre estes segmentos e igual `a razao entre os
outros dois lados do triangulo.
Figura 3.12
3.6. Aplicando sucessivamente aos polgonos a formula encontrada no e-
xerccio anterior, mostre que podemos obter limites cada vez mais
proximos de . Quantos lados tinham os polgonos que Arquimedes
empregou para achar a aproximacao 223/71 <  < 22/7 ?
3.7. Complete os detalhes da demonstracao esbocada na pagina 120 para
provar que a espiral de Arquimedes resolve o problema da quadratura
do crculo.
3.8. Usando a equacao r = a,  0. Use um programa de computador para
explorar diversos tipos de espiral de Arquimedes. Aumente  para alem
de 2 e investigue o que acontece com a distancia r. Faca a variar. O
que acontece com o comprimento do raio vetor quando variamos a de
1 a 2 e de 1 a 1/2?. Experimente, em seguida, valores negativos para a
e .
3.3. APOL ONIO E AS C ONICAS 123
3.9. A construcao a seguir, que utiliza neusis, e um exemplo das varias so-
lucoes do problema da trisseccao do angulo propostas por Arquimedes.
Figura 3.13 Trisseccao do angulo por Arquimedes
Suponha que desejamos trissectar o angulo BOA. Tome uma reta r
que passa por B e, tendo o cuidado para que ela sempre passe por
B, movimente-a para que o segmento MN seja igual ao raio OM do
crculo. Isso e exatamente o que se denomina uma construcao por
neusis: Ajustamos um segmento (o raio OM) entre o crculo e a linha
reta que passa por C e por A.
Prove que
BOA = BNO + MBO = 3  BNO.
3.3 Apolonio e as conicas
Antes de comecar a apresentar a maneira de Apolonio abordar as conicas, e
necessario uma breve introducao `as aplicacoes de area da geometria grega.
Em lngua portuguesa, maiores detalhes podem ser vistos em [27].
3.3.1 A aplicacao de areas
O que e, na terminologia matematica grega, aplicar uma figura (poligonal) a
uma reta dada? Esse problema consiste em construir a figura dada de tal
maneira que o segmento de reta seja um de seus lados. Em geral, e exigido
que a figura construda, preencha algumas exigencias. Por exemplo, sejam
ABCDE um polgono e KL um segmento de reta (Figura 3.14). Aplicar ao
segmento KL, por exemplo, um paralelogramo, com area igual a ABCDE,
significa construir um paralelogramo KLRS de que KL e um dos lados, e
124 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
cuja area seja igual `a area de ABCDE. Pode tambem ser pedido que o
paralelogramo atenda a outras exigencias, como, por exemplo, ter o angulo
SKL igual a um angulo dado.
Na maioria das aplicacoes, o paralelogramo aplicado e um retangulo, ou
seja, o angulo SKL e reto. Neste livro, nos limitaremos a este caso.
Figura 3.14 Aplicacao de areas
Os gregos usavam tres tipos de aplicacao de areas, listados a seguir:
1. Aplicacao parabolica;
2. Aplicacao elptica;
3. Aplicacao hiperbolica.
Em sua formulacao mais geral, a solucao desses problemas exige conhe-
cimentos do Livro VI dos Elementos, que trata exatamente da teoria de pro-
porcionalidade de grandezas, de Eudoxo (exposta no Livro V dos Elementos)
no caso particular das figuras planas.
Aplicacoes parabolicas
Uma aplicacao parabolica (Veja a Figura 3.15) consiste em aplicar a um
segmento (de) um paralelogramo (DEF G) igual a uma figura dada (S), com
um angulo especificado (ABC). Trataremos somente do caso de aplicar um
retangulo a um segmento. Ou seja, construir um retangulo, de que um dos
lados e um segmento dado, e igual a uma figura poligonal dada.
Aplicacoes elpticas.
Em sua formulacao geral, uma Aplicacao elptica ou com falta consiste em a
aplicar a um segmento de reta AB, um paralelogramo, com um angulo dado,
igual a um polgono dado, e de tal maneira que o que falta para completar
3.3. APOL ONIO E AS C ONICAS 125
S
FG
ED
A
CB
Figura 3.15 Aplicacao de areas parabolica
Figura 3.16 Aplicacao de areas elptica ou com falta
a figura a todo o segmento AB seja um paralelogramo semelhante a um
paralelogramo dado (Figura 3.16).
No caso que nos interessa, o de retangulos, o problema e reformulado da
seguinte forma: Dado o polgono C, pede-se que seja construdo o retangulo
ASUT , com area igual `a de C, e tal que SBRU seja um quadrado. dado. O
quadrado SBRU e o que falta para que ASUT tenha AB como lado, isto
e, esteja aplicado a AB. E este problema que resolveremos.
Aplicacoes hiperbolicas
Uma Aplicacao hiperbolica ou com excesso consiste em aplicar a um segmento
de reta AB, um paralelogramo, com um angulo dado, igual a um polgono
dado, e de tal maneira que ele excede o segmento AB por um paralelogramo
semelhante a um paralelogramo dado (Figura 3.17).
Dado o polgono C, pede-se que seja construdo o paralelogramo AP OR
com area igual `a de C, e tal que BP OQ seja semelhante ao paralelogramo
D. O paralelogramo BP OQ e o excesso para que ABQR tenha lado AB,
isto e, esteja aplicado a AB.
Nao abordaremos o problema nesta formulacao mais geral. Mostraremos
somente como resolve-lo, no caso em que o paralelogramo aplicado e um
retangulo, e que o excesso e um quadrado.
126 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
R
Figura 3.17 Aplicacao de areas hiperbolica ou com excesso
3.3.2 As conicas
Os nomes parabola, elipse e hiperbole tem origem no metodo euclidi-
ano de aplicacao de areas, exposto nos Elementos de Euclides, nas proposicoes
15 a 19 do Livro VI. A aplicacao exata e chamada de parabola, a aplicacao
por falta e uma elipse e a aplicacao por excesso, uma hiperbole. Qual
seria, portanto, a relacao entre estes metodos euclidianos e a construcao das
conicas?
Na verdade, ate os trabalhos de Apolonio de Perga, estas curvas nao eram
classificadas dessa maneira, justamente porque nao eram utilizadas aplicacoes
de areas na definicao das conicas. Alguns matematicos da escola de Eudoxo,
como Menecmo e Aristeu, descobriram estas curvas estudando o problema da
duplicacao do cubo. Eles concebiam as conicas como a intersecao de um cone
com o plano perpendicular a sua geratriz. Para estes matematicos, bem como
para Euclides e Arquimedes, os tres tipos de conica (denominadas mais tarde
por Apolonio elipse, parabola e hiperbole) eram obtidas, respectivamente,
quando o angulo do vertice do cone era agudo, reto ou obtuso.
Apolonio foi o primeiro a conceber as conicas como intersecoes de uma
mesma superfcie conica circular, nao necessariamente reta, cortada por pla-
nos de inclinacoes diferentes. Seu livro mais celebre, escrito no seculo III
a.E.C., chamado Conicas, traz um apanhado de muitos resultados sobre
conicas, obtidos ate aquele momento por seus antecessores, mas contem
tambem inovacoes importantes. Uma das novas concepcoes introduzidas por
Apolonio, utilizadas ate hoje, e a consideracao de um cone de duas folhas. A
partir deste cone, as secoes conicas passarao a ser caracterizadas do seguinte
modo: se o plano corta todas as geratrizes sobre uma mesma folha do cone,
obtemos uma elipse; se o plano e paralelo a uma das geratrizes, obtemos uma
parabola; e se o plano corta as duas folhas do cone, obtemos uma hiperbole.
Este ponto de vista de Arquimedes unifica as conicas, como membros de uma
mesma famlia de curvas.
Veremos agora o modo como Apolonio construiu a parabola e sua relacao
com o metodo de aplicacao de areas.
Seja o cone da Figura 3.18, de vertice T , cortado pelo plano de secao P1:
3.3. APOL ONIO E AS C ONICAS 127
B
M
KP
Q
A
O
ZE
V
W
H
T
Figura 3.18
O triangulo T V W esta em um plano que corta o cone em seu eixo T M
(reta pelo vertice ate o centro da base). O segmento V W e a intersecao
deste plano com a base do cone, que faz angulos retos com o segmento EZ
(no qual o plano de secao intercepta a base). O plano de secao P1 corta
T V W no segmento AH. Um plano P2 paralelo `a base corta o cone em uma
circunferencia com P Q como diametro e intercepta o plano de secao em KO.
O ponto K esta sobre o cone e sobre plano de secao, sendo assim um ponto
da conica.
Um os aspectos mais importantes do metodo usado por Apolonio, que ja
era empregado tambem por seus antecessores, e a caracterizacao da conica
por meio de um sintoma. Trata-se de uma relacao entre grandezas que ca-
racteriza os pontos que estao sobre a conica. Vejamos como o sintoma da
parabola e obtido no exemplo acima, em que o plano de secao e paralelo a
T V (como o cone nao e de revolucao, T V nao e geratriz).
Seja KO a meia proporcional de QO e P O. Sabemos, pela propriedade da
circunferencia, que o quadrado de lado KO tem area igual `a de um retangulo
de lados QO e P O (Veja a Figura 3.19). Por um abuso de linguagem, ou seja,
modernizando a linguagem matematica de Apolonio, que usa somente pala-
vras, diremos que KO2 = QO  P O. Mas, na figura 3.19, BA foi construdo
para ser paralelo a V W e igual a QO. Logo,
BA  T A  V W  T W
e
P O  AO  W V  T V
Como BA = QO, podemos obter destas proporcoes que
QO  P O  T A  AO  V W 2  T W  T V.
128 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
ZE
K
P
B
O
H
A
Q
T
W
V
Figura 3.19
Definimos agora um segmento N por
N  T A  V W 2  T W  T V.
Segue-se desta definicao que
N  T A  QO  P O  T A  AO.
Mas sabemos que KO2 = QO  P O, logo podemos dizer que
N  T A  KO2  T A  AO.
Por outro lado,
N  T A  N  AO  T A  AO.
Destas duas igualdades podemos tirar a relacao KO2 = N  AO, que e
o sintoma da parabola obtida interceptando-se o cone pelo plano de secao
definido paralelamente a T V .
O segmento KO e chamado, ja por Apolonio, de ordenada, que quer di-
zer literalmente desenhado em uma direcao conjugada. Podemos concluir,
portanto, que ha duas direcoes conjugadas, KO e AO, que sao co-ordenadas,
ou seja, uma e tomada em uma direcao conjugada `a outra. O sintoma e uma
relacao caracterstica entre estas duas co-ordenadas de um ponto qualquer
sobre a curva.
Traduzindo em nossa linguagem algebrica, e como se tivessemos um sis-
tema de coordenas oblquo de origem A dado por AH e EZ. Fazendo N = p
(que e uma constante que determina a natureza da parabola), as coordenadas
3.3. APOL ONIO E AS C ONICAS 129
obtidas pela construcao seriam AO = x e KO = y. Desta forma, o sintoma
poderia ser reescrito como y2 = px, que e justamente a equacao da parabola.
Isto nao quer dizer que Apolonio ja empregava equacoes. Para ele, o
significado da relacao KO2 = N  AO (sintoma) era que o quadrado de lado
KO aplicado parabolicamente (ou seja, exatamente) sobre N fornece um
retangulo de lado AO. Da o nome parabola para a curva obtida neste
caso. Traduzir os resultados de Apolonio em linguagem algebrica, como
feito por Zeuthen ([152]) e anacronico e e tpico dos defensores da algebra
geometrica dos gregos.
De maneira semelhante, Apolonio estuda a elipse e a hiperbole, relaciona-
das a aplicacoes por falta e por excesso, respectivamente (Veja, por exemplo
[80], [65]).
Exerccios
3.10. Siga o roteiro abaixo para resolver o problema de aplicar um retangulo
a um segmento dado.
 Demonstre a proposicao I.43 dos Elementos de Euclides:
Proposicao I.43: Em qualquer paralelogramo, os complementos
dos paralelogramos em torno da diagonal sao iguais entre si. (Figura
3.20)
Figura 3.20 Elementos I.43
 Demonstre, no caso em que o paralelogramo dado e um retangulo,
e o angulo dado e reto, a proposicao I.44 dos Elementos:
Proposicao I.44:  Aplicar a um segmento dado um paralelogramo
igual a uma area dada, e com um angulo dado.(Veja a Figura 3.21).
De um ponto de vista totalmente anacronico, completamente fora
das cogitacoes dos matematicos gregos, se o comprimento de AB
e a, entao o comprimento de KL resolve a equacao ax = S.
3.11. Siga o roteiro abaixo para aplicar um retangulo a um segmento, com
falta.
130 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
Figura 3.21
 Refaca o Exerccio 15, da pagina 91, que pedia a demonstracao da
proposicao II.5 dos Elementos.
 Efetue a construcao indicada a seguir:
Seja C o ponto medio do segmento AB. Trace CO perpendicular a
AB e igual a b. Prolongue OC ate N, de maneira que ON = CB.
Com centro em O, e raio ON, descreva uma circunferencia que
corta CD em D (Figura 3.22).
Figura 3.22 Resolucao do problema de aplicacao de areas elptica
Demonstre que o retangulo de lados AD e DB resolve nosso pro-
blema.
Esta construcao resolve completamente o problema de aplicar
um retangulo a um segmento, com falta, de maneira que o que
falta seja um quadrado.
3.12. Siga o roteiro abaixo para aplicar um retangulo a um segmento, com
excesso, no caso em que o excesso e um quadrado.
 Refaca o Exerccio 15, da pagina 91, que pedia a demonstracao da
proposicao II.6 dos Elementos.
3.4. A ARITM ETICA DE DIOFANTO 131
 Efetue a seguinte construcao :
Em primeiro lugar, podemos supor que a area dada e um quadrado
de lado b. Trace BQ perpendicular a AB e igual a b. Una C a Q
e com centro C e raio CQ, descreva uma circunferencia que corta
o prolongamento de AB em D. Prove que o ponto D resolve o
problema (Figura 3.23).
Figura 3.23 Resolucao do problema de aplicacao de areas hiperbolica
3.4 A aritmetica de Diofanto
No Captulo 1, descrevemos alguns procedimentos empregados pelos povos
antigos que poderiam ser resolvidos, hoje, por equacoes. No entanto, vimos
o quanto seria anacronico associar os algoritmos usados a qualquer tipo de
algebra. De modo analogo, no captulo anterior observamos tambem que
seria inadequado considerar que havia uma algebra nos Elementos de Eu-
clides. Em ambos os casos, uma das mais fortes razoes para nao tirarmos
conclusoes apressadas e o fato de que nao era usado nenhum tipo de notacao
algebrica, que implica em se utilizar um mesmo smbolo para designar coisas
diferentes. Em particular, a quantidade desconhecida, que chamamos hoje
de incognita, nao era representada por uma notacao especfica.
Ainda no mundo grego, com os trabalhos de Diofanto, surge um modo de
pensar bem mais proximo do que chamamos de algebra. Este matematico,
que viveu no seculo III E.C., 3 portanto bem depois do que os outros que
consideramos neste captulo, introduziu um novo modo de pensar em um
livro chamado Aritmetica. Uma de suas principais contribuicoes esta em ter
introduzido uma forma de representar o valor desconhecido em um problema,
designando-o como arithme, de onde vem o nome aritmetica. Esta obra
contem uma colecao de problemas que faziam parte da tradicao matematica
3Em verdade, ha grande incerteza sobre a epoca em que viveu Diofanto
132 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
da epoca. Ja no Livro 1, ele introduz smbolos, que ele chama designacoes
abreviadas, para representar diversos tipos de numero:
 ((ultima letra da palavra arithmos, a quantidade desconhecida)
Y (primeira letra de dynamis, o quadrado da quantidade desconhecida)
KY (primeira letra de kybos, o cubo)
Y  (o quadrado-quadrado) [quarta potencia]
KY (o quadrado-cubo) [quinta potencia]
KY K (o cubo-cubo) [sexta potencia]
Notamos que o fato de haver smbolos para as potencias superiores ao
cubo ja indica a separacao entre a aritmetica de Diofanto e a geometria,
uma vez que, na geometria da epoca, uma potencia maior que tres para um
numero nao correspondia a nenhuma grandeza. Para dar um exemplo de
como estes smbolos eram usados, descrevemos a solucao do problema 27 do
Livro 1:
Exemplo 3.1. Encontrar dois numeros cuja soma e produto sejam numeros
dados.
Na verdade, Diofanto considera que a soma e 20 e o produto e 96. Este
tipo de procedimento sera comum ate que o simbolismo algebrico se encon-
tre desenvolvido: chegar a resultados gerais com um caso especfico, bem
representativo da situacao geral.
Suponhamos que a diferenca entre os dois numeros seja 2 arithmoi. Co-
mecamos por dividir a soma destes numeros (que e 20) em dois (obtendo
10). A partir deste resultado, consideramos um arithmos somado e subtrado,
respectivamente, a cada uma das metades. Como a metade da soma e 10,
tomando a metade subtrada de 1 arithmos mais a metade acrescentada de
1 arithmos obtemos 20, que e a soma desejada. Para que o produto seja 96,
multiplicamos estas mesmas quantidades, obtendo 100 subtrado do quadrado
do arithmos (um dynamis). Chegamos, assim, `a conclusao de que o dynamis
deve ser 4, logo o valor do arithmos e 2. Os valores procurados serao, portanto,
10 mais 2 e 10 menos 2, ou seja, 12 e 8.
Explicacao misturando as abreviacoes de Diofanto com os smbolos atuais
para as operacoes: Queremos encontrar dois numeros com soma 20 e produto
96. Se estes numeros fossem iguais, cada um deles seria 10. Supomos que a
diferenca entre eles seja 2, ou seja, os dois numeros procurados sao obtidos
retirando  de um destes 10 e adicionando  ao outro. Como a soma nao muda
apos estas operacoes, temos 10   + 10 +  = 20. Mas sabemos tambem que
o produto destes numeros e 96, logo podemos escrever (10  )(10 + ) = 96.
3.4. A ARITM ETICA DE DIOFANTO 133
Conclumos da que o valor de  deve ser 2. Logo, os numeros procurados
sao respectivamente, 8 e 12.
Notem que uma primeira novidade e o fato de nao se recorrer a nenhuma
construcao geometrica para resolver o problema. Uma segunda grande inovacao
e que, na resolucao deste problema, opera-se com quantidades desconhecidas
do mesmo modo que com as conhecidas. Quantidades conhecidas e desconhe-
cidas possuem o mesmo estatuto na resolucao do problema. Logo, supoe-se,
de alguma forma, que todas sejam conhecidas. So por esta razao sera possvel
introduzir um smbolo para uma quantidade desconhecida (a letra ). Isso
caracteriza um pensamento algebrico.
Para Diofanto, o arithme e uma quantidade indeterminada de unida-
des, diferente dos numeros, que sao formados de uma certa quantidade,
determinada, de unidades. No entanto, ambos sao sujeitos ao mesmo tipo de
tratamento:
Do mesmo modo que as partes dos numeros sao denominadas
de maneira correspondente a estes numeros, como o terco cor-
responde a tres, o quarto corresponde a quatro, denominaremos
tambem as partes dos numeros definidos acima [os arithmes] de
maneira correspondente a estes numeros. Por exemplo, para o
arithme, diremos o inverso do arithme, para sua potencia, diremos
o inverso do quadrado. (Eecke, 1926, p.3).
A natureza dos novos objetos, e as operacoes que podemos realizar com
eles, esta calcada sobre a estrutura dos numeros determinados, que sao os
numeros propriamente ditos. Com o objetivo de resolver problemas, os diver-
sos tipos de numeros podem ser agrupados em especies, que correspondem
aos nossos monomios, ou em expressoes, que resultam das operacoes entre
especies.
As solucoes sao descritas de modo discursivo, como no exemplo acima,
mas esta descricao e abreviada pelo uso de smbolos (para numeros, potencias
de numeros, fracoes, incognitas e monomios) que constituem um princpio de
linguagem algebrica4. Este modo de representacao, que nao e ainda comple-
tamente simbolico, e chamado hoje de algebra sincopada. Os smbolos sao
usados para abreviar o texto que descreve a resolucao de um problema.
Alguns historiadores, como Heath, acreditam que e possvel encontrar, em
meio `a enorme variedade de exemplos, alguns procedimentos comuns que se
prestam a um enunciado geral. Em alguns casos, vemos mesmo regras gerais,
4Os resultados dos problemas eram apenas numeros racionais positivos. Da dizermos hoje
que um problema e diofantino quando se procuram suas solucoes racionais positivas. Uma
solucao que nao era um numero racional positivo era declarada inadmissvel.
134 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
como para a solucao de equacoes determinadas ditas puras, que contem
apenas uma potencia da quantidade desconhecida, de um grau qualquer.
Diz Diofanto, na definicao 11:
Se um problema leva a uma equacao na qual quaisquer ter-
mos sao iguais aos mesmos termos mas tem coeficientes distintos,
temos que retirar os semelhantes dos semelhantes em ambos os
lados, ate que obtenhamos um termo igual a um termo. Mas, se
existe de um lado, ou em ambos, algum termo negativo, o termo
deficiente deve ser adicionado a ambos os lados ate que os termos
nos dois lados sejam positivos. Em seguida, retiramos semelhan-
tes de semelhantes ate que reste um termo em cada lado.
Em linguagem atual, diramos que o procedimento serve para reduzir a
equacao `a forma Axm = B. Ainda que esta regra tenha alguma generali-
dade, vemos por este exemplo o quanto seria difcil exprimir regras gerais
por meio unicamente de palavras, sem os recursos de nosso poderoso sim-
bolismo algebrico. Alguns autores relacionam a descricao de procedimentos
gerais `a necessidade de transmissao das tecnicas aritmeticas, ou seja, a uma
tradicao escolar que estava na base do ensino de Matematica. No Captulo
4, ficara claro como a introducao de um novo simbolismo foi fundamental na
constituicao da algebra. A traducao da Aritmetica de Diofanto tera um papel
importante neste desenvolvimento.
Exerccios
3.13. Resolva o seguinte problema de Diofanto: Ache dois numeros tais que
sua diferenca e a diferenca de seus cubos sao iguais a dois numeros dados.
3.14. Mostre que nao pode existir um triangulo retangulo cujos lados sao
numeros inteiros e tal que a bissetriz do angulo reto e um numero
racional.
3.15. Resolva os seguintes problemas que fazem parte da Aritmetica de Dio-
fanto:
 (Problema 21, Livro IV). Ache tres numeros em progressao ge-
ometrica tais que a diferenca entre dois quaisquer deles seja um
numero quadrado.
 (Problema 7, Livro III) Ache tres numeros em progressao aritme-
tica e tais que a soma de dois quaisquer deles seja um numero
quadrado.
3.5. A TRIGONOMETRIA NA GRECIA ANTIGA 135
3.5 A trigonometria na Grecia antiga
A trigonometria foi uma criacao da Matematica grega, e recebeu contribui-
coes importantes de matematicos de varias culturas: hindus, muculmanos e
europeus. Ela surgiu devido `as necessidades da astronomia, a fim de prever
as efemerides celestes, calcular o tempo e ser utilizada na navegacao e na geo-
grafia. Assim, os estudos de trigonometria se concentravam na trigonometria
esferica, que estuda triangulos esfericos, isto e, triangulos sobre a superfcie
de uma esfera. No entanto, foi necessario para isso desenvolver partes da
trigonometria plana.
No mundo grego, foram desenvolvidas diversas tecnicas para medir a
posicao dos astros. Desde a epoca de Platao, o modelo grego para descre-
ver os movimentos celestes baseava-se em duas esferas concentricas. A Terra
era tida como uma esfera fixa envolvida por uma outra esfera, de diametro
muito maior, sobre a qual se encontram os corpos celestes. Incrustadas na
superfcie interna da esfera celeste estao as estrelas fixas, que vemos em mo-
vimento devido ao giro da esfera. Mas, alem dos fixos, ha tambem os corpos
celestes errantes, que vagueiam sobre a superfcie da esfera. Estes incluem o
Sol e a Lua e sao chamados planetas (palavra grega que designa justamente
o que e errante, vagabundo). Para os gregos, todos estes corpos celes-
tes, moviam-se, por princpio, uniformemente, pois nao podemos imaginar
movimentos perfeitos que admitam variacao de velocidade.
Como os astros se movem sobre a superfcie de uma esfera, a fim de poder
calcular suas posicoes, e necessario usar trigonometria esferica, que lida com
triangulos esfericos. Mas esta exige conhecimentos de trigonometria plana.
Especificamente, os problemas que interessavam eram problemas de resolucao
de triangulos, ou seja, dados alguns dos elementos de um triangulo  lados e
angulos  calcular os outros.
O estudo dos triangulos esfericos na Matematica grega vinha sendo feito
anteriormente a Euclides. Ele proprio, em um de seus trabalhos, o Fenomenos,
estudou a geometria esferica. mais tarde, aproximadamente em 20 a.E.C.,
Teodosio compilou o que os gregos conheciam sobre o assunto em seu livro
Sobre a Esfera.
Aristarco de Samos, que viveu em torno de 300 a.E.C., em seu livro Sobre
as distancias do sol e da lua, baseando-se em observacoes, deduziu que
 A distancia da terra ao sol e maior do que 18 vezes e menor do que
20 vezes a distancia da terra `a lua. Na demonstracao deste fato vemos
pela primeira vez a aproximacao do seno de um angulo pequeno.
 Os diametros do sol e da lua tem a mesma razao que suas distancias
da terra.
136 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
 A razao do diametro do sol para o diametro da terra e maior do que
19/3 e menor do que 43/6.
Os erros cometidos por Aristarco devem-se aos dados experimentais que
utilizou. Seus raciocnios dedutivos estavam corretos.
Podemos contudo dizer que o fundador da trigonometria foi Hiparco de
Niceia, que viveu em tomo de 120 a.E.C. Semelhantemente a muitos ma-
tematicos gregos, inclusive ao proprio Euclides, pouco sabemos sobre sua
vida. A maior parte do que conhecemos sobre ele e devida a Ptolomeu o
qual cita varios resultados de Hiparco sobre trigonometria e astronomia, e
a fragmentos de descricoes de seus trabalhos contidos nas obras de outros
autores gregos.
Hiparco tem sido considerado como o primeiro a determinar com precisao
o nascer e o ocaso de varias estrelas, usando para isso uma tabela de cordas
por ele calculada. Suas tabelas foram construdas para serem usadas em
astronomia. As principais contribuicoes de Hiparco em astronomia foram a
organizacao dos dados empricos babilonios, a confeccao de um catalogo de
estrelas e a descoberta da precessao dos equinocios.
Para construir sua tabela, Hiparco necessitava, em primeiro lugar, de
uma medida de inclinacoes ou de angulos. Ate os Elementos de Euclides, os
angulos eram medidos por multiplos ou submultiplos do angulo reto. Mais
tarde, os astronomos gregos utilizavam o sistema sexagesimal dos babilonios,
que ja dividiam a circunferencia em 360 partes, cada uma correspondendo
a um grau, e estabeleciam subdivisoes em minutos e segundos, em estreita
relacao com a base sessenta utilizada por eles.
Temos notcia da tabela de Hiparco devido a fontes indiretas, sobretudo
o Almagesto de Ptolomeu. E provavel que a divisao do crculo em 360 tenha
se originado com a tabela de cordas de Hiparco. Ele provavelmente seguiu a
ideia do matematico grego Hipsiclo, o qual por sua vez tinha dividido o dia
em 360 partes, uma divisao possivelmente inspirada na astronomia babilonia.
Os matematicos gregos nao usavam o seno de um angulo, e sim trabalha-
vam com a corda do arco duplo. Dado o angulo  = AOC, o dobro de  e o
angulo AOB, que subtende o arco AB, e a a corda do arco duplo AB sera o
segmento AB. Alem disso, devido `a influencia babilonia, os gregos tomavam
o raio OA com comprimento 60 e dividiam o crculo em 360 partes iguais.
Vemos entao imediatamente que:
sen  = AC
OA = 1
2
corda AB
OA = 1
120 corda AB.
Todos os matematicos gregos que eram obrigados em seus trabalhos a efe-
tuar calculos com fracoes (Arquimedes e Ptolomeu, entre outros) utilizavam
3.5. A TRIGONOMETRIA NA GRECIA ANTIGA 137
B
C
A
O
Figura 3.24
as fracoes sexagesimais babilonias, devido `a facilidade que elas introduziam
em seus calculos, da a razao do raio de comprimento 60.
Um pouco depois de Hiparco, Menelau de Alexandria, que viveu em torno
de 100 a.E.C., ja apresenta uma trigonometria bem desenvolvida, de que
podemos ver partes em seu livro Geometria esferica, o qual nos chegou em
versao arabe. Nele, Menelau demonstra varios teoremas sobre triangulos
esfericos. Provou, por exemplo, que se dois triangulos esfericos tem angulos
correspondentes iguais, entao os triangulos sao iguais (congruentes). Ele
usou, sem demonstrar, o teorema de geometria plana conhecido hoje como
teorema de Menelau: Se o triangulo ABC e cortado por uma secante que
intersecta seus tres lados como mostrado na Figura 3.25 entao
NA  RB  MC = NC  RA  MB.
NR
A
MCB
Figura 3.25
Menelau, contemporaneo de Ptolomeu, usou este teorema a fim de provar
o resultado correspondente para triangulos esfericos e parece ter escrito o
primeiro tratado especificamente sobre trigonometria esferica.
A trigonometria grega atingiu seu apice com Claudio Ptolomeu, que viveu
em torno de 150 E.C. Seu principal trabalho, o Almagesto, permite datar a
aproximadamente sua vida, pois nele Ptolomeu se refere a observacoes que fez
138 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
de efemerides astronomicas cujas datas conhecemos. O nome grego original
desta obra e A colecao matematica, ou seja, A sintaxe matematica, que foi
traduzido pelos arabes como Megale sintaxis, Megisto e por fim Almagesto.
O Almagesto tem por objetivo descrever matematicamente o funciona-
mento do sistema solar, supondo que a terra esta em seu centro5. Ptolomeu
desenvolveu a trigonometria nos captulos 10 e 11 do primeiro livro de sua
obra, na qual o captulo 11 consiste em uma tabela de cordas (ou seja, de
senos). Para a construcao desta tabela, a partir do fato de que em um
quadrilatero inscritvel ABCD (Veja a Figura 3.26) vale a relacao
AB  CD + BC  AD = AC  BD,
C
B
A
D
Figura 3.26
Ptolomeu deduz o que, com notacao moderna e com as funcoes seno e cosseno,
e a expressao para sen (ab). Alem disso, demonstrou que sen A2 +cos A2 = 1,
em que A e um angulo agudo.
Figura 3.27
5ESta e a teoria geocentrica que sera questionada, no seculo XV, pela teoria heliocentrica,
introduzida por Copernico.
3.5. A TRIGONOMETRIA NA GRECIA ANTIGA 139
Fazendo o raio do crculo igual a 60, Ptolomeu usa este teorema para
provar que se  e  sao dois arcos, entao
120crd (  ) = crd   crd (180  )  crd   crd (18  ).
Ptolomeu usou sua tabela de cordas para resolver varios problemas, como,
por exemplo, calcular o comprimento de uma sombra, bem como para tratar
varios outros de astronomia.
Com as tecnicas expostas em seu livro, Ptolomeu e capaz de resolver qual-
quer triangulo, decompondo-o convenientemente em triangulos retangulos. A
exposicao da trigonometria dada por Ptolomeu no Almagesto foi padrao, ate
o renascimento.
Como ja dissemos, a trigonometria era usada pelos gregos em astronomia.
Eles nunca se preocuparam em utiliza-la em topografia, campo em que hoje
ela tem emprego constante. A topografia grega, como a romana, sempre
recorreu `a geometria euclidiana. Para achar a area de um terreno de forma
poligonal, ele era decomposto em triangulos e a area de cada um destes
triangulos era calculada usando a formula de Hierao, que permite achar a
area de um triangulo em funcao de seus lados. Se os lados do triangulo sao
a, b e c, seu semi-permetro e s = 1
2 a + b + c. Entao,
A = p(p  a)(p  b)(p  c).
Exerccios
3.16. Voce conhece as leis dos senos e dos cossenos, que relacionam os
lados de um triangulo e os senos e os cossenos, respectivamente. Leia
as demonstracoes das proposicoes II.12 e II.13 dos Elementos cujos
enunciados sao reproduzidos a seguir, e deduza, usando-as, a lei dos
cossenos.
  Proposicao II.12. Em um triangulo obtusangulo, o quadrado
sobre o lado que subtende o angulo obtuso e maior do que os
quadrados sobre os lados que compreendem o angulo obtuso, de
duas vezes o retangulo sobre o lado em cujo prolongamento cai a
perpendicular, e sobre este lado prolongado.
  Proposicao II.12. Em um triangulo acutangulo, o quadrado
sobre o lado que subtende o angulo agudo e menor do que os
quadrados sobre os lados que compreendem o angulo obtuso, de
duas vezes o retangulo sobre o lado em cujo prolongamento cai a
perpendicular, e sobre este lado prolongado.
140 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
Obs: Nas demonstracoes dessas duas proposicoes, Euclides Eucli-
des realmente prova igualdades, e nao desigualdades.
3.17. Sejam BC, CA e AB os lados do triangulo esferico ABC e L, N e M,
respectivamente, as interseccoes de um crculo maximo com lados do
triangulo. Prove que,
sen AN
sen NB  sen BL
sen LC  sen CM
sen MA = 1
3.18. Demonstre o teorema de Ptolomeu: Em um quadrilatero inscritvel
ABCD (Veja a Figura 3.28) vale a relacao
AB  CD + BC  AD = AC  BD.
C
B
A
D
Figura 3.28
Sugestao: Escolha E sobre AC tal que o angulo ABE seja igual ao
angulo DBC.
3.19. Demonstre o teorema de Menelau: Se o triangulo ABC e cortado por
uma secante que intersecta seus tres lados, entao (Figura 3.29)
Se o triangulo ABC e cortado por uma secante que intersecta seus tres
lados, como mostrado na Figura 3.29 entao
NA  RB  MC = NC  RA  MB.
3.6 Exercicios suplementares
3.6. EXERCICIOS SUPLEMENTARES 141
NR
A
MCB
Figura 3.29
3.20. O metodo de Hierao para extrair razes quadradas.
Hierao, no Livro I de seu Metricas, reencontrado em 1896, aproxima2 por 1
2 (a + k
a ). Ele apresenta, no incio de seu livro, diversos proble-
mas aritmeticos sobre triangulos (calculo da area e da hipotenusa de
um triangulo retangulo cujos catetos sao dados, area de um triangulo
isosceles cujos lados sao conhecidos, entre outros). No problema 8, ele
apresenta sua famosa formula para o calculo da area de um triangulo
cujos tres lados sao conhecidos,
A = a(s  a)(s  b)(s  c), (3.5)
na qual s = a+b+c
2 e o semi-permetro do triangulo. Neste problema,
Hierao apresenta, como ele proprio afirma, uma prova geometrica
de (3.5) e aplica sua formula ao triangulo cujos lados medem, respec-
tivamente, a = 7, b = 8 e c = 9. Neste caso, e necessario calcular120  5  4  3 = 720.
Nos problemas anteriores, os numeros escolhidos por Hierao tinham
razes quadradas faceis de serem calculadas: (25, 64, 144). Isso
nao e verdade no caso de 720. Entao, ele afirma
Como 720 nao tem lado racional, nos extrairemos o lado
com uma diferenca muito pequena, da maneira seguinte. Co-
mo o primeiro numero quadrado maior do que 720 e 729, cujo
lado e 27, divida 720 por 27, e o resultado e 26 e 2
3 , 6 adicione
27 e obtemos 532
3 ; tome a metade disso, que e igual a 26 1
2
1
3 . 7
Em verdade, 261
2
1
3 multiplicado por ele mesmo da 720 1
36 ; de
modo que a diferenca (dos quadrados) e 1
36 . Se quisermos
tornar esta diferenca menor do que 1
36 , colocaremos 720 1
36
achado ha pouco no lugar de 729 e, procedendo da mesma
6Ou seja, 27 + 2
3 .
7Ou seja, 26 + 1
2 + 1
3 .
142 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
maneira, 8 acharemos que a diferenca (sobre os quadrados) e
muito menor do que 1
36 .
Hierao menciona explicitamente a ideia de repetir o calculo, a partir
do valor obtido anteriormente, a fim de aproximar a raiz quadrada
procurada tanto quanto quisermos. Temos assim um dos mais antigos
exemplos de um algoritmo de recorrencia. Obtemos, pela iteracao do
processo de Hierao, uma sucessao infinita, {an} de numeros a1, a2, a3,
. . ., tal que limn an = k. Nesta sucessao, cada termo esta relacio-
nado com o anterior por
an+1 = 1
2 (an + k
an
) . (3.6)
Temos portanto uma sucessao definida por recorrencia, um metodo po-
deroso para definir sucessoes (Ou, equivalentemente, funcoes f  N 
R).
Hierao nao fornece nenhuma indicacao de como obteve este resultado.
Foi por um raciocnio geometrico, aproximando um quadrado por re-
tangulos de mesma area? Ou se trata de um resultado ja conhecido,
e que pertencia ao folclore matematico da epoca? Simplesmente nao
sabemos. Ja vimos, na subsecao 1.3.1, que os babilonios conheciam
este algoritmo, mas sem efetuar a recorrencia.
 Mostre que a sucessao obtida pelo algoritmo de Hierao realmente
converge para k.
 Compare os termos da sequencia obtida com o metodo de Hierao
com a sequencia obtida usando o metodo de Newton.
 Estude a convergencia do metodo de Hierao (ou seja, avalie o erro
cometido no estagio an da aplicacao do metodo).
3.21. A escada de Theon
Theon de Smirna (viveu em torno de 140 E.C.) apresentou um algo-
ritmo muito simples para calcular a raiz quadrada de 2, e que pode
facilmente ser generalizado para achar a raiz quadrada de qualquer
numero natural. Em verdade, pode ser adaptado para achar qualquer
raiz de numeros naturais (Veja [112]).
Considere as sucessoes {xn} e {yn} definidas recursivamente por
8Ou seja, trabalhando com o lado 26 1
2
1
3 .
3.6. EXERCICIOS SUPLEMENTARES 143
xn = xn1 + yn1, yn = xn1 + xn.
Os primeiros termos da escada de Theon estao mostrados a seguir:
n xn yn
1 1 1
2 2 3
3 5 7
4 12 17
5 29 41
6 70 99
7 169 239
  
Seja, para cada n, rn = yn
xn . Entao, repetindo os primeiros elementos da
escada de Theon, acrescentados de rn, temos
n xn yn rn
1 1 1 1
2 2 3 3/2 = 1, 5
3 5 7 7/5 = 1, 4
4 12 17 17/12 = 1, 41666
5 29 41 41/29 = 1, 41379
6 70 99 99/70 = 1, 41428
7 169 239 239/169 = 1, 41420
   
Prove que a sucessao {rn} converge para 2.
3.22. Equacoes diofantinas lineares.
Uma equacao diofantina linear e uma equacao da forma ax + by = c,
com a, b, c  N. Resolve-la significa achar suas solucoes inteiras.
Ache condicoes para que esta equacao tenha solucoes (inteiras) e um
algoritmo que permita acha-las, quando elas existem.
3.23. A quadratriz e a curva construda da seguinte forma: suponhamos que
no quadrado ABCD o lado AD gira com movimento circular uniforme
em torno de A ate que coincide com o lado AB. Ao mesmo tempo, o
144 CAPITULO 3. A MATEM ATICA GREGA AP OS EUCLIDES
lado DC desce com velocidade constante ate coincidir com AB. Os dois
movimentos estao sincronizados de maneira que ambos os lados, DC
e AD coincidam com AB no mesmo instante. A quadratriz e o lugar
geometrico gerado pelas interseccoes destes dois lados moveis. E a curva
DP Z da Figura 3.30. Ela foi inventada por Hpias de Elis (viveu em
torno de 420 a.C.), originariamente em suas tentativas para trissectar
o angulo. Tudo indica que foi Dinostrato (viveu em torno de 350 a.C.)
quem pela primeira vez usou esta curva para fazer a quadratura do
crculo.
A B
CD
P
Z
Figura 3.30 A quadratriz
 Ache uma equacao cartesiana para a quadratriz.
 Demonstre que, na Figura 3.30, se a e o comprimento do lado do
quadrado, entao AZ = 2a
 .
 Mostre que a quadratriz permite resolver o problema da trisseccao
do angulo.
3.24. Um triagulo de Hierao e um triangulo cujos lados tem medidas inteiras,
e que tem uma altura cuja medida e tambem um numero inteiro.
1. Mostre que a area de um triangulo de Hierao e um numero inteiro.
2. Sera que todas as tres alturas de um triangulo de Hierao tem
medidas que sao numeros inteiros?
3. Demonstre a formula de Hierao que permite calcular a area do
triangulo de lados a, b e c: S = p(p  a)(p  b)(p  c), em que p
e o semi-permetro do triangulo.
4. Mostre que o triangulo de lados 13, 14, 15 e um triangulo de
Hierao.
3.6. EXERCICIOS SUPLEMENTARES 145
5. Como voce construiria outros triangulos de Hierao?
3.25. Demonstre a formula de Hierao: Se a, b e c sao os comprimentos dos
lados de um triangulo, p = 1
2 (a + b + c) e A e a area do triangulo, entao
A = p(p  a)(p  b)(p  c).
3.26. Apolonio escreveu varios tratados que se perderam. Entre eles, o Lu-
gares planos. Prove, geometricamente, sem usar geometria analtica,
os dois resultados abaixo, que sabemos faziam parte desta obra de
Apolonio:
 Sejam A e B dois pontos fixos e k uma constante positiva. Prove
que o lugar dos pontos P do plano tais que
P A
P B = k
e uma circunferencia se k = 1 e uma reta se k=1.
 Sejam A, B, C, . . . N pontos de um mesmo plano e a, b, c, . . . n.
Prove que o lugar dos pontos P do plano tais que
a(P A)2 + b(P B)2 +  + n(P N)2 = k
e uma circunferencia.
s

Captulo 4
Resolucao de equacoes e
Matematica pratica:
Al-Khwarizmi, Cardano, Vi`ete e
Neper
4.1 Contextualizacao historica
Conhecemos o papel dos problemas geometricos na Grecia e explicamos, no
captulo anterior, o carater formal e sistematico de sua exposicao nos Elemen-
tos de Euclides. O pensamento de Platao e invocado frequentemente como a
prova de que o homem grego considerava a Matematica um saber superior ao
conhecimento do senso comum. Talvez esta separacao seja o traco mais atra-
ente do saber grego aos olhos dos pensadores ocidentais que reconstruram a
historia da Matematica privilegiando seu carater teorico. Nossa Matematica
seria a legtima continuacao do pensamento teorico e abstrato, marca da ge-
ometria euclidiana. As artes praticas e a mecanica teriam um papel inferior.
Assim, das praticas transmitidas pelos arabes, o maior valor estaria naquelas
que traduzissem o ideal grego.
No entanto, ao longo da historia da Matematica, a relacao entre teoria e
pratica e mais complexa do que geralmente se considera. O perodo islamico,
por exemplo, e marcado pela evidencia de que praticas sociais e tecnicas
levaram a investigacoes teoricas e, reciprocamente, o pensamento cientfico
pode e deve ser aplicado na pratica.
Nao podemos deixar de achar estranho o gigantesco salto, recorrente nos
livros de historia da Matematica, entre o seculo III a.E.C., quando viveu
Euclides, e o seculo XV, quando a Matematica voltou a se desenvolver na
147
148 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
Europa. E bastante conhecido o fato de que as primeiras universidades sur-
giram na Idade Media, entre os seculos XII e XIII. Suas contribuicoes, no
entanto, sao entendidas como herdeiras do saber dos antigos, e muito influ-
enciadas por correntes filosoficas platonicas e aristotelicas.
A singularidade da dominacao islamica teve um papel fundamental no
modo como o saber antigo se renovou a partir do seculo IX. Este mundo foi
marcado por uma especie de sntese entre teoria e pratica, o que propiciou o
desenvolvimento de uma Matematica de tipo novo, que teve influencia sobre
os procedimentos algebricos realizados pelos arabes.
Podemos conjecturar a existencia de uma Matematica pratica e recrea-
tiva, em continuidade com as culturas babilonia e egpcia, que se espalhava
pelo Oriente e pelos territorios do Imperio Romano durante a Antiguidade
tardia, e parecia estar bem estabelecida nas comunidades comerciais das
regioes cobertas pela expansao islamica. Em textos arabes, ha evidencias
mostrando que esta cultura possua um prestgio social inferior ao nvel do
conhecimento propriamente dito, mas era frequente os matematicos retoma-
rem problemas do senso comum com o fim de dar-lhes um tratamento mais
sistematico. A diferenca se estabelecia entre aqueles que se contentavam em
reproduzir as praticas comuns e os outros, que refletiam sobre estes procedi-
mentos. Juntamente com a cultura cientfica grega, estas diferentes tradicoes
teriam convivido no perodo pre-islamico, mas sem alcancar o grau de desen-
volvimento e criatividade que marcou os primordios da epoca de ouro do Isla,
iniciada no seculo IX. Podemos chamar, portanto, de sntese islamica a cons-
cientizacao sobre a relevancia e as potencialidades da Matematica pratica e
da Matematica teorica quando aplicadas aos problemas, metodos e resultados
uma da outra.
Entre os seculos VIII e XII, a cidade de Bagda era um dos maiores centros
cientficos do mundo e seus matematicos tinham conhecimento tanto das
obras Matematicas gregas quanto das orientais. A partir do seculo IX, esta
cultura evoluiu para uma producao Matematica original que tinha a algebra
como um de seus pontos fortes, no sentido que exporemos adiante. Havia
grande influencia das obras classicas, o que nao impediu que uma Matematica
de tipo novo fosse desenvolvida. O matematico mais ilustre desse seculo foi
Al-Khwarizmi. Daremos alguns exemplos para mostrar em que consiste a
algebra praticada por ele e como os procedimentos geometricos sao usados
para explicar suas tecnicas.
A evolucao dos metodos para resolver problemas de terceiro grau teve um
papel importante na historia da algebra, passando por Omar Khayam, pelos
matematicos italianos e chegando a Francois Vi`ete, considerado mais um
inventor da algebra moderna. Neste caso, a origem da algebra tambem pode
ser associada `a introducao do simbolismo, de cujo uso ha exemplos bastante
4.1. CONTEXTUALIZAC AO HIST ORICA 149
expressivos no Magreb, a partir do seculo XII. As praticas cientficas nesta
regiao, proxima da Andaluzia, na Espanha, sao conhecidas pelo seu papel na
transmissao da cultura antiga.
A partir do seculo XIII, os tratados gregos comecaram a ser traduzidos na
Europa ocidental. No que tange ao uso de smbolos em problemas algebricos,
citaremos o papel dos arabes e dos matematicos italianos entre os seculos
XII e XIV. Mas foi somente no seculo XV que parece ter havido um emprego
mais sistematico da notacao algebrica. A partir do tratamento das equacoes
empreendido pelo italiano Girolamo Cardano, veremos que e possvel definir,
em um novo sentido, o que entendemos por algebra.
Diofanto, pelas razoes expostas no captulo anterior, e algumas vezes
citado como o pai da algebra. Mas para falar da historia de uma disciplina
Matematica, como a algebra, precisamos, antes de mais nada, caracterizar o
que entendemos por algebra. Os procedimentos associados a este tipo de
conhecimento nao podem ter como base sua definicao atual, tida como valida
desde sempre. O passo decisivo para a constituicao da algebra como disciplina
pode ser estar na sua organizacao em torno da classificacao e da resolucao de
equacoes, o que teve lugar pela primeira vez no seculo IX, com os trabalhos de
Al-Khwarizmi e de outros matematicos ligados a ele. Falaremos, portanto, do
papel dos arabes na constituicao de uma teoria das equacoes. Comecaremos
pelos matematicos indianos, em particular Bhaskara, que nao e o inventor da
formula que ganhou seu nome no Brasil. Apesar de conhecerem regras para
resolver problemas que seriam hoje traduzidos por equacoes do segundo grau,
e usarem alguns smbolos para representar as quantidades desconhecidas e
as operacoes, nao se pode dizer que os indianos possussem uma formula de
resolucao dessas equacoes. Usaremos este exemplo para mostrar o quanto e
inadequada a pergunta quem foi o verdadeiro inventor desta formula?.
Chegaremos, portanto, a uma conclusao definitiva sobre quem e o fun-
dador da algebra? Nao. Pretendemos mostrar que, se quisessemos aplicar a
alcunha de o pai da algebra a algum matematico do perodo, obteramos
multiplas respostas: Diofanto, se usarmos a definicao A para algebra; Al-
Khwarizmi, com a definicao B; Cardano, com a C; e, finalmente, Vi`ete, no
sentido D. Ou seja, podemos concluir que alcunhas deste tipo sao inuteis
para a historia da Matematica.
Um ultimo mito, que tentaremos desconstruir neste captulo, diz respeito
`a difusao da algebra arabe e dos tratados dos povos antigos na Europa.
Ouvimos dizer, normalmente, que a Matematica se desenvolveu na Italia
a partir do seculo XIII, sobretudo com as obras de Leonardo de Pisa. Este
matematico, conhecido como Fibonacci, teria feito viagens ao norte da Africa,
onde entrou em contato com a Matematica dos arabes.
E verdade que Fibonacci esteve em Bugia, cidade da Argelia, pela von-
150 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
tade de seu pai, que era comerciante. Depois desta primeira formacao em
Matematica, viajou pelo Egito, Sria, Sul da Franca e Siclia. Ou seja, teve
contato com o mundo mediterraneo onde se aperfeicoou em domnios como
a algebra, uma pratica desconhecida para os europeus. No entanto, a versao
simplificadora sobre a difusao da algebra na Italia teve que ser reformulada
nos ultimos anos, devido a dois complicadores: as descobertas que exibem o
desenvolvimento de uma algebra simbolica no Magreb e na Andaluzia, entre
os seculos XI e XIV, bem como sua transmissao para os cristaos na Espanha;
e as pesquisas sobre as escolas de abaco, que floresceram na Italia a partir do
seculo XIII.
As escolas de abaco, que treinavam jovens comerciantes desde os 11 ou 12
anos em Matematica pratica, se difundiram em varias regioes da Italia, sobre-
tudo em Florenca, e estao relacionadas ao desenvolvimento do capitalismo no
fim da Idade Media. Para tratar problemas ligados ao comercio, ensinava-se
o calculo com numerais indianos (nossos algarismos que chamamos hindu-
arabicos), a regra de tres, juros simples e compostos, os metodos de falsa
posicao, entre outras ferramentas de calculo voltadas para problemas prati-
cos. Ainda que fossem designadas como escolas de abaco, a partir do seculo
XIII, elas se dedicavam a tecnicas de calculo sem abaco. Em conexao com
estas escolas, sobretudo as do centro e do norte da Italia, foram publicados
diversos livros de abaco, que podem ser traduzidos tambem como livros
de calculo.
Alem dos topicos ja citados, estes livros podiam conter secoes de algebra,
sobretudo a partir do seculo XIV. E difcil saber exatamente quem escreveu
estas obras, pois, em muitos casos, tratavam-se de adaptacoes e copias de
materiais ja existentes, alem de a maioria ser de autoria anonima. O livro
mais conhecido de Fibonacci se chama Liber Abaci, ou seja, livro de abaco,
o que levou alguns historiadores a afirmarem que, em geral, os escritos asso-
ciados `as escolas de abaco eram, de fato, resumos e adaptacoes desta obra de
Fibonacci. Estes textos de Matematica pratica, escritos em lngua vernacula,
receberam pouca atencao dos historiadores ate as transcricoes feitas Gino Ar-
righi, e seus colegas italianos, nos anos 1960 e 1970. O interesse foi reforcado
pelos estudos que levaram `a publicacao de uma catalogo destes textos, por
Warren van Egmond, em 1980 ([145]).
O primeiro livro de abaco a propor uma algebra foi escrito por um
certo Jacopo da Firenze, provavelmente em Montpellier, no ano de 1307.
O conteudo deste tratado e totalmente retorico e o autor parece estar se di-
rigindo a um leitor leigo, sem conhecimento previo da materia, e nao contem
nenhum traco que indique a influencia de Fibonacci ou dos classicos arabes,
como Al-Khwarizmi. A partir de multiplas evidencias historicas, pode-se
concluir que a algebra de Jacopo da Firenze pode ter suas razes em praticas
4.1. CONTEXTUALIZAC AO HIST ORICA 151
que estavam presentes na area que se estende da Pennsula Iberica ate a
regiao da Provenca, na Franca, ambas com ancestrais comuns na Andaluzia
e no Magreb.
Um dos indcios mais fortes para esta conclusao e o fato de o livro nao
oferecer provas geometricas, mas somente regras, alem de se caracterizar por
uma mistura de Matematica comercial e algebrica, tpica da cultura Ma-
tematica da Andaluzia e do Magreb. Uma analise da terminologia e das
tecnicas empregadas permite afirmar que a algebra apresentada era influen-
ciada pela algebra arabe, mas nao necessariamente pelos classicos, como os
livros de Al-Khwarizmi e Abu-Kamil. A ausencia de simbolismo pode ter
sido motivada pela tradicao de uso da linguagem retorica pelas pessoas da
regiao `a qual se destinava.
Nao a-nalisaremos a historia da algebra deste perodo em detalhes, li-
mitando-nos somente a resumir algumas de suas etapas ate a difusao do
simbolismo algebrico. Esses comentarios possuem o objetivo de mostrar que
o desenvolvimento algebrico do perodo nao e heranca de um autor  nem de
alguns autores escolhidos , mas sim o produto de praticas compartilhadas
em um contexto determinado.
No final do seculo XII, os matematicos do Magreb usavam, em suas
manipulacoes algebricas, smbolos para a incognita, para as potencias da
incognita, bem como para as operacoes e para a igualdade. Com estes
smbolos, derivados das iniciais das palavras correspondentes, os matematicos
do Magreb conseguiam produzir expressoes compostas, usadas para escrever
o analogo aos nossos polinomios (ver Abdeljaouad, 2002). Nao se encontra
nenhum traco desta influencia na Europa, em nenhuma das introducoes `a
algebra dos seculos XII e XIII. A obra de Fibonacci e um dos raros exemplos
no qual se destaca o uso de algum simbolismo herdado dos arabes, como
a notacao para fracoes. O Lber Abaci e conhecido pela defesa da notacao
indo-arabica e do sistema posicional.
Nos seculos XIV e XV, desenvolveu-se na Italia um movimento que ficou
conhecido como Humanismo, uma corrente filosofica e literaria que se inte-
ressava pela antiga cultura grega e latina e se dedicava aos autores classicos.
As inovacoes aritmeticas e algebricas do perodo, herdadas das praticas do
Magreb, nao se associavam com esta tendencia e, portanto, nao foram parti-
cularmente estimuladas. Somente no final do seculo XV, comecaram a surgir
indcios do uso mais consciente da notacao simbolica e o exemplo mais im-
portante disso e a Summa Aritmetica, de Pacioli, publicada em 1494.
Os algebristas dos seculos XIV e XV, ou mesmo os do seculo XVI, tinham
alguma razao para desenvolver uma abordagem simbolica coerente? Parece
que nao. O tipo de Matematica no qual estavam engajados nao tornava
esta necessidade urgente. Mesmo os mestres de abaco com ambicoes enci-
152 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
clopedicas, como Pacioli, e mais tarde Tartaglia, nao encontravam estmulo
para uma tal sistematizacao na Matematica praticada nas universidades, ou
no meio dos pensadores humanistas. Ao contrario, a aspiracao de conectar
sua Matematica ao ideal euclidiano os fez reinserir provas geometricas na
tradicao algebrica, que ja tinha se livrado desta influencia, o que retardou a
compreensao de que uma argumentacao puramente aritmetica, ou algebrica,
poderia ser considerada legtima, sem o auxlio da geometria.
A evolucao dos metodos para resolver problemas de terceiro grau teve
um papel importante na historia da algebra, passando pelos matematicos
italianos e chegando a Francois Vi`ete. Antes de Vi`ete, a algebra europeia
se aplicava a problemas cuja resolucao nao era auxiliada pelo uso de simbo-
lismo. Somente quando a influencia de Arquimedes e Apolonio trouxe novos
problemas `a cena Matematica, seus praticantes perceberam que o simbolismo
era um fator capaz de auxiliar na resolucao de problemas e a generalizar os
metodos empregados. Exceto pela notacao, a algebra deste perodo e muito
parecida com a que nos e ensinada nas escolas, mas ha uma grande distancia
entre esta arte e a disciplina Matematica que chamamos hoje de algebra.
Veremos, na proxima secao, que o trabalho de Cardano, dedicado `a grande
arte, pode ser considerado, em certo sentido, o primeiro tratado de algebra.
Nao falaremos aqui da historia da algebra, e sim da historia dos metodos
de resolucao de equacoes. Alguns metodos usados pelos babilonicos ou pelos
gregos podem ser traduzidos pelo que conhecemos hoje como uma equacao do
segundo grau e a solucao encontrada equivale `a raiz positiva desta equacao.
O processo de resolucao pode ser traduzido, em ambos os casos, na formula
que conhecemos hoje. Podemos concluir da queestes povos ja possuam uma
formula? Nao. Uma formula propriamente dita so pode ser estabelecida
quando:
1. passou-se a representar simbolicamente as incognitas e as operacoes
que estao contidas em uma equacao e;
2. a equacao do segundo grau passou a ser considerada de modo generico,
ou seja, com todas as parcelas possveis e coeficientes indeterminados.
Decorreram seculos para que as condicoes 1 e 2 fossem satisfeitas, desde
os antigos egpcios e babilonios, passando pelos gregos, chineses, hindus e
arabes, em um percurso que nada tem de linear.
Veremos que Vi`ete introduziu um simbolismo algebrico sistematico em
seu livro In artem analyticam isagoge (Introducao `a arte analtica), publicado
em 1591. Depois de analisar brevemente suas contribuicoes, aproveitaremos
a mencao `a Matematica pratica para falar do desenvolvimento dos logaritmos
com John Neper, logo no incio do seculo XVII.
4.2. BH ASKARA E OS PROBLEMAS DO SEGUNDO GRAU 153
4.2 Bhaskara e os problemas do segundo grau
O matematico indiano Bhaskara 1 viveu no seculo XII e, nesta epoca, os
problemas que exigiam o que chamamos hoje de equacao eram enunciados
usando somente palavras e de modo poetico. Eis um exemplo de verso:
Verso 77: De um enxame de abelhas, tome a metade, depois
a raiz. Este grupo extrai o polen de um campo de jasmins. Oito
nonos do todo flutuam pelo ceu. Uma abelha solitaria escuta seu
macho zumbir sobre uma flor de lotus. Atrado pela fragrancia,
ele tinha se deixado aprisionar na noite anterior. Quantas abelhas
havia no enxame?
O que designamos hoje de equacao equivalia a um enunciado como o
seguinte:
De uma quantidade retiramos ou adicionamos a sua raiz multiplicada
por um coeficiente e a soma ou a diferenca e igual a um numero dado.
A quantidade citada e um quadrado e a raiz deste quadrado e a incognita.
Ele forma, assim, usando somente palavras, a equacao x2  px = q.
O metodo de resolucao consiste em reduzir o problema a uma equacao
linear. Isto era feito por meio do metodo que Bhaskara denominava de eli-
minacao do termo medio, equivalente ao nosso metodo de completar qua-
drados:
Seja uma igualdade contendo a quantidade desconhecida, seu
quadrado, etc. Se temos os quadrados da quantidade desconhe-
cida, etc., em um dos membros, multiplicamos os dois membros
por um fator conveniente e somamos o que e necessario para que
o membro das quantidades desconhecidas tenha uma raiz; igua-
lando em seguida esta raiz `a do membro das quantidades conhe-
cidas, obtemos o valor da quantidade desconhecida.
Observamos que era concebida uma igualdade, usando somente palavras,
entre dois membros, sem utilizacao do sinal de igual. Esta igualdade, bem
proxima de uma equacao, estava posta, em geral, entre um membro con-
tendo a quantidade desconhecida e o seu quadrado e outro membro contendo
as quantidades conhecidas. Este procedimento esta bem proximo do que
1Bhaskara, tambem conhecido como Bhaskara II e Bhaskara Acharya (que significa
Bhaskara, o professor) viveu de 1114 a 1185. Seu principal trabalho foi o Siddhanta Siro-
mani, dividido em quatro partes: Lilavati, Bijaganita, Grahaganita and Goladhyaya, dedicados
`a aritmetica, algebra, astronomia e trigonometria esferica, respectivamente. Ele representa o
apice da Matematica do seculo XII.
154 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
fazemos ao escrever uma equacao. A diferenca e devida ao fato de que os
indianos usavam somente palavras, nao utilizavam a linguagem simbolica de
nossa algebra.
O metodo acima deve ser aplicado a um problema seguindo as especifica-
coes:
E por unidades iguais a quatro vezes o numero de quadrados
que e preciso multiplicar os dois membros; e e a quantidade igual
ao quadrado do numero primitivo de quantidades desconhecidas
simples que e preciso adicionar.
Assim temos a condicao requerida por Bhaskara de que o membro das
quantidades desconhecidas tenha uma raiz. Trata-se do metodo de completar
o quadrado, como dizemos hoje em dia, mas que era expresso por meio de
palavras. Este metodo resolve uma equacao expressa hoje como ax2 + bx = c
e consiste no seguinte procedimento: multiplicamos ambos os lados por 4a,
obtendo 4a2x2 + 4abx = 4ac. Em seguida adicionamos b2 a ambos os lados,
obtendo 4a2x2 + 4abx + b2 = 4ac + b2. Agora o membro das quantidades
desconhecidas tem uma raiz e tomamos a raiz quadrada para obter
2ax + b = 4ac + b2  x =
4ac + b2  b
2a .
Isto e exatamente o que faz Bhaskara, usando somente palavras.
No exemplo das abelhas, fazendo o enxame igual a 2x2, a raiz da metade
e x e os oito nonos do todo dao 16
9 x2, que aumentados do casal de abelhas e
da raiz, devem ser iguais a 2x2, ou seja,
x + 16
9 x2 + 2 = 2x2.
Bhaskara obtem da a equacao 2x2  9x = 18 que deve ser resolvida pelo
metodo descrito acima. Lembramos que as quantidades desconhecidas ao
quadrado, etc. sao reunidas no primeiro membro e as quantidades conhe-
cidas no segundo. Ele explica entao, por meio exclusivamente de palavras,
o procedimento que podemos traduzir da seguinte maneira: multiplicando
os dois membros por 8 e somando 81 temos 16x2  72x + 81 = 225, na qual
os dois membros sao quadrados. Tomando as razes e igualando-as obtemos
4x  9 = 15, de que tiramos que o valor de x, 6. Logo, o numero de abelhas e
72.
De forma geral, o metodo de resolucao empregado por Bhaskara consiste
em:
4.2. BH ASKARA E OS PROBLEMAS DO SEGUNDO GRAU 155
1. completar o quadrado no primeiro membro para tornar o termo que
contem a quantidade desconhecida e seu quadrado um quadrado per-
feito;
2. diminuir o grau da equacao extraindo a raiz quadrada dos dois mem-
bros;
3. resolver a equacao de primeiro grau que da resulta.
Exerccios
4.1. Em cada um dos seguintes versos de Bhaskara, ache, pelo metodo pro-
posto por ele, as quantidades procuradas.
Verso 75: De um bando de gansos, quando apareceu uma
nuvem, dez vezes a raiz quadrada [do total] foram para o lago
de Manasa, um oitavo foi para a floresta coberta de hibiscos, e
tres pares foram vistos brincando na agua. Diz-me, donzela,
o numero de gansos no bando.
Verso 76b: [Este episodio encontra-se no Mahabharata]
Enraivecido numa batalha, Arjuna disparou uma quanti-
dade de setas para matar Karna. Com metade das setas
desviou as setas do seu adversario; com quatro vezes a raiz
quadrada do total, matou o seu cavalo; com seis setas, ma-
tou o seu cocheiro Salya; depois com tres setas destruiu a
protecao, o estandarte e o arco do seu inimigo; e com uma
seta, cortou a sua cabeca. Quantas setas Arjuna disparou?
4.2. Resolva o seguinte problema proposto por Bhaskara:
Um bando barulhento de macacos se divertia. Um oi-
tavo ao quadrado brincava no bosque. Doze, os que sobra-
ram, gritavam ao mesmo tempo, no alto da colina verdejante.
Quantos eram os macacos no total?
Qual o fator novo que aparece nesta resolucao?
156 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
4.3 A algebra arabe
O matematico arabe mais conhecido foi Al-Khwarizmi, nome que deu ori-
gem `as palavras algoritmo e algarismo. Apos se apropriar do saber
matematico grego mais avancado, os matematicos arabes expandiram esse
conhecimento produzindo metodos sistematicos e se empenharam em ge-
neraliza-los. Primeiramente, a algebra arabe permitiu ultrapassar a predo-
minancia do conhecimento grego. A algebra, tal como estudada pelos arabes,
ultrapassou a divisao numero/grandeza, que era constituinte da Matematica
euclidiana. Essa inovacao permitiu que fossem aplicados resultados de um
domnio aos objetos de outro.
A palavra al-jabr, era utilizada para designar restauracao. A utilizacao
desta nomenclatura para o que conhecemos hoje como algebra tem origem
em um dos livros arabes mais importantes da idade media, o Tratado sobre
o calculo de al-jabr e al-muqabala, escrito por Al-Khwarizmi. A palavra al-
muqabala queria dizer algo como balanceamento.
Apesar de a linguagem utilizada por Al-Khwarizmi usar somente pala-
vras, ele emprega um vocabulario padrao para os objetos que aparecem no
problema. Ao estudar problemas que atualmente correspondem a equacoes
do segundo grau, ele introduziu os termos necessarios para o seu entendi-
mento, principalmente os tres modos sob os quais o numero aparecia no
calculo da algebra: a raiz, o quadrado e o numero simples. Na sua notacao,
o quadrado e um conceito algebrico designado pela palavra mal, que significa
possessao, ou tesouro. Esta palavra e empregada para designar o quadrado
da quantidade desconhecida. Nao e o quadrado geometrico (murabbaa).
Al-Khwarizmi afirma que raiz e o termo essencial, designado pela palavra
Jidhr, mas poderia tambem ser designada pela palavra coisa. As duas palavras
eram usadas para exprimir o que atualmente chamamos de incognita. Trata-
se da quantidade desconhecida no problema (a raiz do mal). Por sua vez,
adad, e um numero dado qualquer, ou seja, a quantidade conhecida.
Palavra Significado Sentido nos problemas Notacao
moderna
Adad Quantidade conhecida (numero dado) c
Jidhr raiz Quantidade desconhecida x
Mal possessao
tesouro
Quadrado da quantidade desconhecida x2
Vale destacar que a palavra coisa era utilizada para enfatizar a condicao
de incognita, pois, em arabe, esta palavra esta associada a uma indefinicao
4.3. A  ALGEBRA ARABE 157
ou indeterminacao. Uma vez que o calculo de Al-Khwarizmi era formal
e a incognita designava objetos de qualquer natureza, a escolha da palavra
coisa revela a preocupacao em elaborar um calculo que pudesse ser aplicado
tanto aos numeros quanto `as grandezas geometricas. Essa preocupacao foi
fundamental para a criacao de um novo domnio (a algebra).
A utilizacao do termo raiz para a solucao de uma equacao vem da
traducao para o latim do termo arabe jidhr usado por Al-Khwarizmi. No-
tem que o emprego do termo raiz (jidhr) por Al-Khwarizmi para designar
a quantidade desconhecida esta estreitamente ligado ao fato de que o qua-
drado desta quantidade desconhecida era tambem uma incognita, que possua
inclusive uma nomenclatura propria (mal).
Depois de mostrar como efetuar as quatro operacoes sobre expressoes
contendo quantidades desconhecidas ou radicais, Al-Khwarizmi passa `a enu-
meracao dos seis problemas, ou seis casos, possveis, enunciados por palavras:
1. quadrados iguais a razes (ax2 = bx)
2. quadrados iguais a um numero (ax2 = c)
3. razes iguais a um numero (bx = c)
4. quadrados e razes iguais a um numero (ax2 + bx = c)
5. quadrados e um numero iguais a razes (ax2 + c = bx)
6. razes e um numero iguais a quadrados (bx + c = ax2)
Em todos os casos, os coeficientes eram sempre considerados positivos.
Para cada um dos tipos enumerados, Al-Khwarizmi possua regras de solucao
justificadas por resultados dos Elementos de Euclides, ainda que os gregos nao
concebessem equacoes propriamente ditas, apenas relacoes entre grandezas.
Cada caso e tratado inicialmente a partir de exemplos. Para o quarto
caso, Al-Khwarizmi considera o exemplo um mal e dez jidhr igualam trinta
e nove denares, que em nossa notacao algebrica moderna seria escrito como
x2 + 10x = 39. O algoritmo de resolucao era descrito do modo seguinte: tome
a metade da quantidade de jidhr (que neste exemplo e 5); multiplique esta
quantidade por si mesma (obtendo 25); some no resultado os adad (fazemos
39 + 25 = 64); extraia a raiz quadrada do resultado (que da 8); subtraia deste
resultado a metade dos Jidhr, encontrando a solucao (esta solucao e 85 = 3).
Traduzindo este procedimento em linguagem algebrica atual teramos que a
solucao de uma equacao do tipo x2 + bx = c e dada por  b
2 +
b2
4 + c.
Apresentamos esta solucao organizada em uma tabela, a fim de comparar
a solucao de Al-Khwarizmi com o procedimento que utilizamos atualmente:
158 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
Solucao dada por al-
Khwarizmi
Operacoes corresponden-
tes em linguagem mo-
derna
Operacoes correspondentes em lin-
guagem moderna, para uma equacao
generica do tipo ax2 + bx + c = 0
Tome a metade da quan-
tidade de jidhr.
10
2 = 5 b
2
Multiplique esta quanti-
dade por si mesma.
52 = 25 ( b
2 )2
Some no resultado os
adad.
25 + 39 = 64 ( b
2 )2 + c
Extraia a raiz quadrada
do resultado.
64 = 8

( b
2 )2 + c
Subtraia deste resultado
a metade dos jidhr, en-
contrando a solucao.
8  5 = 3

( b
2 )2 + c  b
2
Vemos que a solucao apresentada por Al-Khwarizmi corresponde exata-
mente `a raiz positiva da equacao x2 + 10x = 39, equivalente ao seu problema.
Observando a terceira coluna da tabela, percebemos que o algoritmo de re-
solucao e uma sequencia de operacoes equivalentes `a formula de resolucao
de equacao do segundo grau usada atualmente, o que mostra a generalidade
da solucao apresentada, mesmo que tenha sido exposta para um exemplo
particular.
Em seguida, ele afirma: A figura para explicar isto e um quadrado cujos
lados sao desconhecidos. Deve-se construir um quadrado de diagonal AB
que representa o Mal, ou o quadrado da raiz procurada, e dois retangulos
iguais G e D cujos lados sao a raiz e 5, metade de 10. A figura obtida e um
gnomon de area 39. Usando a proposicao II.4 dos Elementos de Euclides e
completando esta figura com um quadrado de lado 5 (area 25), obtemos um
quadrado de area 64 = (39 + 25). O lado AH deste quadrado mede 8. Da
obtem-se que a raiz procurada e 3 = (8  5).
Figura 4.1
4.3. A  ALGEBRA ARABE 159
Essa construcao geometrica reproduz exatamente o procedimento de reso-
lucao de Al-Khwarizmi e demonstra a necessidade de completar o quadrado
durante a resolucao algebrica. Fica claro que ele estabeleceu uma analogia
entre a geometria e a algebra ao identificar o lado do quadrado geometrico
`a raiz do quadrado algebrico. A justificativa geometrica apresentada por Al-
Khwarizmi nao serve apenas para garantir a verdade do algoritmo, ela nos
faz compreender sua causa: a necessidade de completar o quadrado. Esse
papel para uma argumentacao geometrica e totalmente novo.
Empregando metodos algebricos expressos por meio de palavras e justi-
ficados geometricamente, Al-Khwarizmi fornece solucoes para os seis casos
enunciados. Em seguida, trata-se de saber como reduzir uma equacao
qualquer, ou seja, um problema qualquer, a um destes casos. Esta e a im-
portancia dos procedimentos de restauracao (al-jabr) e balanceamento
(al-muqabala). Suponhamos, por exemplo, em notacao atual, a equacao:
2x2 + 100  20x = 58.
Como todos os coeficientes devem ser positivos, para que possamos conce-
ber uma igualdade entre os dois membros desta equacao, devemos imaginar
que o primeiro membro da equacao possua um excedente de 20x em relacao ao
segundo. Sendo assim, a igualdade nesta equacao deve ser restaurada pelo
procedimento de al-jabr, ou seja, devemos enriquecer 2x2 + 100 do deficit
que lhe causou a retirada de 20x. Em nossa linguagem, isto e equivalente
a dizer que o termo subtrado no primeiro membro deve ser adicionado ao
segundo membro, de forma a se obter uma igualdade com todos os termos
positivos:
2x2 + 100 = 20x + 58.
Observamos que este modo de passar para o outro lado nao se justifica
pela concepcao que temos de que a soma e a subtracao sao operacoes inversas.
O modo de operar dos arabes esta mais proximo da crenca, frequentemente
encontrada, de que realmente retiramos uma quantidade de um lado a fim de
passa-la para o outro lado, forcada pela restricao ao universo dos numeros
positivos.
Em seguida, as especies do mesmo tipo e iguais sao subtradas de ambos os
lados, o que seria equivalente a retirar 58 de ambos os lados. E preciso equi-
librar os dois lados, ou seja, balancea-los pelo procedimento de al-muqabala,
equilibrando os dois numeros e reduzindo-os a um so. Chegamos assim a
uma equacao do tipo (5):
2x2 + 42 = 20x.
160 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
Dividindo esta equacao por 2, podemos resolve-la pelos metodos ja en-
contrados no Exerccio 4.2 para a solucao de x2 + 21 = 10x.
Vimos ate aqui que o procedimento de Al-Khwarizmi resolve perfeita-
mente o que chamamos hoje de equacao do segundo grau, como ja era o
caso, alias, do metodo de Bhaskara. Ainda assim, seria um exagero atribuir-
lhes a invencao da formula que usamos atualmente. Por que? Os indianos
ja utilizavam smbolos para as incognitas e para as operacoes. O metodo
enunciado por Bhaskara permite reduzir uma equacao do segundo grau a
uma equacao do tipo ax2 + bx = c, mas ainda nao havia smbolos algebricos
para expressar coeficientes genericos da equacao, no caso, os coeficientes a,
b e c. Se traduzirmos o metodo usado por eles na linguagem algebrica atual
e o aplicarmos a uma equacao geral do tipo ax2 + bx + c = 0, obteremos o
equivalente da formula para resolucao de equacoes do segundo grau. Isto
quer dizer que havia um metodo geral para resolucao de equacoes, ainda que
expresso por palavras. No entanto, nao podemos dizer que ja existisse uma
formula para resolucao de equacoes, no sentido que entendemos hoje, uma
vez que nao se usava nenhum simbolismo para os coeficientes. Isto sera feito
por Vi`ete, como veremos ao final deste captulo.
Vimos que Bhaskara considerava equacoes do segundo grau, expressas
em palavras, com algumas abreviacoes e alguns smbolos para incognitas e
operacoes. Al-Khwarizmi forneceu algoritmos de resolucao justificados por
procedimentos geometricos, alguns dos quais ja utilizados por egpcios e
babilonios. Ou seja, nao sabemos exatamente quem inventou o metodo, mas
formula geral que utilizamos hoje para resolver uma equacao do segundo grau
generica nao pode ter sido formulada por Bhaskara, nem pelos arabes, uma
vez que eles nao dispunham de um simbolismo para os coeficientes.
O metodo arabe e bem diferente da nossa formula, em particular por
tratar cada um dos seis casos separadamente e associar sua solucao a metodos
geometricos.
Exemplo 4.1. Estudemos a resolucao de Al-Khwarizmi para as equacoes do tipo
px + q = x2, exemplificado por 3x + 4 = x2, justificada pela seguinte ilustracao
(Figura 4.2).
Seja AB = x e construa o quadrado ABDE. Marque F , sobre AE, de
maneira que EF = p. Como x2 = px + q, vemos que a area do retangulo
ABCF e igual a q.
Seja G o ponto medio de EF . Entao, por construcao, AG mede s = x  p
2 .
Construa os quadrados F KLG e AP OG. Entao, a congruencia dos
retangulos KNOL e P BNC acarreta que (traduzindo em nossa notacao):
4.3. A  ALGEBRA ARABE 161
Figura 4.2 Solucao de 3x + 4 = x2.
SAP OG = s2 = SF KLG + SAP N F + SKN OL =
= SF KLG + SAP N F + SP BN C =
= (p
2 )
2
+ q.
Assim,
x = s + p
2 = p
2 +

(p
2 )
2
+ q.
Exerccios
4.3. Resolva os seguintes problemas propostos por al-Khwarizmi:
 Um Mal e vinte e um igualam dez Jidhr (x2 + 21 = 10x) pelo
seguinte algoritmo: tomamos a metade de dez, que e 5, e multi-
plicamos 5 por 5 obtendo 25. Subtramos, em seguida, 21 de 25 e
obtemos 4 cuja raiz e 2. Subtramos entao 2 de 5 encontrando a
primeira raiz que e 3. Em seguida, somamos 24 a 5 para obter a
segunda raiz que e 7. Use este exemplo para deduzir um metodo
geral para o quinto caso. Enuncie este metodo algebricamente e
justifique-o, em seguida, pela geometria.
 Inscrever, em um triangulo isosceles de base igual a 12 e lados
iguais a 10, um quadrado de que um dos lados repousa sobre a
base do triangulo.
162 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
 Dividi dez em duas partes, e dividia primeira pela segunda, e a
segunda pela primeira, e a soma dos quocientes e dois. Ache as
partes.
4.4. Resolva o seguinte problema proposto por Abu Kamil: Suponha que 10
e dividido em duas partes e que o produto de uma delaspor ela mesma
e igual ao produto da outra pela raiz quadrada de 10. Ache as duas
partes.
4.5. Escreva os algoritmos para os casos 4 e 5 dos tipos estudados por Al-
-Khwarizmi usando simbolos para representar incognitas e coeficientes
e obtenha a nossa formula para resolucao de equacoes do segundo grau.
4.6. Resolva, usando o metodo de Al-Khwarizmi, a equacao x2 + 5x = 15,
justificando geometricamente a resolucao.
4.4 A resolucao de equacoes algebricas por radi-
cais
O Ocidente comecou a tomar conhecimento dos tratados arabes no seculo
XII, a partir de traducoes para o latim. Nesta epoca, a Matematica arabe
era muito superior `a que se fazia na Europa. No incio do seculo XIII, os
tratados arabes tiveram grande difusao na Italia.
Nesta epoca, os termos arabes usados na resolucao destes problemas serao
traduzidos para o latim, bem como os metodos algebricos e aritmeticos em-
pregados. As traducoes latinas dos tratados arabes usavam o termo coisa
para designar a quantidade desconhecida, ou radix (raiz). O seu quadrado
se chamara quadratus ou census, o cubo, cubus e o termo constante, nume-
rus. Ao longo dos seculos XIII e XIV diversas abreviacoes comecaram a ser
usadas. As operacoes de mais e menos eram designadas por variacoes das
letras p (de plus) e m (de minus) e a raiz era designada por variacoes de R
(de radix).
Mas sera apenas no seculo XV que a algebra ira se desenvolver, sobretudo
na Alemanha e na Italia (mas tambem na Inglaterra e na Franca), a partir do
livro de Fibonacci e da influencia direta dos tratados arabes, em particular
do livro de Al-Khwarizmi. Foi entao que a traducao do termo al-jabr levou
a que os metodos arabes fixassem conhecidos como algebra.
Mas o que era a algebra do seculo XV e incio do XVI? Essencialmente
a mesma dos arabes, mas com o recurso a um simbolismo (nao unificado)
tanto para as incognitas quanto para as operacoes.
4.4. A RESOLUC AO DE EQUAC OES ALGEBRICAS POR RADICAIS 163
No seculo XVI, desenvolveram-se na Europa pesquisas dedicadas `a alge-
bra, empregando uma grande quantidade de smbolos, e que foram responsa-
veis por alguns que conhecemos hoje. Os smbolos de + e  ja eram usados
na Alemanha. O smbolo para raiz quadrada, por exemplo, foi introduzido
em 1525 pelo matematico alemao Christoff Rudolff. Seu aspecto vem de
uma abreviacao da letra r, inicial de raiz. Em 1557, o matematico ingles
Robert Recorde publicou um livro de algebra no qual introduziu o smbolo
= que usamos hoje para a igualdade: um par de retas paralelas, pois nao
pode haver duas coisas mais iguais. Os smbolos para o quadrado e o cubo
da quantidade desconhecida provinham de abreviacoes das palavras latinas
e eram distintos.
Supondo que o cubo fosse expresso por C, o quadrado por Q, reunindo
todos os avancos simbolicos da epoca, a equacao expressa hoje como x3 
5x2 + 7x = x + 6 seria escrita como
C  5Q + 7R = R + 6.
No entanto, nao havia um padrao comum na notacao algebrica, como
hoje em dia. O smbolo de =, por exemplo, proposto em 1557, era usado
na Inglaterra, mas nao era difundido no resto da Europa, onde eram usadas
abreviacoes da palavra igual. A padronizacao dos smbolos matematicos
se deu muito mais tarde, sobretudo a partir do final do seculo XVII, devido `a
popularidade dos trabalhos de Descartes, Leibniz e Newton, como veremos
nos captulos seguintes.
Os desenvolvimentos algebricos mais importantes dos seculos XV e XVI
deveram-se aos esforcos para encontrar uma solucao da cubica por radicais.
Hoje, pensamos em equacoes cubicas como sendo essencialmente todas de
um mesmo tipo e que podem ser resolvidas por um mesmo metodo. Con-
tudo, naquela epoca, quando os coeficientes eram numericos e os coeficientes
negativos ainda nao eram utilizados, existiam diferentes tipos de equacoes
cubicas, como as enumeradas por Al-Khayam, que dependiam da posicao do
termo quadratico, do linear e do termo numerico.
No incio do seculo XVI, Scipione Del Ferro obteve uma formula usando
radicais para a solucao de um certo tipo de equacao, o que constituiu uma
novidade em relacao aos trabalhos arabes. Mas esta formula foi mantida
secreta, como era costume na epoca. Alguns anos mais tarde, por volta de
1535, outro matematico italiano Niccolo Fontana, conhecido pela alcunha de
Tartaglia, resolveu diversas equacoes cubicas, em particular as do tipo que
escrevemos hoje como x3 + mx2 = n, considerada com coeficientes exclusiva-
mente numericos.
Um terceiro matematico italiano, Girolamo Cardano, que parece ter obti-
164 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
do a formula de Tartaglia, com a promessa de manter segredo, publicou esta
formula por volta de 1545. Ainda que os coeficientes da equacao devessem
ser numeros positivos, Cardano chega a admitir solucoes negativas para as
equacoes, denominadas razes menos puras ou numeros fictcios.
Em seu livro Ars magna (A grande arte), publicado em 1545, Cardano
trata a solucao de cada um dos treze tipos de equacao cubica em captulos
separados. O captulo XI, por exemplo, e destinado `a resolucao da cubica
do tipo cubo e coisas igual a numero. A demonstracao e feita tendo como
base um exemplo particular, numerico, de uma cubica e, posteriormente,
estabelece-se uma regra de resolucao deste tipo de cubica.
Exibiremos o metodo de resolucao fornecido por Cardano, que nao uti-
lizava nossa linguagem algebrica e que possua uma fundamentacao geome-
trica. A demonstracao feita por Cardano e difcil de compreender pelo que
a traduzimos para nossa linguagem simbolica, para facilitar o entendimento
do raciocnio de Cardano.
A equacao x3 + 6x2 = 20 era escrita como cub p 6 reb qualis 20 (cubo e
seis coisas igual a 20). No captulo XI do Ars magna, Cardano fornece um
metodo para resolver esta equacao. Queremos determinar um segmento GH
tal que o cubo de GH mais seis vezes o lado GH seja igual a 20. Sejam dois
cubos AE e CL cuja diferenca e 20 (A representacao plana destes cubos esta
na Figura 4.3).
Figura 4.3
Logo, o produto do lado AC pelo lado CK deve ser 2, ou seja, a terca
parte do numero de coisas. Fazendo BC igual a CK, teremos que AB e
igual a GH, ou seja, o valor da coisa. Neste momento, podemos associar
`as grandezas AC e CK as variaveis u e v, tais que AC = u e CK = v, de
modo que u  v = 2, que equivale a 1/3 do coeficiente de x na equacao. A
solucao desejada e AB = GH = u  v.
Devemos determinar AB. Comecamos por observar que DC e o cubo de
BC, DF e o cubo de AB, DA e tres vezes CB vezes o quadrado de AB e
DE e tres vezesAB vezes o quadrado de BC. Primeiro, Cardano enuncia
a propriedade de decomposicao do cubo: se uma quantidade e dividida em
duas partes, o cubo do todo e igual aos cubos das duas partes mais tres vezes
os produtos de cada uma das partes pelo quadrado da outra. Esta regra,
4.4. A RESOLUC AO DE EQUAC OES ALGEBRICAS POR RADICAIS 165
que nada mais e do que nossa regra para o cubo da soma, e demonstrada
geometricamente. Observemos a figura abaixo:
Figura 4.4
A partir da figura, podemos obter que DC = v3, DF = (u  v)3 = x3,
DA = 3 (u  v)2 v e DE = 3 (u  v) v2.
Ja que o produto de AC por CK da 2, o triplo de AC vezes CK da 6,
que e o numero de coisas. Como AB e igual a GH (coisa), temos que AB
vezes o triplo de AC vezes CK da 6 coisas. Sendo CK igual a BC, temos
que tres vezes o produto deAB, BC e AC e 6 vezes AB. Pela hipotese, temos
que a diferenca entre o cubo de AC e o cubo de CK e 20, que e a diferenca
entre o cubo de AC e o cubo de BC.
Em outros termos, ja que u.v = 2, temos que 3.u.v = 6, que e o coeficiente
de x na equacao dada. Assim, AB  3u.v = 6x. Por hipotese, temos que
u3  v3 = 20. A soma dos solidos DA, DE e DF e 20, o que nos remete `a
equacao (u  v)3 + 3. (u  v)2 v + 3. (u  v) v2 = 20.
Cardano manipula esta igualdade para concluir que o cubo de AB mais
6 vezes AB sera igual a 20. Mas o cubo de GH mais 6 vezes GH tambem e
igual a 20. Logo, GH sera igual a AB, portanto GH e a diferenca entre AC e
BC. As grandezas AC e BC, ou AC e CK, sao numeros ou linhas contendo
uma area igual `a terca parte do numero de coisas cujos cubos tem como
diferenca o termo numerico da equacao. Assim, teremos a seguinte regra:
Eleve ao cubo a terca parte do numero de coisas ao qual sera
somado o quadrado da metade do termo numerico da equacao
e extraia a raiz quadrada deste total que sera usado, em dois
momentos. Em um deles, adicione a metade do termo numerico
da equacao e no outro subtraia o mesmo numero. Teremos entao,
um binomium e o seu apotome respectivamente. Subtraia a raiz
cubica do apotome da raiz cubica do binomium e o resultado final
e o valor da coisa.
166 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
No caso particular da equacao cubo e seis coisas igual a 20, teremos:
eleve 2 ao cubo, que e a terca parte de 6, o que resulta em 8; Multiplique
10, metade do termo numerico, por ele mesmo resultando 100; some 100 e
8, obtendo 108. Extraia a raiz quadrada, que e 108, e a utilize em um
primeiro momento somando 10, e em um segundo momento subtraindo a
mesma quantidade, e teremos o binomium 108 + 10 e o apotome 108  10.
Extraia a raiz cubica desses valores e subtraia o valor do apotome do valor
do binomium, e teremos o valor da coisa: 3
108 + 10  3
108  10, escrito
em sua linguagem como R. v. cu. R. 108. p. 10. m. R. v. cu. R. 108. m. 10.
Utilizando termos algebricos atuais, poderamos reescrever como segue
o desenvolvimento e a regra de Cardano para a resolucao de uma equacao
cubica reduzida do tipo x3 + mx = n. Escrevemos os coeficientes m, n da
equacao em termos de valores a e b. observando uma identidade do tipo
(a  b)3 + 3ab(a  b) = a3  b3. Tomando m = 3ab e n = a3  b3 na equacao,
obtemos x = a  b. Desta forma, e possvel obter x a partir dos valores de a
e de b, mas para isso devemos resolver as equacoes de a e b em termos de
m e n. Fazendo a = m
3b e n = a3  b3 chegaremos `a equacao 27b6 + 27nb3 = m3
que pode ser resolvida para achar b por meio de uma equacao quadratica.
Resolvendo o sistema para a e b obtemos:
a3 = (n/2) + (n/2)2 + (m/3)3
b3 = (n/2) + (n/2)2 + (m/3)3
Tomando as respectivas razes cubicas positivas, Cardano obtem o valor
de x. Lembramos que Cardano nao usava este simbolismo algebrico e nao
empregava um raciocnio puramente algebrico na deducao da formula. O
papel da geometria na demonstracao de Cardano e o de justificar o metodo
algebrico. Vemos que ele se orgulha de ter obtido um metodo algebrico
baseado em argumentacoes geometricas:
No mais, quando entendi que a regra que Tartaglia havia
fornecido tinha sido descoberta por mim a partir de uma de-
monstracao geometrica, pensei que este seria o melhor caminho
a seguir em todos os casos.
Nesta citacao, podemos ver que o objetivo de Cardano podia nao ser
o de disputar a prioridade do metodo com Tartaglia, mas fornecer uma
justificativa mais legitima, permitindo que este metodo fosse generalizado
para outros casos, de ordens superiores.
4.4. A RESOLUC AO DE EQUAC OES ALGEBRICAS POR RADICAIS 167
Analisando a formula escrita em nossa notacao, podemos ver que quando
(n/2)2 + (m/3)3 e negativo, encontramos duas razes de numeros negativos
durante a solucao. Como veremos no Captulo 6, mesmo neste caso, pode
existir uma raiz valida para a equacao, que seria obtida pela formula quando
as razes de numeros negativos se cancelam, quando fazemos x = a  b. E o
caso da equacao x3 = 15x+4, chamada irredutvel. Se aplicarmos a formula
a esta equacao, obtemos que x = 3

2 + 121 + 3

2  121. Por tentativas
e erros, baseados em formulas geometricas como a que Cardano obteve para
o cubo da soma, era possvel descobrir que as razes cubicas acima eram algo
como o que expressamos hoje por 2+1 e 21. Fazendo x = a+b, temos
que x = 4 e uma raiz valida da equacao.
Mas para resolver este tipo de equacao e obter razes validas, era preciso
manipular expressoes que contem razes de numeros negativos, que nao eram
consideradas numeros. Quantidades negativas ja tinham aparecido em pro-
blemas mais simples, envolvendo equacoes do segundo grau. Neste caso, no
entanto, quando a quantidade negativa aparece no resultado, era facil driblar
a dificuldade, bastava dizer que a equacao nao tinha solucao. A aplicacao da
formula para resolver equacoes do terceiro grau faz com que nao seja possvel
se desviar da questao com facilidade.
O problema das equacoes irredutveis sera resolvido por outro italiano
chamado Bombelli. 2 Para isto, ele designara as razes quadradas de numeros
negativos por pi`u di meno (p.d.m.), no caso da raiz positiva que chamamos
hoje de i, e meno di meno, (m.d.m.), no caso da raiz negativa, que chamamos
de i, e fornecera as regras de adicao e multiplicacao destes numeros. Mas
deixaremos esta discussao para o Captulo 6, que trata da historia dos nu-
meros complexos.
Dentre os metodos mais importantes introduzidos por Cardano no Ars
magna esta a transformacao ou reducao de equacoes. Por exemplo, reduzia-
se uma equacao cubica em outra sem o termo de segundo grau que, em
linguagem atual, significa reescrever a equacao x3 + ax2 + bx + c = 0 em uma
nova variavel. Fazendo a substituicao x = y  a
3 , obtem-se uma equacao com
coeficientes arbitrarios onde o termo em y2 fica ausente. Com esta nova
variavel, a equacao adquire a forma y3 + py = q, que tambem e conhecida
como uma forma reduzida da equacao cubica.
Em muitos casos, Cardano estuda o efeito que a transformacao de uma
equacao em outra pode ter na alteracao das razes. Por exemplo, da equacao
x3 +8x = 64, que ele sabia resolver pelo metodo descrito acima, podemos obter
x3 = x2 + 8 por meio da transformacao que leva x em 8/x. Logo, aplicando
2Rafael Bombelli nasceu em Bolonha, 1526 e morreu em 1572, provavelmente em Roma.
Seu livro Algebra foi importante no desenvolvimento da algebra.
168 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
esta transformacao, tambem podemos resolver a segunda equacao.
Este metodo permite transformar problemas conhecidos em problemas
desconhecidos e descobrir novas regras. Realmente, a transformacao de
equacoes e a solucao pela adaptacao das razes foi um metodo central para
os matematicos posteriores, como Vi`ete.
Diferente dos exemplos anteriores, de descricao de metodos para resolver
equacoes de determinados tipos, Cardano inaugurava a investigacao sobre a
estrutura e a solvabilidade das equacoes, ponto de partida da algebra mo-
derna abstrata. Segundo Stedall, esta razao e suficiente para considerarmos
Cardano o verdadeiro pai da algebra europeia, ver ([137]). Vi`ete seria o seu
herdeiro.
Se acreditarmos nesta afirmacao e lembrarmos que o trabalho de Car-
dano continha muito pouca notacao, seremos obrigados a relativizar nossa
definicao usual de algebra como o ramo da Matematica que usa letras, e
smbolos em geral, para representar numeros e quantidades. A inovacao
de Cardano esta nos metodos propostos, sobretudo os de transformacao de
equacoes, descritos praticamente sem notacao simbolica.
Veremos, na ultima secao, que Vi`ete mostrara como a algebra permite
entender outros ramos da Matematica, como a geometria, em contraste com
seus predecessores, como Al-Khwarizmi e Cardano, que usavam a geometria
para justificar a algebra. Antes disso, falaremos de um novo simbolismo
introduzido por este matematico frances que, apesar de nao ser o traco mais
relevante de sua obra, contribuiu de modo decisivo para que se possa escrever
formulas para resolver equacoes.
Exerccios
4.7. Resolva a equacao x3 = 63x + 162 pelo metodo de Tartaglia e Cardano.
Note que (3 + 23)3 = 81 + 303 e (3  23)3 = 81  303.
4.8. E possvel encontrar as tres razes dessa equacao pela formula de Car-
dano? Esta formula so vale para uma equacao do tipo x3 + mx = n ou
tambem vale para x3 = mx + n.?
4.9. O seguinte problema fez parte da disputa matematica entre Ferrari e
Tartaglia: Divida o numero 8 em duas partes x e y tais que xy(x  y) e
maximo. Observe que, quando este problema foi formulado, e resolvido,
as tecnicas do calculo infinitesimal ainda nao existiam. Resolva-o sem
usar calculo.
4.5. OS N UMEROS NEGATIVOS E IMAGIN ARIOS 169
4.5 Os numeros negativos e imaginarios no con-
texto da resolucao de equacoes
O advento da algebra trouxe `a tona, ao mesmo tempo, o problema dos
numeros negativos e de suas razes que, apesar de surgirem no calculo ou
nas solucoes das equacoes, nao possuam um estatuto definido. Nas civi-
lizacoes mais antigas (babilonios, egpcios, chineses, gregos, hindus, etc), nao
se usavam numeros negativos no sentido proprio. Eram admitidas operacoes
de subtracao e multiplicacao que envolvessem, por exemplo, a subtracao de
um numero maior de um menor, como 2  6, mas o numero 4 nao era ad-
mitido enquanto tal. As regras de operacao entre somas ou diferencas, que
exprimimos hoje como (a + b)  (a  b) ou (a  b)  (a  b), e que eles expri-
miam para valores numericos especficos, deviam levar em consideracao as
regras de sinais. Muitos destes povos ja sabiam, portanto, intuitivamente,
que mais com mais da mais, menos com mais da menos e menos com menos da
mais. No entanto, esse problema, bem como o dos numeros imaginarios, so
surgira, de modo mais explcito, com o desenvolvimento da algebra a partir
do Renascimento.
Sabemos que alguns matematicos indianos, bem como Fibonacci, ja pro-
punham interpretar um numero negativo como uma perda, no lugar de um
ganho. No seculo XV, Nicolas Chuquet ja representava o numero negativo
a como 0  a, o que mostra que o sinal  ainda nao era um atributo do
numero, mas sim a indicacao de uma operacao.
Cardano, que, como vimos, foi um dos principais responsaveis pelo desen-
volvimento da algebra no seculo XVI, ja admitia razes negativas de equacoes,
mas designava estas solucoes como fictcias. Logo, ainda que a natureza des-
tes numeros nao estivesse clara, os matematicos deste perodo investigavam
as regras de operacao com numeros negativos. No caso de Cardano, ele nao
admitia que menos com menos pudesse dar mais. E interessante observar
que numeros negativos, quando apareciam nos calculos, ja eram chamados,
na maioria dos casos, de negativos. No entanto, quando representavam a
solucao de uma equacao, deviam ser chamados de fictcios, como em Car-
dano. Isto mostra que, apesar do reconhecimento da utilidade pratica destes
numeros para os calculos, eles nao eram considerados numeros verdadeiros,
ou seja, verdadeiros objetos matematicos. Isto porque os objetos que de-
viam ser admitidos na Matematica ainda se confundiam com as grandezas
geometricas e, por esta razao, o sentido matematico de um numero negativo
ainda nao podia ser plenamente admitido. Em uma tentativa de dar sentido
aos numeros negativos, ainda no seculo XVI, o italiano Bombelli chegou a
enunciar que: p 15 com m 20 da m 5 porque, se tivesse 15 unidades de moeda
170 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
e devesse 20, pagando as 15 continuaria devendo 5.
Uma situacao semelhante `a dos numeros negativos ocorre para suas razes.
No seculo XIII, Fibonacci foi desafiado por um problema que levou ao calculo
das razes da equacao que denotaramos hoje como x3 + 2x2 + 10x = 20 e
mostrou que a solucao nao pode ser classificada em nenhum dos casos listados
nos Elementos de Euclides.
Ja vimos o metodo usado por Cardano e Tartaglia para resolver equacoes
cubicas. No entanto, surgia um problema no caso das chamadas equacoes
irredutveis, como x3 = 15x + 4. E facil ver que esta equacao possui uma raiz
valida (racional positiva) que e 4. No entanto, o metodo fazia aparecer razes
de numeros negativos como intermediarias no calculo das razes das equacoes
cubicas, apesar de somente as razes racionais positivas serem admitidas como
solucao.
Os algebristas da Renascenca tinham por objetivo resolver equacoes e,
por esta razao, apesar de nao admitirem certas quantidades como solucao
da equacao, podiam aceitar quantidades que apareciam nos calculos, mas
que desapareciam no resultado. Estas quantidades eram utilizadas de modo
puramente pragmatico, sem que sua natureza fosse questionada. Apesar
de afirmar explicitamente que a raiz quadrada de um numero positivo e
positiva e a raiz quadrada de um numero negativo nao e correta, Cardano
nao se priva de operar com razes de numeros negativos. Por exemplo, diz
ele, se queremos dividir o numero 10 em duas partes cujo produto seja 40, e
evidente que este problema e impossvel, mas podemos fazer os calculos do modo
que segue: dividimos 10 em duas partes iguais obtendo 5, que multiplicado
por si mesmo da 25; subtramos de 25 o produto requerido, ou seja 40, e
restara m15.
A solucao devia ser justificada geometricamente e Cardano apresenta
uma tentativa interessante para suprir a ausencia de uma representacao
geometrica natural para esta situacao. Segundo as proposicoes de Eucli-
des, a equacao de que tratamos aqui exigiria a construcao de um quadrado
de area m15. Dividindo o segmento AB de comprimento 10 em dois segmen-
tos iguais e desiguais, queremos encontrar o ponto D que resolve o problema.
Para isto, seria necessario retirar do quadrado CEF B (Veja a Figura 4.5), de
area 25, um quadrado de area 40 (igual ao produto de AD por DB). Sendo
assim, o quadrado em CD deveria ter area m 15.
A figura e equivalente `a da proposicao II.5 dos Elementos de Euclides, a
qual afirma que AB  DB + CD2 = CB2 = CEF B:
A fim de encontrar um sentido geometrico para a regra de calculo uti-
lizada, Cardano observa que 40 e o quadruplo de 10, logo queremos que o
produto AD  DB seja o quadruplo de AB. Devemos, portanto, retirar de
CEF B o quadruplo de AB. Se restasse algo, a raiz quadrada desta quanti-
4.5. OS N UMEROS NEGATIVOS E IMAGIN ARIOS 171
Figura 4.5
dade, respectivamente somada `a raiz de CEF B e subtrada da mesma, daria
o resultado procurado. Mas como o resultado e negativo, e a diferenca entre
CEF B e o quadruplo de AB e m15, esta raiz seria Rm15, quantidade que
respectivamente somada a 5 e subtrada de 5, nos daria a solucao desejada.
Estas solucoes eram escritas como 5 p R m 15 e 5 m R m 15 e Cardano afirma
que fazendo abstracao das torturas infligidas ao nosso entendimento podemos
concluir que o produto destes dois numeros e 40, ou seja, 25 mm15 quad est
40. No entanto, CEF B nao possui a mesma natureza que AB, logo nao
possui a mesma natureza do quadruplo de AB, que e 40, pois uma superfcie
e por natureza diferente de um numero e de uma reta. As quantidades obtidas
(5 p R m 15 e 5 m R m 15) sao, portanto, diz Cardano, realmente sofsticas,
uma vez que podemos realizar com elas operacoes que nao podemos realizar
nem com os numeros puramente negativos, nem com os outros ([24], p.66).
Na verdade, ele esta realizando a multiplicacao de 5 + 15 por 5  15
e obtem como resultado 25  (15) = 40. No entanto, para justificar geo-
metricamente esta operacao, e obrigado a utilizar quantidades sofsticas que
permitem a realizacao de operacoes como retirar um segmento de um qua-
drado. Este e um dos indcios de que Cardano ficava dividido entre assumir
as operacoes algebricas por si mesmas e tentar justifica-las geometricamente.
Um exemplo desta ambiguidade e que, ao mesmo tempo em que afirma que
nao haveria sentido em considerar equacoes acima do terceiro grau, uma
vez que geometricamente remeteriam a quantidades absurdas, pois superi-
ores ao cubo, Cardano comenta a solucao de uma equacao de grau quatro.
Vemos pelo uso das quantidades realmente sofsticas que, para Cardano, era
ao mesmo tempo necessario e confuso dar sentido geometrico `as operacoes
algebricas as quais, todavia, funcionavam tao bem. Mas o problema de jus-
tificar a possibilidade de calcular a raiz de um numero negativo permanece.
Vimos que este problema surge no caso das equacoes irredutveis estuda-
das no seculo XVI e resolvidas pelo metodo de Cardano e Tartaglia. Este
metodo so apresenta uma raiz, mas pode ser aplicado para o caso em que
a equacao possui mais de uma raiz. Isto pode exigir o calculo de razes
cubicas de numeros do tipo que exprimimos hoje como a  b1. Atual-
172 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
mente, quando queremos encontrar razes cubicas envolvendo numeros deste
tipo, usamos a formula de De Moivre. Mas esta formula so foi introduzida
na primeira metade do seculo XVIII e, na verdade, o primeiro matematico
a calcular efetivamente uma raiz real a partir da raiz cubica de numeros
complexos (que aparecem na formula de Cardano) foi Bombelli.
O problema era o de calcular a raiz da equacao que escrevemos hoje como
x3 = 15x + 4. Primeiramente, aplicava-se a formula de Cardano, que permite
obter a = 3

2 + 121 e b = 3

2  121. A raiz seria dada, portanto, por:
3

2 + 121 + 3

2  121 = 4.
E possvel calcular a raiz destes numeros complexos supondo elas devem
ser do tipo a  b1. Supondo que 3

2 + 121 = x + y1, obtemos
2 + 111 = x3 + 3x2y1  3xy2  y31.
Separando os termos que sao multiplicados pela raiz dos que nao sao,
conclumos que x33xy2 = 2 e 3x2yy3 = 11. Partindo de que x(x23y2) = 21
e supondo que x = 2, obtemos de 43y2 = 1 que y = 1 (poderamos ter suposto
inicialmente x = 1, mas isto forneceria y = 0 o que nao e possvel). Conclumos
assim que 3

2 + 121 = 2 + 1.
Obviamente, Bombelli nao usa esta notacao e nao sabemos se ele empre-
gou um procedimento deste tipo. O raciocnio apresentado supoe que um
numero complexo tem sempre a forma a  b1, uma conclusao que so foi
estabelecida no seculo XVIII.
Designando a raiz quadrada por R.q. e a raiz cubica por R.c., Bombelli
escreve que R.c. 2.p.dm.R.q.121 + R.c.2.m.dm.R.q.121 e 4s. Observamos que
ele usa a notacao dm.R.q.121 para 121, o que e diferente de R.q.m121.
A notacao muda se esta raiz e somada ou subtrada, o que indica que sua
notacao para 121 privilegia a operacao realizada com este numero e nao
o numero dado pela raiz de um numero negativo.
O mais interessante desta notacao e que p.dm., que e a abreviacao para
pi`u di meno em italiano, designa que estamos somando, na verdade, a raiz
quadrada do numero negativo 121 e m.dm., abreviacao de meno di meno, de-
signa a subtracao desta mesma quantidade. Nao esta claro exatamente como
Bombelli encontra a raiz cubica, mas ele conclui que seu valor e 4. Quanto `as
outras operacoes entre os numeros p.dm. e m.dm., Bombelli fornece algorit-
mos que permitem calcular suas multiplicacoes por qualquer outro numero,
afirmando inclusive que m.dm. vezes m.dm. da m., o que e equivalente
a dizer que 1  1 = 1. Isto mostra que Bombelli ja admitia es-
tes numeros como entidades aritmeticas aceitaveis, sobre as quais podamos
4.5. OS N UMEROS NEGATIVOS E IMAGIN ARIOS 173
enunciar regras de calculo.
Os numeros imaginarios sao abordados em seu primeiro livro, juntamente
com definicoes de conceitos elementares, como potencias, razes, binomios e
as operacoes que os envolvem. Ele reconhece a existencia das razes negativas
e segue adiante afirmando que estas expressoes sao mais sofsticas que reais,
como podemos perceber no trecho citado abaixo, encontrado na pagina 133
de Lalgebra:
Encontrei um outro tipo de raiz cubica composta muito di-
ferente das outras, que nasce no captulo do cubo igual a tanto
e numero, quando o cubo da terca parte do tanto e maior que o
quadrado da metade do numero, como nesse captulo se demons-
trara, (. . . ) porque quando o cubo do terco do tanto e maior que
o quadrado da metade do numero, o excesso nao se pode cha-
mar nem mais nem menos, pelo que lhe chamarei de pi`u di meno,
quando se adicionar e meno di meno quando se subtrair. (. . . )
E esta operacao e necessaria (. . . ) pois sao muitos os casos de
adicionar onde surge esta raiz, (. . . ) que podera parecer a muitos
mais sofstica que real, tendo eu tambem essa opiniao, ate ter
encontrado a sua demonstracao (. . . ) mas primeiro tratarei de os
multiplicar, escrevendo a regra de mais e de menos.
Alguns historiadores da Matematica, como Bourbaki, chegam a afirmar
que pi`u, meno, meno di meno e pi`u di meno sao respectivamente 1, 1, i e
i. Sobretudo porque Bombelli, no captulo Summare di p.di m. et m.di m,
apresenta um importante axioma que revela que nao se pode somar pi`u com
piu.di.meno. Esta ideia e vista como uma primeira nocao de independencia
linear entre os valores real e imaginario.
Poderamos efetivamente estabelecer uma comparacao entre as regras de
Bombelli e aquelas que utilizamos atualmente, porem dizer que pi`u, meno,
meno di meno e pi`u di meno sao respectivamente 1, 1, i e i nos parece peri-
goso. A razao mais forte para nos precavermos desta associacao apressada e
que nos utilizaremos mais tarde o smbolo i para representar a unidade ima-
ginaria, ao passo que pi`u di meno e meno di meno contem em suas expressoes
as ideias de adicao e de subtracao, ou seja, relacionam-se a operacoes. Ou
seja, nos parece valioso insistir, do ponto de vista da historia da Matematica,
que pi`u di meno e meno di meno, mesmo tendo respectivamente o significado
de +1 e 1, nao significam os nossos i e i. Os sinais que precedem as
razes do numero 1 indicam que estas quantidades nao sao independentes,
mas sao sempre somadas a, ou subtradas de, um numero real.
A obra de Bombelli nao teve muita repercussao e o emprego dos numeros
negativos e de suas razes ainda inquietava os matematicos do seculo XVII,
174 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
com excecao do caso em que as razes de numeros negativos eram apenas um
intermediario para se chegar a razes reais.
A introducao de uma nova notacao, com os trabalhos de Vi`ete, desviou
a atencao dos matematicos que sucederam aos algebristas do seculo XVI.
No entanto, apesar das grandes inovacoes propostas em sua obra, Vi`ete nao
admitia nem numeros negativos, nem suas razes.
Um problema ligado ao da consistencia desses numeros diz respeito jus-
tamente `a notacao, ou seja, ao modo como eles sao escritos. Na solucao da
equacao cubica, com base nas formulas desenvolvidas pelos matematicos do
seculo XVI, os numeros imaginarios eram sempre da forma a  b1 (com
a e b reais), escritos na notacao da epoca (antecipacoes do smbolo 1
so comecaram a ser usadas no final do seculo XVII). Cabia perguntar, no
entanto, se nas equacoes de grau maior os numeros imaginarios, como desig-
nados por Descartes, seriam sempre desta forma, ou se existiriam universos
mais amplos onde esses numeros poderiam ser escritos de outro modo. Isto
porque nao se sabia sequer se as razes de equacoes de grau maior que tres
podiam ser expressas por radicais.
Em 1629, o frances Albert Girard introduziu o problema de saber qual o
numero de razes de uma equacao qualquer, problema que funda uma pers-
pectiva mais geral de analise das equacoes. Ele afirma que todas as equacoes
possuem tantas solucoes quanto o grau da quantidade de maior grau, o que
consiste em uma primeira versao do que conhecemos hoje como teorema fun-
damental da algebra. Obviamente, para admitir este numero de solucoes, sera
necessario admitir como validas as solucoes que ele chama de impossveis. Mas
para que servem estas solucoes se elas sao impossveis? Girard responde que
elas servem pela sua utilidade, mas, sobretudo, para garantir a generalidade
do resultado:
Todas as equacoes da algebra recebem tantas solucoes quanto
a denominacao da mais alta quantidade, exceto as incompletas.
(. . . ) Poderamos perguntar para que servem as solucoes que sao
impossveis, respondo que para tres coisas: para a certeza da
regra geral, para a certeza de que nao ha outra solucao por sua
utilidade.([69])
Em seguida, ele afirma que as solucoes podem ser mais que nada, me-
nos que nada ou do tipo . A solucao negativa e interpretada por Girard
de um modo ja bastante proximo do atual, indicando que, em geometria, ela
se explica como um recuo, no lugar do avanco indicado pelo smbolo
+.
Alguns anos mais tarde, em seu A geometria, Descartes tambem admite
que uma equacao possui tantas razes quantas sao as dimensoes da quantidade
4.5. OS N UMEROS NEGATIVOS E IMAGIN ARIOS 175
desconhecida. No entanto, Descartes afirma que pode acontecer que algumas
destas razes sejam falsas ou menos que nada e investiga, dada uma equacao
qualquer, quantas sao as razes verdadeiras e quantas sao as falsas. Ele
conclui, entao, que:
Tanto as verdadeiras razes quanto as falsas nao sao sem-
pre reais, mas `as vezes apenas imaginarias; o que quer dizer
que podemos sempre imaginar tantas quanto dissemos em cada
equacao, mas `as vezes nao ha nenhuma quantidade que corres-
ponda `aquelas que imaginamos. ([43], p.86).
O exemplo utilizado para ilustrar este caso e o da equacao x3  6xx +
13x  10 = 0, para a qual podemos imaginar tres solucoes das quais ape-
nas uma e real, dada pelo numero 2, ao passo que as outras, mesmo que
as aumentassemos, diminussemos, ou multiplicassemos, nao conseguiramos
fazer com que deixassem de ser imaginarias. A palavra imaginaria, talvez
devido `a grande influencia da obra de Descartes, passara a ser a mais usada
para designar estas quantidades e indica a impossibilidade de representacao
geometrica para as solucoes encontradas.
Resultados como os que antecederam o teorema fundamental da algebra
levam `a necessidade de se considerar todas as razes, sejam elas reais ou ima-
ginarias. Observamos que o real de que se trata aqui e um real geometrico. A
exigencia algebrica faz surgir o problema de se estabelecer o estatuto para as
quantidades negativas e imaginarias, mas ainda nao era colocado o problema
de fornecer uma definicao e uma representacao para estes numeros.
Exerccios
4.10. Empregando a substituicao x = y  2/3 use a formula de Cardano e
Tartaglia para encontrar as razes da equacao x3  6xx + 13x  10 = 0.
4.11. Resolva o seguinte problema, que se encontra no livro de Bombelli,
e que transcrevemos em notacao moderna: Escreva 3

52 + 2209 na
forma a + bi.
4.12. Resolva o seguinte problema proposto por Cardano: O dote da mulher
de Francisco e igual a mais 100 moedas de ouro do que os bens do
proprio Francisco, e o quadrado do dote e 400 moedas de ouro a mais
do que o quadrado dos bens de Francisco. Ache o dote e os bens de
Francisco. (Cardano interpretaa a solucao negativa como uma dvida).
4.13. Siga o roteiro abaixo para resolver, como Ferrari, a equacao x4 +4x+8 =
10x2.
176 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
1. Reescreva a equacao como x4 = 10x2  4x  8.
2. Adicione 2bx2 + b2 a ambos os lados.
3. Determine que condicao b deve satisfazer para que cada lado da
equacao resultante seja um quadrado perfeito.
4. Para cada solucao da equacao cubica obtida, ache todos valores
da incognita x.
5. Quantas razes tem a equacao original?
4.6 O passo decisivo para a obtencao de uma
formula para resolver equacoes e o trabalho
de Vi`ete
Sabemos que os matematicos indianos ja utilizavam abreviacoes para desig-
nar as incognitas, que eram expressas pelas iniciais dos nomes das cores.
Em meados do seculo XVI torna-se razoavelmente comum o uso de letras
(distintas) para designar incognitas (distintas) em equacoes com coeficientes
numericos. Alem disso, as potencias das incognitas eram designadas por pa-
lavras que eram tambem abreviadas, ou mesmo simbolizadas, desde alguns
matematicos arabes que sucederam a Al-Khwarizmi. Mas note que, nas re-
gras para a resolucao de equacoes de segundo grau, dizemos: tomar a metade
do numero de Jidhr. O que muda nestas regras de resolucao de equacoes
quando introduzimos smbolos para as quantidades desconhecidas, conside-
rando que as potencias destas quantidades eram expressas por smbolos dis-
tintos? Se substituirmos Jidhr por x teramos: tomar a metade do numero de
x. O mesmo para o Mal, quantidade desconhecida que e o quadrado de x
mas que seria, dentro desta logica, designada por y.
Smbolos para adicao e subtracao ja eram conhecidos desde os egpcios.
Smbolos para operacoes mais gerais ja foram usados por Diofanto, incluindo
a designacao simbolica para uma quantidade desconhecida. Os indianos ja
usavam abreviacoes e smbolos para operacoes de modo generalizado. No
caso dos arabes, a algebra usava predominantemente palavras (apesar do uso
esparso de simbolismo para a utilizacao de algoritmos), mas suficientemente
geral para enunciar regras que poderiam ser aplicadas a um tipo geral de
equacao. Os matematicos dos seculos XV e XVI, especialmente os italianos,
introduziram um simbolismo, que inclua a representacao das incognitas e
das operacoes, para enunciar as regras algebricas desenvolvidas pelos arabes.
Se alguem tivesse reunido a um so tempo, nesta epoca, todos estes avancos
simbolicos isolados, vejamos o que essa pessoa poderia ter obtido. Adicio-
4.6. O PASSO DECISIVO DE VI `ETE 177
nando a generalidade das regras arabes ou indianas a todos os simbolis-
mos usados ate entao, teramos algo como a expressao abaixo, obtida pela
adaptacao da regra de Al-Khwarizmi aos simbolismos existentes:
Seja a equacao A+21 = 10B, em que A e o quadrado de B. Para qualquer
numero que substituirmos por 21 e 10 na equacao, o valor de B (que e a raiz
da equacao) pode ser obtido pelo procedimento: tomar a metade do numero
de Bs (note que aqui nao estamos falando de B2, mas da metade do numero
que multiplica B, que nesta equacao e 10, mas pode mudar de uma equacao
para outra); multiplicar o resultado por si mesmo; subtrair do resultado o
numero (que na equacao e 21 mas tambem pode mudar de uma equacao para
outra); . . .
O passo decisivo para que possamos transformar esta regra em uma
formula, tal como conhecemos hoje, sera a introducao de um simbolismo para
os coeficientes da equacao, que nos permita escrever algo como A+m = nB. A
introducao destes smbolos nos permite entrever, diante somente do smbolo,
a relacao entre A e B, que e o que temos quando escrevemos A + m = nB. Os
tres primeiros passos do procedimento descrito acima se resumiriam, entao,
a escrever: (n/2)2  m.
Este foi justamente o passo dado pelo matematico frances Francois Vi`ete,
que viveu entre os anos 1540 e 1603. Ele introduz uma representacao padrao
para os coeficientes de uma equacao. As incognitas serao representadas
pelas vogais e os coeficientes pelas consoantes do alfabeto, todas maiusculas.
Alem disso, ele simboliza as potencias usando uma mesma letra: se A e
a incognita, seu quadrado e chamado A quadratum, seu cubo A cubum, e
assim por diante. Se chamarmos x de A, a equacao x2 + b = cx (significando
area+area=area) seria escrita, na notacao de Vi`ete, como A quadratum +
B aequatur C in A. (A palavra aequatur quer dizer igual). Na verdade, esta
equacao e escrita adicionando a palavra plano depois B, uma vez que todas
as parcelas devem possuir as mesmas dimensoes, e teramos A quadratum +
B plano aequatur C in A. De modo analogo, um numero a ser igualado a um
cubo era denominado solido.
Chegamos, assim, a uma concepcao proxima da algebra que conhecemos
atualmente, sobretudo apos o seculo XVII, quando algumas notacoes serao
sugeridas, como a substituicao das vogais, para representar as incognitas,
pelas ultimas letras do alfabeto como x, y, z, w, . . .; e a representacao dos
coeficientes pelas primeiras letras do alfabeto.
E importante observar que ha uma diferenca de natureza fundamental
entre uma incognitae um coeficiente. A incognita e uma quantidade que
esta desconhecida e que sera conhecida a partir das restricoes representadas
pela equacao, ja o coeficiente e uma quantidade conhecida generica que esta,
portanto, indeterminada na expressao de uma equacao qualquer. Ambos os
178 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
casos pressupoem indeterminacoes, mas em nveis distintos: a determinacao
dos coeficientes e obtida pela escolha de uma equacao particular (arbitraria)
e a determinacao do valor da incognita, pela resolucao (nao arbitraria) desta
equacao. Sendo assim, no universo das equacoes, a escolha arbitraria de
coeficientes determina uma equacao. Ja a determinacao da incognita depende
das restricoes dadas por uma equacao.
A notacao introduzida por Vi`ete representou uma generalizacao dos me-
todos algebricos que permitiu classificar as equacoes tratadas anteriormente
como casos. Isto foi possibilitado pelo fato de podermos trabalhar no
universo das equacoes, usando coeficientes.
O livro mais importante de Vi`ete chama-se Arte analtica, o que ja indica
que os metodos que ele desenvolve visam encarar os problemas de forma geral,
investigando sua estrutura, antes de buscar resolver casos particulares. Esta
obra foi influenciada pela traducao da Colecao Matematica de Pappus, em
1588, que fez ressurgir o interesse pelos problemas de construcao dos gregos.
Para resolver problemas de geometria, Vi`ete propunha usar o tipo de ar-
gumentacao denominado analise, que ja tinha sido empregado pelos gregos,
mas identificando-o `a ferramenta algebrica. A Arte analtica comeca com uma
explicacao do que e a analise:
Encontra-se na Matematica uma certa maneira de procurar a
verdade, que diz-se ter sido primeiramente inventada por Platao,
que Theon chamou Analise e que, para ele, define a suposicao
daquilo que procuramos como se estivesse concedido para che-
gar a uma verdade procurada, por meio das consequencias; ao
contrario, a Sntese e a suposicao de uma coisa concedida para
chegar ao conhecimento daquilo que procuramos pelo meio das
consequencias.
A geometria sintetica e aquela na qual construmos as solucoes. Ja pelo
metodo analtico, supomos que as solucoes desconhecidas sao conhecidas e
operamos com elas como se fossem conhecidas, ate chegar a um resultado
conhecido que determina a solucao. A simbolizacao algebrica permite repre-
sentar estas solucoes desconhecidas por smbolos, manipulados segundo as
mesmas regras que os numeros conhecidos.
A resolucao de equacao algebrica fornece um otimo exemplo de analise.
A incognita, ou o x, e a quantidade desconhecida. Quando escrevemos
x + 2 = 3, tratamos o x como se fosse conhecido e operamos com esta quan-
tidade da mesma forma que fazemos com o 3 e o 2 que sao, efetivamente,
numeros conhecidos. Com esta manipulacao, fazemos x = 3  2 = 1 e en-
contramos o valor da quantidade desconhecida. Operamos, neste exemplo,
4.6. O PASSO DECISIVO DE VI `ETE 179
com as quantidades procuradas, como se elas ja estivessem dadas. Logo,
para resolver o problema de encontrar duas grandezas com soma e produto
dados pelo metodo analtico, comecamos supondo que estas grandezas, que
procuramos, sao dadas, e podem ser chamadas de x e y. Em seguida, por
manipulacoes algebricas, encontramos os valores reais de x e y.
Para Vi`ete, no entanto, o metodo analtico, empregado por meio da
ferramenta algebrica, era somente um auxiliar na resolucao de problemas
geometricos. Em seu livro Effectionum geometricarum canonica recensio ele
mostra como as solucoes de uma equacao do 2o.grau podem ser achadas geo-
metricamente utilizando somente regua e compasso:
R M O N
S
T
Figura 4.6 Solucao de A2 + AB = D2.
Dada a equacao, A2 + AB = D2, que escreveramos hoje como x2 + px = q2,
Vi`ete procede como segue (Figura 4.6).
Construa MN = p e seja T N = q perpendicular a MN. Seja O o ponto
medio de MN. com centro em O, trace a circunferencia de raio OT . Sejam
R e S os pontos em que esta circunferencia corta o prolongamento de MN.
Entao, o triangulo retangulo RST fornece imediatamente que T N2 = RN 
NS, ou seja, q2 = (x + p)x = x2 + px.
No mesmo livro, Vi`ete constroi tambem, geometricamente, as solucoes
das equacoes A2  AB = D2 e AB  A2 = D2. Deixamos ao cuidado do leitor
achar construcoes, analogas `a que fizemos, para resolver estas equacoes.
Exerccios
4.14. Escreva, na notacao de Vi`ete, a equacao x3 + bx2 + cx = d.
4.15. Explique como Vi`ete achou, geometricamente, as solucoes de equacoes
dos tipos A2  AB = D2 e AB  A2 = D2.
4.16. Siga o roteiro abaixo para resolver o seguinte problema de Vi`ete: Dado
o produto de dois numeros e sua razao, encontrar os numeros.
180 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
 Sejam A e E os dois numeros, seu produto AE = B, e sua razao
A  E = S  R. Mostre entao que
R  S = B  A2 e que S  R = B  E2.
 Se B = 20, R = 1 e S = 5 (ou seja, o produto dos dois numeros
e 20 e eles estao entre si assim como 1 esta para 5), conclua que
A = 10 e E = 2.
 Como voce resolveria o problema, hoje?
4.7 Os logaritmos de Neper
Como vimos na secao sobre a historia da trigonometria, desde a Antigui-
dade eram usadas tabelas contendo quantidades trigonometricas associadas
a angulos. Estas quantidades continuaram sendo usadas ate a epoca de que
tratamos, em relacao com problemas praticos, como os da astronomia e da
navegacao. As tabelas trigonometricas construdas para tratar estes proble-
mas usavam circunferencias de raios grandes, para evitar o problema de lidar
com numeros fracionarios.
Devido aos dados deste tipo de problema serem inacessveis `a medida
direta, as grandezas do problema deviam ser obtidas de modo indireto, por
meio de propriedades de figuras geometricas. Neste contexto, nao e difcil
imaginar o valor pratico de se calcular o angulo ou o lado de um triangulo
com dimensoes dadas por numeros grandes, como no problema abaixo:
Exemplo 4.2. Seja o triangulo ABC com lados AB = 26.302, BC = 57.995 e
angulo C = 26o dados (Figura 4.7). Queremos calcular o angulo A sabendo que
ele e agudo.
Figura 4.7
Ja era conhecida a propriedade de que AB
sen (C) = BC
sen (A) . Logo, podemos
escrever
26.302
sen (26o) = 57.995
sen (A) . (4.1)
4.7. OS LOGARITMOS DE NEPER 181
Para calcular sen (A) e, portanto, encontrar o angulo A, era necessario
efetuar multiplicacoes e divisoes com estes numeros que, por advirem de
problemas astronomicos, podiam ser muito grandes e conter uma parte fra-
cionaria tambem grande.
Assim, seria conveniente que um problema contendo multiplicacoes e di-
visoes como este pudesse ser resolvido por intermedio de outro, no qual as
multiplicacoes e divisoes fossem reduzidas a adicoes e subtracoes. A partir
de nossos conhecimentos da Matematica atual, sabemos que a nocao de lo-
garitmo permite esta simplificacao. Usando logaritmos, a igualdade 4.1 seria
equivalente a:
log(AB)  log(sen (C)) = log(BC)  log(sen (A))
Com esta transformacao do problema, a resolucao seria dada pelo seguinte
procedimento: procura-se em uma tabela de senos o valor dos logaritmos
de AB = 26.302, BC = 57.955 e sen (26o). Efetuando somente adicoes e
subtracoes com os numeros encontrados, obtemos log(sen (A)) = 346.675.
Deve-se, em seguida, consultar a tabela de senos para encontrar um angulo
cujo seno seja proximo deste valor3. Como log(sen (75o)) = 346.683, pode-se
concluir que o angulo A mede, aproximadamente, 75o.
Observamos, no exemplo acima, que o procedimento de resolucao usa
fortemente as tabelas de senos e de logaritmos. No caso dos senos, ja vimos
como elas foram construdas, queremos investigar o caso dos logaritmos. Em
primeiro lugar, gostaramos de mostrar como se desenvolveu esta ideia de, a
partir de um numero dado, definir um novo numero que facilite os calculos
com o primeiro. Faremos isso a partir dos trabalhos de John Neper. Obvia-
mente, como e frequente na historia da Matematica, ele nao foi o primeiro
a descobrir os logaritmos, nem teve uma ideia brilhante a partir do nada.
No entanto, este exemplo exprime de modo claro as preocupacoes da epoca
e o contexto no qual estas novas ferramentas foram desenvolvidas.
No final do seculo XVI e incio do XVII, os praticantes do calculo eram
astronomos, navegadores, mas tambem mercadores e comerciantes. Logo
no prefacio de sua obra Mirifici logarithmorum canonis descriptio (Descricao
da maravilhosa tabela de logaritmos)4, Neper se dirige a eles ao exprimir a
preocupacao, comum na epoca, de facilitar certas operacoes:
Dado que nada (caros amadores apaixonados pela Matematica)
3Lembramos que o valor dos senos usados nos problemas trigonometricos da epoca nao
variava entre 0 e 1, pois considerava-se um ciclo trigonometrico cujo raio fosse um numero
conveniente para os calculos astronomicos.
4Talvez a melhor traducao para canonis nao seja tabela, e sim canone ou regra. Usamos
tabela associando esta ideia `a sua nomenclatura atual.
182 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
e tao desagradavel `a pratica Matematica (freiando e retardando
os especialistas no calculo) quanto as multiplicacoes, as divisoes
e as extracoes de razes quadradas ou cubicas de numeros gran-
des que, alem do incomodo devido ao seu tamanho, induzem a
diversos erros perigosos; como consequencia, eu me dediquei a
procurar por que meios seguros e comodos poderia me livrar des-
tas dificuldades (Prefacio).
Pouco depois, ainda sem dizer como foi feita a construcao, Neper exibe
uma tabela de logaritmos dos senos usados em problemas praticos. Interes-
sante notar que a descricao da tabela foi publicada em um livro separado,
publicado antes de outro contendo o procedimento de construcao: Mirifici
logarithmorum canonis constructio (Construcao da maravilhosa tabela de lo-
garitmos). Na verdade, este segundo so foi conhecido depois da morte de
Neper, em 1619. Designaremos as duas obras somente por Descricao e Cons-
trucao, respectivamente. No primeiro, encontramos tabelas distintas para
cada angulo, com valores dos senos e dos logartmos para cada minuto so-
mado `aquele angulo. Por exemplo, esta e a tabela para o angulo 20o:
20o + minutos seno logaritmo
0 3.420.201 10.728.852
1 3.422.934 10.720.865
  
30 3.502.075 10.492.295
  
Lembramos que os valores trigonometricos de Neper sao calculados u-
sando um ciclo trigonometrico de raio 107, logo todos os senos, cossenos e
tangentes considerados aqui seriam iguais aos nossos, multiplicados por este
valor. O valor do seno de 20o e, portanto, 3.420.201 e o logaritmo deste seno
e 10.728.852.
Na verdade, esta tabela era apresentada conjuntamente com a tabela
referente a outro angulo, no caso 69o, com os minutos listados em ordem
decrescente (ao contrario dos minutos de 20o). Na segunda tabela, a coluna
intitulada diferenca refere-se `a diferenca entre as duas colunas intituladas
logaritmo. Por exemplo, temos, na primeira linha, 10.728.852  622.827 =
10.106.025.
4.7. OS LOGARITMOS DE NEPER 183
20o + seno logaritmo diferenca logaritmo seno 69o +
minutos minutos
0 3.420.201 10.728.852 10.106.827 622.025 9.396.926 60
1 3.422.934 10.720.865 10.097.781 623.084 9.395.931 59
      
30 3.502.075 10.492.295 9.838076 654.219 9.366.722 30
      
Podemos obter assim que sen (69o 60
= 70o) = 9.396.926 e o logaritmo
deste seno e 622.025. Usando o resultado da coluna das diferencas, e possvel
obter que:
log(sen (20o))  log(sen (70o)) = log (sen (20o)
sen (70o)) = 10.106.827.
Mas sen (70o) = sen (90o  20o) = cos(20o) e, portanto, a igualdade acima
pode ser reescrita como:
log (sen (20o)
cos(20o) = log(tg (20o)) = 10.106.827
Consultando-se uma outra tabela de tangentes obtinha-se o valor da
tg (20o).
E interessante observar que Neper nao fornece uma tabela de logaritmos
de numeros inteiros, e sim de logaritmos de senos. Isto reforca a impressao
de que seu objetivo inicial era ganhar a adesao daqueles que iriam usar efe-
tivamente as tabelas. So depois, ele se preocupa em convencer os leitores de
que sua construcao e valida. Sabemos que todo inteiro compreendido entre
0 e 107 pode ser considerado como um seno, no sentido de Neper. Logo,
quando se trata de explicar e justificar como gerou as tabelas, na Construcao,
Neper considera que esta obtendo, para cada numero natural, um numero
artificial correspondente. O proprio Neper chamam estes novos numeros, ar-
tificiais, de logaritmos. Isto decorre da propriedade fundamental admitida
por ele, da qual podem ser deduzidas diversas outras:
Os logaritmos de numeros proporcionais diferem de um mesmo valor.
Em notacao atual, isso pode ser escrito como:
Se a
b = c
d , entao log(a)  log(b) = log(c)  log(d).
Assim, compreendemos que o logaritmo e o numero de uma razao, o
arithmo (numero) de uma logos (razao).
184 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
Esta propriedade fundamental decorre de sua definicao, que passamos a
explicar.
Neper define o logaritmo por meio da associacao entre uma sequencia
geometrica e uma sequencia aritmetica. Suponhamos um segmento G0B,
como na Figura 4.8, percorrido por um corpo movel que comeca a se mover
com velocidade igual ao tamanho do segmento (no caso 107) e vai diminuindo
a velocidade conforme se aproxima de B. Marcamos, sobre este segmento,
um ponto G1 tal que G1B = qG0B. Ou seja, para uma dada razao q < 1,
podemos marcar outros pontos G2, Gk, Gk+1 respeitando a mesma proporcao,
ou seja, G2B = qG1B, G3B = qG2B e assim por diante. Os comprimentos
dos segmentos GiB formam uma progressao geometrica de razao q, pois
G2B = q2G0B,. . . , GkB = qkG0B.
G0 G1 G2 . . . Gk Gk+1 B
Figura 4.8
Neper deseja definir o logaritmo de qk por meio de uma correspondencia
entre os pontos Gi definidos acima e outros pontos, definidos por uma pro-
gressao aritmetica sobre um segmento de mesmo tamanho que G0B (Veja A
Figura 4.9).
A0 A1 A2 . . . Ak Ak+1 A
Figura 4.9
Dado o segmento A0A, tambem de tamanho 107, marcamos os pontos A1,
A2,. . . , Ak+1 a igual distancia um do outro, satisfazendo a seguinte condicao:
se dois moveis partem de G0 e de A0, com a mesma velocidade inicial, eles
atingem, respectivamente G1 e A1 no mesmo intervalo de tempo. Ou seja,
quando um movel vai de A0 a A1, um outro movel vai de G0 a G1. Neper
afirma, entao, que o comprimento do segmento A0A1 nos da o logaritmo de
G1B, bem como o de A0A2 da o logaritmo de G2B e assim por diante.
Observamos, de imediato, que quanto menor GkB, maior sera o valor de
seu logaritmo A0Ak (pois a razao e menor que um) e o logaritmo do seno
total (isto e, G0B) e o segmento A0A0, agora reduzido a um ponto (ou seja,
e nulo).
A partir desta associacao, ele obtem um modo de calcular o valor do
logaritmo. Esta definicao fornece o princpio, mas nao diretamente um modo
de construir as tabelas. No entanto, ela permite justificar a propriedade
fundamental enunciada acima que, por sua vez, servira ao calculo dos valores
das tabelas, como veremos.
4.7. OS LOGARITMOS DE NEPER 185
Suponhamos, em linguagem atual, que a razao da progressao aritmetica
definida pelos Ai seja r. Logo, A0A1 = r, A0A2 = 2r,. . . , A0Ak = kr. Como
sabemos que G0B = 107, GkB = qkG0B e ele definiu que log(GkB) = A0Ak,
temos que log(qkG0B) = kA0A1, ou seja, log(qk107) = kr.
Da igualdade acima, podemos concluir que:
Se GmB
GnB = GpB
GsB
entao
qmnG0B = qpsG0B
.
Pela definicao acima do logaritmo, temos que:
(m  n)A0A1 = log(qmnG0B) = log(qpsG0B) = (p  s)A0A1.
Logo,
A0Am  A0An = mA0A1  nA0A1 = pA0A1  sA0A1 = A0Ap  A0As.
Mas sabemos tambem, pela definicao, que A0Am = log(GmB) e assim
deduzimos a propriedade fundamental sobre as grandezas proporcionais con-
sideradas no incio:
log(GmB)  log(GnB) = log(GpB)  log(GsB).
Esta propriedade permite construir as tabelas. Neper constroi, primeira-
mente, sequencias geometricas de numeros naturais entre 107 e 107
2 , escritos
em forma decimal com vrgulas (o que nao era muito comum na epoca). Em
seguida, ele calcula os logaritmos correspondentes. Para obter uma sequencia
que chamaramos hoje densa, que permita obter boas aproximacoes, os
numeros listados a partir de 107 sao muito proximos uns dos outros. Ele
escolhe uma razao proxima de 1,
q = 0, 9999999 = 1  0, 0000001 = 1  107.
Os termos seguintes formarao uma sequencia decrescente com esta razao.
Resta-nos calcular os logaritmos de tais numeros. Pela definicao, log(107) = 0
e os outros termos serao obtidos um a um, por meio da definicao cinematica.
Por exemplo, se queremos calcular log(107q) = log(99999999) podemos en-
quadrar este numero entre dois limites:
186 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
1
1  107 > log(99999999) > 1
Estas desigualdades decorrem imediatamente das propriedades cinemati-
cas da definicao. O valor de 1
1107 pode ser aproximado por 1, 0000001 e o
logaritmo procurado sera obtido pela media entre os dois extremos, o que
fornece:
log(99999999) = 1, 00000005.
Usando a propriedade fundamental e enquadramentos analogos, ele conse-
gue obter os outros valores a partir deste, com um bom grau de aproximacao.
Inspirado por Neper e usando um metodo analogo, tambem de carater
cinematico, o professor de Matematica ingles Henri Briggs propos, poucos
anos depois, uma tabela de logaritmos decimais dos numeros inteiros. Ele
sugeriu a Neper que o numero 10 fosse escolhido como base dos logaritmos,
e que log 1 = 0.
Exerccios
4.17. Katz ([96], pp. 536-537.) propoe a seguinte construcao dos logaritmos,
a qual preserva as ideias de Neper, vistas acima, e simplifica seu texto
original.
A B C D E F G H K
Figura 4.10
r2 r1 r0
r1 r2
Figura 4.11
Sejam duas sucessoes de numeros, a primeira uma progressao aritmetica
de razao a, . . . , 5a, 4a, 3a, 2a, a, 0, a, 2a, 3a, . . . , mostrados na reta
superior da Figura 4.10, e a segunda de numeros em progressao geome-
trica de razao r, . . . , 1/r5, 1/r4, 1/r3, 1/r2, 1/r, 1, r, r2, r3, . . . com r > 1,
mostrados na reta inferior.
4.7. OS LOGARITMOS DE NEPER 187
Sejam P e Q dois pontos, que se movem sobre cada uma das retas,
respectivamente, de maneira que P percorre os intervalos [a, a], [a, 2a],
[2a, 3a], . . . , no mesmo tempo em que Q percorre os intervalos [1, r],
r, r2], [r2, r3], . . . e suponha que a velocidade de Q e constante em cada
um dos intervalos.
1. Demonstre que a velocidade do ponto Q em qualquer um dos
pontos em progressao geometrica e proporcional `a distancia do
ponto considerado ao ponto 0.
2. Prove que, se [x1, x2] e [y1, y2] sao dois intervalos de quaisquer
comprimentos e tais que x2/x1 = y2/y1, entao os tempos para
Q percorrer, respectivamente, os intervalos [x1, x2] e [y1, y2] sao
iguais.
3. Entre os pontos 1 e r introduza o ponto s=r e, nos intervalos
[r, r2], [r2, r3], . . . , insira os pontos s2, s3, . . . , respectivamente.
Semelhantemente, na reta superior, considere o ponto b = 1
2 a e os
pontos 2b, 3b, . . . . Prove que se P se desloca com velocidade cons-
tante, e Q percorre os intervalos [1, s], [s, s2], [s2, s3] no mesmo
tempo em que P percorre os intervalos [0, b], [b, 2b], entao conti-
nuam validos os resultados dos dois itens anteriores.
4. Suponha agora que o ponto Q se move de tal maneira que em
qualquer ponto sua velocidade e proporcional a sua distancia do
ponto 0. Suponha, tambem, que P continua se deslocando com
velocidade constante, v. Alem disso, suponha que o ponto de
partida de Q e o ponto 1, que sua velocidade inicial e v e que o
ponto de partida de P e o ponto 0. Se, em um certo instante, P
e Q estao, respectivamente, em y e x, dizemos que y e o logaritmo
de x, e escrevemos
y = log x.
Demonstre que log 1 = 0 e prove que se x2/x1 = y2/y1, entao o
tempo necessario para Q percorrer [x1, x2] e igual ao tempo em
que percorre y1, y2]. Demonstre que, portanto, log x2  log x1 =
log y2  log y1.
5. Demonstre que log (y2/y1) = log y2 log y1, log x2y1 = log x2 +log y1,
e que log (xn
2 ) = n log x2. Conclua que, para qualquer numero
racional z, log (xz
2) = z log x2.
6. Demonstre, usando calculo infinitesimal, que a funcao log definida
acima e nosso logaritmo natural moderno, ln.
188 CAPITULO 4. AL-KHWARIZMI, CARDANO, VI `ETE E NEPER
4.8 Exerccios suplementares
4.18. O que e a forma irredutvel de uma cubica? Que condicoes os coeficientes
(numeros reais) a, b, c e d da equacao cubica ax3 +bx2 +cx+d = 0 devem
satisfazer para que a equacao tenha
 Tres razes reais distintas?
 Somente uma raiz real?
4.19. Resolva, usando a regra de dupla falsa posicao, o seguinte problema
proposto por Fibonacci:
Dois passaros voam do topo de duas torres (Figura 4.12), res-
pectivamente, com a mesma velocidade, e chegam, ao mesmo
tempo, a uma fonte. Quais as distancias das torres `as fontes
se uma delas tem 40 metros de altura, a outra 30 metros, e
distam entre si de 50 metros?
35 40
18725
30
F Z
E A
G
BD
Figura 4.12
4.20. O matematico muculmano Abu Kamil nasceu no Cairo, em 850. Era
apelidado o calculador egpcio. Ele aprofundou os resultados alge-
bricos de al Khwarizmi, tanto tecnicamente quanto conceitualmente.
Resolva o seguinte problema proposto por Abu Kamil:
O numero 50 e dividido por outro numero. Se o divisor e aumentado
de 3 unidades, o quociente diminui de 3 3
4 . Qual e o divisor?
4.21. Ibrahim Ibn Sinan (908 - 946) foi um matematico muculmano que fez
importantes trabalhos em geometria, entre outros ramos da Matema-
tica. Resolva o seguinte problema proposto por ele:
4.8. EXERCICIOS SUPLEMENTARES 189
Dados dois crculos e um segmento de reta, construa o crculo que e
tangente a ambos e tal que o segmento de reta entre os pontos de
tangencia e igual ao segmento dado.
4.22. O seguinte problema encontra-se em um texto italiano das escola de
abaco: Divida 10 em duas partes cujo produto dividido por sua dife-
renca e igual a 28.
4.23. Resolva este problema discutido por Christoff Rudolff (viveu na pri-
meira metade do seculo XVI): Escreva

27 + 200 na forma a + b.
4.24. Resolva os seguintes problemas propostos pelo frances Nicolas Chuquet
(? - 1487):
 Um tonel de vinho possui tres torneiras. Se abrirmos a maior
delas, o tonel e esvaziado em 3 horas. Se abrimos torneira media,
o tonel e esvaziado em 4 horas. Se abrirmos a pequena, ele e
esvaziado em 6 horas. Se abrirmos todas as torneiras, em quanto
tempo o tonel sera esvaziado?
 Um homem morreu durante a gravidez de sua mulher. Em seu
testamento, ele estipulou que 100 escudos devem ser divididos da
seguinte maneira: Se sua mulher der `a luz uma filha, a mae deve
receber duas vezes mais do que a filha. Se ela tiver um filho,
este devera receber duas vezes o que couber `a mae. A viuva teve
gemeos, um filho e uma filha. Como devem ser divididos os 100
escudos?

Captulo 5
A transformacao da matematica
no seculo XVII: Descartes,
Fermat, Leibniz e Newton.
5.1 Contextualizacao historica
O objetivo aqui sera analisar as transformacoes ocorridas na Matematica
durante o seculo XVII, em particular na geometria, com a intervencao de
metodos algebricos e infinitesimais. Os nomes de Rene Descartes (1596-
1650) e de Pierre de Fermat (1601-1665) estao no centro das mudancas, que
culminaram com a invencao do que chamamos hoje geometria analtica.
Mas se quisermos inserir as transformacoes da Matematica do seculo XVII
em um contexto mais abrangente, precisaremos relacionar os desenvolvimen-
tos intelectuais com a transformacao da sociedade e, em particular, com o
crescimento da importancia da tecnica.
Mencionamos, no captulo anterior, o desenvolvimento das praticas alge-
bricas, mas havia outros interesses na ordem do dia. A geometria ainda era
o principal domnio da Matematica e qualquer pessoa que quisesse aprender
ciencia devia comecar pelos Elementos de Euclides. No entanto, aos poucos,
foi crescendo a consciencia de que grande parte do conhecimento geometrico
devia servir a aplicacoes, desde as mais praticas, como as tecnicas para cons-
truir mapas, ate as mais abstratas, como a teoria da perspectiva, na pintura,
e a astronomia.
O seculo XVII e marcado pela consciencia de que o desenvolvimento
tecnico pode melhorar a vida dos homens, ainda que esta visao nao tenha sido
inaugurada neste momento. Nao iremos detalhar a relacao entre as crencas
da epoca e os ideais da sociedade de modo generalizado, mas e possvel citar
191
192 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
tres exemplos tpicos deste seculo: Galileu, Bacon e Descartes.
Descartes postula um metodo para a invencao de verdades na ciencia, pu-
blicado em seu Discurso do Metodo, que contem como apendice a Geometria.
Por isso, passou a ser interessante associar o empreendimento geometrico de
Descartes ao esprito da primeira metade do seculo XVII. Ao privilegiar a
invencao e a intervencao na natureza, o pensamento da epoca se associava ao
estudo quantitativo dos fenomenos. Ou seja, em consonancia com o ideal de
seu tempo, Descartes defendia que o pensamento nao deve se dedicar a com-
preender todos os tipos de coisas, mas somente aquelas que sao passveis de
quantificacao. As deducoes logicas que permitem passar de uma proposicao
a outra devem ser substitudas por relacoes entre coisas quantificaveis, tra-
duzidas por equacoes (igualdades entre quantidades).
Contra os saberes antigos, permeados por demonstracoes estereis, seria
preciso fundar uma nova arte da invencao, que pudesse fornecer novos objetos
capazes de servir `a Matematica, assim como os objetos tecnicos serviam `a
vida social. Para muitos pensadores, as demonstracoes matematicas nao
tinham somente o papel de convencer e estabelecer uma certeza, mas deviam,
sobretudo, esclarecer a natureza do problema e propor metodos de invencao
direta que permitissem resolve-los. Por isso, eles rejeitavam, por exemplo, a
demonstracao por absurdo. Neste contexto, os objetos geometricos passavam
a ser vistos com novos olhos, pois podiam ser uteis na resolucao de problemas
praticos.
No ano de 1626, Descartes frequentou o crculo de pensadores que gravi-
tavam em torno do padre Mersenne, em Paris, que se dedicava, entre outras
coisas, a problemas oticos ligados ao estudo do movimento dos raios lumino-
sos. Estes estudos levaram Descartes a escrever A Dioptrica, um dos ensaios
publicados com o Discurso do metodo, em 1637, ou seja, juntamente com
a Geometria. Trata-se de um tratado de otica, compreendendo uma teoria
da refracao da luz e, desde o incio da obra, percebe-se a proximidade de
Descartes com os artesaos de instrumentos oticos.
Podemos dizer que a epoca e marcada por uma concepcao geral das curvas
que nao se limitava ao estudo de curvas particulares, ampliando o universo
dos objetos geometricos pela introducao de curvas que descrevem movimentos
ou sao expressas por equacoes algebricas. Em diversos problemas, tratava-
se de procurar um objeto desconhecido que podia ser uma curva, em um
sentido bem mais geral do que se considerava anteriormente. A geometria
se transformava, assim, por meio dos objetos que se propunha a investigar e
das tecnicas empregadas com este fim. O metodo a que se refere o Discurso
do Metodo deve ter sua eficacia comprovada por aplicacoes materiais, como
fica claro na Dioptrica, mas sua superioridade e demonstrada na geometria.
Este sera o papel da resolucao, descrita adiante, de um problema herdado
5.1. CONTEXTUALIZAC AO HIST ORICA 193
dos antigos, cuja solucao ainda nao havia sido encontrada: o problema de
Pappus.
O incio do seculo XVII foi marcado por esforcos de diversos matematicos
para recuperar as obras gregas que haviam sido perdidas, em particular os
classicos mencionados por Pappus ([147]). Foi neste contexto que Fermat,
encantado pelas Conicas de Apolonio, assumiu a tarefa de recupera-las e o
contato com o pensamento matematico deste classico influenciou profunda-
mente sua obra.
A exatidao dos procedimentos empregados em geometria foi redefinida
por Descartes. Ao inves de construcoes geometricas, foram admitidas tecni-
cas algebricas na definicao de curvas, institudas como objeto central da ge-
ometria. A segunda metade do seculo XVII sentira os efeitos desta mudanca
e o trabalho com curvas, incluindo a busca de tangentes e areas, incentivara
o desenvolvimento dos metodos infinitesimais. Uma discussao relativa ao
modo de justificar a Matematica acompanhou estas transformacoes tecnicas.
Para que a Matematica pudesse se libertar dos padroes gregos, associados ao
canone euclidiano, pensadores do seculo XVII, incluindo Leibniz, defendiam
suas praticas como uma arte da invencao: nao importavam tanto os criterios
de demonstracao, mas o que as ferramentas permitiam obter de novo.
Nos trabalhos do fim do seculo XVII, o conceito de curva recobre tres con-
cepcoes: a curva como expressao algebrica, eventualmente infinita; a curva
como trajetoria de um ponto em movimento; e a curva como polgono com
numero infinito de lados. As tres exercem um papel central no desenvolvi-
mento dos metodos infinitesimais e Leibniz foi um dos protagonistas desta
mudanca. Depois de ler a geometria de Descartes, em 1673, ele achou o
metodo de tangentes do matematico frances restritivo. Alem de ser compli-
cado, este procedimento nao se aplica a uma grande quantidade de curvas.
Uma das principais contribuicoes de Leibniz sera estender o domnio das cur-
vas para alem das algebricas, consideradas por Descartes como as curvas de
que a geometria deve se ocupar.
Apos ter estudado direito e filosofia, G.W. Leibniz (1646-1716) participa
de uma missao diplomatica `a corte de Louis XIV, em 1672, onde conhece
Christian Huygens. Este ultimo, que tinha sido aluno de Descartes, tra-
balhava intensamente sobre series e apresentou a Leibniz, ate entao pratica-
mente ignorante em Matematica, os trabalhos de Cavalieri, Pascal, Descartes,
St.Vincent, Wallis e Gregory.
Os metodos analticos de Descartes e Fermat motivaram o estudo das
propriedades aritmeticas de series infinitas na Inglaterra, sobretudo por John
Wallis e James Gregory. Estes pesquisadores conseguiram resolver um grande
numero de problemas, como o de encontrar a tangente a uma curva, calcular
quadraturas ou retificar curvas, e tiveram grande influencia sobre Newton e
194 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Leibniz. A grande diferenca introduzida por estes ultimos esta no grau de
generalidade e unidade que os metodos infinitesimais adquiriram com seus
trabalhos. Antes de Newton e Leibniz, problemas envolvendo o estudo de
curvas, como os que envolviam a determinacao de tangentes e areas, eram
tratados de forma independente. Os metodos empregados por diferentes es-
tudiosos possuam semelhancas entre si, mas estas nao eram ressaltadas. Os
matematicos ja tinham um enorme conhecimento sobre o modo de resolver
problemas especficos do calculo infinitesimal, mas sem reconhecer a genera-
lidade e a potencialidade das tecnicas empregadas.
A deselegante polemica sobre a prioridade da invencao do calculo, na
qual participaram seguidores de Leibniz e de Newton, os segundos instigados
pelo proprio Newton, Leibniz escreveu, em sua defesa, em 1714, o Historia
et Origo Calculi Differentialis. Hoje, os historiadores refutam a ideia de que
Leibniz plagiou Newton e ressaltam que os metodos e motivacoes dos dois
eram basicamente diferentes.
O livro principal de Newton, os Princpios Matematicos da Filosofia Natu-
ral, nao contem desenvolvimentos analticos. Os resultados sao apresentados
na linguagem da geometria sintetica, ao passo que Leibniz defende vigoro-
samente os metodos analticos. Podemos destacar, ainda, as diferentes con-
cepcoes de quantidade variavel, ou as diferentes nocoes de continuidade de
ambos. No entanto, historiadores como N. Guicciardini ([72]), nao acham
estas diferencas fundamentais. Na pratica, seria possvel traduzir os proce-
dimentos fluxionais de Newton nos algoritmos diferenciais de Leibniz. Em
sua visao, o que os distingue e a relacao de cada um com a Matematica
de seu tempo. Para Leibniz, os problemas de fundamento do calculo eram
preocupacoes que nao deviam interferir no desenvolvimento dos algoritmos
diferenciais. Ao passo que Newton se esforcou para colocar sua teoria em
uma linguagem rigorosa, no caso, a da geometria classica. Para fazer com
que sua teoria fosse aceita, Newton se preocupava em garantir uma continui-
dade historica entre seus metodos e os dos antigos.
Se compararmos os calculos de Newton e de Leibniz com o atual, veremos
que eles trabalhavam essencialmente com variaveis definidas sobre curvas,
ao passo que atualmente o calculo se fundamenta na nocao de funcao. O
principal objeto de estudo no seculo XVII era o desenvolvimento de metodos
para resolver problemas sobre curvas geometricas, muitas vezes de origem
fsica, como o de encontrar a tangente, calcular a area sob uma curva e achar
comprimentos de curvas ou velocidades de pontos se movendo sobre uma
curva. Ou seja, problemas de natureza geometrica ou cinematica tratados
com as ferramentas do calculo. Tratava-se, portanto, de entrar em um novo
domnio, o da relacao entre quantidades, o que ira contribuir, mais tarde,
para o surgimento da ideia de funcao como relacao entre quantidades.
5.2. O M ETODO CARTESIANO 195
Neste captulo enfocaremos o tratamento algebrico de problemas geome-
tricos, como introduzido por Descartes na Geometria, o qual analisaremos em
detalhes, procurando permanecer fieis aos termos e aos argumentos da epoca.
Alem desta obra, mencionaremos os trabalhos geometricos de Fermat e suas
discussoes com o colega frances.
Falaremos das contribuicoes de Leibniz para o calculo, bem como de suas
justificativas, comparando brevemente seu estilo com o de Newton. Para en-
tender porque novas definicoes foram propostas, e preciso analisar a recepcao
do calculo diferencial e integral e as discussoes acerca da legitimidade de suas
tecnicas.
5.2 O metodo cartesiano
Apos Galileu, o movimento e os fenomenos da natureza em geral puderam ser
compreendidos por meio da Matematica. O mundo real, que nao e equivalente
ao mundo percebido, e a materializacao da geometria e deve ser descrito pela
Matematica. E neste contexto que o pensamento de Descartes se desenvolve,
com as certezas aristotelicas, que haviam dominado a Idade Media, sacudidas
pela Nova Ciencia, assentada sobre os trabalhos de Galileu.
Em seu Regras para a direcao do esprito, escrito por volta de 1628, portanto
antes de seu Geometria, Descartes ja anunciava o projeto de uma nova ciencia
que seria uma especie de Matematica universal (Mathesis universalis).
A Mathesis universalis nada tem a ver com a Matematica vulgar de seu
tempo. Ela permitiria reduzir a analise de um fenomeno qualquer a proble-
mas relacionados `a ordem e a relacoes, por meio de raciocnios dedutivos.
Com a algebra, qualquer deducao pode ser traduzida em termos de equacoes.
Os problemas geometricos devem ser formulados em linguagem algebrica para
que se possa penetrar nas relacoes que existem entre os objetos do universo.
Este passo e fundamental para legitimar o estudo da geometria por meio da
algebra, pois o que esta ultima permite apreender sao as proporcoes envolvi-
das nos objetos geometricos.
Logo no incio do Geometria, Descartes propoe a utilizacao do metodo
analtico:
Se queremos resolver qualquer problema, primeiramente su-
pomos que a solucao ja esta encontrada, e damos nomes a todas
as linhas que parecem necessarias para constru-la. Tanto para
as que sao desconhecidas como para as que sao conhecidas. Em
seguida, sem fazer distincao entre linhas conhecidas e desconhe-
cidas, devemos percorrer a dificuldade da maneira mais natural
196 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
possvel, mostrando as relacoes entre estas linhas, ate que seja
possvel expressar uma unica quantidade de dois modos. A isto
chamamos uma Equacao, uma vez que os termos de uma destas
duas expressoes sao iguais aos termos da outra. ([43] p. 8-9).
Dar nomes `as linhas da figura, tanto para as que sao desconhecidas como
para as que sao conhecidas era a essencia do metodo analtico, como vimos
no estudo da Arte Analtica de Vi`ete no captulo anterior. O objetivo de
Descartes era utilizar na geometria, para resolver problemas de construcao,
uma especie de aritmetica, na qual regras simples de composicao levassem dos
objetos simples a outros mais complexos. Por razoes puramente geometricas,
era necessario algebrizar a geometria.
Na abertura do primeiro livro do Geometria, Descartes se refere `as cinco
operacoes basicas da aritmetica, adicao, subtracao, divisao, multiplicacao e
radiciacao, e mostra que estas operacoes correspondem a construcoes simples
com regua e compasso. No exemplo abaixo (Figura 5.1), tomando-se AB
como unidade, o segmento BE e o produto dos segmentos BD e BC obtidos
ligando-se os pontos A e C e desenhando-se DE paralela a AC.
Figura 5.1
Uma consequencia deste procedimento e que o produto dos segmentos BD
e BC pode ser considerado um segmento BE. Suponhamos, por exemplo,
que BA = 1 e BD = a e marcamos C de modo que BC = b. Temos que
a
1 = BE
b , logo BE = ab, produto de BD e BC (notem que aqui ja podemos
usar o produto dos meios e dos extremos, uma vez que estamos operando
com numeros, e nao mais com grandezas). Podemos tambem marcar o ponto
C de modo que BC = a e, neste caso, BE = a2. Temos assim uma potencia
quadrada que nao e associada a um quadrado, mas a um segmento de reta.
Procedimentos deste tipo permitirao vencer o problema da homogeneidade
das grandezas que estava presente na geometria, ate a epoca de Vi`ete.
Isto foi possvel pela escolha de um segmento de reta arbitrario para uni-
dade. A partir da, o produto de dois segmentos pode ser interpretado como
um outro segmento, e nao mais necessariamente como a area de um retangulo.
Este segmento produto era construdo pelo procedimento acima. Apesar de
construir geometricamente a solucao, este metodo e absolutamente inovador
5.2. O M ETODO CARTESIANO 197
na geometria, pois permite ultrapassar a homogeneidade das grandezas e
operar com elas como se fossem numeros. Isto implica uma mistura entre
generos tradicionalmente considerados distintos, a aritmetica e a geometria.
Depois de construir a multiplicacao de dois segmentos, Descartes analisa
alguns casos de equacoes quadraticas, mostrando que a solucao, ou seja, a
incognita, e um segmento de reta que pode ser construdo. Por exemplo,
para a equacao z2 = az + b2, a reta incognita z seria construda como segue
(Figura 5.2).
Figura 5.2
Construmos o triangulo retangulo NLM com LM = b e NL = a/2. Que-
remos construir z que satisfaca a equacao. Prolongamos MN ate o ponto O
tal que NO = NL e obtemos OM = z. Entao, z = a
2 +
a2
4 + b2.
Com efeito trace a circunferencia com raio a/2 e centro N. Ela corta MN
em P . Podemos concluir que
LM
OM = P M
LM  OM.P M = LM2.
Isto porque M LP = L OM (angulos que determinam o mesmo arco na cir-
cunferencia), logo os triangulos OLM e LPM sao semelhantes. Sendo assim,
se OM = z, P M = z  a, como OM.P M = LM2, conclumos que b2 = z(z  a),
ou b2 = z2  az. Logo, OM, a raiz da equacao, e dada por z = 1
2 a +
1
4 a2 + b2.
Descartes ignora a segunda raiz, pois ela e negativa.
Em seguida, Descartes mostra, respectivamente, como podemos cons-
truir as razes das equacoes z2 = az + b2 (notem que ele ja usa a, mas,
como a e positivo, o sinal de menos e uma operacao sobre o coeficiente
positivo) e z2 = az  b2. Para resolver esta ultima equacao, tracamos, como
no exemplo anterior, um segmento NL de comprimento a/2 e um segmento
LM de comprimento b (Figura 5.3).
No entanto, em vez de ligar M a N, tracamos MQR paralela a LN e,
com centro em N, tracamos uma circunferencia por L, a qual corta MQR nos
198 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Figura 5.3
pontos Q e R. A linha z procurada e MQ ou MR, expressas respectivamente
por:
z = 1
2 a +
1
4 a2  b2
z = 1
2 a 
1
4 a2  b2
De fato, Q LM = L RM, uma vez que sao ambos angulos inscritos que
determinam o mesmo arco. Como M e um ponto comum a ambos, os
triangulos LRM e LQM sao semelhantes. Logo, LM/MR = MQ/LM e
LM2 = MR.MQ, do que se conclui que RQ = 2(MR  a/2). Fazendo
LM = b, se MR = z, temos, de LM2 = MR.MQ, que b2 = zMQ. Mas
como RQ = 2(MR  a/2), conclumos que MQ = z  RQ. Sendo assim,
MQ = z  2(z  a/2) e MQ = a  z. Portanto, de b2 = zMQ obtemos que
b2 = z(a  z). Logo z = MR. Fazendo z = MQ, obtemos a segunda solucao.
Neste caso, Descartes fornece as duas solucoes, uma vez que ambas sao po-
sitivas.
Para deduzir a formula algebrica da solucao a partir da construcao geo-
metrica acima, basta observar que LN = a/2 = NQ = NR (Figura 5.3).
Apos a analise deste caso, Descartes acrescenta entao uma observacao
importante: Se o crculo descrito por N e que passa por L nao corta nem
5.2. O M ETODO CARTESIANO 199
toca a linha MQR, a equacao nao tem nenhuma raiz, de forma que podemos
dizer que a construcao do problema e impossvel ([43], p. 15). Sabemos
hoje que o caso em que b > a/2 da origem a duas razes complexas, o que
devia ser excludo.
Observe ainda que Descartes considera separadamente os seguintes tipos
de equacao quadratica: z2 = az + b2, z2 = az + b2 e z2 = az  b2. Por
que ele nao generalizou o problema escrevendo apenas uma equacao do tipo
z2 + az + b2 = 0? Porque so eram considerados coeficientes positivos, uma vez
que deviam estar associados a linhas construtveis. Sendo assim, a equacao
z2 + az + b2 = 0 nao possui razes positivas e nao foi considerada.
Ele tambem considerou equacoes cubicas, mas sua preocupacao nao era
resolve-las, como fez Cardano, mas mostrar como possibilitavam construir a
solucao de problemas geometricos.
Ao mesmo tempo em que renovou a geometria, Descartes estava, de algum
modo, ligado `a tradicao. Nao bastava resolver equacoes, era preciso construir
suas solucoes. Seu objetivo nao era propriamente algebrico, mas consistia
em aplicar a algebra para resolver problemas geometricos. Para isto, ele
propoe um metodo que permite reduzir a resolucao de problemas geometricos
`a resolucao de uma ou mais equacoes.
A grande novidade da obra geometrica de Descartes e a introducao de
um sistema de coordenadas para representar equacoes indeterminadas. A
introducao desta ferramenta, fundamental para o projeto cartesiano, foi mo-
tivada inicialmente pelo problema de Pappus:
Encontrar o lugar geometrico de um ponto tal que, se segmentos de
reta sao tracados desde este ponto ate tres ou quatro retas dadas,
formando com elas angulos determinados, o produto de dois destes
segmentos deve ser proporcional ao produto dos outros dois (se ha
quatro retas) ou ao quadrado do terceiro (se ha tres retas).
Pappus ([147]) demonstrou que, no caso geral, a solucao deve ser uma
conica e Descartes, inspirado por este matematico grego, passou a considerar
o problema para mais de quatro retas, o que dara origem a curvas de maior
grau. Em uma forma simplificada o problema consiste em: dadas 2n retas,
encontrar o lugar geometrico de um ponto movel tal que o produto de suas
distancias (nao necessariamente em angulo reto) a n das retas (em posicoes
determinadas, com angulos dados) e proporcional ao produto das distancias
`as outras n retas. No caso de quatro retas, o lugar geometrico foi descrito
por Descartes de modo generalizavel para um maior numero de retas.
200 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Vejamos a solucao de Descartes.
Sejam inicialmente as retas AB, AD, EF e GH, como na Figura 5.4.
Figura 5.4
Queremos encontrar um ponto C a partir do qual possamos construir
segmentos de reta CB, CD, CF e CH que facam angulos dados CBA,
CDA, CF E e CHG com as retas dadas. Alem disso, um outro dado do
problema e que o produto dos comprimentos de alguns destes segmentos e
igual ao produto dos comprimentos dos restantes, ou pelo menos temos que
estes produtos estao em uma dada razao. Por exemplo, podemos ter que o
produto de CB por CH seja igual a k vezes o produto de CF por CD.
Para resolver o problema de encontrar o lugar geometrico do ponto C,
Descartes propoe, primeiramente, que se suponha o problema resolvido, como
na figura (o que significa que ele esta usando o metodo analtico). Como ha
muitas linhas, afirma Descartes, para simplificar o problema, considero uma
das linhas dadas e uma outra a ser tracada (por exemplo, AB e BC) como
linhas principais, `as quais tentarei referir todas as outras. Chame o segmento
da linha AB entre A e B de x e BC de y. ([43], p. 28). O que ele esta
fazendo e justamente criar um sistema de coordenadas no qual as linhas AB
e BC sao consideradas como eixos coordenados.
Se os eixos forem escolhidos de modo conveniente, o problema sera bas-
tante simplificado. Como os angulos do triangulo ARB sao conhecidos (uma
vez que BC corta AB e, indiretamente, AD segundo angulos dados, pois
AB corta AD segundo um angulo dado), a razao entre AB e BR tambem e
conhecida e podemos dizer que AB esta para BR assim como uma constante
qualquer z esta para uma constante b, isto e, AB
BR = z
b . Logo, como AB = x,
temos BR = bx
z . Considerando que B esta entre C e R (como na figura) con-
clumos que CR = y + bx
z . Como os angulos do triangulo DRC sao conhecidos
(pois CB e CD cortam AD segundo angulos dados), a razao entre CR e CD
e dada pela razao entre a mesma constante z e uma outra constante qual-
quer c. Sendo assim, conclumos que CD = cy
z + bcx
z2 . Usando procedimentos
5.2. O M ETODO CARTESIANO 201
analogos, obtemos tambem CF e CH em funcao das quantidades x e y:
CF = ezy + dek + dex
z
CH = gzy + f gl  f gx
z
(nas quais todas as letras, com excecao de x e y designam constantes dadas
no problema).
O produto de dois destes comprimentos, como CF e CD por exemplo,
possui portanto grau (no maximo) 2 em x e em y; o produto de tres compri-
mentos possui grau (no maximo) 3 em x e em y, e assim por diante. Logo,
como um dado do problema e uma igualdade entre produtos (a menos de
uma constante) teremos uma equacao com duas variaveis em cada membro.
Por exemplo, se e dado no problema que CF  CD = k  CH  CB, esta
igualdade sera dada pela equacao:
ezy + dek + dex
z  cyz + bcx
z2 = k gzy + f gl  f gx
z  y.
Trata-se de uma equacao do segundo grau em x e y. Atribuindo, por-
tanto, um valor qualquer a x (ou a y), podemos encontrar o valor da outra
quantidade por meio de uma equacao do segundo grau. Por exemplo, atri-
buindo valores a y teremos equacoes do tipo x2 = ax  b2, para as quais
a solucao pode ser construda com regua e compasso (gracas aos metodos
que ele havia deduzido para a construcao de razes de equacoes quadraticas).
Tomando sucessivamente infinitos valores para y, obtemos infinitos valores
para x e podemos desenhar uma curva que determinara os infinitos valores
que podem ser atribudos ao ponto C.
Observamos que a utilizacao de um sistema de coordenadas, passo fun-
damental na invencao da geometria analtica, esta associada a um problema
indeterminado, ou seja, com duas quantidades desconhecidas (chamadas mais
tarde de variaveis). E importante notar ainda que, em Descartes, este sis-
tema nao empregava necessariamente um sistema de eixos ortogonais, pois,
para cada problema, devia ser escolhido o sistema mais conveniente.
Para cinco retas, o metodo funciona da mesma maneira, para mostrar que
a solucao e uma cubica. Descartes nao se preocupou em descrever exatamente
qual e a curva que resolve o problema em uma situacao especfica, mas em
mostrar que, mesmo aumentando o numero de retas, o seu metodo pode
ser generalizado para encontrar curvas, de diferentes graus, que resolvem o
problema.
Observamos que o papel das coordenadas na geometria de Descartes par-
ticipa do objetivo de introduzir metodos algebricos na geometria para resolver
202 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
problemas de construcao que, mesmo mais sofisticados, nao escapam `a natu-
reza essencial da geometria grega, dedicada a problemas deste tipo. Resolver
problemas sobre os quais os mais brilhantes geometras gregos se debrucaram
era motivo de gloria para o esprito vaidoso que caracterizava este que e
considerado o pai da geometria analtica. Em relacao ao metodo usado na
resolucao do problema de Pappus, Descartes chega a dizer que ele esta para
a geometria antiga como a retorica de Ccero para o ABC das criancas.
Exerccios
5.1. Sejam a e b os comprimentos de dois segmentos. Faca uma construcao
para calcular geometricamente o quociente a/b.
5.2. Dado um segmento de reta a, construa o segmento de reta a.
5.3. Descartes concebeu um compasso especial, o mesolabio para construir
meias proporcionais entre dois comprimentos dados a e b, ou seja, achar
comprimentos x e y tais que a  x  x  y  y  b.
G
F
E
D
C
B
VU
X
ZY
Figura 5.5
A reta Y Z e fixa, e Y X gira em torno de Y . Seja Y B = a. De B,
levante a perpendicular a Y X, a qual corta Y Z em C. Por C, levante
a perpendicular a Y Z, a qual intercepta Y X em D. Finalmente, por
este ultimo ponto, levante a perpendicular a Y D, e seja E seu ponto
de interseccao com Y Z.
Faca Y X girar, ate que DE = b. Demonstre que, entao, Y C e Y D sao
duas meias proporcionais entre a e b.
5.4. Demonstre que o mesolabio de Descartes permite construir n meias
proporcionais entre dois comprimentos dados.
5.5. Descartes afirma que a situacao mais simples do problema de Pappus,
no caso de termos cinco retas l1, l2, l3, l4 e l5, e quando as quatro
5.3. FERMAT E OS LUGARES GEOM ETRICOS 203
primeiras sao paralelas e equidistantes entre si e a quinta, l5 e perpen-
dicular a esse feixe de paralelas. Se di e a distancia do ponto P `a reta
li, devemos achar o lugar geometrico dos pontos P tais que
ad2d5 = d1d2d4.
Escolha os eixos convenientemente e prove que a equacao cartesiana do
lugar geometrico e
axy = y3  2ay2  a2y + 2a3.
5.6. Com um aplicativo de algebra simbolica (por exemplo o programa gra-
tuito Winplot), trace o grafico da curva dada pela equacao do item
5.5, para alguns valores de a, ou seja, o lugar geometrico que e a solucao
deste caso do problema de Pappus.
5.3 Fermat e os lugares geometricos
Ja mencionamos que Fermat foi profundamente influenciado pelas traducoes
das obras gregas, em particular a de Apolonio. Logo, ele estava suficien-
temente familiarizado com o fato de que, dada uma curva, ha sempre uma
relacao entre duas quantidades indeterminadas (sintoma da curva). O ob-
jetivo inicial de Fermat sera exprimir, na linguagem algebrica proposta por
Vi`ete os problemas geometricos tratados por Apolonio. Seu principal inte-
resse era, portanto, realizar um estudo geral dos lugares geometricos.
Sua primeira obra, denominada Ad locos planos et solidos isagoge (In-
troducao aos lugares geometricos planos e solidos), foi escrita provavelmente
em 1636 e e contemporanea do Geometria de Descartes. No entanto, ao que
parece, estas obras nao se influenciaram mutuamente. Apesar de ambas in-
troduzirem coordenadas para tratar de problemas geometricos, os objetivos
de Descartes e Fermat eram distintos.
A geometria analtica tal como a conhecemos atualmente consiste em
duas associacoes recprocas: (i) dado um lugar geometrico, encontrar a equa-
cao que seus pontos satisfazem; e (ii) dada uma equacao, encontrar o lugar
geometrico dos pontos que a satisfazem. Descartes estudou o primeiro pro-
blema, mas Fermat foi pioneiro em atacar o segundo. Logo no princpio de sua
Introducao, enuncia: Sempre que em uma equacao final, duas quantidades
desconhecidas sao encontradas, temos um lugar geometrico e a extremidade
de uma delas descreve uma linha, reta ou curva.
204 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Exemplo 5.1. Vejamos como Fermat mostra, usando a notacao de Vi`ete, que
uma equacao do primeiro grau e satisfeita por pontos que estao em linha reta.
Figura 5.6
Sejam NZM uma reta, com um ponto N fixo, e NZ igual `a quantidade
desconhecida A, e ZI (a reta tracada para formar o angulo NZI) a outra
quantidade desconhecida E (Figura 5.6). Se D vezes A e igual a B vezes E,
o ponto I descreve uma reta.
Para chegar a esta conclusao, basta observar que D  A = B  E implica que
B  D = A  E. Mas a razao B  D e conhecida, pois so envolve quantidades
conhecidas. Logo, a razao A  E entre as quantidades desconhecidas tambem
sera determinada, assim como o triangulo NZI. Sendo assim, NI e uma
reta (dada em posicao, como diz Fermat).
Observamos que ele utiliza apenas um eixo coordenado e a reta e gerada
pela extremidade I do segmento variavel ZI quando Z se move ao longo do
eixo. As coordenadas ZN e ZI sa o solucoes da equacao D  A = B  E.
Em seguida, ele passa a estudar as equacoes de segundo grau. Para cada
caso, Fermat mostra que o lugar geometrico dos pontos que satisfazem a
equacao e um crculo ou uma conica. Ele conclui que, se os eixos coorde-
nados forem dados em posicao e os coeficientes da equacao forem dados em
magnitude, os parametros que definem a conica (o vertice e o eixo) serao
dados em posicao e em magnitude. Ou seja, a conica esta definida e seus
pontos podem ser tracados (apesar da construcao nao ser descrita).
Dada uma hiperbole, por exemplo, os gregos ja haviam deduzido a pro-
priedade assintotica dos seus pontos, enunciada em termos de proporcoes.
Usando a algebra de Vi`ete, Fermat escrevia a equacao desta conica e apli-
cava o procedimento inverso: dada uma certa propriedade, expressa por uma
equacao, deduzir a curva que a satisfaz.
Antes de Descartes e Fermat poucos matematicos, alem de Arquime-
des e Omar Khayam, haviam trabalhado sobre a construcao de problemas
solidos usando conicas. Vi`ete tinha acrescentado o axioma da neusis `a sua
5.3. FERMAT E OS LUGARES GEOM ETRICOS 205
geometria justamente para lidar com a construcao de tais problemas. Mais
tarde, Fermat utilizou as tecnicas algebricas para definir conicas e estudar
suas intersecoes aplicando-as `a resolucao de problemas solidos.
`A sua Introducao aos lugares geometricos planos e solidos, Fermat acres-
centou um apendice sobre a solucao de problemas solidos por lugares geo-
metricos. Nestes problemas, dada uma equacao de grau tres ou quatro em
uma variavel, era preciso determinar o valor da incognita x. Para encontra-
lo, Fermat escrevia duas equacoes de segundo grau em duas variaveis x e
y, tomados como coordenadas dos pontos de intersecao de conicas. Um dos
exemplos em que este metodo pode ser aplicado e o da construcao de duas
meias proporcionais, ou seja, dados os segmentos a e b, encontrar x e y tais
que a:x:: x:y:: y:b.
Exemplo 5.2. Metodo de Fermat para achar duas meias proporcionais entre os
segmentos a e b:
Para obtermos a meia proporcional, x deve satisfazer `a equacao do ter-
ceiro grau x3 = a2b, e podemos escrever
1. x2 = ay, uma parabola (na verdade x2 = y);
2. xy = ab, uma hiperbole.
Em seguida, supondo o problema resolvido, ou seja, x dado, encontramos
efetivamente x, solucao da equacao, por meio da intersecao das conicas (Veja
a Figura 5.7).
1. considerando as duas equacoes (1) e (2) em x e y que deram origem `a
equacao de terceiro grau, pode-se concluir que o problema e resolvido
por uma hiperbole e por uma parabola (cujas equacoes haviam sido
estudadas na introducao);
2. considerando eixos perpendiculares OX e OY , fazemos x = OA y = AB;
Figura 5.7
206 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
3. da equacao (1), temos que B esta em uma parabola com vertice em O
e eixo OY ;
4. tomamos um ponto C arbitrario em OX e desenhamos uma perpendi-
cular CD a este eixo tal que CD  OC = ab. Desenhamos, em seguida,
uma hiperbole pelo ponto D com assntotas OX e OY . Esta hiperbole
contem todos os pontos tais que o produto da abscissa pela ordenada
e ab. Assim, pela equacao (2), sabemos que esta hiperbole passa pelo
ponto B;
5. o ponto B pertence, portanto, `a intersecao da parabola com a hiperbole
e satisfaz `as equacoes (1) e (2), logo sua abscissa e sua ordenada sao as
meias proporcionais requeridas.
Fermat constroi deste modo a solucao da equacao cubica obtida a partir
do problema das duas meias proporcionais. O metodo pode ser assim resu-
mido: dada uma equacao cubica com uma incognita, obtem-se duas equacoes
quadraticas com duas incognitas que correspondem a conicas e resolve-se
o problema construindo a interseccao destas conicas.
Podemos usar o mesmo procedimento para um problema qualquer que
recai em uma equacao do terceiro ou do quarto grau, como ele mostra no
exemplo abaixo:
Exemplo 5.3. Dado um problema solido reduzido a uma equacao de terceiro ou
quarto grau em x, encontrar as equacoes de dois lugares geometricos, planos ou
solidos, cujas intersecoes determinam x.
Solucao:
1. assumimos que a equacao pode ser reduzida, pela eliminacao do termo
de terceiro grau, `a forma x4 = a + bx + cx2;
2. adicionamos 2dx2 + d2 a cada um dos lados (d um numero qualquer a
ser ajustado posteriormente), obtendo (x2 d)2 = a+bx+(c2d)x2 +d2;
3. igualamos cada lado a e2y2 (e um numero qualquer a ser ajustado
posteriormente), obtendo as duas equacoes do segundo grau em x e y:
x2  d = ey e a + bx + d2 = (2d  c)x2 + e2y2;
4. a primeira equacao representa uma parabola e a segunda pode repre-
sentar um crculo se tomamos d tal que 2d  c >0 e se tomamos e tal
que e2 = 2d  c;
5. o problema e resolvido desenhando-se a parabola e o crculo.
5.3. FERMAT E OS LUGARES GEOM ETRICOS 207
Fermat criou assim um metodo para resolver uma equacao de grau tres
ou quatro utilizando interseccoes de conicas. Com uma notacao proxima de
Vi`ete, ele combina os objetivos de investigar problemas classicos de lugares
geometricos e de construir solucoes de equacoes cubicas e quadraticas pela
intersecao de conicas.
Descartes deduzia equacoes para resolver problemas geometricos e nao
estava tao interessado em estudar as equacoes por si mesmas. Ja Fermat nao
se debrucou sobre as questoes de legitimidade das construcoes geometricas
que motivaram Descartes. Ele aceitava a analise algebrica como topico ma-
tematico autonomo, independente da geometria, o que nao era uma atitude
comum na sua epoca.
Exerccios
5.7. Resolva, utilizando os metodos de Fermat, o seguinte problema que ele
propos e resolveu: Dividir a reta AC pelo ponto E, de tal maneira
que o produto do quadrado de AE por EC seja maximo.
5.8. A Cissoide de Diocles, estudada desde a antiguidade grega, e a curva
definida como segue (Veja a Figura 5.8):
Considere a circunferencia de diametro OA e sua tangente por A. Seja
C um ponto arbitrario sobre a tangente. Seja B o ponto em que o
segmento OC corta a circunferencia. A cissoide e o lugar geometrico
dos pontos P tais que OP = BC.
Figura 5.8
208 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
1. Sejam M e D os pontos em que a paralela `a tangente por A cortam,
respectivamente, a circunferencia e o diametro OA. Demonstre,
como fez Fermat, usando a definicao da cissoide, que
MD
DO = DO
DP .
2. Empregue o metodo de Fermat para provar que a tangente `a
cissoide pelo ponto P pode ser determinada da seguinte maneira,
enunciada por Fermat:
Seja K o ponto em que a cissoide intercepta a circunferencia e C
o pe da perpendicular por K ao diametro. Sobre o prolongamento
do diametro, tome V tal que V A = AC. Divida AD  DG por
V D. Seja DF o quociente. A reta que passa por F e por P e a
tangente pedida.
5.4 O estudo das curvas e as primeiras nocoes
de funcao
O conceito de funcao surgiu bem depois das tecnicas de derivacao introdu-
zidas por Leibniz e Newton. Comecaremos, pois, com algumas nocoes que
antecedem a de funcao, passando em seguida ao advento do calculo.
Atualmente, quando pensamos no conceito de funcao, algumas ideias nos
vem `a mente. Por exemplo, a ideia de uma correspondencia. Deste ponto de
vista, poderamos dizer que as tabelas babilonias e egpcias ja pressupunham,
de alguma forma, a ideia de funcao, uma vez que se tratavam justamente de
registros de correspondencias (entre um numero e o resultado das operacoes
que envolvem este numero). As tabelas astronomicas de Ptolomeu, simila-
res `as nossas tabelas de senos, tambem estabeleciam correspondencias que
consideramos hoje de natureza funcional.
A enfase sobre a ideia de correspondencia fez com que alguns historiadores
da Matematica vissem um antecedente desta nocao nas tabelas babilonicas e
egpcias, ou ainda nas tabelas usadas pela astronomia grega e na Matematica
antiga em geral. Obviamente, estes povos nao propuseram uma nocao de
funcao para compreender suas tabelas e esta associacao nao parece ajudar a
entender a natureza da Matematica que praticavam.
Alem disso, diversas ideias fundamentais no conceito que temos hoje de
funcao nao estavam presentes nestes exemplos, como e o caso da ideia de
de variacao. A nocao de variavel so foi introduzida formalmente no seculo
XIX, mas antes da formalizacao deste conceito, a nocao de variacao estava
5.4. AS PRIMEIRAS NOC OES DE FUNC AO 209
presente na fsica matematica dos seculos XVI e XVII. O estudo da variacao
dos fenomenos naturais em relacao ao tempo, por meio de leis matematicas,
se deve em grande parte ao desenvolvimento da fsica apos Galileu. Esta
relacao era analisada, contudo, por meio de proporcoes geometricas. Em se-
guida, passou-se a associar o movimento a uma curva, que pode ser expressa
por meio de uma equacao. Vimos que Descartes trabalhava com equacoes
indeterminadas, nas quais tomando-se infinitos valores para x, e possvel
encontrar infinitos valores para y. Esta presente aqui a ideia de que uma
equacao em x e y e um modo de representar uma dependencia entre duas
quantidades variaveis, de modo que se possa calcular os valores de uma delas
a partir dos valores da outra. As quantidades ocupam um lugar geometrico
representado por uma curva que pode nao respeitar a restricao atual de que,
a cada valor da abscissa, corresponda apenas uma ordenada. Uma circun-
ferencia, por exemplo, e um exemplo de curva que, hoje em dia, nao seria
considerada funcao. Esta caracterstica nao importa para nos no momento,
uma vez que estamos falando somente de relacoes entre variaveis que estao
sobre uma curva, o que antecede o conceito de funcao propriamente dito.
Desde Vi`ete, a representacao simbolica de uma quantidade desconhecida
permitia exprimir estas relacoes por formulas algebricas. Mas este matema-
tico se dedicava, principalmente, `a solucao de problemas determinados, nos
quais nao se coloca o problema de se relacionar duas grandezas que variam.
Diferenca entre uma equacao determinada e uma equacao in-
determinada.
A quantidade desconhecida assume um valor dado quando resolve-
mos a equacao, ou seja, ela e apenas provisoriamente desconhecida;
trata-se de uma quantidade que possui um valor determinado que
esta, em uma certa equacao, desconhecido e resolvemos a equacao
com o objetivo de encontra-la. Mas ha uma grande diferenca entre
equacoes determinadas, que possuem uma incognita, e as indetermi-
nadas, que podem possuir duas ou mais incognitas. Como o proprio
nome diz, nessas equacoes as quantidades estao indeterminadas,
ou seja, nao encontro nunca apenas um valor para uma quanti-
dade desconhecida, mas uma infinidade de valores que variam de
acordo com os valores de outra quantidade.
Na analise de equacoes indeterminadas, realizada por Descartes, introduz-
se a ideia de que uma equacao em x e y e um modo de representar uma de-
pendencia entre duas quantidades variaveis, de modo que se possam calcular
os valores de uma delas a partir dos valores da outra. Podemos dizer, por-
tanto, que nas curvas estudadas por Descartes a relacao entre as quantidades
210 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
indeterminadas e de tipo funcional, uma quantidade sendo associada `a outra
por meio de uma equacao. As quantidades ocupam um lugar geometrico
representado por uma curva que pode nao respeitar a restricao atual de que,
a cada valor da abscissa, corresponda apenas uma ordenada. Uma circun-
ferencia, por exemplo, e um exemplo de curva que, hoje em dia, nao seria
considerada uma funcao. Esta caracterstica nao importa para nos no mo-
mento, uma vez que estamos falando somente de relacoes entre variaveis que
estao sobre uma curva, o que antecede o conceito de funcao propriamente
dito.
Ainda que os tipos de relacao entre variaveis nao fossem tematizados na
epoca, havia uma concepcao implcita de que estas relacoes eram dadas por
expressoes analticas de curvas algebricas ou por meio de series infinitas. Di-
versos exemplos demandavam o uso de series infinitas, o que levou a uma
ampliacao do universo de objetos considerados centrais na Matematica da
epoca. As curvas constituiam o principal objeto da Matematica neste mo-
mento e mencionaremos dois problemas paradigmaticos, associados ao estudo
das curvas.
5.4.1 Aplicacoes da nova geometria: o calculo de tangen-
tes
No livro III dos Elementos de Euclides encontramos apenas a definicao da
tangente a um crculo: uma reta que encontra o crculo, mas que pode ser
prolongada sem voltar a corta-lo. A proposicao III.16 demonstra que a reta
perpendicular ao diametro do crculo tracada por um ponto no crculo sera
exterior ao crculo. Alem disso, nao e possvel intercalar uma outra reta deste
tipo entre a reta tangente e o crculo.
Na antiguidade, o problema de encontrar tangentes a curvas devia ser
tratado de modo puramente geometrico. No seculo XVII, a importancia
de se determinar tangentes a curvas passou a ser justificada pelo estudo
do movimento, uma vez que a tangente a uma curva fornece a direcao do
vetor velocidade de um movel que percorre esta curva. Mas para Descartes,
nao devia ser permitido empregar um movimento dependente do tempo para
encontrar a tangente a uma curva e, na Geometria, ele propoe o seguinte
metodo algebrico.
Deve-se tracar um crculo, com centro O sobre um eixo coordenado, in-
terceptando uma curva dada por uma equacao. Em geral, este crculo corta
a curva em dois pontos C e E e o metodo se resume a encontrar qual deve
ser o centro do crculo de modo que estes dois pontos se reduzam a um so.
Suponhamos que a equacao da curva da qual queremos encontrar a tan-
5.4. AS PRIMEIRAS NOC OES DE FUNC AO 211
Figura 5.9
gente seja dada por f (x, y) = 0 e que o ponto C no qual queremos encontrar a
tangente tenha coordenadas (a, b) (Figura 5.9). Tomemos outro ponto F so-
bre o eixo coordenado, com coordenadas (c, 0). A equacao da circunferencia
com centro em F passando por C e (x  c)2 + y2 = (a  c)2 + b2. Se eliminamos
y entre esta equacao e a equacao f (x, y) = 0 temos uma equacao em x que
determina as abscissas dos pontos onde o crculo corta a referida curva.
Determinamos em seguida o valor de c tal que esta equacao em x tenha
razes iguais. O crculo com centro no ponto (c, 0) toca a curva apenas no
ponto C e a tangente `a curva sera a tangente ao crculo. Logo, quando este
crculo e conhecido podemos construir a tangente.
Exemplo 5.4. Usaremos este metodo para encontrar a tangente `a parabola
y2 = x no ponto (1, 1).
O raio da circunferencia com centro no ponto (c, 0) seria r2 = (1  c)2 + 12
e sua equacao seria, portanto, (x  c)2 + y2 = (1  c)2 + 1. Substituindo y2 = x
temos a equacao x2 +(12c)x+2c2 = 0. Para que esta equacao tenha apenas
uma raiz, fazemos (12c)2 4(2c2) = 4c2 12c+9 = 0 e obtemos c = 3
2 . Logo,
o ponto ( 3
2 , 0) e o centro da circunferencia procurada que tambem passa pelo
ponto (1, 1). O coeficiente angular da tangente, portanto, deve ser 1
2 , e esta
reta tangente, que passa pelo ponto (1, 1) e por um ponto (x, y) qualquer,
possui equacao y = x+1
2 .
Fermat tambem apresenta uma maneira de encontrar tangentes em seu
Metodo para a procura do maximo e do mnimo, publicado em 1637, mesmo
ano da geometria de Descartes ([60], tome III, pp. 122-123).
Seja a parabola BDN, de vertice D e eixo AD (Figura 5.10). Se B e
um ponto sobre a parabola, traco por este ponto uma perpendicular ao eixo,
passando pelo ponto C. Em seguida, tracamos uma reta BE tangente `a
parabola cortando o eixo no ponto E (temos B e E e e facil determinar uma
reta por dois pontos). Resta determinar, portanto, a posicao do ponto E.
212 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Figura 5.10
Tomemos um ponto O qualquer sobre a reta BE. Tracamos, respectiva-
mente, as ordenadas OI do ponto O e BC do ponto B. Se o ponto O estivesse
sobre a parabola, pelas propriedades que vimos no Captulo 4, teramos que
DC/DI = BC2/OI2. Como o ponto O e exterior `a parabola, temos que
DC/DI > BC2/OI2. Por semelhanca de triangulos, BC2/OI2 = CE2/IE2,
logo DC/DI > CE2/IE2. Mas o ponto B e dado, logo conhecemos a or-
denada BC, o ponto C e DC. Assim, podemos considerar que DC = d e
fazemos CI = e e CE = a, em que CE e o que queremos determinar e CI e
uma quantidade a ser ajustada. Obtemos assim a desigualdade expressa por
d/(d  e) > a2/(a2 + e2  2ae). Fazendo o produto dos meios pelos extremos
obtemos que da2 + de2  2dae > da2  a2e.
O ponto central do metodo de Fermat esta na aplicacao de um proce-
dimento, que ele atribui a Diofanto, chamado adequacao, que significa esta-
belecer uma equacao, ou uma igualdade, aproximada. Ele obtem, portanto,
uma igualdade aproximada a partir da desigualdade acima.
Retirando os termos comuns e dividindo todos os termos por e temos que
de + a2  2da. Supondo que O e suficientemente proximo de B e esta sobre a
parabola, podemos desprezar o termo de (a desigualdade DC/DI > BC2/OI2
torna-se uma igualdade). Podemos concluir entao que a2 = 2da, ou a = 2d.
Este metodo e caracterstico do calculo infinitesimal que sera desenvol-
vido alguns anos mais tarde por Leibniz e Newton. Podemos observar que o
metodo de Descartes so funciona para curvas algebricas (as unicas que lhe in-
teressavam), ao passo que o metodo de Fermat pode funcionar para qualquer
curva, desde que justificado pelo calculo infinitesimal.
Exerccios
5.9. Demonstre a proposicao III.16 dos Elementos de Euclides:
A reta que faz angulo reto com o diametro de um crculo a partir de
uma das extremidades e exterior ao crculo, e na regiao compreendida
entre a reta e o crculo e impossvel intercalar outra reta; alem disso,
5.4. AS PRIMEIRAS NOC OES DE FUNC AO 213
por um lado o angulo do semi-crculo e maior, e por outro lado o angulo
que sobra e menor, do que qualquer angulo retilneo agudo.
Segundo Euclides, o angulo entre duas curvas e a inclinacao de uma
relativamente `a outra (Definicao 8, Livro I). No caso em que as curvas
sao retas, o angulo e chamado de retilneo Este resultado mostra que
os gregos sabiam que o conceito geral de angulo e complexo. Esta
proposicao mostra que nao e possvel estabelecer a razao entre dois
angulos (Definicao 4, Livro V).
5.10. No exemplo citado, aplicamos o metodo de Descartes `a parabola de
equacao y2 = x. Usando o mesmo procedimento, tente calcular a
tangente em um ponto da parabola x2 = y. O que aconteceria se
quisessemos calcular a tangente a uma funcao de grau 3?
5.11. Empregue o metodo de Fermat para achar a tangente `a elipse de
equacao x2/16 + y2/9 = 1, no ponto de coordenadas (2, 33/2).
5.4.2 O calculo de areas por meio de decomposicoes infi-
nitas
Cavalieri e Pascal, no seculo XVII, calculavam areas usando a decomposicao
de uma figura. Cavalieri argumentava que uma linha e composta de pontos,
assim como um cordao e composto de contas; um plano e feito de linhas, assim
como uma roupa, de fios; e um solido e composto de planos, assim como um
livro, de paginas. A area da figura seria a soma de um numero indefinido de
segmentos de reta paralelos, e o volume seria a soma de um numero indefinido
de areas paralelas. Estes seriam, respectivamente, os indivisveis de area e
de volume.
Uma consequencia deste metodo e que, se dois solidos tem a mesma altura
e se as secoes obtidas por cortes paralelos `as suas bases estao, sempre, na
mesma razao, os volumes dos solidos estao um para o outro nesta mesma
razao. Usando este princpio, Cavalieri demonstrou que o volume do cone
e 1/3 do volume do cilindro circunscrito. Apos a publicacao da Geometria
de Descartes, Cavalieri tambem usa coordenadas para calcular, por seu novo
metodo, a quadratura da parabola. A praticidade do metodo de Cavalieri fez
com ele que fosse amplamente utilizado em sua epoca. Tratava-se de uma
maneira eficaz de evitar os procedimentos infinitos indiretos usados pelos
gregos. Por sua vez, durante a primeira metade do seculo XVII, Fermat,
Roberval e Pascal utilizam o metodo dos indivisveis, concebendo, entretanto,
a area como uma soma de retangulos infinitamente pequenos, em vez de uma
soma de linhas.
214 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Neste perodo, surge uma nova maneira de calcular areas e volumes, dis-
tinta do metodo de exaustao, que expusemos no Captulo 3. Ao passo que
o procedimento usado pelos gregos empregava diferentes tipos de figuras re-
tilneas para aproximar uma area curvilnea, como os triangulos usados na
quadratura da parabola, fundava-se agora um procedimento sistematico que
usava retangulos. A vantagem e que a aproximacao por retangulos infinita-
mente finos serve para qualquer figura curvilnea. Um exemplo tpico deste
tipo de aproximacao e fornecido por Fermat e Pascal.
Figura 5.11
Figura 5.12
Um problema importante, que ja tinha sido atacado por Arquimedes,
como vimos no Captulo 3, era o de achar a quadratura da parabola, ou seja,
dada a parabola da Figura 5.11, calcular a area limitada pela corda HE e
pelo arco de parabola situado entre os pontos H e E.
Se O e o vertice da parabola, podemos coloca-lo na origem de um sistema
de coordenadas cujo eixo dos y seja o eixo da parabola. Neste sistema, a
equacao da parabola sera da forma y = kx2. Suponha que a corda HE e
paralela ao eixo dos x, k = 1 (ou seja, a equacao da parabola e entao y = x2)
e que as coordenadas do ponto E sao (b, b2).
E facil ver que para efetuar a quadratura deste setor parabolico, e sufi-
ciente calcular a area entre o eixo dos x, a parabola, e a reta vertical que
passa por E. Entre O e B marcamos n pontos equidistantes. Seja d = b
n e
5.4. AS PRIMEIRAS NOC OES DE FUNC AO 215
construamos os retangulos com base D, como mostrado na Figura 5.12. As
bases destes retangulos medem sempre d e suas alturas, de acordo com a
equacao da parabola, serao dadas respectivamente por d2, 4d2, 9d2, . . . n2d2.
Para encontrar a area, somam-se as areas destes retangulos obtendo:
S = d3 + 4d3 + 9d3 +  + n2d3 = d3(1 + 22 + 32 +  + n2).
Motivados pela resolucao de problemas deste tipo, Pascal e Fermat ja
haviam calculado a soma das m-esimas potencias dos n primeiros numeros
naturais. Logo, a soma dos termos entre parenteses podia ser substituda por
n
6 (n + 1)(2n + 1) = n3
3 + n2
2 + n
6 .
Mas d e obtido dividindo-se OB por n, logo a soma S sera dada por
d3 ( n3
3 + n2
2 + n
6 ) = OB3 (1
3 + 1
2n + 1
6n2 ) .
Quando o numero de retangulos aumenta, os dois ultimos termos podem
ser desprezados. Assim, a soma das areas dos retangulos sera
S = OB3
3 = x3
3 .
Observamos que este sera justamente o resultado encontrado quando in-
tegramos, pelos procedimentos que conhecemos atualmente, a funcao que
define a parabola.
Ha uma diferenca fundamental entre este metodo e os processos usados
pelos gregos, pois aqui nao se usa nenhuma prova indireta para se chegar ao
resultado final. O numero de retangulos cresce arbitrariamente, ou, como
dizemos hoje, tende para o infinito. Toma-se o limite da soma quando n
tende para o infinito, embora este procedimento de passar ao limite nao fosse
explicitado, nem considerado rigoroso, nesta epoca. Alem disso, o resultado
do calculo da area e uma expressao analtica, e nao outra area (como era o
caso dos metodos gregos de que tratamos no Captulo 2).
E facil observar que este metodo se estende facilmente para outras curvas,
desde que tenhamos uma expressao analtica pela qual possamos calcular as
alturas dos retangulos. Para isto, era preciso conhecer a soma das m-esimas
potencias dos n primeiros numeros naturais. Por volta de 1636, Fermat ja
sabia que, para n racional e diferente de 1, a area sob o grafico de y = xn
entre dois pontos O e B (situado a uma distancia a de O) e dada por an+1
n+1 .
Os metodos analticos de Descartes e Fermat motivaram o estudo das
propriedades aritmeticas de series infinitas na Inglaterra, sobretudo por John
Wallis (1616-1703) e James Gregory (1638-1675). O primeiro e o responsavel
216 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
pela introducao do smbolo  para designar o infinito e utilizou o metodo
dos indivisveis para fazer diversas quadraturas. Um de seus resultados mais
importantes e obtido a partir da tentativa de calcular analiticamente a area
do crculo, o que permite obter uma boa aproximacao para . Apesar das res-
tricoes em relacao `a legitimidade dos metodos infinitesimais, eles permitiam
resolver um grande numero de problemas, como o de encontrar a tangente
a uma curva, calcular quadraturas ou retificar curvas. Poderamos citar
ainda os nomes de Isaac Barrow e Christian Huygens, que tiveram grande
influencia, respectivamente, sobre Newton e Leibniz.
Antes das definicoes formais de funcao e de limite, a derivada era sem-
pre a derivada de uma curva e, portanto, se identificava `a tangente (como
melhor aproximacao local da curva por uma reta). O interesse por esta
questao foi suscitado por dois desenvolvimentos paralelos: o movimento pas-
sou a ser representado por curvas; e estas curvas passaram a ser expressas
por equacoes. Sendo assim, as equacoes passam a descrever movimentos e
as tangentes `as curvas passam a representar a velocidade do movimento. As
tangentes deixam de ser definidas por propriedades geometricas globais (reta
que toca a curva em apenas um ponto) e passam a ser definidas localmente
de modo dinamico (reta que aproxima localmente a curva). E a partir da
que o problema de encontrar a velocidade de um corpo em um determinado
instante podera ser visto como o equivalente do problema matematico de se
encontrar a tangente a uma determinada curva descrita algebricamente. Esta
associacao sera uma das motivacoes para o surgimento do calculo infinitesi-
mal. No entanto, o problema de achar a tangente a uma curva e o problema
de encontrar taxas de variacao ainda eram estudados separadamente.
Veremos adiante algumas caractersticas do calculo desenvolvido parale-
lamente por Leibniz e Newton. Ao passo que o calculo de Newton estava in-
timamente ligado ao estudo de quantidades variaveis com o tempo, o calculo
de Leibniz considera quantidades que variam em uma sequencia de valores
infinitamente proximos um do outro, da a estreita relacao de seus procedi-
mentos com o estudo de series. Assim, ao passo que o conceito fundamental
do calculo newtoniano e o de fluxao, que pode ser traduzido como velocidade
ou taxa de variacao de uma quantidade em relacao ao tempo, o conceito
fundamental do calculo leibniziano e o de diferencial, que e uma diferenca
infinitamente pequena entre valores sucessivos de uma serie.
Exerccios
5.12. O seguinte problema e geralmente considerado difcil por alunos uni-
versitarios, e resolvido, nos cursos de calculo, usando integracao. Em
verdade, o problema parece ter sido resolvido, a primeira vez, por Evan-
5.5. O C ALCULO DE LEIBNIZ 217
gelista Torricelli (1608 - 1647), contemporaneo de Cavalieri. Resolva o
problema usando o princpio de Cavalieri.
Problema: Sao dadas duas superfcies cilndricas circulares, com raios
iguais, e cujas diretrizes se cortam em angulo reto. Calcule o volume
do solido formado pela interseccao das duas superfcies.
(Sugestao: Inscreva uma esfera no solido formado pela interseccao dos
dois cilindros. Cortando o solido por planos paralelos ao plano definido
pelas duas diretrizes, obtemos crculos de raio r, de area r2, e quadra-
dos de area 4r2. Assim, a razao entre duas secoes feitas pelo mesmo
plano e 4r2/(r2).)
5.13. Calcule a area da elipse usando o princpio de Cavalieri.
(Sugestao: Considere a elipse e o crculo de equacoes, respectivamente
x2
a2 + y2
b2 = 1
e
x2 + y2 = a2.
Corte o crculo e a elipse por retas paralelas ao eixo dos y e veja qual
a razao das cordas obtidas.
5.14. Calcule, usando o princpio de Cavalieri, o volume de uma esfera.
5.15. Usando o procedimento para calcular areas sob graficos de curvas des-
crito acima, ja empregado por Pascal e Fermat, tente calcular a area
sob uma curva de grau 3 entre dois pontos dados.
5.5 O Calculo de Leibniz
Em seu livro Historia et Origo Calculi Differentialis, Leibniz afirma que sua
primeira inspiracao para a invencao do calculo foi tirada do Tratado dos
senos do quarto de crculo, de Pascal. O metodo exposto nesta obra e usado
pelo autor para demonstrar um resultado sobre quadraturas, mas Leibniz
extrai dele o triangulo caracterstico, uma ideia bem mais geral, que sera
usada muitas vezes em seus trabalhos.
218 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Figura 5.13
Tracamos um quarto de crculo ABC (Figura 5.13) e uma tangente EE
em um ponto D. Em seguida, desenhamos uma perpendicular a AC e mar-
camos o ponto I de intersecao. Por E, tracamos EK paralela a AC e por
E, tracamos EK paralela a DI.
Pascal ja havia observado que o triangulo DIA e semelhante a EKE, pois
E DI = 
2  A DI = I AD, logo D EK = I DA e E EK = I AD (isto vale para
a circunferencia porque a tangente EE e perpendicular ao raio DA). Como
este resultado independe das posicoes de E e de E, ele permanece valido se fi-
zermos com que E e E se aproximem muito de D. Leibniz afirma, entao, que
Pascal nao enxergou a relevancia da semelhanca de triangulos que ele proprio
tinha demonstrado, pois ela permite diminuir a distancia entre E e E, ate
que nao possamos mais atribuir-lhe um valor. Ainda assim, ou seja, quando
esta grandeza (a distancia) nao e atribuvel, o triangulo pode ser determi-
nado pela sua semelhanca com o triangulo DIA que, ele, e atribuvel. Ha
uma relacao que se conserva no triangulo EKE na passagem do finito ao
infinitesimal, que e justamente a sua semelhanca ao triangulo DIA.
O argumento acima so e valido para a circunferencia, mas Leibniz fornece
um metodo analogo que e valido em um caso mais geral. Podemos tratar o
triangulo nao atribuvel constitudo por um pedaco da tangente como sendo
o elemento caracterstico de uma curva, designado como triangulo carac-
terstico (analogo ao triangulo EKE).
Fazemos y = EK e x = RR e este metodo exprime analiticamente
todos os elementos do problema fazendo com que a relacao y
x se torne uma
relacao infinitesimal dy
dx (grandezas do triangulo caracterstico).
Os artigos de Leibniz sobre o calculo foram publicados a partir de 1684
em um periodico cientfico da epoca chamado Acta Eruditorum. Um de seus
trabalhos mais importantes nesta revista introduz um novo metodo para
encontrar maximos e mnimos, utilizando o calculo de tangentes por meio do
do triangulo caracterstico.
Considere a Figura 5.14, na qual temos uma curva e uma tangente a esta
5.5. O C ALCULO DE LEIBNIZ 219
curva no ponto M.
Figura 5.14
Vejamos o metodo utilizado para encontrar a tangente (que podemos com-
parar com o de Fermat). Tracando um segmento NR paralelamente ao eixo
das abscissas, obtemos um triangulo retangulo NMR semelhante a T MP
formado pela ordenada P M, pela subtangente1 T P e pelo comprimento da
tangente T M. O ponto T nao e fixo, ou seja, nao e um ponto especfico da
curva. Este ponto e marcado de modo que T M seja perpendicular `a tangente.
O segmento T P e chamado de subtangente.
Segundo Leibniz, ainda que dy e dx sejam quantidades infinitamente pe-
quenas, a razao dy
dx = M R
N R entre estas quantidades e finita, pois e dada pelo va-
lor P M
T P da razao entre a ordenada e a subtangente. Logo, sendo dx uma quan-
tidade qualquer, a diferencial dy e definida pela proporcao dy
dx = y
subtangente .
E neste contexto que Leibniz introduz a palavra funcao, designando a
funcao que uma reta desempenha em uma curva, como a de ser tangente,
normal ou subtangente. Voltaremos a falar sobre a historia desta nocao.
Retornemos `as questoes levantadas a partir do triangulo caracterstico.
Como e possvel entender e justificar a razao entre duas quantidades que
deixaram de existir? Este tipo de consideracao gerou inumeras controversias
sobre o estatuto destas quantidades infinitamente pequenas, como podemos
ver pela seguinte citacao de Lazare Carnot em 1797:
Nao houve descoberta que tivesse produzido, nas ciencias
matematicas, uma revolucao tao feliz e tao rapida quanto a da
Analise Infinitesimal; nenhuma forneceu meios mais simples, nem
1Projecao sobre um eixo, e especialmente sobre um eixo de coordenadas, do segmento da
tangente compreendido entre o ponto de contato de uma curva e o ponto onde a tangente
encontra o eixo considerado.
220 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
mais eficazes, para penetrar no conhecimento das leis da natureza.
Decompondo, por assim dizer, os corpos ate os seus elementos, ela
parece ter indicado sua estrutura interior e sua organizacao; mas,
como tudo o que e extremo escapa aos sentidos e `a imaginacao,
so pode-se formar uma ideia imperfeita destes elementos, especies
de seres singulares que tanto fazem o papel de quantidades ver-
dadeiras, quanto devem ser tratados como absolutamente nulos e
parecem, pelas suas propriedades equvocas, permanecer a meio
caminho entre a grandeza e o zero, entre a existencia e o nada.
([25]).
Estas quantidades que estao entre a existencia e o nada sao justamente as
grandezas nao atribuveis de Leibniz. Durante muitos anos, os matematicos
se debateram com o problema de fundamentar o uso de quantidades infinita-
mente pequenas, os elementos infinitesimais, tambem chamados de dife-
renciais. O problema dos fundamentos deriva do fato de que o calculo leib-
niziano empregava os chamados elementos infinitesimais, que ele designou
por dx e dy. Tais quantidades eram utilizadas nos calculos como quantidades
auxiliares, e com muito exito. Por exemplo, para encontrar a derivada a uma
curva de equacao y = x2, era preciso tomar a diferenca entre as ordenadas de
dois pontos vizinhos, obtendo-se que d(x2) = (x + dx)2  x2 = 2xdx + (dx)2,
logo dy
dx = 2x. No resultado, o ultimo termo deveria ser desprezado, uma
vez que possui, comparativamente, ordem de grandeza bem menor que a do
primeiro.
Este procedimento obtinha sucesso nos calculos e nas aplicacoes. O que
estava em jogo, portanto, na discussao sobre os fundamentos, nao era a
utilizacao destas quantidades nao finitas nos calculos, mas sim o estatuto
destas quantidades, que suscitou crticas e controversias, em relacao `as quais
Leibniz ofereceu varias justificativas.
Uma das respostas mais convincentes e a sua observacao de que, quando
escrevemos o quociente de duas diferenciais dy
dx designamos uma razao que
nao e o mesmo que a divisao infundada de duas quantidades infinitamente
pequenas dy e dx. Logo, esta relacao nao pode ser entendida como um
quociente entre duas quantidades infinitamente pequenas, que equivaleria,
no fim das contas, `a divisao de 0 por 0. Trata-se de uma relacao, cuja
natureza e independente dos termos que a compoem. Ou seja, esta relacao
nao e uma quantidade. Justamente por isso, mais tarde, ela sera expressa
por uma funcao.
Na verdade, Leibniz pratica um calculo diferencial sem diferenciais, ope-
rando somente com relacoes diferenciais. A relacao dy
dx entre dois infinitesi-
mais nao e um infinitesimal, mas e resultado de uma operacao de diferen-
5.5. O C ALCULO DE LEIBNIZ 221
ciacao (e as derivadas de ordens superiores resultarao da mesma operacao
reiterada). A riqueza da notacao proposta por Leibniz e justamente a de ter
introduzido o operador d, o qual, ao mesmo tempo, separa-o da quantidade
x a qual ele se relaciona e indica sua ligacao com esta quantidade.
O procedimento de Leibniz supoe um princpio subjacente que demonstra
a extrema potencia de seu calculo e sua incompreendida modernidade. Em
linguagem atual, este princpio estabelece o seguinte: e sempre necessario
determinar a variavel em relacao `a qual se quer derivar. Uma quantidade
varia em funcao da outra, ou seja, ja temos aqui uma nocao implcita de
variavel dependente e variavel independente, que antecede a nocao de funcao.
Como afirma Bos ([15]), nao e sobre a diferencial, como objeto, que se
funda o calculo leibniziano, mas sobre a ideia de diferenciabilidade. Da a
importancia de se introduzir a expressao diferenciar em relacao a, indicando
a percepcao clara de que a diferenciacao e a nocao central do calculo e nao
as diferenciais. Escolher a variavel em relacao `a qual se quer diferenciar
indica uma dupla variacao, uma variabilidade combinada que sera associada
`a relacao diferencial, que e o fundamento do calculo para Leibniz.
Nao se encontra uma definicao de funcao na obra de Leibniz, mas os tra-
balhos que irao propor definicoes explcitas deste conceito serao influenciados
por ele.
Exerccios
5.16. Um dos primeiros feitos matematicos de Leibniz foi achar a soma da
serie
1
1 + 1
3 + 1
6 + 1
10 + 1
15 +  + 2
n(n + 1) + ,
ou seja, achar a soma dos inversos dos numeros triangulares, problema
que lhe foi proposto por Huygens. Mostre, como fez Leibniz, que a
soma desta serie e igual a 2.
5.17. Estudaremos um desenvolvimento em serie de potencias para /4, pro-
posto por Leibniz.
Considere a curva OP QD da Figura 5.15, na qual os pontos P e Q estao
infinitamente proximos, de maneira que entre eles a curva pode ser
considerada uma linha reta e seja a reta que passa por P e Q, que sera
a tangente `a curva, por P , a qual determina o ponto T sobre o eixo dos
y. Sejam OW perpendicular a essa tangente e z = OT , h = OW .
Sejam ds, dx e dy os acrescimos respectivamente ao arco da curva, `a
abscissa de P e `a sua ordenada, quando passamos de P a Q.
222 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Figura 5.15
1. Mostre que o triangulo T W O e semelhante ao triangulo diferencial
formado por ds, dx e dy e conclua que dx  h = ds  z, ou seja, que
zdx = hds.
2. Mostre que zdx e a area do retangulo UV RS e que hds e duas
vezes a area do triangulo OP Q.
3. Prove que a area definida pela curva OP QD e a reta OD e igual
a metade da area sob a curva cuja ordenada e z. Conclua que
1
2  z dx =  y dx  1
2OG  GD.
4. Fazendo OG = x0 e GD = y0, mostre que
 y dx = 1
2 (x0y0 +  z dx) .
Este e o chamado teorema da transmutacao de Leibniz. Ele e util
quando  z dx e mais facil de calcular do que  y dx.
5. Considere a circunferencia de equacao y2 = 2x  x2. Mostre que,
neste caso,
z = y  x =
 x
2  x .
6. Prove que, para a circunferencia estudada,  z dx = 1   x dz.
Conclua que
 y dx = 1   z2
1 + z2 dz.
5.6. O C ALCULO DE NEWTON 223
7. Prove que
z2
1 + z2 = z2(1  z2 + z4  z6 + 
8. Conclua que
 y dx = 1  1
3 z3 + 1
5 z5  1
7 z7 + 
9. Prove que

4 = 1  1
3 + 1
5  1
7 + ,
Esta e a famosa expressao encontrada por Leibniz para calcular o
numero .
5.6 O calculo de Newton
No final da decada de 60 (do seculo XVII), Newton ja empregava procedi-
mentos infinitesimais, como nos mostra o exemplo seguinte.
Seja uma curva como na figura 5.16, tal que a area ABD = z,BD = y e
AB = x.
Figura 5.16
Escolhamos em seguida B = o e BK = v tais que a area curvilnea BD
seja igual `a area do retangulo KBH = ov. Consideremos, por exemplo,
a curva para a qual z = 2
3 x3
2 (ou z2 = 4
9 x3). Podemos concluir entao que
(z + ov)2 = 4
9 (x + o)3 ou z2 + 2zov + o2v2 = 4
9 (x3 + 3x2o + 3xo2 + o3). Dividindo
tudo por o obtemos 2zv + ov2 = 4
9 (3x2 + 3xo + o2).
Neste momento, Newton da o passo crucial que caracteriza o calculo in-
finitesimal: considerando B infinitamente pequeno, os termos multiplicados
por o desaparecem e v = y, logo temos 2zy = 4
3 x2. Substituindo o valor de
224 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
z, que supusemos ser z = 2
3 x3
2 , obtemos a equacao y = x1
2 que determina o
ponto da curva para o qual a area e igual a z. Isso, em linguagem atual,
seria a derivada de z. Podemos observar que o mesmo metodo permite obter
a derivada de qualquer funcao algebrica z de x.
Um pouco mais tarde, no incio dos anos 70, Newton ira reformular estes
algoritmos na linguagem de fluentes e fluxoes. Os fluentes para Newton eram
quantidades variaveis com o tempo, quantidades que fluem. Esta concepcao
leva alguns historiadores a afirmar que sua nocao de continuidade implica o
movimento, a variacao das quantidades no tempo, diferente de Leibniz, que
emprega justificativas de natureza metafsica.
A taxa de variacao de uma quantidade com o tempo era chamada fluxao.
Se v, x, y, z sao quantidades fluentes, seus fluxoes serao designados respecti-
vamente por v, x, y, z. O problema fundamental do Calculo seria entao: dada
a relacao entre quantidades fluentes, encontrar a relacao entre seus fluxoes,
e vice-versa.
Se tivermos dois fluentes x e y, o interessante nao sera calcular os fluxoes
em si, mas a razao entre eles y
x , que determina a inclinacao da tangente `a
curva descrita nas variaveis x e y.
Seja, por exemplo, a curva definida por y = xn. Consideramos o um
intervalo de tempo infinitamente pequeno. Entao, xo e yo (correspondentes a
dx e dy) sao os incrementos infinitamente pequenos de x e y respectivamente.
Para encontrar a relacao entre os fluxoes, Newton substitui x + xo e y + yo
na equacao da curva obtendo y + yo = (x + xo)n. Utilizando a formula que
conhecemos hoje como binomio de Newton, e que ele generalizou para
expoentes fracionarios, escreveu
y + yo = xn + no xxn1 + n(n  1)
2 o2 x2xn2 + 
Lembrando que y  xn e igual a 0, e dividindo tudo por o obtem-se:
y = nxn1 x + n(n1)
2 o x2xn2 +  Considerando que o e infinitamente pequeno,
e possvel negligenciar os termos contendo esta quantidade, o que nos permite
obter a formula y = nxn1 x.
O problema deste procedimento e que a quantidade o, considerada infini-
tamente pequena (quase zero) neste ultimo passo, foi usada como quociente
em uma etapa anterior. Ora, o que pode ser esta quantidade que e quase
zero, mas nao e zero?
Reside aqui a fonte dos problemas de fundamentacao do calculo que serao
enfrentados por Newton. Ele tem consciencia de que a consideracao de quan-
tidades infinitamente pequenas poderia inviabilizar a aceitacao de seu metodo
e apresenta um novo procedimento que pretende resolver estas ambiguidades
por meio do metodo das primeiras e ultimas razoes.
5.6. O C ALCULO DE NEWTON 225
Em vez de simplesmente eliminar os termos contendo a quantidade o, ele
forma a razao y
x entre os fluxoes. Esta razao e igual `a primeira (ou `a ultima)
razao entre os incrementos (ou decrementos) de y e x. Se chamarmos, em
notacao atual, estes incrementos de x e y, poderemos dizer que Newton
considera a razao y
x , quando x e y decrescem ambos para 0 ou crescem
ambos a partir de 0. No primeiro caso, existe uma ultima razao entre x e
y, antes que ambos atinjam o 0, e no segundo caso uma primeira razao entre
x e y, assim que eles comecam a existir a partir de 0. A razao y
x e igual
a esta ultima razao entre quantidades evanescentes, ou igual a esta primeira
razao entre quantidades nascentes.
No primeiro livro de sua obra mais famosa, Princpios matematicos da
filosofia natural, Newton justifica o metodo das primeiras e ultimas razoes,
empregados em seguida, dizendo que:
As quantidades e as razoes de quantidades que tendem con-
tinuamente a se tornar iguais durante um tempo finito e que,
antes do fim deste tempo, se aproximam tanto da igualdade que
sua diferenca pode ser considerada menor que qualquer diferenca
dada, terminam por ser iguais.
Vemos que o princpio de continuidade enunciado por Newton e temporal.
Nesta tentativa de fundar o metodo dos infinitesimais, usando as primeiras
e as ultimas razoes, Newton faz o seguinte.
Chamando os incrementos somente de o, em vez de xo e yo, ele escreve
(y + o) = (x + o)n = xn + nxn1.o + . O incremento pode ser obtido como:
o = nxn1.o + n(n  1)
2 xn2.o2 + 
Dividindo tudo por o, obtemos:
1 = nxn1 + n(n  1)
2 xn2.o + 
Fazendo com que a quantidade o desapareca, a ultima razao e nxn1
1 e
y
x e a primeira razao. Como a ultima razao entre quantidades evanescentes
deve ser igual `a primeira razao entre as quantidades nascentes, temos que
y
x = nxn1.
Mas, apesar dos esforcos de Newton, e do fato que ele admite implici-
tamente uma nocao de limite, o metodo das primeiras e ultimas razoes nao
resolve por completo o problema dos fundamentos do calculo, pois enquanto
estes incrementos existem, a razao entre eles nao e a ultima razao e, quando
226 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
eles deixam de existir, nao existe mais uma razao entre eles. Logo, as pri-
meiras e ultimas razoes tambem sao difceis de conceber.
Os metodos de Newton e Leibniz sao distintos. No entanto, as justifica-
tivas de Newton parecem ser tao difceis de entender quanto as de Leibniz.
O livro principal de Newton, os Princpios Matematicos da Filosofia Natural,
nao contem desenvolvimentos analticos. Os resultados sao apresentados na
linguagem da geometria sintetica. Preocupado desde o princpio em fundar
um calculo universal, os metodos de Leibniz sao apresentados como metodos
e algoritmos, o que, juntamente com a praticidade da notacao, fez com que
os metodos diferenciais deste ultimo tivessem uma melhor recepcao do que o
primeiro.
Exerccios
5.18. Voce certamente conhece o binomio de Newton, resultado que per-
mite calcular potencias de (a + b) e que esta relacionado com os coefi-
cientes binomais (n
k):
Se n e um numero natural qualquer, entao
(a + b)n =
n

i=0
aibni(n
i ).
Isaac Newton, em torno de 1665 generalizou esta expressao para po-
tencias quaisquer de (a + b), definindo os coeficientes binomais genera-
lizados:
Defina, para r  R, k  N:
(r
k) = r(r  1)(r  k + 1)
k .
Entao, Newton provou que
(a + b)r =
r

i=0
aibr1.
1. Demonstre, por inducao, a formula tradicional do binomio de
Newton, para n um numero inteiro.
2. Demonstre que se r e um numero natural a nova definicao dos
coeficientes binomiais coincide com a velha.
5.7. AS FUNC OES COMO EXPRESS OES ANALITICAS 227
3. Prove que se r nao e um numero natural, entao (r
k) nunca se anula.
Em consequencia, nesse caso, o desenvolvimento binomial e uma
serie infinita. Sabe-se que essa serie e convergente, o que so foi
provado corretamente por Abel, no seculo XIX.
4. Usando o resultado de Newton, desenvolva em serie a funcao1 + x2 = (1 + x2)1/2.
A descoberta, por Newton, da generalizacao do teorema do binomio,
alem de matematicamente importante, e muito interessante porque po-
demos saber como ele chegou ao resultado. Em resposta a uma carta de
Leibniz, Newton descreve como descobriu a generalizacao do teorema.
Em Matematica, poucas vezes temos acesso aos caminhos trilhados pe-
los matematicos para chegarem a suas descobertas.
5.19. Newton e o desenvolvimento em serie de 1
1x2 .
1. Calcule, como Newton, usando o teorema do binomio, o desenvol-
vimento em serie de 1
1x2
2. Verifique, desenvolvendo em serie diretamente 1/(1x2), como fez
Newton, dividindo a serie formal 1 pela serie formal (1  x2) que
1
(1  x2) = 1 + x2 + x4 + x6 + x8 +  + x2n + 
3. Multiplique o desenvolvimento obtido no item anterior por 1  x2
e verifique que o resultado e 1.
Isso convenceu Newton da certeza de seu metodo. Em verdade,
uma demonstracao correta do teorema do binomio de Newton, so
foi achada no seculo XIX, por Abel.
5.7 As funcoes como expressoes analticas
Nos trabalhos sobre o calculo infinitesimal, a nocao de funcao propriamente
dita so ira intervir, ainda de modo implcito, no chamado problema inverso das
tangentes. Neste problema, tratado por Leibniz, dada uma reta, queremos
encontrar a curva cuja tangente e essa reta. Sabemos que este problema
pode ser dado de dois modos distintos que associamos hoje, respectivamente,
a problemas de integracao de uma funcao e de equacoes diferenciais.
Como vimos, nos problemas da geometria analtica, anteriores ao advento
do calculo, uma curva era sempre o dado de um problema e, a partir da curva,
queramos encontrar uma tangente ou uma quadratura. A partir do final do
228 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
seculo XVII, problemas como o inverso das tangentes requerem a introducao
de uma curva como solucao de um problema cujo dado e a reta tangente.
Na abordagem newtoniana pensamos tambem nos problemas de equacoes
diferenciais cuja solucao e associada a uma lei de variacao. Em ambos os
casos, o importante e que a incognita do problema passa a ser uma curva,
uma lei de variacao ou, como dizemos hoje, uma funcao. Trata-se de uma
transformacao crucial por que passa a Matematica durante o seculo XVIII
e que substitui seu objeto principal. Ate o seculo XX, a Matematica sentiu
as consequencias desta mudanca, descrita por Jaques Hadamard do seguinte
modo:
O ser matematico, em uma palavra, deixou de ser o numero:
passou a ser a lei de variacao, a funcao. A Matematica nao apenas
foi enriquecida por novos metodos, mas foi transformada em seu
objeto. ([73]).
Nao sao mais as grandezas geometricas, nem os numeros, os objetos cen-
trais da Matematica, mas as funcoes.
No entanto, apesar de identificarmos esbocos da nocao de funcao nos
calculos de Leibniz e Newton, o conceito propriamente dito so foi formulado
alguns anos mais tarde.
Vimos que o calculo infinitesimal partia do estudo de curvas que, desde
Descartes, eram expressas por equacoes. Estas representavam, por sua vez,
um modo de associar duas quantidades variaveis x e y. Mas as curvas estu-
dadas por Descartes se restringiam `as de natureza algebrica. Em meados do
seculo XVII, diversos matematicos introduziram series infinitas para estudar
curvas. A partir da, a relacao funcional entre as variaveis podia ser dada
por uma serie infinita e e justamente pela importancia destas series que uma
funcao sera definida por sua expressao analtica. Neste momento, as series
infinitas tornam-se o meio mais geral e fecundo para estudar qualquer funcao
e a definicao de sua expressao analtica ocupara um lugar central na analise
matematica.
A falta de um termo geral para exprimir quantidades arbitrarias, que
dependem de outra quantidade variavel, motiva a definicao de funcao, que
aparece pela primeira vez em uma correspondencia entre Leibniz e Johann
Bernoulli.
No final do seculo XVII, Johann Bernoulli ja emprega a palavra funcao
relacionando-a indiretamente a quantidades formadas a partir de quantidades
indeterminadas e constantes. Em resposta a uma carta de Bernoulli, de 1698,
Leibniz discute sobre a melhor notacao para uma funcao. Nesta epoca, ele ja
havia introduzido os conceitos de constante e de variavel, que se tornarao de
5.7. AS FUNC OES COMO EXPRESS OES ANALITICAS 229
uso corrente com a publicacao do primeiro tratado de calculo diferencial im-
presso, escrito pelo Marques de LHospital e publicado em 1696. Alem destes
termos, Leibniz tambem ja usava as nocoes de coordenadas e parametros. A
classificacao utilizada por Descartes, que dividia as curvas em geometricas e
mecanicas, e considerada inconveniente e Leibniz propoe separar as curvas
algebricas (que podem ser representadas por uma equacao de uma certa or-
dem) das transcendentes (representadas por equacoes `as quais nao e possvel
atribuir uma ordem).
A nova nocao de funcao so foi publicada, todavia, muitos anos mais tarde,
em um artigo de Bernoulli apresentado `a Academia de Ciencias de Paris em
1718:
Definicao. Chamamos funcao de uma grandeza variavel uma
quantidade composta, de um modo qualquer, desta grandeza
variavel e de constantes. (Opera omnia, Vol. II, p.241)
No mesmo artigo, ele usa a letra grega  para representar a caracterstica
da funcao, escrevendo o argumento sem os parenteses: x. Bernoulli nao diz
mais nada sobre o modo de constituir funcoes a partir da variavel indepen-
dente, mas o que ele tem em mente sao as expressoes analticas de funcoes.
A nocao de funcao introduzida aqui tem por objetivo somente expressar uma
variavel em funcao da outra.
Esta definicao analtica indica uma tendencia da epoca, que fez o calculo
infinitesimal abandonar todas as suas referencias geometricas e mecanicas,
para ser formulado exclusivamente em linguagem aritmetica ou algebrica.
Este movimento sera levado adiante pelos analistas do seculo XVIII, sobre-
tudo Euler, mas tambem Lagrange. Em sua Mecanica Analtica, publicada
em 1788, este ultimo chega a afirmar que a mecanica e uma parte da analise
matematica e a sua exposicao pode prescindir de figuras, ou de qualquer
outra consideracao geometrica.
Apesar da nocao de funcao nao ter sido inventada por Euler, ele foi o
primeiro a tratar o calculo como uma teoria das funcoes. A ideia de que a
analise matematica e uma ciencia geral das variaveis e de suas funcoes foi
fundada por Euler e exerceu grande influencia sobre a Matematica da epoca
a partir da publicacao de seu Introducao `a analise dos infinitos, publicado em
1748. Neste trabalho, que praticamente nao contem exemplos geometricos,
encontramos logo no incio uma definicao de funcao:
Uma funcao de uma quantidade variavel e uma expressao
analtica composta de um modo qualquer desta quantidade e de
numeros, ou de quantidades constantes.(Opera omnia, ser. I,
Vol. VIII, p.17).
230 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Um pouco antes, na mesma obra, ele ja havia definido uma constante
como uma quantidade definida que possui sempre um mesmo e unico va-
lor, e uma variavel como uma quantidade indeterminada, que pode possuir
qualquer valor:
Uma quantidade variavel compreende todos os numeros nela
mesma, tanto positivos quanto negativos, inteiros e fracionarios,
os que sao racionais, transcendentes e irracionais. Nao devemos
excluir nem mesmo o zero e os numeros imaginarios.
O que significa dizer que uma funcao e uma expressao analtica composta
de um modo qualquer destas quantidades constantes e variaveis? Euler con-
sidera nao somente funcoes algebricas, mas tambem transcendentes, as quais
podem ser definidas por operacoes nao necessariamente algebricas, ou por
combinacoes de operacoes algebricas repetidas um numero infinito de vezes.
Consequentemente, ele tenta definir de modo mais preciso o que e uma ex-
pressao analtica, enumerando as operacoes por meio das quais ela pode ser
obtida. Em primeiro lugar, estao as operacoes algebricas (que incluem a re-
solucao de equacoes algebricas); em seguida, sao listadas diversas operacoes
transcendentes, que incluem logaritmos e exponenciais, bem como funcoes
obtidas pela integracao de equacoes diferenciais.
A quantidade variavel, como quantidade indeterminada, podia receber
qualquer valor, inclusive transcendente, irracional ou imaginario, ainda que,
nesta epoca, estas quantidades nao fossem consideradas numeros como os
outros, naturais e fracionarios. Uma expressao analtica podia ser formada
pela aplicacao de finitas ou infinitas operacoes algebricas de adicao, sub-
tracao, multiplicacao, divisao, potenciacao e radiciacao.
A definicao analtica de Euler nao e mais uma definicao puramente alge-
brica. Diante da impossibilidade de enumerar todos os metodos para formar
uma expressao analtica, ele afirma que a forma mais universal de uma funcao
seria dada por uma serie de potencias da forma A+Bz +Cz2 +Dz3 +. Como
nao se sabe se toda funcao pode ser escrita deste modo, ele acrescenta que
devemos considerar tambem expoentes dados por qualquer numero (e nao
apenas por numeros inteiros).
A consideracao da funcao como uma expressao analtica, cuja forma mais
geral e uma serie de potencias, foi aceita por inumeros matematicos da epoca,
uma vez que ja era a nocao usada implicitamente desde Leibniz e Newton.
Acreditava-se que toda funcao podia ser escrita deste modo, que corresponde,
na Matematica atual, ao domnio das funcoes analticas.
No entanto, o proprio Euler chegou a apresentar uma concepcao mais geral
de funcao, em seus estudos sobre um problema fsico, que ja o interessava
5.7. AS FUNC OES COMO EXPRESS OES ANALITICAS 231
desde antes da publicacao de seu livro de analise. Trata-se do estudo das
vibracoes infinitamente pequenas de uma corda presa por suas extremidades:
Uma corda elastica com extremidades fixas 0 e l e deformada ate uma posicao
inicial, e em seguida liberada. A corda comecara a vibrar e o problema e o
de determinar a funcao que descreve a forma da corda em um instante t.
Figura 5.17
DAlembert ja havia traduzido este problema por uma equacao diferencial
parcial e concludo que sua solucao pode ser representada pela soma de duas
funcoes arbitrarias nas variaveis x e t: (x + at) e (x  at). Supondo que
a velocidade inicial e nula, a funcao  e determinada no intervalo (0, l) pela
forma inicial da corda. As condicoes iniciais podem ser muito diversas, mas
DAlembert acreditava que elas deviam ser sempre representadas por uma
expressao analtica.
Ainda em 1748, Euler escreve um trabalho no qual concorda com a solucao
de DAlembert, mas observa que ela permanece valida se a configuracao
inicial da corda nao e dada por uma unica formula. As formas iniciais podem
ser dadas por diferentes expressoes analticas em subintervalos distintos ou,
de modo mais geral por uma curva desenhada a mao livre. Esta ultima
suposicao seria a mais razoavel, uma vez que a forma inicial e engendrada ao
nosso bel prazer, pois podemos atribuir uma posicao qualquer `a corda, antes
de solta-la. Mas Euler nao chega a aprofundar seu estudo da solucao neste
caso.
Esta questao da origem a uma longa controversia sobre a natureza das
condicoes iniciais das solucoes de equacoes diferenciais parciais. Alguns anos
mais tarde, Daniel Bernoulli sustenta que a forma inicial da corda e arbitraria
e pode ser representada por uma serie infinita de termos trigonometricos,
considerada tao geral quanto uma serie de potencias. Isto implica que uma
funcao qualquer pode ser representada por uma serie trigonometrica, mas
Bernoulli estava mais interessado no problema fsico e nao chegou a propor
uma nova definicao de funcao.
232 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Para entender os debates que envolveram o problema da corda vibrante,
devemos mencionar que os matematicos do seculo XVIII acreditavam que se
duas expressoes analticas coincidem em um intervalo, entao elas coincidem
em todo o conjunto de numeros para os quais estao definidas. Isso era uma
verdadeira profissao de fe. Esta pressuposicao era natural, visto que o tipo de
funcoes consideradas na epoca eram as definidas por expressoes analticas.
Como consequencia, a totalidade de uma curva dada por uma expressao
analtica era completamente determinada por uma pequena parte da curva.
Implicitamente, assumia-se que a variavel independente em uma expressao
analtica varia sem restricao no que chamamos hoje de cojunto dos numeros
reais. Por exemplo, em 1744, Euler considerava que as funcoes
f (x) =   x
2
e
f (x) =


n=1
sen (nx)
n
eram iguais, uma vez que as duas expressoes analticas coincidem no intervalo
(0, 2), ainda que nao coincidam fora dele.
No entanto, a aceitacao de condicoes iniciais mais gerais no problema
das cordas vibrantes, sugerida por Euler, teve importantes consequencias no
desenvolvimento da nocao de funcao, levando os matematicos a estenderem
a definicao para incluir funcoes definidas por partes por meio de expressoes
analticas que podem ser distintas em intervalos distintos. Por exemplo,
passaram a ser admitidas funcoes como:
y = { x, x  0
x, x < 0
Ate mesmo funcoes desenhadas a mao livre, possivelmente nao expressas
por combinacoes de expressoes analticas passaram a ser consideradas. Al-
guns anos mais tarde, no prefacio de sua obra Institutiones calculi differentialis,
publicada em 1755, Euler formula uma nova definicao de funcao que nao se
baseia nas suas expressoes analticas:
Se certas quantidades dependem de outras quantidades de
maneira que, se as outras mudam, estas quantidades tambem
mudam, entao temos o habito de chamar estas quantidades de
funcoes destas ultimas. Esta denominacao e bastante extensa e
contem nela mesma todas as maneiras pelas quais uma quanti-
dade pode ser determinada por outras. Consequentemente, se x
5.7. AS FUNC OES COMO EXPRESS OES ANALITICAS 233
designa uma quantidade variavel, entao todas as outras quanti-
dades que dependem de x, de qualquer maneira, ou que sao de-
terminadas por x, sao chamadas de funcoes de x. (Opera omnia,
ser. I, Vol.X, p.4]).
Como afirma Lutzen, ao passo que D Alembert deixou que seu conceito de
funcao limitasse as configuracoes iniciais possveis da corda, Euler permitiu
que a variedade de formas iniciais estendesse seu conceito de funcao. Ou
seja, a generalizacao da definicao de funcao proposta por Euler teria sido
influenciada pelo problema fsico das cordas vibrantes.
Em um artigo sobre as funcoes descontnuas, publicado em 1767, o proprio
Euler afirma que o principal aspecto da integracao de equacoes diferenciais
parciais e que elas dao origem a uma nova classe de funcoes descontnuas, ab-
solutamente indefinidas e dependentes de nossa vontade, ou seja, arbitrarias.
Mas ele nao avanca no estudo deste tipo de funcao.
A concepcao geral de uma funcao, definida de modo arbitrario, ganhara
cada vez mais destaque na Matematica. Um dos primeiros a avaliar a sua
importancia foi Condorcet que enumera, ainda no final do seculo XVIII, tres
tipos de funcoes: as que possuem uma forma conhecida (explcita); as que sao
introduzidas por equacoes nao explicitadas entre F e x, y, z (implcitas); e as
que sao dadas somente por certas condicoes, por exemplo, como solucoes de
equacoes diferenciais. Lacroix, que parece ter lido este tratado pouco difun-
dido na epoca, segue uma definicao analoga, afirmando que toda quantidade
que depende de outras quantidades e dita funcao destas ultimas, ainda que
nao se saiba por quais operacoes podemos passar destas ultimas quantidades
`a primeira. O livro de Lacroix, chamado Traite du calcul differentiel et du cal-
cul integral, publicado pela primeira vez em 1797, tornou-se muito conhecido
e teve grande responsabilidade em difundir esta nova ideia de funcao.
Em seu Introducao `a analise dos infinitos, apesar de se dedicar preferenci-
almente `as funcoes que podem ser expressas por series de potencias, Euler
ja sabia que poderiam existir funcoes de outro tipo, estudadas no segundo
volume. Ele se dedica ao estudo de curvas planas que podem ser contnuas ou
descontnuas. A continuidade de Euler era uma nocao muito distinta da nossa,
pois se relacionava `a invariabilidade da expressao analtica que determina a
curva. Se a curva e expressa por apenas uma equacao em todo o domnio
dos valores da variavel, ela e continua. Ela e descontnua se, ao contrario, e
necessario mudar a expressao analtica que exprime a curva quando passamos
de um domnio a outro das variaveis.
Com esta definicao, seria descontnua, por exemplo, a curva que e grafico
da funcao que expressamos hoje por:
234 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
y = { x, 0  x  1
x2, 2 > x > 1
Por nossa definicao, esta curva e perfeitamente contnua no ponto x = 1.
As curvas descontnuas, para Euler, eram mistas e podiam ser compostas de
partes contnuas. As curvas contnuas estao associadas, portanto, `as funcoes
que podem ser expressas por apenas uma expressao analtica em todo o
domnio. No contexto do calculo diferencial, Euler ira se limitar a este tipo
de funcao.
Veremos, no proximo captulo, que as tentativas de enumerar e delimitar
os varios tipos de funcoes possibilitou a expansao do universo de funcoes
consideradas em Matematica. Isto levou ao surgimento, no seculo XIX, de
uma teoria geral das funcoes analticas, por Cauchy, Riemann e Weierstrass.
Por exemplo, em meados do seculo XIX, Cauchy fornece um exemplo
para criticar a definicao de funcoes mistas de Euler, definidas por expressoes
analticas distintas em regioes distintas de um mesmo intervalo. Ele mostra
que a funcao descontnua
y = { x, x  0
x, x < 0
pode ser representada pela unica equacao y = x2,  < x < +. Logo, ela
seria tambem contnua e, portanto, e superfluo classificar funcoes contnuas
e descontnuas pela unicidade de sua expressao analtica.
Veremos que, no contexto da teoria das series trigonometricas, desenvol-
vida por Fourier e Dirichlet, as crticas `as concepcoes anteriores do conceito
de funcao e de continuidade serao ainda mais incisivas.
As pesquisas que ajudaram a desenvolver uma nova visao sobre o calculo
diferencial, durante o seculo XIX, tem como motivacao, segundo alguns histo-
riadores, um retorno ao rigor. Esta expressao nao e muito elogiosa para com os
analistas do seculo XVIII. Euler, mas tambem DAlembert, Clairaut, e mais
tarde, Lagrange e Laplace foram responsaveis por transformar o calculo dife-
rencial de Leibniz e Newton, por meio de uma exploracao exaustiva das ferra-
mentas da analise algebrica, que permitissem liberar o calculo de raciocnios
injustificados com infinitesimos. O ttulo da principal obra de Lagrange elu-
cida por si so o seu objetivo: Theorie des fonctions analytiques, contenant les
principes du calcul differentiel, degages de toute consideration dinfiniments pe-
tits, devanouissants, de limites et de fluxions, et reduits `a lanalyse algebrique
des quantites finies (Teoria das funcoes analticas, contendo os princpios do
calculo diferencial, livres de qualquer consideracao de infinitamente pequenos,
evanescentes, limites e fluxoes, e reduzidos `a analise algebrica de quantidades
5.8. EXERCICIOS SUPLEMENTARES 235
finitas). Ou seja, o objetivo dos matematicos do seculo XVIII tambem era
fundar o calculo sobre bases rigorosas, mas de acordo com a concepcao de
rigor da epoca.
Exerccios
5.20. Siga o roteiro abaixo para provar que existem funcoes f  R  R que
nao possuam desenvolvimento em serie de potencias do tipo a0x+a1x2 +
 + anxn + 
Considere a funcao f  R  R dada por f (x) = e(1/x2 ), se x = 0 e
f (0) = 0.
 Prove que a funcao f definida acima e derivavel na orgem, isto e,
Df (0) = 0, calculando diretamente esta derivada, pela definicao.
 Prove que a funcao derivada de f , Df , esta definida para todo
numero real, que Df e derivavel na origem e que D2f (0) = 0.
 Prove que a funcao f possui derivadas de todas as ordens na
orgem, e que todas elas sao iguais a 0.
 Conclua que a funcao f nao pode ser escrita como uma serie do
tipo a0x + a1x2 +  + anxn + .
5.8 Exerccios suplementares
5.21. Analisaremos o desenvolvimento em serie de arc sen x proposto por
Newton (Veja o livro de Katz [96], pp. 643-644).
1. Mostre, usando a formula do binonio de Newton, que o desenvol-
vimento em serie de (1  x2)1/2 e igual a
1  1
2 x2  1
8 x4  1
16x6  
2. Na Figura 5.18, seja y o arco de crculo AE. Mostre que a area
do setor circular AP E e igual a y = arcsen x.
3. Mostre que a area deste setor e igual `a area sob y = 1  x2 de 0
a x menos 1
2 x1  x2.
4. Use integracao termo a termo para mostrar que
y = arcsen x = 2 
x
0
1  x2 dxx1  x2 = x+1
6 x3+ 3
40 x5+ 5
112 x7+
236 CAPITULO 5. A NOVA MATEM ATICA DO SECULO XVII
Figura 5.18
5. Deduza, do item anterior, que
x = sen y = y  1
6y3 + 1
120y5  1
5040 y7 + 
6. Usando o desenvolvimento em serie de 1  (sen y)2 e o item an-
terior, ache o desenvolvimento de cos y em serie de potencias.
5.22. Considere a parabola de equacao y = kx2, estudada por Fermat, entre
outros. Prove, usando os metodos do calculo infinitesimal, que a tan-
gente a esta parabola, pelo ponto de coordenadas (a, ka2), passa pelo
ponto (0, ka2). Arquimedes, usando metodos puramente sinteticos, ja
conhecia este resultado.
Captulo 6
Funcoes, numeros reais e
complexos: conceitos
fundamentais dos seculos XVIII e
XIX
6.1 Contextualizacao historica
Hoje, quando pensamos em uma funcao, duas coisas vem `a mente: a curva
que a representa graficamente; e sua expressao analtica. Em seguida, se
fizermos um exerccio mais formal, tambem lembramos da ideia de correspon-
dencia, expressa pela definicao em termos de conjuntos. As duas primeiras
ideias serviram, durante muito tempo, como definicao do conceito de funcao.
No universo de Descartes, as curvas que podiam ser expressas analitica-
mente eram apenas as de natureza algebrica. O passo fundamental para a
ampliacao desta nocao foi dado por Leibniz, quando foi expandido o universo
das curvas, para incluir as transcendentes, que podiam ser representadas por
series infinitas. Vimos que o uso de series infinitas esta na base da definicao
de funcao do seculo XVIII, quando passou a ser o objeto central da analise.
A funcao passou a ser definida como uma expressao analtica composta de
um modo qualquer de quantidades constantes e variaveis.
Chama-se analise algebrizada esta concepcao que transforma o calculo
infinitesimal no estudo algebrico de series. A institucionalizacao deste ponto
de vista esta ligada `as mudancas que acompanharam a Revolucao Francesa,
que levou a uma reestruturacao do sistema de ensino e do papel da ciencia.
Muitos matematicos importantes viviam na Franca, como Lagrange, Laplace,
Legendre e Monge, mas nao tinham a funcao de ensinar. Na epoca pre-
237
238 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
revolucionaria, a instrucao matematica era relegada a um papel marginal e
sofria da carencia de professores qualificados. A ideia de que a formacao ci-
entfica podia ser util `a nacao era cada vez mais aceita, tanto na expansao da
industria como no aperfeicoamento da forca militar. Esta consciencia levou
`a criacao de novas escolas e departamentos cientficos. Em 1794, foi fundada
a Ecole Polytechnique, dedicada `a formacao de engenheiros e cientistas. Foi
neste contexto que Lagrange e Lacroix produziram livros-textos que se torna-
ram ferramentas cruciais para o ensino superior da Matematica e formaram
geracoes de matematicos fundamentais nesta transformacao, como Cauchy.
O estabelecimento destas instituicoes publicas levou a uma inedita padro-
nizacao do currculo. A estimada posicao do metodo analtico na sociedade,
bem como sua operacionalizacao na Matematica por meio da ferramenta
algebrica, criaram um ambiente favoravel, na Franca, para a recepcao do
ponto de vista de Euler sobre a analise, alem de inspirar a concepcao ainda
mais radical que tera Lagrange logo em seguida. A arquitetura da analise
sera reformulada nos livros-textos de Cauchy, em particular em seu Cours
danalyse algebrique, escrito para suas aulas na Escola Politecnica.
A definicao de funcao como expressao analtica comecara a mudar com os
trabalhos de Fourier. A teoria deste ultimo sobre as series trigonometricas,
vista com desconfianca em um primeiro momento, ganhara grande destaque
durante o seculo XIX. O problema da convergencia das series de Fourier sera
abordado por Cauchy, em 1826 e por Dirichlet em 1829.
A nocao de rigor ira se transformar neste contexto, se separando da abor-
dagem da analise algebrizada, proposta pelos matematicos do seculo XVIII
para dar legitimidade aos metodos do calculo infinitesimal. Um dos pro-
blemas internos, a demandar uma nova nocao de rigor, surgiu da crtica `a
fundamentacao de nocoes basicas da Matematica sobre a ideia de quanti-
dade, como e o caso dos numeros. Esta associacao, a partir de certo mo-
mento, passou a bloquear o desenvolvimento da Matematica. A discussao
sobre as quantidades negativas, durante o seculo XVIII, mostra que somente
os numeros absolutos eram aceitos, pois se pretendia relacionar a existencia
em Matematica a uma nocao qualquer de realidade. Para avancar, era pre-
ciso migrar para um conceito abstrato de numero nao subordinado `a ideia
de quantidade.
As discussoes a partir das quais numeros problematicos (como irracionais,
negativos e imaginarios) passaram a ser admitidos na Matematica tem ori-
gem em praticas muito antigas. No desenvolvimento da algebra, a resolucao
de equacoes ja fazia aparecer numeros indesejaveis, que nao possuam um es-
tatuto definido em Matematica. Depois disso, a teoria das curvas, nos seculos
XVII e XVIII, e a proliferacao de metodos infinitos, para resolver problemas
do calculo infinitesimal, como o das quadraturas, enfatizou a necessidade de
6.1. CONTEXTUALIZAC AO HIST ORICA 239
ultrapassar a nocao de numero como quantidade.
Antes do seculo XIX, todos os nomes que eram usados para designar estes
numeros exprimiam a dificuldade de se admitir sua existencia. Eram usa-
das designacoes de numeros surdos ou inexprimveis, para os irracionais,
quantidades falsas, fictcias, impossveis ou imaginarias, para os nu-
meros negativos e complexos. Isto mostra que estes numeros nao tinham uma
cidadania matematica e, em ultima instancia, nao eram sequer admitidos
como numeros. Normalmente, a historia destes numeros e desconectada das
questoes internas que apareceram em outros problemas da Matematica. Mas
a percepcao da necessidade de se incorporar estes numeros envolve etapas es-
senciais do processo de generalizacao, bem como a compreensao abstrata dos
numeros e das operacoes. A transicao do conceito de quantidade para o de
numero foi marcante para a nocao de rigor que se constituiu a partir do seculo
XIX. Enquanto os numeros eram associados a quantidades geometricas, nao
se concebiam operacoes abstratas e arbitrarias sobre eles. Os matematicos
que se deparavam com problemas relativos `a fundamentacao da analise esta-
vam cientes de que o progresso deste ramo da Matematica dependia de uma
extensao do conceito de numero. Nao e `a toa que uma parte importante
deste movimento ficou conhecida como aritmetizacao da analise.
Para dar consistencia `as praticas da analise, tornou-se necessario introdu-
zir um conceito abstrato de numero, independente das ideias de quantidade
e grandeza. Gauss, por exemplo, defendia uma concepcao mais abstrata da
Matematica, bem como outros matematicos alemaes do seculo XIX.
A substituicao do paradigma das quantidades implicou em uma mudanca
irreversvel no edifcio da Matematica, que culminou com a transformacao
da Matematica em Matematica pura. Esta transformacao teve incio na
Alemanha, nos primeiros anos do seculo XIX. Ainda que procurasse se es-
tabelecer como uma disciplina independente, a analise do seculo XVIII era
motivada por problemas fsicos, que continuaram a exercer grande influencia
no incio do seculo seguinte. Mas com a crescente abstracao e formalizacao
imposta pela reflexao sobre os fundamentos da Matematica, no final do seculo
XIX, a fsica deixara de ser central.
As preocupacoes com a formalizacao e a axiomatizacao da Matematica
culminaram com o desenvolvimento da nocao de conjunto, que acabou pre-
dominando ate o incio do seculo XX, levando `a redefinicao de suas nocoes
centrais a partir dos conjuntos. A predominancia do ponto de vista conceitual
em Matematica, que abriu caminho para a abordagem conjuntista, ja havia
sido estimulada por Dirichlet, que juntamente com Riemann e Dedekind,
que se via como seu discpulo, sera marcante para a Matematica praticada
na Universidade de Gottingen. Todos tres seguiam a inspiracao de Gauss,
e promoviam uma visao abstrata e conceitual da Matematica. Apesar das
240 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
diferencas entre seus campos de pesquisa, eles convergiam nas preferencias
metodologicas e teoricas. Riemann e Dedekind se dedicaram mais direta-
mente `a compreensao das teorias matematicas sem recurso a representacoes
externas. Os novos objetos matematicos deviam ser definidos por suas ca-
ractersticas internas e admitidos como princpios da teoria. Esta ausencia
de referencia externa pode ser vista como a inauguracao de uma nova fase da
abstracao, que transformara definitivamente a Matematica em Matematica
pura.
A partir deste momento, a teoria dos conjuntos passou a ser o enquadra-
mento mais adequado para se obter um novo consenso sobre os fundamentos
da analise, e de toda a Matematica. O papel de Bourbaki foi importante na
cristalizacao deste ponto de vista no ensino, que teve como consequencia a
redefinicao de todas as nocoes basicas da Matematica na linguagem dos con-
juntos. Esta tendencia mudou a concepcao sobre numero e funcao, nocoes
que possuem, todavia, uma longa historia previa.
6.2 Discussao sobre a forma dos numeros ima-
ginarios
O seculo XVIII apresentou uma intensa atividade em torno da forma dos
imaginarios1. Os primeiros resultados podem ser encontrados em 1747, na
dissertacao de dAlembert sobre os ventos (Ver [40]). No artigo 79, ele afirma
que uma quantidade qualquer, composta de tantos imaginarios quanto dese-
jarmos, pode ser reduzida `a forma A + B1 com A e B quantidades reais;
Se a quantidade proposta for real, isto significa que B = 0.
Em seguida sao apresentados os seguintes resultados sobre a forma dos
imaginarios que resultam de operacoes com imaginarios:
 a+b1
g+h1 = A + B1;
 [a + b1]g+h1 = A + B1;
 a+b1(g +1) = A+B1 e que a+b1(g +1) = A+B1;
Euler aborda esta tematica em sua obra Recherches sur les racines imagi-
naires des equations, de 1749, com diversos teoremas e corolarios, dos quais
ressaltamos o teorema XII que afirma que toda fracao formada por adicao,
subtracao, multiplicacao ou por divisao, envolvendo quantidades imaginarias
1De acordo com a terminologia da epoca, chamaremos de imaginarios o que designamos
hoje como numeros complexos.
6.2. DISCUSS AO SOBRE A FORMA DOS N UMEROS IMAGIN ARIOS 241
quaisquer da forma M + N1, tera a mesma forma M + N1, em que as
letras M e N representam quantidades reais.
Deste teorema decorre que, quando N = 0, a forma geral M + N1
compreende todas as quantidades reais. Deste modo, as quatro operacoes
mencionadas anteriormente atendem nao somente aos imaginarios da forma
M + N1, mas tambem aos numeros reais.
Vi`ete, em seu Supplementum geometricae, publicado em 1590, ja havia no-
tado que o caso irredutvel das equacoes de terceiro grau estava relacionado
`a trisseccao do angulo e ja havia obtido uma formula de multiplicacao por n
usando regras trigonometricas. Descartes ja havia observado que o problema
da trisseccao do angulo pode ser resolvido por meio de uma equacao cubica
e chegou a interpretar a formula de Cardano a partir deste problema.
No caso particular dos numeros imaginarios, De Moivre foi um dos primei-
ros a observar que estes numeros podem ser uteis para problemas de divisao
de arcos de crculos, mostrando que um numero imaginario unitario pode ser
representado por cos a  1sen a. A partir desta constatacao, obtem-se que
n

cos a + 1 sen a fornece n valores para a divisao do arco a, uma vez que
(cos a  1 sen a)n = cos na  1 sen na.
Isto permite um estudo mais aprofundado das expressoes n

a + b. Em
1738, De Moivre declara que estas expressoes admitem n valores, todos da
forma p + q1, em que p e q sao numeros reais. Este resultado se baseia na
demonstracao da expressao particular n

cos +1sen a, em que os n valores
sao obtidos justamente por meio da divisao do arco a.
Trabalhando sobre os casos irredutveis das equacoes de terceiro grau,
utilizando o metodo inventado por Leibniz para fazer desaparecer os numeros
imaginarios das expressoes n

a + b + n

a  b, F. Nicole, em seu artigo
Sur le cas irreductible du troisi`eme degre, publicado em 1738, registra que e
surpreendente que uma grandeza real seja expressa por uma composicao de
quantidades reais e imaginarias. Ele verificou que era necessario que essas
quantidades imaginarias se destruissem mutuamente durante os calculos.
Nicole apresenta um metodo com uma sequencia de resultados e corolarios
que estao diretamente relacionadas `as solucoes de uma equacao cubica do tipo
x3 px+q = 0, resolvida pelo metodo de Cardano. Ele mostra que, no caso de
1
27 p3 ser maior que 1
4 q2, a equacao possuira tres razes reais, todas diferentes
entre si, embora elas so possam ser encontradas por meio de imaginarios, ja
que
1
4 q2  1
27 p3 e uma quantidade imaginaria.
Um importante resultado de seu trabalho foi mostrar que a expressao
242 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
(a
b + 1)
n
+ ( a
b  1)
n
,
que envolve quantidades imaginarias, com n um numero inteiro ou fraciona-
rio, positivo ou negativo, sempre conduz a uma quantidade real.
Euler prosseguira com esta investigacao, mostrando que, para o caso dos
numeros complexos unitarios, ja tratados por De Moivre, e possvel decompor
(cos a)2 + (sen a)2 = 1 como (cos a + 1sen a)(cos a  1sen a) = 1. Ele
comenta em seguida que, apesar de imaginarios, estes fatores sao de grande
utilidade para as operacoes com arcos de circunferencia. Fazendo o produto
dos fatores(cos a + 1sen a)(cos b  1sen b) obtemos:
cos a cos b  sen a sen b + (cos a sen b + sen a cos b)1.
Euler conclui, a partir das igualdades trigonometricas
cos a cos b  sen a sen b = cos(a + b)
cos a sen b + sen a cos b = sen (a + b),
que o produto acima deve ser igual a cos(a + b) + 1sen (a + b). A partir
desta igualdade, o resultado que chamamos hoje formula de De Moivre
pode ser demonstrado sem problemas. Euler deduz da que a raiz de um
complexo qualquer a  b1 tambem pode ser escrita desta forma.
No entanto, a representacao de um complexo qualquer ainda nao esta
completamente estabelecida. A representacao trigonometrica foi anterior `a
representacao geometrica dos numeros complexos, assunto de que trataremos
na proxima secao.
Todos os estudos que relacionavam o grau de uma equacao polinomial
e o numero de suas razes esbarravam necessariamente na possibilidade de
decompor esta equacao em fatores simples. Para isso, foram indispensaveis
conjecturas a respeito dos numeros imaginarios e de sua forma generica. Alem
disso, o estudo da decomposicao de uma fracao em elementos simples se re-
laciona com o desenvolvimento da teoria dos logaritmos, que levara a uma
extensao da definicao desta nocao para incluir logaritmos de numeros nega-
tivos e imaginarios. O desenvolvimento do estudo dos numeros imaginarios
muito se deveu a controversias a este respeito: entre Leibniz e Bernoulli, em
primeiro lugar; em seguida, entre Bernoulli e Euler; e, posteriormente, entre
Euler e dAlembert.
Um contexto importante no qual se inserem as discussoes acerca da forma
dos numeros complexos e o do calculo infinitesimal. As contribuicoes de Leib-
niz e Jean Bernoullli para a integracao de funcoes racionais, decompondo-as
6.2. DISCUSS AO SOBRE A FORMA DOS N UMEROS IMAGIN ARIOS 243
em elementos simples, foi o primeiro passo para o estudo de novos proble-
mas envolvendo numeros complexos. Eles ampliaram para as quantidades
imaginarias as regras demonstradas, no calculo integral, para os numeros re-
ais. Assim, estes estudos deveriam conduzir naturalmente `a decomposicao
de uma funcao racional inteira de variavel x em um produto de fatores de
primeiro grau da forma x  a ou x  a  b1 e os problemas de integracao
fazem surgir o problema dos logaritmos dos numeros imaginarios.
Tomemos, como exemplo, a expressao 1
x2+1 da qual queremos encontrar
uma primitiva.
Em uma primeira etapa chegamos `a decomposicao 1
2i log ( 1
xi + 1
x+i ), cuja
primitiva sera arctg x, ou em um calculo formal, 1
2i log (xi
x+i ) + c.
Efetuando as seguintes mudancas de variaveis, arctg x = y
2 e tg y
2 = t,
obteremos
y
2 = 1
2i log t  i
t + i,
ou
yi = log t  i
t + i,
ou ainda
yi = log t2  2it  1
t2 + 1 ,
o que nos da, finalmente,
xi = log [ (cos x + isen x)] .
O sinal  nesta expressao foi a primeira dificuldade que originou a
divergencia entre Leibniz e Bernoulli. Partindo do fato que log (+1) = 0,
Bernoulli conclui que:
log (1) = log (1)2 = 2 log (1) = 0,
ou seja,
log (1) = 0.
log (1) = log (1)1
2 = 1
2 log (1) = 0,
ou seja,
244 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
log (1) = 0.
Desta forma, ele afirma que todo numero negativo possui um logaritmo
real que e igual ao logaritmo de seu valor absoluto. Esta conclusao  que sa-
bemos hoje nao ser verdadeira  pode ser expressa em linguagem matematica
por:
(a)2 = a2 
log (a)2 = log (a)2 
2 log (a) = 2. log (a) 
log (a) = log (a) .
Euler, em uma carta enviada a Bernoulli, em 1728, mostra a contradicao e
sugere que ele desconsidere a caracterstica unvoca do logaritmo, apontando
para o fato de que todo numero complexo deve admitir uma infinidade de
logaritmos.
Usando metodos de comparacao entre progressoes aritmeticas e geome-
tricas, o estudo da funcao exponencial  realizado principalmente por Wallis,
Newton e J. Bernoulli  revelou que a funcao logartmica seria a inversa desta
nova funcao.
A aplicacao das exponenciais aos numeros imaginarios ja consta do traba-
lho de Euler em torno de 1740. Na nota 133 de sua Introducao `a analise dos in-
finitos (1748), ele parte do resultado (cos z  1 sin z)n
= cos nz 1 sin nz
e obtem as seguintes igualdades:
cos  = e1 + e1
2
sin  = e1  e1
21
Por conseguinte:
e1 = cos  + 1 sen 
e
e1 = cos   1 sen .
Euler entao partiu dos pontos de vista de Leibniz e Bernoulli e esclareceu
a questao no artigo Da controversia entre os senhores Leibniz e Bernoulli sobre
6.2. DISCUSS AO SOBRE A FORMA DOS N UMEROS IMAGIN ARIOS 245
os logaritmos dos numeros negativos e imaginarios. Para provar a existencia de
logaritmos de numeros negativos, ele partiu do princpio de que o numero e e
base para todos os logaritmos e exponenciais. Ele observou que, se o smbolo
log w for interpretado como o conjunto de todos os numeros complexos z,
tais que ez = w, continua valida a propriedade do logaritmo do produto, ou
seja, um numero complexo e logaritmo de wz, se e somente se, log(wz) =
log w + log z, como pretendia Bernoulli.
Isso significa que, ao admitir-se uma infinidade de logaritmos para cada
numero, manteve-se a validade da regra elogw = w, como queria Leibniz, o
que nao ocorreria se para cada numero houvesse apenas um logaritmo.
A relacao
eix = cos x + i sen x,
conhecida como identidade de Euler, estabeleceu a tao necessaria conexao
entre os logaritmos e as funcoes trigonometricas. Alem dessas conquistas,
a identidade de Euler deu significado aos logaritmos de numeros negativos.
De fato, se x = , Euler obteve e i + 1 = 0, e assim ln (1) =  i, ou seja, os
logaritmos de numeros negativos sao numeros imaginarios puros.
Com esses resultados, podemos retornar `a controversia gerada em relacao
aos logaritmos de numeros negativos. Durante os anos de 1747 e 1748, Euler
remeteu a dAlembert diversas cartas nas quais sustentava que os numeros
negativos nao possuam logaritmos reais, como pensavam dAlembert e Ber-
noulli. Sua objecao em relacao `a teoria de dAlembert se baseava no fato
de que e na equacao y = ex poderia assumir um valor positivo e negativo.
Euler afirma que, se e assumisse o valor da expressao 1 + 1
2 + 1
1.2 + 1
1.2.3 + ,
x seria o logaritmo hiperbolico do numero y e seria impossvel encontrar um
valor para x tal que ex fosse negativo. Isto faz com que ele considere que os
logaritmos de numeros negativos devem ser impossveis.
Esta denominacao impossvel dada por Euler aos logaritmos dos numeros
negativos, remete `a denominacao dos numeros imaginarios. Esta observacao
pode ser notada em sua obra Vollstandige Anleitung zur Algebra (1769) (In-
troducao `a algebra) em que encontramos as seguintes citacoes:
Uma vez que todos os numeros que sao possveis de imagi-
nar sao, ou maiores ou menores que 0, ou sao o proprio 0, e claro
que nao podemos incluir a raiz quadrada de um numero nega-
tivo entre os numeros possveis, entao e necessario dizer que e
uma quantidade impossvel. E desta forma que nos somos con-
duzidos `a ideia de numeros que pela sua propria natureza sao
impossveis. Nos chamamos ordinariamente estes numeros de
246 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
quantidades imaginarias porque eles existem puramente na ima-
ginacao.
(. . . )
Os numeros 1, 2, 3, 4, 5, 6,. . . , ou seja, todos os numeros
positivos, sao logaritmos da raiz a (inteira natural  1) e de
suas potencias, e por conseguinte, logaritmos de numeros mai-
ores que a unidade. Contrariamente, os numeros negativos como
1, 2,, sao os logaritmos das fracoes 1
a , 1
a.a , etc. que sao
menores que a unidade, entretanto sao ainda maiores que nada.
Segue entao que, se o logaritmo e positivo, o numero e sempre
maior que a unidade, mas se o logaritmo e negativo, o numero e
sempre menor que 1, e portanto maior que zero. Por conseguinte,
nao saberamos indicar os logaritmos de numeros negativos, e e
necessario concluir que os logaritmos de numeros negativos sao
impossveis, e que eles pertencem `a classe das quantidades ima-
ginarias.
Utilizando os resultados de Euler e a linguagem conhecida atualmente,
teramos que ei = cos  + i  sen , ou seja, ei = 1 o que significaria escre-
ver que ln (1) =   i, logo os logaritmos de numeros negativos nao seriam
reais, como haviam suposto dAlembert e Bernoulli, e sim quantidades ima-
ginarias. Devido aos seus estudos, Euler tambem ressalta que os numeros
positivos e negativos possuem uma infinidade de logaritmos e, no caso dos
positivos, apenas um e real. Devemos a Euler uma serie de resultados na
forma p + q1, envolvendo expressoes como sen (a + b1), cos (a + b1)
e tg (a + b1), alem de uma teoria dos logaritmos muito proxima da que
conhecemos atualmente.
Exerccios
6.1. O matematico italiano Bombelli propos o seguinte o problema de es-
crever 3

52 + 2209 na forma a + bi, em que i = 1. Como voce
procederia para resolver este problema?
6.2. Como voce explica a seguinte situacao, aparentemente correta, que
causou perplexidade a Euler?
Como a  b = ab, e (1)(1) = 1, temos:
1 = 1 = (1)(1) = (1)(1) = i i = i2 = 1 !
Assim, foi provado que 1 = 1, e portanto 2 = 0.
6.3. FORMA GEOM ETRICA DAS QUANTIDADES IMAGIN ARIAS 247
6.3 Forma geometrica das quantidades imagi-
narias: Argand e Gauss
Apesar de toleradas, pela sua utilidade pratica na realizacao de calculos,
estas quantidades nao eram consideradas rigorosas. Somente a partir do
final do seculo XVIII e inicio do seculo XIX comecaram a ser sugeridas di-
ferentes representacoes geometricas para os numeros negativos e complexos,
o que ira garantir sua plena aceitacao no universo dos numeros. Alem do
nome de Gauss, o matematico mais conhecido a propor uma representacao
geometrica para os numeros complexos, tambem sao importantes os nomes
do dinamarques Caspar Wessel e do suco Jean-Robert Argand. 2
6.3.1 Argand
Argand principia com as quantidades negativas, uma vez que elas nao po-
diam ser rejeitadas, sob o risco de termos que questionar diversos resultados
algebricos importantes. Tomemos as grandezas a, 2a, 3a, 4a, etc. E evi-
dente que este processo pode continuar indefinidamente. Mas, e a operacao
inversa? Podemos subtrair a grandeza a de cada um dos termos anteriores,
obtendo: 3a, 2a, a, 0. E depois? Como prosseguir? Que sentido atribuir
`a subtracao 0  a? Os termos que seguem so podem existir na imaginacao,
sendo chamados, por isso, de imaginarios. Argand propora uma construcao
capaz de assegurar, em suas proprias palavras, alguma realidade a estes
termos.
Consideremos uma balanca com dois pratos A e B. Acrescentemos ao
prato A as quantidades a, 2a, 3a, 4a, e assim sucessivamente, o que faz a
balanca pender para o lado do prato A. Se quisermos, podemos retirar uma
quantidade a de cada vez, restabelecendo o equilbrio. E quando chegamos
a 0? Podemos continuar retirando estas quantidades? Sim, afirma Argand,
basta acrescenta-las ao prato B. Ou seja, introduz-se aqui uma nocao relativa
do que retirar significa: retirar do prato A significa acrescentar ao prato B.
Deste modo, as quantidades negativas puderam deixar de ser imaginarias
para se tornar relativas.
A representacao proposta por Argand permite atribuir um sentido `as
operacoes com numeros negativos, como, por exemplo, `a multiplicacao por
1, que passa a ser vista como uma reflexao em relacao `a origem. Isto
possibilita entender mais facilmente porque 1  1 = +1, pois basta observar
que, apos a reflexao de 1 em relacao `a origem, obtem-se +1.
2Uma discussao sobre a biografia incerta de Argand pode ser encontrada em Schubring
([133]).
248 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
Figura 6.1
Estabelecida uma representacao para as grandezas relativas (positivas e
negativas) como grandezas direcionadas, Argand passa a analisar todas as
possibilidades de relacao de proporcao entre estas grandezas, obtendo que:
+1  + 1   1  1 e + 1   1   1 + 1.
Sabemos que a meia proporcional entre +1 e 1 ou entre 1 e 1 e +1
ou 1, pois se 1  +x  +x  1, ou se+1  +x  +x  +1, a quantidade x
deve ser+1 ou 1. Cabe, portanto, perguntar como seria possvel determinar
a meia proporcional entre +1 e 1 ou entre 1 e +1 ? Argand investiga,
entao, as grandezas que satisfazem `a proporcao +1  +x  +x  1 e encontra
a resposta por meio do seguinte diagrama:
Figura 6.2
Os segmentos KA e KI sao entendidos, respectivamente, como segmentos
direcionados de K para A e de K para I e representam as grandezas unitarias
positiva e negativa. Em seguida, traca-se uma perpendicular EN `a reta que
une I a A. O segmento KA esta para o segmento direcionado KE assim como
KE esta para KI; e KA esta para o segmento direcionado KN assim como
KN esta para KI. Logo, a condicao de proporcionalidade exigida acima
para a grandeza x e satisfeita por KE e KN. As grandezas geometricas que
satisfazem `a proporcao requerida sao, portanto, KE e KN, que podem ser
vistas como representacoes geometricas de +1 e 1.
Para a representacao das quantidades imaginarias, somos bem sucedidos
combinando as ideias de grandeza absoluta e de orientacao, mas a orientacao
nao e mais dada somente como uma oposicao, pois a proporcao impoe que
6.3. FORMA GEOM ETRICA DAS QUANTIDADES IMAGIN ARIAS 249
+1 esteja para +x como esta quantidade esta para 1. Portanto, temos uma
nova direcao que, neste caso, deve ser uma perpendicular. A multiplicacao
por 1 deve ser entendida agora como uma rotacao. As quantidades +1
e 1 tornam-se reais porque podemos concebe-las como orientacoes dis-
tintas na direcao perpendicular que determinam dois lados para o segmento
inicial IA. Como requerido pela meia proporcional, a orientacao positiva
esta para a perpendicular como esta perpendicular esta para a orientacao
negativa, e vice-versa. Temos agora, no lugar de uma reflexao, uma rotacao.
O zero nao e, portanto, um ponto neutro, mas um centro de rotacao, o ponto
que organiza o giro. A oposicao pode ser vista, agora, como o produto do
giro, fixando os extremos de uma rotacao (se pensarmos a reflexao como o
extremo de uma rotacao, (1)2 = 1).
6.3.2 Gauss
Quando, em 1831, Gauss publicou o que denominava metafsica das gran-
dezas imaginarias (na obra Theoria residuorum biquadraticorum commentatio
secunda), ele ja era um matematico de renome, bastante respeitado, diferente-
mente de Argand, que exercia a atividade de guarda-livros e era considerado
um matematico marginal. Gauss foi o primeiro matematico influente a defen-
der publicamente as quantidades imaginarias que, dali em diante, tornaram-
se entidades reconhecidas como tais, com lugar na aritmetica, numeros com-
plexos sobre os quais sera possvel realizar calculos de modo consistente.
Embora os trabalhos de Gauss sobre quantidades imaginarias nao tivessem
grandes novidades em relacao aos de seus antecessores, ele apresentara uma
sntese de trabalhos de Wessel e Argand, mas tambem de outros matema-
ticos desconhecidos. Defensor da abstracao como caracterstica essencial da
Matematica, Gauss nao enxerga as quantidades imaginarias como entidades
que precisam ser realizadas, e sim como objetos plenamente abstratos, o
que era suficiente para que tivessem lugar na Matematica.
Nao sera mais necessario, portanto, qualificar as quantidades negati-
vas e imaginarias pela sua natureza, o que as levava a serem consideradas
sofsticas, absurdas, impossveis, falsas ou imaginarias. As quan-
tidades negativas e complexas passam a ser objetivas, mas, conforme a defi-
nicao da objetividade matematica proposta por Gauss, elas serao entendidas
como relacoes.
Os numeros negativos so podem ser compreendidos, segundo Gauss, quan-
do entendemos que as coisas contadas podem ser de especies opostas, de
modo que a unidade de uma especie possa neutralizar a unidade de outra
especie (como +1 e 1). Para isso, ele afirma que as coisas contadas nao
devem ser encaradas como substancias, como objetos considerados em si
250 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
mesmos, mas como relacoes entre esses objetos:
E necessario que estes objetos formem, de algum modo, uma
serie como . . . A, B, C, D, . . . e que a relacao que existe entre A
e B possa ser vista como igual `aquela que existe entre B e C
e assim por diante. Essa nocao de oposicao implica ainda uma
possvel troca entre os termos da relacao, operando de modo que,
se a relacao (ou a passagem) de A a B e indicada por +1, a relacao
de B com A e indicada por 1 (Gauss, Werke, II, pp. 175-176;
Beman, pp. 178-179).
Quanto aos numeros complexos, eles devem ser compreendidos tambem
como uma relacao e Gauss comeca por destacar a similitude entre a relacao
de +1 com 1 e a relacao de +i i (smbolos que ele introduz). De certa forma,
trata-se de um entendimento que nao esta muito distante da meia propor-
cional proposta por Argand e a consideracao das quantidades imaginarias
como objetos reais da aritmetica sera defendida, justamente, a partir da ob-
servacao de que +i e i podem ser vistos como meias proporcionais entre +1
e 1. Gauss afirma entao que estas relacoes podem ser tornadas intuitivas
por uma representacao geometrica. Para isto, basta considerar no plano um
duplo sistema de retas paralelas que se cortam em angulos retos. Os pontos
de intersecao serao os numeros complexos e, dado um certo ponto A, ele e
envolvido por quatro pontos adjacentes: B, B, C e C.
O smbolo +1 indica a relacao do ponto A com um dos pontos adjacentes,
o que faz com que 1 indique automaticamente a relacao com o adjacente
no sentido oposto. O smbolo +i indicara a relacao com um dos dois pontos
adjacentes que restaram, dependendo da escolha anterior para +1, o que faz
com que i indique automaticamente a relacao com o adjacente no sentido
6.3. FORMA GEOM ETRICA DAS QUANTIDADES IMAGIN ARIAS 251
oposto. Note que, assim, +1 poderia indicar a relacao de A com B ou com
C, enquanto 1 poderia indicar a relacao com B ou com C. O fato de
podermos trocar +1 por +i indica que os numeros +1 e +i nao possuem
nenhuma realidade, mas designam apenas uma relacao. No entanto, nao
podemos trocar +1 por i (nao podemos ter i no mesmo segmento de +1,
mantendo os outros inalterados), o que mostra que e escolhida uma orientacao
do plano.
Os eixos dos reais e dos imaginarios sao escolhidos, portanto, de modo ar-
bitrario, mas Gauss nao deixa de observar que, se quisessemos chamar de +1
a relacao que exprimimos por +i, teramos que chamar de +i a relacao antes
chamada de 1, justamente porque +i e uma meia proporcional entre +1 e 1.
A representacao escolhida utiliza fortemente, como Gauss assinala, a proprie-
dade do plano de que, escolhidos um em cima e um embaixo, a distincao
entre uma direita e uma esquerda fica automaticamente determinada
(Werke, II, pp. 176-177); trad. Beman, pp. 179-180). A nomenclatura de
positivo, negativo e imaginario respectivamente para +1, 1 e 1 foi
exatamente o que deu margem, segundo Gauss, a muitas confusoes quanto ao
estatuto destes numeros, que deveriam ser chamados unidade direta, in-
versa e lateral, o que mostra seu papel relativo `a orientacao das direcoes
do plano.
A associacao dos numeros complexos aos pontos do plano e enfatizada
por Gauss como por nenhum outro matematico antes dele. No entanto, apos
algumas hesitacoes introduzidas por Cauchy quanto ao estatuto destas quan-
tidades como grandezas orientadas, que ele propoe conceber como expressoes
simbolicas, o passo decisivo para que o estatuto dos numeros complexos seja
firmemente estabelecido e a construcao de uma teoria algebrica para estes
numeros, o que so foi possvel com a introducao da nocao de vetor. Este
conceito-chave da Matematica surgiu, ainda no seculo XIX, com o trabalho
de W. R. Hamilton, mas nao podemos deixar de notar que as quantidades
direcionadas de Argand ja se pareciam bastante com vetores.
Exerccios
6.3. Seja z um numero completo dado por sua representacao trigonometrica:
z = r(cos  + isen ).
Demonstre que
zn = rn(cos n + isen n).
252 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
6.4. Seja u um numero complexo, tal que u = 1. Assim, u pode ser escrito
como
u = cos  + isen .
Seja z  C. Mostre que efetuar o produto u  z equivale a girar o numero
complexo z de  graus.
Neste exerccio vemos que as rotacoes do plano podem ser feitas por
meio da multiplicacao por um numero complexo de modulo unitario.
O matematico e fsico irlandes William Rowan Hamilton (1805 - 1865)
tentou construir um conjunto de numeros que pudessem ser usados para
descrever rotacoes no espaco. Ao fazer isso, descobriu os quaternions,
H.
6.4 Os primeiros passos para a definicao de uma
funcao arbitraria: Fourier e Dirichlet
Os trabalhos de Fourier sobre a teoria da propagacao do calor, publicados
no incio do seculo XIX, deram um novo impulso `a evolucao do conceito
de funcao. Ele coloca o problema de mostrar que uma funcao arbitraria
definida em um intervalo pode ser sempre representada por desenvolvimentos
em series que contem funcoes senos e cossenos.
Este resultado ja era conhecido por Euler e Lagrange, mas somente para
funcoes particulares. Fourier defendia que sua validade para qualquer funcao,
no que este termo ganhava uma acepcao bem mais geral. Como ele afirma
em 1822, uma funcao f (x) representa uma sucessao de valores, ou ordenadas,
arbitrarias. Dada uma infinidade de valores para as abscissas x, existe um
igual numero de ordenadas f (x), todas com valores numericos que podem
ser positivos, negativos ou nulos. Nao precisamos supor que estas ordenadas
sejam sujeitas a uma lei comum, elas se sucedem de uma maneira qualquer
e cada uma delas e determinada como se fosse uma unica quantidade.
Notamos que, para um valor dado da abscissa, deve existir somente um
valor correspondente da ordenada, uma vez que deve haver o mesmo numero
de ordenadas, f (x), que de abscissas, x. Apesar de a demonstracao, forne-
cida por Fourier, de que toda funcao pode ser expressa por uma serie tri-
gonometrica ser insatisfatoria para nossa concepcao de rigor, este resultado
impulsionou uma nova definicao de funcao.
Em primeiro lugar, Fourier nao subscrevia a profissao de fe dos mate-
maticos do seculo XVIII, uma vez que duas funcoes dadas por expressoes
6.4. A DEFINIC AO DE UMA FUNC AO ARBITR ARIA 253
analticas diferentes podem coincidir em um intervalo sem coincidir fora dele.
Alem disso, ele mostrou que uma funcao descontnua, no sentido de Euler,
podia ser representada por uma serie, que e uma expressao analtica, logo ela
tambem seria considerada contnua. Isto mostra que a definicao anterior de
continuidade e inadequada.
Inicialmente, a teoria de Fourier foi vista com desconfianca, mas ganhou
grande destaque durante o seculo XIX. Na verdade, uma ano antes da pu-
blicacao do trabalho de Fourier, em 1821, Cauchy publica seu Curso de Analise
([32]), primeiro livro-texto em que a nova visao da analise se fez presente.
Nesta obra, sao estabelecidos criterios para a convergencia de series e defini-
dos os coeficientes da serie trigonometrica que pode representar uma funcao
qualquer, chamada serie de Fourier. Sobre o conceito de funcao, Cauchy ja
fornecia uma definicao analoga `a de Fourier, considerando que quantidades
variaveis podem ser relacionadas de modo que, dados valores para uma de-
las (chamada variavel independente), podemos obter os valores da outra, ou
seja, da funcao desta variavel independente. Apesar do carater geral desta de-
finicao, Cauchy pressupunha implicitamente funcoes definidas por expressoes
analticas.
O perodo que vai da primeira metade do seculo XVIII ate este trabalho
de Cauchy pode ser visto como uma epoca de exploracao de aplicacoes das
ferramentas do calculo na solucao de problemas fsicos, como o das cordas
vibrantes ou da propagacao do calor. Mas estes metodos empregam no-
vos conceitos teoricos, como os de funcao, continuidade e convergencia, que
precisam ser mais bem definidos. O conceito de funcao, por exemplo, era
visto primeiramente como uma expressao analtica dada por uma serie de
potencias. Mas, em outros momentos, tambem era identificado a uma curva
desenhada `a mao livre. Em seguida, com Fourier, passou a ser visto no-
vamente como uma expressao analtica, mas desta vez uma serie especfica,
trigonometrica. O conceito de funcao, que passava a ser o objeto central da
analise, necessitava, assim, de uma reformulacao teorica.
Lejeune-Dirichlet foi um dos primeiros a caracterizar o esprito crtico e
teorico que marcou a Matematica do seculo XIX, sobretudo na Alemanha.
Sua visao sobre o que deveria constituir uma prova matematica rigorosa
influenciou os matematicos da epoca e, em meados do seculo XIX, ele ja
era visto por seus contemporaneos como a expressao dos novos tempos e da
nova concepcao sobre o rigor, que transformaria definitivamente os padroes
herdados dos franceses.
Nos anos 1820, Dirichlet estudou em Paris. Assim, ele foi uma figura
central na transmissao da tradicao francesa em analise e em fsica matematica
para a Alemanha. Ele tambem estudou e divulgou os trabalhos de Gauss
sobre analise de Fourier, integracao e fsica matematica
254 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
Antes de tudo, era preciso dar uma consistencia aos trabalhos de Fourier,
que pareciam nao ser corretos mas eram frutferos. Os trabalhos iniciais de
Dirichlet sobre as series de Fourier nos interessam em particular, uma vez
que propoem uma nova definicao de funcao. Em 1829, ele tentou demonstrar
que as series de Fourier convergem.
Fourier queria mostrar que uma funcao arbitraria definida no intervalo
(l, l) pode ser sempre representada por uma serie contendo senos e cossenos:
f (x) = a0
2 +


n=1
[an cos nx
l + bnsen nx
l ]
em que os coeficientes an e bn sao dados por integrais que envolvem a funcao
f no intervalo (l, l).
Para convencer os matematicos da epoca de que isso era verdade, era pre-
ciso calcular os coeficientes an e bn das series acima. Fourier interpretou estes
coeficientes como areas sob o grafico de uma funcao dada por uma funcao tri-
gonometrica multiplicada por alguma outra funcao. Ou seja, ele estudava a
area delimitada pelo grafico de funcoes do tipo g(t) cos(nt) ou g(t)sen(nt).
Esta area podia ser calculada por uma integral. Mas obviamente, a area so
interessava no intervalo ao qual se referem os dados do problema, que e do
tipo (l, l). Logo, era preciso calcular a area, ou a integral, em um intervalo.
Um dos principais problemas tratados por Dirichlet diz respeito `as condi-
coes para que se possa calcular a integral de uma funcao. Ate este momento,
o calculo da integral era um problema pratico, pois, como as funcoes eram
expressoes analticas, as integrais eram calculadas em exemplos especficos.
Bastava ter um metodo algebrico eficiente e encontrar a expressao analtica
da integral, ou da area. Os matematicos do seculo XVIII nao estavam muito
preocupados com as condicoes de integrabilidade, ou seja, com as condicoes
que uma funcao deve satisfazer para poder ser integrada.
Dirichlet percebeu que nem toda funcao pode ser integrada e, em um
artigo publicado em 1829, da o seguinte exemplo:
f (x) = { 0 para x racional
1 para x irracional
Tratava-se do primeiro exemplo de funcao que nao pode ser dada por
uma, nem por varias expressoes analticas, nem pode ser desenhada `a mao
livre. Alem disso, ela nao pode ser representada por uma serie de Fourier,
nao e derivavel e e descontnua em todos os pontos.
Fica claro que estas consideracoes pressupunham um conceito de funcao
mais geral do que os usados anteriormente, logo era preciso discutir a nocao
que os matematicos tinham em mente ao colocar problemas deste tipo. Segu-
6.4. A DEFINIC AO DE UMA FUNC AO ARBITR ARIA 255
ramente, ja nao se tratava de conceber uma funcao a partir de sua expressao
analtica, mas qual sera a nova definicao?
Cauchy ja tinha empregado uma definicao conceitual de funcao, definindo
algumas propriedades, como a continuidade, de modo independente da ex-
pressao analtica que a representa. Mas o exemplo de Dirichlet e tido como
o primeiro passo para que se percebesse a necessidade de expandir a nocao
de funcao, uma vez que, neste caso, a funcao nao tem nenhuma das propri-
edades admitidas tacitamente como gerais: ela nao pode ser escrita como
uma expressao analtica (segundo Dirichlet); nao pode ser representada por
uma serie de potencias; e nao e contnua em nenhum ponto (alem do que
tambem nao e derivavel nem integravel). Logo, o exemplo de Dirichlet so
pode ser visto como uma funcao se este conceito for entendido como uma
relacao arbitraria entre variaveis numericas.
A teoria das series trigonometricas ja havia levado Fourier a afirmar que
uma funcao e dada por uma sequencia de valores arbitrarios das ordenadas.
Estas ordenadas se sucedem de um modo qualquer e independentemente
umas das outras, sem precisar obedecer a nenhuma lei comum. Dirichlet ira
desenvolver, mais detalhadamente, esta concepcao.
No primeiro artigo, de 1829, escrito em frances, o autor nao define o que e
uma funcao, mas discute problemas relacionados `a continuidade das funcoes
estudadas por Cauchy e Fourier. Uma versao revisada deste primeiro texto
foi publicada em alemao em 1837, contendo uma definicao bastante citada:
Sejam a e b dois numeros fixos e x uma quantidade variavel
que recebe sucessivamente todos os valores entre a e b. Se, a cada
x, corresponde um unico y finito de maneira que, quando x se
move continuamente no intervalo entre a e b, y = f (x) tambem
varia progressivamente, entao y e dita uma funcao contnua de x
neste intervalo. Para isto, nao e obrigatorio, em absoluto, nem
que y dependa de x de acordo com uma mesma e unica lei, nem
mesmo que seja representada por uma relacao expressa por meio
de operacoes matematicas (Dirichlet, [46], pp. 135-136).
Antes de tudo, observamos que esta definicao enfatiza o fato de que,
dadas duas quantidades variaveis x e y, para que y seja uma funcao de x,
nao e necessario que exista uma expressao algebrica associando esta variavel
a x. Alem disso, para que a funcao esteja bem determinada, y=f (x) deve
receber apenas um valor para cada x. A exigencia de que para cada x temos
somente um valor para y tambem esta presente na definicao conjuntista que
aprendemos na escola, mas a concepcao de Dirichlet e independente da nocao
de conjunto.
256 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
Esta definicao vislumbra uma funcao como uma relacao mais geral entre
duas variaveis, o que permite que Dirichlet enuncie as condicoes para que
ela possa ser representada por uma serie de Fourier em um intervalo (l, l).
Dentre elas, destacamos:
1. ser bem definida, ou seja, cada um dos valores da ordenada ser deter-
minado univocamente pelo valor da abscissa;
2. ter um numero finito de descontinuidades no intervalo (-l,l).
Apesar do que ele considerava como arbitrario ser mais um caso parti-
cular do que nos entendemos por este adjetivo, parecia importante, naquele
momento, afirmar a generalidade como forma de questionar a reducao da
pratica matematica ao escopo das expressoes analticas.
Estas expressoes, compostas por operacoes aritmeticas simples, foram,
durante muitos anos, o principal objeto de estudo da analise matematica,
sobretudo no seculo XVIII. Com o passar do tempo, outras propriedades
tornaram-se importantes de se destacar e classes de funcao foram introdu-
zidas, a partir de novos problemas, como as funcoes unvocas, contnuas,
descontnuas em pontos isolados, diferenciaveis e etc. Estas propriedades
eram independentes das possibilidades de se representar uma funcao anali-
ticamente. Esta e a principal diferenca entre a concepcao tpica da analise
matematica do seculo XVIII e da teoria das funcoes fundada no seculo XIX.
As propriedades das funcoes estudadas deixam de ser deduzidas das suas ex-
pressoes analticas e passam a definir, a priori, uma classe de funcoes a ser
considerada.
Nao queremos dizer, com isso, que a nocao de funcao defendida por Dirich-
let foi imediatamente incorporada pela Matematica da epoca. Sua definicao
so foi popularizada pelo tratado publicado por H. Hankel em 1870.
Uma nocao abstrata de funcao tambem sera empregada por Riemann, a
partir dos anos 1850. Ele propoe uma extensao do conceito de integral que
consolidara a definicao arbitraria de funcao, uma vez que seus estudos fazem
intervir, de modo sistematico, funcoes reais descontnuas. Riemann ira se
preocupar, portanto, em estabelecer uma teoria das funcoes a partir somente
de suas propriedades.
Veremos no final deste captulo que, apos a consideracao de funcoes
patologicas, ou de funcoes definidas em domnios mais amplos que o dos
numeros reais, o conceito de funcao passou a ser visto como um tipo especial
de relacao entre conjuntos. Esta visao foi reforcada com o surgimento da
teoria dos conjuntos e sua preocupacao em dar um tratamento axiomatico
`a Matematica. Com isto, uma variavel passou ser vista apenas como um
6.5. CAUCHY E A NOVA NOC AO DE RIGOR NA AN ALISE 257
elemento de um conjunto, `A nocao dinamica de funcao, herdada da fsica,
substitui-se uma nocao estatica.
6.5 Cauchy e a nova nocao de rigor na analise
A revolucao francesa modificou radicalmente o papel dos matematicos na
Franca e sua atuacao na sociedade. A criacao das Grandes Ecoles, nas
quais alguns dos melhores matematicos da epoca foram professores, intro-
duziu uma componente na atividade Matematica, o ensino, que teria con-
sequencias importantes para a evolucao da propria Matematica. Enquanto
os matematicos eram membros de academias cientficas, mantidos por gover-
nantes, geralmente por questao de prestgio, sua obrigacao era gerar novos
conhecimentos, comunicados frequentemente de maneira informal, por cartas,
por exemplo, a colegas matematicos. Quando o matematico e professor, com
a obrigacao de expor um campo da Matematica para principiantes, muitos
dos quais nao almejavam tornar-se matematicos mas sim engenheiros, ofici-
ais do exercito, etc, surge a necessidade de organizar e expor com clareza o
campo em questao. A partir desta epoca, muitos novos metodos e resultados
aparecem em primeiro lugar nos livros-texto que consistiam nas licoes dadas
nas Grandes Ecoles ou em universidades. Como professor da Ecole Polyte-
chnique, Lagrange publicou sua Theorie das Fonctions Analytiques, em 1798,
e Cauchy alguns anos mais tarde, em 1821, seu Cours danalyse algebrique.
Um dos fatores que impulsionaram a transformacao da analise na epoca e
o fato de que a grande maioria dos matematicos militantes estavam empenha-
dos no ensino, e portanto tinham que reorganizar didaticamente as teorias
matematicas. Isso significa isolar os princpios fundamentais da teoria (em
analise, o conceito de funcao, continuidade, limite, derivada, integral, etc.)
e destes conceitos deduzir o corpo da teoria. A partir desta epoca, tempos
os tratados escritos por matematicos franceses, como Lacroix, Lagrange e
Cauchy.
Nos ultimos anos do seculo XVIII, Laplace adquiriu grande poder na
cena francesa e passou a incentivar uma padronizacao do ensino na Escola
Politecnica, com base na analise e na mecanica. O curso de analise devia ser
divido em tres partes: analise pura (ou analise algebrica); calculo diferencial;
e calculo integral. A enfase no lado teorico do ensino e nos fundamentos foi
predominante durante a primeira decada do seculo XIX. Depois, a orientacao
da Ecole mudou radicalmente, passando a se voltar para a formacao de en-
genheiros. Foi decidido que era necessario remover do programa de ensino
todo o conhecimento que nao fosse essencial para a pratica profissional.
Cauchy assumiu a cadeira de analise na Escola Politecnica em 1816 e
258 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
tratou de reformar radicalmente o curso. A direcao nao ficou satisfeita de
incio, pois a abordagem escolhida por ele, por ser muito teorica, ia alem
das demandas de um curso de engenharia e gerava resistencia por parte dos
alunos. Depois da mudanca de orientacao, os professores deveriam introduzir
a analise de forma sucinta e conveniente para a mecanica, com enfase nas suas
aplicacoes. Como forma de resistencia, Cauchy decidiu escrever a serie de
aulas introdutorias que constituem o seu Cours danalyse algebrique. Esta
obra contem os fundamentos do tipo de ensino defendido por Cauchy que
nao segue o metodo dos antigos.
Este e o primeiro livro-texto no qual a nova visao da analise se fez pre-
sente. Os metodos empregados em problemas fsicos, como o das cordas
vibrantes ou da propagacao do calor, faziam uso de novos conceitos, como
os de funcao, continuidade e convergencia, que demandavam definicoes mais
precisas. Por exemplo, a obra de Cauchy estabelece criterios para a con-
vergencia de series e define os coeficientes da serie trigonometrica que pode
representar uma funcao qualquer, ja denominada na epoca serie de Fourier.
Uma das caractersticas mais importantes do movimento que se inicia
com Cauchy e a conscientizacao, por parte dos matematicos, de que so po-
deriam ser usadas propriedades que tivessem sido explicitamente definidas.
Ou seja, a definicao de funcao, bem como sua propriedade de continuidade,
por exemplo, nao deviam ser pressupostas implicitamente, mas definidas ex-
plicitamente. A nocao de funcao sera entao definida antes das nocoes de
continuidade, limite e derivada.
Os trabalhos anteriores sobre as series de Fourier traziam o problema de
se conhecer o comportamento de uma funcao definida como a soma de uma
serie de funcoes. Por exemplo, se estas funcoes forem contnuas em um ponto,
acontecera o mesmo com a soma da serie naquele ponto? Antes de Cauchy,
nao se formulava a questao de definir com exatidao o que e continuidade de
uma funcao. As conceituacoes apresentadas se baseavam na percepcao visual
e intuitiva.
A preocupacao com o rigor de Cauchy era expressa pelo cuidado de defi-
nir, sempre que possvel, o domnio de validade de uma definicao ou de um
teorema. Esta motivacao o levou a introduzir as novas nocoes de convergencia
de series e de continuidade, bem como a fornecer provas de existencia, como
a de somas de series e das solucoes de equacoes diferenciais. Foi justamente
a arquitetura proposta por Cauchy, vista em seu conjunto, mais do que o
modo de definir este ou aquele conceito, ou de demonstrar este ou aquele
teorema, que funcionou como um divisor de aguas na historia da analise.
O rigor matematico e em si mesmo um conceito historico e, portanto, em
transformacao. Os matematicos do seculo XVIII eram rigorosos de acordo
com os padroes do seu tempo. Mas, segundo Grabiner ([71]), quando um
6.5. CAUCHY E A NOVA NOC AO DE RIGOR NA AN ALISE 259
matematico do seculo XIX pensava em rigor na analise, ele tinha tres coisas
em mente:
1. todo conceito teria que ser definido explicitamente em termos de outros
conceitos cujas naturezas fossem firmemente conhecidas;
2. os teoremas teriam que ser provados e cada passo deveria ser justificado
por outro resultado admitido como valido;
3. as definicoes escolhidas e os teoremas provados teriam que ser suficien-
temente amplos para servir de base `a estrutura de resultados validos
pertencentes.
O conteudo matematico do Cours danalyse se inicia com uma revisao
dos diversos tipos de numero. Mas, da mesma maneira que os demais ma-
tematicos de sua epoca, Cauchy admitia como certo, ou como dado, o que,
entao, era aceito, sem precisao, sobre os numeros reais. Cauchy definia funcao
a partir da distincao entre variaveis independentes e dependentes. Duas
quantidades variaveis podem ser relacionadas de modo que, dados valores
para uma delas, podemos obter os valores da outra, que sera a funcao:
Quando quantidades variave-s sao ligadas de modo que, quan-
do o valor de uma delas e dado, pode-se inferir os valores das ou-
tras, concebemos ordinariamente estas varias quantidades como
expressas por meio de uma delas que recebe, portanto, o nome
de variavel independente; e as outras quantidades, expressas
por meio da variavel independente, sao as que chamamos funcoes
desta variavel. (Cauchy, [32], p.19)
Apesar do carater geral desta definicao, os comentarios subsequentes mos-
tram que Cauchy tinha em mente exemplos particulares de funcoes. Ele clas-
sifica as funcoes em simples e mistas. As simples sao: a + x, a  x, ax, a/x,
xa, ax, log x, sen x, cos x, arcsen x, arccos x. As mistas sao compostas das
simples, como log(cos x).
Apesar de nao considerar o que designaramos hoje como funcoes ar-
bitrarias, e admitir implicitamente as funcoes como associadas `as curvas que
as representam, o universo das funcoes tratadas por Cauchy e bem mais am-
plo do que o do seculo XVIII. Ele fornece um exemplo para criticar a definicao
de funcao descontnua de Euler, mostrando que a funcao descontnua
y = { x, x  0
x, x < 0
260 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
pode ser representada pela unica equacao
y = x2,  < x < +
Logo, ela seria tambem contnua, no sentido de Euler. Isto mostra que nao
faz sentido classificar funcoes contnuas e descontnuas pela unicidade de sua
expressao analtica, como era feito no seculo XVIII.
Alem disso, Cauchy fornece exemplos de funcoes nao analticas, como
f (x) = e 1
x2 , que nao pode ser escrita como uma serie de Taylor, contradi-
zendo o pressuposto de Lagrange, que afirmava que todas as funcoes podiam
ser expressas por uma serie deste tipo.
Sera preciso definir, de modo novo, o que e uma funcao contnua:
Seja f (x) uma funcao da variavel x e suponhamos que, para
cada valor de x entre dois limites (cotas) dados, esta funcao ad-
mite sempre um valor finito bem determinado. Se, partindo de
um valor de x situado entre estes limites, dermos `a variavel x um
acrescimo infinitamente pequeno, a funcao sofrera um acrescimo
dado pela diferenca
f (x + )  f (x)
que dependera ao mesmo tempo da nova variavel  e do valor de
x. Posto isso, a funcao f (x) sera, entre os dois limites da variavel
x, uma funcao contnua desta variavel, se, para cada valor de x
intermediario entre estes limites, o valor numerico da diferenca
f (x + )  f (x)
diminui indefinidamente com o de  (Cauchy, [32], p. 34).
Feito isso, Cauchy reformula esta definicao em termos de infinitesimos,
apos o que define derivada e integral.
No Cours danalyse tambem se encontra a primeira apresentacao abran-
gente dos numeros complexos. Nele, Cauchy trata nao somente das propri-
edades algebricas mas tambem do que significa falar de limites no conjunto
dos numeros complexos. Ele define continuidade de funcoes f  C  C, suas
derivadas e integrais. Para lidar com limites, Cauchy utiliza o conceito de
modulo de um numero complexo (Se z = a + b i  C, seu modulo, z e definido
por z = a2 + b2).
Exerccios
6.5. CAUCHY E A NOVA NOC AO DE RIGOR NA AN ALISE 261
6.5. Dentre as inumeras contribuicoes de Cauchy `a Matematica temos a
seguinte maneira de construir o corpo dos numeros complexos.
1. Considere o anel R[x], dos polinomios de uma variavel e coefici-
entes reais.
Seja o ideal de R[x] gerado pelo polinomio x2 + 1. Prove que o
anel quociente
R[x]
(x2 + 1)
e um corpo, que sera representado por C.
2. Se p(x)  R[x], a classe de equivalencia de p(x) sera sera represen-
tada por p(x). Prove que podemos escolher, para representante de
cada classe de equivalencia, um unico polinomio da forma a + bx.
A classe a + bx sera denotada por a + b i:
a + b i = a + bx.
3. Prove que i2 = 1
4. Prove que o corpo dos numeros reais e um subcorpo de C, por
meio da correspondencia
y  y + 0 i, y  R.
6.6. Sejam U  R, uma funcao f  U  R e x0  U.
1. De uma definicao, com nosso simbolismo moderno, de continui-
dade da funcao f no ponto x0.
2. Defina a continuidade de f em seu domnio U.
3. Defina a continuidade uniforme de f em U.
4. Na pagina 260 encontra-se a definicao de Cauchy para o conceito
de continuidade de uma funcao. Traduza-a para nossa linguagem
simbolica atual.
5. Cauchy definiu continuidade ou continuidade uniforme?
6.7. Sejam V um subconjunto dos numeros complexos, f  C  C uma
funcao e z0  V . Defina a continuidade de f no ponto z0.
262 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
6.6 Funcoes e numeros reais: Dedekind e Cantor
Como vimos, Dirichlet havia mostrado que, para resolver o problema da
convergencia das series de Fourier, e preciso investigar, em primeiro lugar,
quando uma funcao e integravel em certo intervalo. Cauchy tinha tentado
esclarecer o significado da integracao e as condicoes que propos serao aper-
feicoadas por Dirichlet (e mais tarde por Riemann).
Intuitivamente, se concebemos a integral como a area sob o grafico de uma
funcao, nao e difcil entender que a estranha funcao proposta por Dirichlet
nao possui integral, no sentido classico. Sendo descontnua em todos os
pontos, ela nao pode definir uma area.
Na verdade, este exemplo foi fornecido, nos ultimos paragrafos do artigo
de 1829, a fim de mostrar que as condicoes para que uma funcao pudesse ser
integrada deviam ser definidas de modo mais preciso. Fourier ja havia notado
que, se queremos integrar uma funcao, seus valores em certo intervalo devem
ser atuais e bem determinados, ou seja, o valor da funcao nao pode ser
infinito em nenhum ponto. Dirichlet acrescenta que, ainda que tenha valores
finitos, a funcao tambem nao pode ser descontnua, como no caso extremo
do exemplo.
A partir da segunda metade do seculo XIX proliferarao exemplos de
funcoes patologicas, sobretudo na segunda metade do seculo XIX, que levam
`a percepcao da necessidade de se expandir a definicao de funcao. Um exem-
plo famoso destes monstros, como diziam alguns matematicos da epoca, e
a funcao construda por Weierstrass, que desafiava o senso comum da epoca.
Por volta de 1860, Weierstrass adotava uma definicao semelhante `a de
Dirichlet, mas, em 1872, apresentou `a Academia de Ciencias de Berlim um
exemplo de funcao contnua, mas que nao e derivavel em nenhum ponto.
Este tipo de funcao contraria nossa intuicao geometrica de que uma funcao
tracada continuamente, por um desenho `a mao livre, deve ser suave, salvo
em pontos excepcionais, ou seja, ela nao pode ter bicos em absolutamente
todos os seus pontos.
Diversos exemplos contra-intuitivos surgiram na epoca. Riemann foi res-
ponsavel por alguns deles, em seu estudo da integracao; a investigacao das
series trigonometricas tambem deu origem a funcoes estranhas, como a pro-
posta por du Bois-Reymond (que e continua mas nao pode ser desenvol-
vida em serie de Fourier); Hankel e Darboux construram outras funcoes
patologicas e investigaram suas propriedades.
Antes, as funcoes surgiam de problemas concretos, como os de natureza
fsica, mas agora elas surgiam do interior da Matematica, em seus esforcos
para delimitar os novos conceitos que vinham sendo forjados, e que deviam
servir de fundamento para a analise, como os de funcao, continuidade e dife-
6.6. FUNC OES E N UMEROS REAIS 263
renciabilidade. Esta autonomia sinaliza a tendencia crescente de se estabe-
lecer as definicoes sobre bases abstratas, independentes da intuicao sensvel
e da percepcao geometrica.
Na funcao de Dirichlet, fica claro que sua plena compreensao depende
do modo como os racionais e irracionais estao distribudos sobre o eixo das
abscissas, ou seja, sobre a reta numerica. As pesquisas sobre convergencia
que se seguiram ao estudo das series de Fourier estabeleciam condicoes que
tambem se baseavam na distribuicao dos pontos sobre uma reta.
Na verdade, em meados do seculo XIX, diversos problemas matematicos
conduziam a um questionamento sobre o que e um numero real, e como os
racionais e irracionais se distribuem na reta. O estudo da convergencia de
series e o uso dos limites motivavam a analise dos numeros para os quais
as series convergem: como estes numeros se distribuem na reta, como uma
sequencia de numeros tende para numeros de outro tipo, que outras especies
de numeros podem surgir, etc. . .
Antes deste momento, supunha-se, de modo geral, que a reta continha
todos os numeros reais, e nao havia preocupacao de se definir este tipo de
numero. Um exemplo disso foi visto acima, no estudo das razes de uma
equacao de grau mpar, ao se admitir que o grafico de uma funcao, positiva
(para x positivo) e negativa (para x negativo), deve cortar o eixo das abscissas
em um ponto que e assumido como um numero real.
A partir de 1870, Cantor ira se debrucar sobre o problema das series
de Fourier, investigando quando a serie trigonometrica que representa uma
funcao e unica. Ele mostra que isto acontece se a serie e convergente para
todos os valores de x. Mas, em seguida, esta exigencia e enfraquecida e, na
busca de condicoes menos rgidas, conclui que a unicidade tambem pode ser
verificada quando a serie trigonometrica deixa de ser convergente, ou deixa
de representar a funcao, em um numero finito de pontos excepcionais. Logo
depois, Cantor refina o argumento, percebendo que sua conclusao ainda e
valida se o numero destes pontos excepcionais e infinito, contanto que eles
estejam distribudos sobre a reta de um modo especfico. Para estudar esta
distribuicao dos pontos, era necessario descrever os numeros reais de um
modo mais meticuloso e detalhado, sem supor implicitamente, e de modo
vago, que estes numeros eram dados pelos pontos da reta. Nao entraremos
nos detalhes do problema, pois queremos destacar somente a conexao entre
o estudo das series trigonometricas e a conceitualizacao dos numeros reais.
O trabalho de Cantor sobre este assunto foi publicado em 1872, mas
Dedekind ja vinha refletindo sobre os numeros reais e sobre a necessidade de
estuda-los mais a fundo. Em um trabalho publicado em 1872 ([41]), fazendo
referencia a reflexoes anteriores, este ultimo afirma que:
264 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
Discutindo a nocao de aproximacao de uma quantidade va-
riavel em direcao a um valor limite fixo (. . . ) recorri a evidencias
geometricas (. . . ) E tao frequente a afirmacao de que o calculo di-
ferencial lida com quantidades contnuas, e uma explicacao desta
continuidade ainda nao e dada (Dedekind, [41], pp.1-2).
A fim de caracterizar a continuidade, Dedekind julgava necessario inves-
tigar suas origens aritmeticas. Foi o estudo aritmetico da continuidade que
levou `a proposicao dos chamados cortes de Dedekind. Ele comecou por es-
tudar as relacoes de ordem no conjunto dos numeros racionais, explicitando
verdades tidas como obvias, por exemplo: se a>b e b>c entao a>c. A partir
da, ele deduziu propriedades menos evidentes, como a de que ha infinitos
numeros racionais entre dois racionais distintos a e c. Dedekind nota que
um racional a qualquer divide os numeros racionais em duas classes A1 e
A2, a primeira contendo os numeros menores que a, e a segunda contendo os
numeros maiores que a. Podemos concluir, assim, que qualquer numero em
A1 e menor do que um numero em A2.
Comparando os racionais aos pontos da reta, ele observou que existem
mais pontos na reta do que os que podem ser representados como numeros
racionais. Mas como definir estes numeros? A argumentacao de Dedekind
recorre aos gregos, afirmando que eles ja sabiam da existencia de grandezas
incomensuraveis. Mas nao e possvel usar a reta para definir os numeros
aritmeticamente, pois os conceitos matematicos nao devem ser estabelecidos
com base na intuicao geometrica. Logo, era necessaria a criacao de novos
numeros tal que o domnio descontnuo dos numeros racionais, Q, possa
ser tornado completo para formar um domnio contnuo, como era o caso
da linha reta (Dedekind, [41], p. 6). A palavra usada para designar a pro-
priedade da reta que distingue os reais dos racionais e continuidade, que
seria equivalente ao que chamamos de completude. Apesar de Dedekind
afirmar que e preciso completar os racionais, este termo nao e empregado
em sentido tecnico.
Ate este momento, a continuidade dos reais nao era justificada porque
nao era demandada explicitamente, ou seja, tratava-se de uma pressuposicao
implcita dos matematicos. A elaboracao de uma teoria aritmetica da reta,
associada a um contnuo numerico, sera iniciada somente no seculo XIX, com
Dedekind. Isto nao quer dizer que os matematicos anteriores falhassem, ou
fossem negligentes em relacao rigor. Simplesmente a continuidade era um
dado, e nao um problema.
Dedekind expoe a questao em uma correspondencia com Lipschitz, em
1876, afirmando que a continuidade do domnio das quantidades era uma
pressuposicao implcita dos matematicos, alem da nocao de quantidade nao
6.6. FUNC OES E N UMEROS REAIS 265
ser definida de modo preciso. Ate ali, os objetos da Matematica, as quan-
tidades, existiam, e a necessidade de definir sua existencia nao se colocava.
Ao contrario destas suposicoes, no texto publicado em 1888, ele insiste que
o fenomeno do corte, em sua pureza logica, nao tem nenhuma semelhanca
com a admissao da existencia de quantidades mensuraveis, uma nocao que
ele rejeita veementemente (Dedekind, [42]).
A construcao dos reais sera feita a partir dos racionais, considerados como
dados. para definir estes novos numeros, Dedekind propos transferir para o
domnio dos numeros a propriedade que traduz, segundo ele, a essencia da
continuidade da reta: o fato de que todos os pontos da reta estao em uma de
duas classes, de modo que, se todo ponto da primeira classe esta `a esquerda
de todo ponto da segunda classe, entao existe apenas um ponto que produz
esta divisao.
Como os racionais podem ser representados na reta numerica, o ponto
que divide os racionais em duas classes A1 e A2 sera chamado um corte
dos racionais. Todo numero racional a determina um corte deste tipo, tal
que a e o maior numero em A1, ou o menor em A2. Mas nao ha somente
cortes racionais.
Ilustracao da completude da reta
Exemplo 1 (corte racional): Definimos o conjunto A2 contendo
os racionais menores que 1 (A2 = {q  Qq < 1}) e A1 contendo
os outros racionais, ou seja, A1 = Q  A2. O numero que produz
o corte e o racional 1, neste caso temos o exemplo de um corte
racional.
Ilustracao da completude da reta
Exemplo 2 (corte irracional): Definimos A2 contendo os racionais
positivos cujo quadrado e maior que 2, e A1 contendo os outros
racionais, ou seja:
A2 = {q  Qq2 > 2}  {q  Qq > 0} e A1 = Q  A2.
O numero que produz o corte nao e racional, pois deve ser um
numero cujo quadrado e 2, ou seja, 2. Reside justamente nesta
propriedade a incompletude, ou a descontinuidade, dos racionais.
A Figura 6.3 mostra alguns elementos de A1 e A2 para este segundo
exemplo.
266 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
Ponto que produz o corte
Alguns elementos de WAlguns elementos de Z
7/4
k
3/2 21/2 1-1/2 0-1
Figura 6.3
Para obter um conjunto numerico que traduza fielmente a continuidade
da reta, Dedekind usa um procedimento que se tornara muito frequente em
Matematica. Sempre que encontrarmos um numero nao racional produzindo
um corte, deveremos incluir este numero na nova categoria a ser criada, que
deve incluir racionais e nao racionais. Ou seja, quando o corte e um numero
irracional, este numero sera reunido aos racionais formando um conjunto,
que gozara da propriedade de continuidade da reta, chamado conjunto dos
numeros reais. Com esta operacao, este conjunto nao sera mais admitido
como dado, mas definido de modo preciso.
Os estudos de Cantor e Dedekind sobre o conjunto dos numeros re-
ais darao origem a uma multiplicidade de novas perguntas envolvendo os
seus subconjuntos. Por exemplo: Ha mais numeros racionais ou irracionais?
Como enumerar estes numeros?
No estudo da representacao de uma funcao qualquer por uma serie tri-
gonometrica, Cantor ja admitia que esta serie pudesse ser descontnua em
infinitos pontos, contanto que estes pontos se comportassem de um modo es-
pecfico. Este modo especfico esta relacionado justamente `a continuidade
dos reais.
E possvel que um conjunto infinito de pontos, como os racionais, nao
complete a reta. A principal propriedade dos numeros racionais, que os torna
essencialmente distintos dos reais, e o fato de eles poderem ser enumerados.
O que e isso? Eles sao pontos discretos, nao imbricados entre si, logo podemos
associa-los a numeros naturais e conta-los. O resultado desta contagem sera
um numero infinito, mas ela permite enumerar os racionais.
Esta propriedade levara Cantor a concluir que o conjunto dos numeros
racionais e infinito de uma maneira distinta do conjunto dos numeros reais,
que nao podem ser enumerados. Este procedimento de enumeracao dos
elementos de um conjunto e feita por meio da associacao de cada um des-
tes elementos a um numero natural. Esta associacao e definida como uma
6.6. FUNC OES E N UMEROS REAIS 267
funcao de um conjunto no outro, uma correspondencia biunvoca entre seus
elementos.
Neste contexto surgira a ideia de funcao como uma correspondencia en-
tre dois conjuntos numericos. Se x e um elemento do conjunto dos reais,
e n um elemento do conjunto dos naturais, pode ser estabelecida uma cor-
respondencia entre x e n, de modo que cada elemento de um conjunto seja
associado a um e somente um elemento do outro?
Esta e a pergunta que Cantor formula para Dedekind em 1873. Ele mesmo
provou que e impossvel encontrar uma tal correspondencia, o que estabeleceu
uma diferenca fundamental entre o numero de elementos (cardinalidade) do
conjunto de numeros reais e o numero de elementos do conjunto dos numeros
naturais.
O conceito de correspondencia biunvoca servira de base para a cons-
tituicao da nova teoria dos conjuntos, por volta de 1879. Dois conjuntos
tem a mesma potencia se existe uma correspondencia biunvoca entre seus
elementos. Os conjuntos que possuem a mesma potencia dos naturais sao
chamados enumeraveis, e os outros sao nao enumeraveis. A resposta ao
criterio para que uma serie trigonometrica represente uma funcao, fornecida
por Cantor, repousa sobre esta diferenciacao, e esta resposta e afirmativa
no caso de a serie deixar de convergir em infinitos pontos, contanto que eles
formem um subconjunto enumeravel da reta.
Dedekind dara os proximos passos no desenvolvimento da teoria dos con-
juntos, ao propor a caracterizacao dos naturais e racionais em termos de
conjuntos. Para ele, os numeros naturais formam um conjunto de coisas
ou objetos de pensamento. Acontece, frequentemente, que, por alguma
razao, coisas distintas a, b, c, . . . podem ser entendidas a partir de um mesmo
ponto de vista. E o caso dos numeros: coisas distintas sao entendidas sob um
mesmo ponto de vista quando consideradas a partir de seus numeros. Neste
caso, podemos dizer que estas coisas formam um conjunto. Em seguida, De-
dekind enuncia as relacoes basicas envolvendo conjuntos, que se tratam das
nocoes que conhecemos hoje de subconjunto, uniao e intersecao.
A partir dos anos 1880, Dedekind e outros matematicos, como Frege
e Peano, propuseram construcoes do conjunto dos naturais, com as quais
provaram suas principais propriedades. Cantor e Dedekind ja tinham ca-
racterizado os reais e seus trabalhos, juntamente com as contribuicoes de
Weierstrass, foram responsaveis por fundar a analise sobre novas bases.
Exerccios
6.8. Para provar que o conjunto dos numeros reais nao e enumeravel, Cantor
introduziu seu famoso processo de diagonalizacao, um novo metodo de
demonstracao.
268 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
Suponha que o conjunto R e enumeravel. Entao, seus elementos podem
ser postos em correspondencia biunvoca com os numeros naturais, e
podemos escrever que
R = {x1, x2, x3, . . . , xn, . . .}.
Escrevamos desenvolvimentos dos elementos de R no sistema de nu-
meracao decimal:
x1 = p1, a1,1a1,2a1,3a1,4 . . . a1,n . . .
x2 = p2, a2,1a2,2a2,3a2,4 . . . a2,n . . .
x3 = p3, a3,1a3,2a3,3a3,4 . . . a3,n . . .
. . .
xn = pn, an,1an,2an,3an,4 . . . an,n . . .
. . .
Nestas representacoes, o numero pi e a parte inteira de xi.
Considere agora o numero x dado pelo seguinte desenvolvimento deci-
mal
x = 0, b1b2b3bn,
no qual os bi sao definidos como segue:
i, bi = ai,i.
Ora, este numero e diferente de cada xi, e portanto nao pode constar da
lista x1, x2, x3, . . . , xn, . . ., o que e uma contradicao, pois supusemos
que todos os numeros reais constam da lista.
Prove que realmente o numero x e diferente de cada xi.
6.6. FUNC OES E N UMEROS REAIS 269
6.9. Os cortes de Dedekind nao sao a unica maneira de tornar rigoroso o
conceito de numero irracional. O matematico frances Charles Meray,
em 1872, em um livro de calculo infinitesimal para o ensino, entitulado
Nouveau precis danalyse infinitesimale, construiu os irracionais como se-
gue. 3
Definicao: Uma sucessao x1, x2, . . . , xn, . . . de numeros racionais e de
Cauchy se, para todo > 0, existe N tal que
r, s > N, xr  xs < .
Seja M o conjunto de todas as sequencias de numeros racionais que sao
de Cauchy.
Introduza a seguinte relacao em M:
Se (xi)iN e (yi)iN sao elementos de M, dizemos que eles sao equivalentes
[(xi)iN  (yi)iN] se e somente se para todo > 0, existeN tal que
r, s > N, xr  ys < .
1. Prove que a relacao  definida acima e uma relacao de equiva-
lencia.
A classe de equivalencia da sucessao (xi)iN sera representada por
x. O quociente M/  sera representado por M.
2. Defina x + y = (xi + yi) e x  y = xi  yi. Prove que estas operacoes
estao bem definidas em M (isto e, seus resultados independem dos
representantes de classes escolhidos).
3. Seja Q o campo dos numeros racionais, isto e, o conjunto dos
numeros racionais com as operacoes e a relacao de ordem usuais.
Prove que Q  M.
4. Mostre que a relacao de ordem < em Q pode ser estendida, de
maneira natural, a uma relacao de ordem em M.
5. Prove que, com as operacoes e a relacao de ordem definidas acima
M e um corpo ordenado.
6. Prove que qualquer sucessao de Cauchy em Q, interpretada como
uma sucessao de elementos de M tem um limite. Ou seja, M e um
corpo ordenado completo.
3Na exposicao a seguir, modernisamos o metodo seguido por Meray para facilitar seu
entendimento.
270 CAPITULO 6. FUNC OES, N UMEROS REAIS E COMPLEXOS
O conjunto dos numeros reais R e, por definicao, o conjunto M
com as operacoes de soma e produto e a relacao de ordem definidas
acima.
Assim, os numeros irracionais podem ser definidos como classes de equi-
valencia de sucessoes de Cauchy com elementos em Q.
6.10. Normalmente, nos referimos ao conjunto dos numeros reais, sem
explicitar que muito mais esta envolvido: R e um corpo ordenado com-
pleto, isto e,
 R e um corpo.
 Existe em R uma relacao de ordem, <, compatvel com as opera-
coes de corpo.
 Toda sequencia de Cauchy de elementos de R converge para um
elemento de R.
Assim, nao e suficiente definir os numeros irracionais como cortes de
Dedekind. E necessario definir a adicao e o produto de cortes e uma
relacao de ordem entre cortes, compatvel com as operacoes definidas.
Dados dois cortes de Peano, c1 e c2, defina c1 + c2 e c1  c2. Defina
uma relacao de ordem entre cortes e prove que ela e compatvel com as
operacoes definidas.
Agradecimentos
Agradeço a este livro pela compreensão por tantas horas em que não o
escrevi porque estava dedicado à minha família.
Biografia do Autor
Raul Sidnei Wazlawick é professor associado II da Universidade Federal
de Santa Catarina (UFSC), lotado no Departamento de Informática e
Estatística. Graduado em Ciência da Computação, UFSC, 1988. Mestre em
Ciência da Computação, UFRGS, 1991. Doutor em Engenharia de
Produção, UFSC, 1993. Pós-doutorado pela Universidade Nova de Lisboa
(UNL), 1998.
Conselheiro da Sociedade Brasileira de Computação (SBC). Exmembro
da Comissão de Especialistas de Ensino de Computação e Informática do
Ministério da Educação (MEC). Ex-representante do Brasil na International
Federation for Information Processing (IFIP). Ex-coordenador do IFIP
Working Group on Higher Education (WG 3.2). Ex-coordenador do Curso
de Bacharelado em Ciência da Computação, UFSC. Ex-coordenador do
Programa de Pós-Graduação em Ciência da Computação, UFSC. Ex-
coordenador de vários cursos de pós-graduação lato sensu da UFSC. Ex-
membro da Câmara de Pesquisa da UFSC. Criador e ex-editor da Revista
Brasileira de Informática na Educação da SBC.
Coordenou vários eventos científicos no Brasil e no exterior, incluindo o
Congresso da SBC (2002). Foi presidente de comitês de programa de
eventos científicos no Brasil e exterior. Membro de comitê de programa de
dezenas de eventos científicos. Membro de comitê de revisores de
periódicos científicos. Orientador de dezenas de dissertações de mestrado,
teses de doutorado, monografias de especialização e trabalhos de conclusão
de cursos de graduação. Membro de mais de uma centena de bancas de
mestrado, doutorado, especialização e graduação em várias universidades
brasileiras. Conta com quase uma centena de publicações em periódicos e
eventos científicos e é autor do livro Análise e Projeto de Sistemas de
Informação Orientados a Objetos, de 2004, pertencente à série didática
Campus/SBC. Coordenador de vários projetos de pesquisa na UFSC e
interinstitucionais, com intensa atividade de consultoria em Engenharia de
Software. Não é pesquisador do CNPq.
Entre outras disciplinas, leciona Metodologia da Pesquisa em Ciência da
Computação, no Programa de Pós-Graduação em Ciência da Computação,
trimestralmente, desde 2003, de onde partiu a inspiração para escrever este
livro.
Prefácio do Autor
Este livro se destina principalmente aos alunos de cursos de ciência da
computação, seja na graduação, especialização, mestrado ou doutorado, que
vão realizar um trabalho científico escrito na forma de uma monografia,
dissertação ou tese.
Aqueles que, como eu, se sentiram perdidos durante seu curso em relação
ao que é o trabalho de pesquisa em ciência da computação poderão
encontrar algumas informações valiosas neste livro e, portanto, diminuir um
pouco a tensão da tese, ou seja, a sensação de angústia que quase
invariavelmente atinge os alunos que precisam escrever um trabalho
científico.
O aluno de computação que tenha lido livros de metodologia científica de
outras áreas já deve ter percebido que nem sempre os autores falam a
linguagem que nós entendemos. Nem sempre os métodos de pesquisa de
outras áreas se aplicam à computação, devido às características especiais
dessa ciência, que permeia praticamente todas as outras atividades
humanas.
Este livro, então, procura apresentar conceitos de ciência que sejam
compreensíveis ao aluno de computação. Em especial são apresentadas
histórias informativas e dicas baseadas na experiência do autor em cerca de
20 anos de orientação e elaboração de trabalhos científicos.
Fica ainda um agradecimento especial ao meu colega Pedro Alberto
Barbetta pelas sugestões dadas à Seção 3.4.
Praia dos Ingleses, Florianópolis, 6 de fevereiro de 2009
(um belo dia de sol).
C A P Í T U L O 1
Introdução
Era uma vez um aluno de mestrado que queria fazer uma monografia.1 Ele
pensou um pouco sobre o assunto, olhou ao redor e resolveu que havia um
problema relevante em sua cidade que ele poderia resolver durante seu
mestrado.
O problema era o seguinte: havia um rio cortando a cidade ao meio e não
havia forma segura de atravessá-lo.
Disposto a resolver o problema, o aluno conseguiu convencer seu
orientador de que teriam material para uma monografia, e começou a
trabalhar. Primeiramente, estudou tudo o que podia sobre rios. À medida
que estudava, foi escrevendo um capítulo de revisão bibliográfica. Escreveu
sobre água, citou a criação dos oceanos de acordo com o Gênesis, escreveu
sobre a molécula de água e seus componentes, o hidrogênio e o oxigênio,
sobre as diferentes maneiras como os rios desembocam no oceano
(incluindo um estudo detalhado sobre os mais importantes deltas do mundo
e sua história) e finalmente concluiu com um pequeno tratado sobre a
maneira como a gravidade atrai as moléculas de água para o centro da terra,
produzindo assim a correnteza dos rios.
Encerrada essa parte da pesquisa, o aluno deparou-se com o problema em
si, que era a inexistência de um meio para cruzar o rio. Pensando um pouco
sobre o assunto, ele se lembrou de um instrumento sobre o qual já tinha
ouvido falar e que servia para levar objetos de um ponto A para um ponto B.
Esse instrumento era a catapulta.
Escolhida a ferramenta de trabalho, o aluno passou a planejar os
experimentos. Inicialmente transportou 100 indivíduos de um lado ao outro
do rio usando a catapulta. Desses indivíduos, 95 não sobreviveram ao
experimento. O aluno concluiu que a eficácia do instrumento era, portanto,
de apenas 5%, e que haveria grandes possibilidades de melhoria. Portanto, o
tema era promissor.
Como segundo experimento, o aluno entregou um paraquedas a cada uma
de suas cobaias, e fez o teste com mais 100 indivíduos. Observou então o
seguinte: cerca de 20% dos indivíduos se assustavam durante a travessia e
abriam o paraquedas antes da hora, caindo dentro do rio e sendo arrastados
pela correnteza; cerca de 30% dos indivíduos se assustavam durante a
travessia e esqueciam-se de abrir o paraquedas, sofrendo as consequências
da queda na outra margem. Habilmente, o aluno concluiu que houve uma
melhora no experimento, pois o índice de sucesso passou de 5% para
aproximadamente 50%, o que é uma melhora substancial.
Não satisfeito, o aluno resolveu testar outra abordagem para melhorar o
sistema. Eliminou o uso do paraquedas, que causava pelo menos 20% de
perda sobre o rio, e instalou um colchão de ar na margem oposta. Realizou
um novo teste com mais indivíduos e verificou que 95% das vezes os
indivíduos sobreviviam à travessia, sendo que apenas 5% dos casos
aterrissaram fora do colchão de ar.
Nesse momento, já satisfeito com os resultados, o aluno encerrou os
experimentos (até porque estava ficando difícil encontrar voluntários).
Como trabalho futuro ele já havia pensado em propor um algoritmo de
cálculo da velocidade da catapulta baseado no peso do passageiro e no seu
índice de pânico, com vistas a diminuir ainda mais a taxa de erro observada.
Ele não ia programar esse algoritmo porque não teria tempo. Então, deixou
isso como trabalho futuro para outro fazer. Escreveu, portanto, o capítulo do
desenvolvimento e entregou o texto para o orientador, sendo que só faltava
escrever as conclusões e o resumo.
O aluno foi reprovado.
Por incrível que pareça, exageros à parte, a história contada corresponde
à história de muitas dissertações de mestrado em Ciência da Computação.
Ao longo deste livro se tentará mostrar por que o aluno foi reprovado.
Apesar de seu trabalho ter ares de ciência, ele pecou em vários aspectos
no que concerne ao seu comportamento e à metodologia científica. Apenas
para citar alguns:
a) Desde o momento da definição do tema até a conclusão dos
experimentos, ele não voltou a entrar em contato com seu orientador,
que poderia tê-lo redirecionado.
b) Não realizou uma revisão bibliográfica adequada, pois estudou muita
coisa sobre rios, mas não sobre as formas que já existiam para cruzá-los,
como, por exemplo, pontes, barcos, teleféricos etc. Por ter feito uma
revisão bibliográfica inadequada, ele concluiu, erroneamente, que era a
primeira pessoa no mundo a tentar resolver esse tipo de problema.
c) Ele escolheu uma ferramenta a priori e começou a trabalhar com ela
sem uma justificativa adequada para ter eliminado outras ferramentas
candidatas.
d) Seus resultados consistem na comparação do seu trabalho com o seu
próprio trabalho, ou seja, não há comparação com trabalhos correlatos
de outros autores.
e) O aluno escolheu como problema-alvo algo que ele observou apenas na
sua cidade. Problemas locais nem sempre são problemas para todo
mundo. Soluções locais nem sempre podem ser generalizadas.
Este livro tem como objetivo apresentar aos estudantes de Ciência da
Computação e áreas correlatas teoria e técnicas para a execução de bons
trabalhos científicos, no nível de exigência adequado aos cursos de
graduação, especialização, mestrado e doutorado. Casos semelhantes ao
citado já aconteceram muitas vezes, mas podem ser evitados com alguma
orientação.
A propósito, nenhuma pessoa ou animal foram feridos pelo autor deste
livro enquanto ele escrevia a história da catapulta. Pelo menos não que ele
tivesse conhecimento, já que a ciência o leva a não crer em verdades
absolutas (ele poderia ter pisado em uma formiga sob a mesa sem perceber).
1Usualmente no Brasil diz-se “dissertação” de mestrado e “tese” de doutorado. Em outros países
usam-se os termos indistintamente ou até com significados diferentes. Neste livro o trabalho
individual para obtenção de um grau, seja graduação, especialização, mestrado ou doutorado, será
denominado “monografia”, para simplificar o texto.
C A P Í T U L O 2
Estilos de Pesquisa Correntes em
Computação
Com alguma frequência se ouve dizer que a Computação ou Informática é
uma área nova no campo das ciências, e que está em franco
desenvolvimento. Mas isso não justifica que o método científico específico
da área de Computação tenha de ser vago e que tantas monografias sejam
escritas sem um embasamento metodológico adequado.
Essa discrepância de estilos de pesquisa e baixa conformação à
metodologia científica acontecem não só pelo fato de a área ser nova, mas
também pelo fato de que a Computação permeia praticamente todas as
atividades humanas, e, portanto, se inter-relaciona com muitas outras
disciplinas.
A própria observação do surgimento dos primeiros cursos de Ciência da
Computação no Brasil é evidência dessa variedade de abordagens e inter-
relacionamentos. Alguns cursos surgiram nas faculdades de Engenharia. Em
outras universidades, os cursos de Computação foram oriundos das
faculdades de Matemática ou de Física. Em alguns casos ainda, cursos de
Computação surgiram a partir de departamentos de processamento de dados
cuja finalidade era a prestação de serviços e não o ensino.
A variedade de cursos, e mesmo de denominações, causou grande
confusão no cenário nacional até aproximadamente o ano 2000. Até essa
data, cursos na área poderiam ser denominados “Bacharelado em Ciência da
Computação”, “Análise de Sistemas”, “Bacharelado em Informática”,
“Engenharia de Computação”, “Engenharia de Informática”, e assim por
diante. Usualmente, não havia nenhum tipo de correspondência entre a
denominação do curso e o tipo de formação que era oferecido. Após o ano
2000, os cursos da área foram definidos pela Comissão de Especialistas de
Ensino de Computação e Informática, do Ministério da Educação, em
apenas quatro denominações:
a) Bacharelado em Ciência da Computação.
b) Bacharelado em Sistemas de Informação.
c) Licenciatura em Informática.
d) Engenharia de Computação.
Tal classificação, porém, ainda é imprecisa, sendo que em muitos casos
um licenciado em Informática poderá perfeitamente exercer as atribuições
de um bacharel em Sistemas de Informação. Por outro lado, um engenheiro
de Computação poderá dar aulas de Informática, e assim por diante.
Se as ideias já são difusas na nomenclatura dos cursos, quanto mais na
pesquisa realizada pelos profissionais da área.
Este capítulo apresenta uma possível classificação para os tipos de
pesquisa realizados em Ciência da Computação e áreas correlatas,
considerando o grau de amadurecimento da pesquisa na subárea específica,
bem como seu inter-relacionamento com outras ciências. Essa classificação
é baseada em uma discussão ocorrida na lista sbc-l@sbc.org.br há cerca de
10 anos.
2.1. Estilo “Apresentação de um Produto”
Dentre as áreas emergentes dentro da Computação, ou seja, aquelas que,
mesmo para a Computação, são consideradas muito novas, é aceitável uma
pesquisa em que simplesmente se procura apresentar algo novo. Nessas
áreas, a pesquisa é eminentemente exploratória, sendo difícil comparar um
trabalho com trabalhos anteriores, pois estes podem não existir.
Sendo assim, as pesquisas nessas áreas apresentariam resultados da
forma “Fiz algo novo. Eis meu produto”. É muito pouco provável que áreas
mais maduras reconheçam pesquisas apresentadas assim.
Exemplificando: um artigo do tipo “um novo método para análise de
sistemas” dificilmente seria aceito em um evento de Engenharia de
Software, a não ser que o autor apresentasse claramente os problemas com
os velhos métodos e como o seu novo método os resolve. Outro exemplo
consiste em artigos ou trabalhos que apresentam uma ferramenta ou
protótipo. Normalmente existe pouca preocupação em apresentar
comparativos com outras ferramentas. Alega-se que não existem
ferramentas iguais, o que normalmente é até verdade. Mas se uma
ferramenta ou protótipo construído justificasse a concessão do título de
mestre, por exemplo, as universidades distribuiriam diplomas de mestre a
todos os analistas e programadores que criam ferramentas diariamente nas
suas empresas, não é mesmo? Evidentemente existe algo mais.
De qualquer maneira, apresentações desse tipo normalmente são
ingênuas e devem ser evitadas. Mesmo que se esteja trabalhando em uma
área nova do conhecimento, é interessante que a pesquisa demonstre que se
está resolvendo um problema relevante. Se o problema é relevante, então
provavelmente já se tentou resolvê-lo, e a partir daí, já é possível traçar um
comparativo. O aluno da catapulta, mencionada anteriormente, apresentou
uma solução para o problema sem ter tomado conhecimento de outras
soluções que já existiam, e por isso falhou em sua pesquisa.
Um tipo de artigo que se encaixa muito bem nessa categoria é aquele em
que o aluno desenvolve um sistema e escreve um artigo apresentando-o.
Não há comparativos, não se apresenta nenhum conhecimento novo, a não
ser o sistema em si, e, portanto, esse tipo de artigo tem poucas chances de
ser aceito em um veículo de publicação relevante. Muitas vezes, tais artigos
são vistos mais como uma propaganda do grupo que desenvolveu o sistema
do que como uma contribuição científica. Em outras palavras, artigos do
tipo “manual da ferramenta” devem ser evitados.
Esse tipo de publicação poderá ter seu espaço em sessões especiais de
apresentação de ferramentas, ou em eventos cujo tema seja a aplicação da
informática a alguma outra área, como, por exemplo, a Medicina, a
Educação e outras. Mesmo assim, essas áreas têm, cada vez mais, exigido
que os artigos apresentados sejam mais do que uma mera descrição de um
sistema, que tragam conhecimento novo para a área e, principalmente,
comparem o trabalho apresentado com trabalhos anteriores.
O desenvolvimento de um sistema e sua apresentação podem ser
considerados um trabalho relevante em cursos de graduação ou
especialização, desde que fique evidente que o aluno aplicou técnicas no
sistema ou no processo de desenvolvimento do sistema aprendidas durante
o curso. Dificilmente esse tipo de trabalho seria aceito no mestrado e
doutorado.
2.2. Estilo “Apresentação de algo Diferente”
Um segundo tipo de pesquisa, um pouco mais amadurecido, consiste na
apresentação de uma forma diferente de resolver um problema. Esse tipo de
pesquisa também é característico de áreas emergentes, e os trabalhos
normalmente são apresentados como uma simples comparação entre
técnicas, em que não se exige necessariamente rigor científico na
apresentação dos resultados. As comparações normalmente são muito mais
qualitativas do que quantitativas.
Um exemplo típico desse tipo de pesquisa seria um trabalho em
Engenharia de Software no qual se apresenta uma nova técnica para realizar
algo, em que se compara essa técnica com outras técnicas existentes (não
necessariamente todas e não necessariamente as melhores, muitas vezes por
falta de uma métrica para decidir sobre isso), e em que se apresenta um ou
dois estudos de caso para reforçar o argumento.
Os resultados de um artigo deste tipo poderão ser aceitos em algum
veículo de publicação, desde que os argumentos utilizados pelo autor sejam
convincentes.
Um estudo de caso raramente prova alguma coisa, e a possibilidade de
generalizar o resultado é responsabilidade do autor do texto, não do leitor.
Se o método funcionou no estudo de caso A ou no estudo de caso B, isso
não quer dizer que funcionará sempre. Não há aqui, portanto, prova com
rigor científico, mas uma tentativa de convencimento do leitor.
Apesar disso, o estudo de caso pode servir para provar que um método
consagrado falha em uma ou outra situação. Esse resultado, sim, poderia ser
interessante desde que o motivo da falha fosse claramente identificado e
uma solução para o problema fosse proposta e validada.
Esse tipo de pesquisa é típico em áreas novas nas quais não se dispõe de
grandes bases de dados para testar teorias empiricamente, ou quando o
tempo e os recursos necessários para realizar a pesquisa empiricamente são
inviáveis.
Para que esse tipo de pesquisa funcione é necessário que se tenha uma
boa hipótese de trabalho, uma boa teoria construída para sustentá-la e uma
boa argumentação para fazer com que um eventual leitor se convença da
validade da teoria, mesmo sem poder testá-la com métodos estatisticamente
aceitos.
Em relação à hipótese, convém mencionar que ela é o coração da
monografia. Se a hipótese for mal escolhida, o trabalho pode não alcançar
os objetivos. Nesse caso, quem é penalizado? O aluno! Portanto, uma boa
hipótese com evidências de efetividade deve ser buscada.
Trabalhos de mestrado e doutorado, em geral, propõem algo: um novo
método, uma nova ideia, um novo sistema etc. Porém, “propor” algo é fácil.
Difícil é mostrar que a proposta apresenta algum tipo de melhoria em
relação a outras propostas semelhantes que existem por aí.
Por exemplo, propor um método de compressão de textos mais eficiente
do que os que atualmente estão no mercado é possível e até louvável como
objetivo de uma tese. Mas daí o problema é: como criar um método mais
eficiente do que os atuais? É necessário ter uma boa hipótese.
Uma hipótese, segundo a Wikipédia (2008), é uma teoria provável, mas
ainda não demonstrada, ou uma suposição admissível. A hipótese norteia o
trabalho de pesquisa justamente porque ainda não se sabe se ela é
efetivamente verdadeira. Ela será testada ao longo do trabalho. Caso se
confirme, o trabalho terá sido um sucesso. Caso não se confirme, será
necessário juntar os cacos e tentar outra linha de pesquisa. Por isso é que é
necessário ter uma hipótese bem embasada e justificada. O risco é sempre
do aluno.
Uma das formas de aumentar a chance de sucesso desse tipo de trabalho
é estruturá-lo na forma de uma tabela comparativa. A ideia é que não se vai
criar algo simplesmente diferente daquilo que já existe, mas algo que
incorpore várias características importantes em um mesmo artefato.
Idealmente o trabalho começa com uma boa pesquisa bibliográfica para se
descobrir quais são as formas correntes usuais para se resolver o problema
em questão. Em seguida, analisam-se diferentes propriedades de cada uma
das abordagens, construindo uma tabela como a da Figura 2.1.
FIGURA 2.1 Exemplo de tabela comparativa de artefatos e características.
Uma vez identificados os artefatos usados para resolver o problema em
questão e as principais características desses artefatos, pode-se proceder à
criação ou definição de um novo artefato que abranja todas as
características, conforme a Figura 2.2.
FIGURA 2.2 Proposta de um novo artefato que tenha todas as características
dos anteriores.
Esse novo artefato será diferente dos demais, pois seu conjunto de
características não é possuído por nenhum dos outros artefatos
isoladamente. O novo artefato será útil na medida em que as características
forem efetivamente relevantes. E a tabela comparativa será uma boa
ferramenta para a pesquisa, caso as características possam ser efetiva e
independentemente verificadas.
2.3. Estilo “Apresentação de algo
Presumivelmente Melhor”
Áreas um pouco mais amadurecidas do que as anteriores exigem que
qualquer nova abordagem apresentada seja comparada quantitativamente
com outras da literatura. Na falta de bancos dados (benchmark)
internacionalmente aceitos ou acessíveis, o próprio autor do artigo acaba
criando e realizando os testes que demonstram que a sua abordagem é
melhor do que outras.
Um problema com esse tipo de pesquisa é que o autor terá de testar a sua
abordagem e também as outras, que constam da literatura, resultando em
excesso de trabalho, além de, possivelmente, introduzir o risco de erro,
visto que não há garantias de que as abordagens apresentadas na literatura
estejam testadas nas melhores condições pelo autor do trabalho. Sendo
assim, tais comparações muitas vezes são temerárias. Para que uma
pesquisa desse tipo seja bem aceita, é necessário que o autor deixe bem
claro a forma como aplicou cada uma das técnicas e que isolou todos os
fatores que poderiam possivelmente afetar os resultados.
De qualquer maneira, uma abordagem para um determinado problema
que se revela melhor do que outras abordagens requer alguns cuidados. Em
primeiro lugar, o pesquisador deve se certificar de que está comparando a
nova abordagem com alguma outra que seja do estado da arte. Em
computação, muitas vezes é inadmissível apresentar um método e compará-
lo com outro de uma referência bibliográfica de 15 anos atrás. Mesmo que o
novo método seja melhor que o antigo, o artigo terá pouca credibilidade, a
não ser que o autor deixe bem claro que nos últimos 15 anos não houve
nenhum avanço nessa área. Um artigo, porém, que apresente melhorias em
relação a um processo publicado recentemente, digamos, no máximo um ou
dois anos, terá mais credibilidade.
Não é necessário, porém, que o autor de algum método novo demonstre
que o seu método é melhor que outro método do estado da arte para toda e
qualquer situação. É possível, muitas vezes, apresentar métodos ou
abordagens que funcionam melhor em determinadas situações. Nesse caso,
o artigo deve deixar bem claro quais são as situações nas quais a nova
abordagem funciona melhor e o porquê disso. Experimentos deverão ser
feitos para demonstrar tal melhoria.
Aqui entra em foco um aspecto muito importante na pesquisa que leva
em consideração o uso de dados comparativos: a métrica. Afirmações do
tipo “O sistema x é mais fácil de usar” não terão fundamento a não ser que
se defina claramente o que significa “ser fácil de usar”. Um exemplo de
definição nesse caso poderia ser a quantidade de cliques de mouse que o
usuário tem de usar para executar uma tarefa dada em um ou outro sistema.
Poderia ser questionado se a métrica é boa e eficiente, mas dentro da
definição dada é possível confirmar qual sistema é mais fácil de usar.
2.4. Estilo “Apresentação de algo
Reconhecidamente Melhor”
O nível mais maduro da pesquisa desta linha, em que a apresentação de
dados empíricos é relevante para a aceitação dos resultados, é aquele no
qual um trabalho é desenvolvido e seus resultados são apresentados em
função de testes padronizados e internacionalmente aceitos. Nesse caso, o
autor do trabalho não precisa testar outras abordagens, pois seus resultados
já estão publicados. O autor deverá buscar os dados de entrada para testar a
sua abordagem em um banco de dados conhecido e apresentar os resultados
usando uma métrica aceita pela comunidade. Dessa forma, os experimentos
poderão ser reproduzidos por equipes independentes. Se for demonstrado
que a nova abordagem é superior às abordagens anteriores, esta passará a
ser considerada como estado da arte.
Pesquisas que apresentam resultados desse tipo são típicas de boas teses
de doutorado. Supõe-se que após a publicação dos resultados ninguém mais
possa ignorar essa nova abordagem em função das vantagens que ela
oferece em relação às anteriores. Isso é o que se entende por “avançar o
estado da arte”.
Por incrível que pareça, essa é a pesquisa mais fácil de executar, desde
que o autor tenha uma boa hipótese de trabalho. Por que isso? Porque os
testes-padrão já estão definidos e os dados já estão disponíveis. Basta
implementar a abordagem e realizar os testes. O grande problema e
dificuldade inerente, então, consistem em encontrar uma boa hipótese de
trabalho, que faça sentido e que seja promissora (isso, infelizmente, em
geral não é trivial).
Portanto, esse tipo de pesquisa exigirá, por parte do autor, amplo estudo
sobre o estado da arte em uma determinada área, e muita reflexão sobre a
forma como as técnicas são desenvolvidas para resolver os problemas dessa
área. Problemas em aberto serão excelentes focos de atenção para pesquisa.
Além disso, poderá ser de muita valia se o autor possuir conhecimentos
em outras áreas, que muitas vezes nem estejam relacionadas ao problema
em questão. Algumas vezes técnicas de áreas distintas aplicadas a um
problema produzem resultados muito interessantes. Porém, deve-se lembrar
que apenas aplicar uma técnica diferente para um problema remete o
trabalho para “apresentar algo diferente”. Quando se opta por utilizar uma
técnica alienígena em um problema conhecido, é necessário que se tenha
bons motivos para acreditar que a técnica possa produzir resultados
melhores do que as técnicas correntes.
2.5. Estilo: “Apresentação de uma Prova”
Os diferentes tipos de pesquisa apresentados anteriormente se enquadram
nas subáreas da computação em que normalmente os resultados são
apresentados a partir de evidências empíricas ou pelo menos de
argumentações ou estudos de caso que sugerem provas.
Outro tipo de pesquisa exige provas matemáticas, de acordo com as
regras da lógica. A área de métodos formais ou compiladores, por exemplo,
dificilmente aceitará trabalhos que não apresentem demonstrações claras de
correção ou eficiência.
Deve ser construída uma teoria, afirmando claramente quais são os
conceitos utilizados e mostrando que a aplicação desses conceitos leva,
logicamente, a determinados resultados. Esses resultados podem ser a
demonstração de que um determinado algoritmo é o melhor algoritmo
possível para resolver um determinado tipo de problema, ou que um
algoritmo para resolver um determinado tipo de problema não existe, ou
ainda que a complexidade de qualquer algoritmo que resolve um
determinado tipo de problema não pode ser menor do que um determinado
polinômio.
2.6. Discussão
A partir das observações feitas, pode-se verificar que diferentes subáreas da
Computação podem ser caracterizadas por diversos estilos de pesquisa. É
possível classificar esses estilos, então, em três tipos básicos:
a) Pesquisas formais, em que é exigida a elaboração de uma teoria e uma
prova formal de que essa teoria é correta. A lógica formal será a grande
ferramenta de trabalho do pesquisador que optar por essa linha.
b) Pesquisas empíricas, em que uma nova abordagem apresentada é
comparada com outras através de testes aceitos pela comunidade. Os
métodos estatísticos serão a grande ferramenta de trabalho do
pesquisador que optar por essa linha.
c) Pesquisas exploratórias, em que não se consegue provar uma teoria nem
apresentar resultados estatisticamente aceitos. Mas entram aqui os
estudos de caso, as análises qualitativas e as pesquisas exploratórias em
áreas emergentes. A argumentação e o convencimento são as principais
ferramentas do pesquisador.
Embora a pesquisa formal aparentemente seja mais difícil de realizar,
seus resultados, quando obtidos, são mais difíceis de refutar.
A pesquisa empírica, mesmo baseada em métodos estatísticos, poderá ser
refutável se não estiver também embasada em uma boa teoria, isso porque a
estatística não explica causas. É bem conhecida a anedota do pesquisador
que mandava uma aranha pular e em seguida lhe arrancava uma das pernas.
Após arrancar sete pernas, a aranha ainda pulava com a perna que restava.
Após arrancar a última perna, o cientista percebeu que a aranha não atendia
mais à ordem de pular. A conclusão do pesquisador foi de que a aranha sem
pernas fica surda, pois não escutava mais a ordem para pular.
Em último lugar, a pesquisa exploratória parece ser mais fácil de realizar,
porque não é necessário utilizar os métodos da lógica formal e nem realizar
experimentos exaustivos. Porém, em termos de pesquisa, é a abordagem
mais arriscada, pois a aceitação dos argumentos não é universal, e artigos
que não se fundamentam em uma boa teoria e/ou em um bom conjunto de
testes têm menor chance de serem publicados em bons veículos do que os
demais tipos. A apresentação de estudos de caso e exemplos, no caso de
pesquisas exploratórias, poderá ajudar o pesquisador a convencer o leitor do
seu ponto de vista, mas não constituem provas.
C A P Í T U L O 3
Preparação de um Trabalho de
Pesquisa
A preparação de um trabalho de pesquisa é uma etapa que deve ser
realizada antes que se comece a escrever sobre a pesquisa.
Parece estranho, mas muitas vezes esse é um ponto que deve ser
ressaltado. Alunos, ansiosos por escrever a monografia, começam a
escrever páginas e páginas sem terem feito nenhuma pesquisa. Uma
ressalva: é necessário diferenciar o termo “pesquisa”, que pode ser
entendido como revisão bibliográfica, da sua significação como pesquisa
científica, ou seja, produção de conhecimento novo. A revisão bibliográfica,
diga-se de passagem, não produz conhecimento novo, mas apenas supre ao
estudante conhecimentos que lhe faltavam.
Portanto, não se recomenda que o aluno comece a escrever sua
monografia ou trabalho de conclusão de curso sem ter realizado alguma
pesquisa que tenha produzido conhecimento novo. Explicando melhor: não
há necessidade de sair escrevendo o capítulo de revisão bibliográfica antes
de saber o que efetivamente será feito em termos de produção de
conhecimento.
A revisão bibliográfica de um trabalho de pesquisa em Computação, em
geral, não deve ser um tratado sobre a área de pesquisa. Muitas vezes, um
aluno que começa a escrever o capítulo da revisão antes de decidir o
objetivo da pesquisa acabará escrevendo demais e desnecessariamente. Esse
capítulo será cansativo para o leitor, e muitas vezes ele não compreenderá
por que determinados assuntos são ali colocados se não são abordados na
monografia em si, que vai iniciar mais adiante.
O segredo de um trabalho de pesquisa de sucesso consiste em ter um bom
objetivo. Uma vez definido o objetivo do trabalho, tudo o mais gravita em
redor dele. A justificativa vai dizer por que vale a pena buscar esse
objetivo; o método informa como o objetivo pode ser alcançado; os
resultados esperados mostram o que muda no mundo após o objetivo ser
atingido; o capítulo de revisão bibliográfica vai apresentar os conceitos
necessários para a compreensão do objetivo e os trabalhos relacionados ao
objetivo.
3.1 Escolhendo o Objetivo de Pesquisa
A escolha de um objetivo de pesquisa é frequentemente a tarefa mais difícil
em um trabalho de mestrado ou doutorado.
Muitas vezes, o objetivo é confundido com o tema da pesquisa. O tema
da pesquisa pode ser a influência da batata inglesa na língua portuguesa.
Mas nesse caso qual é o objetivo? Ou seja, o que se quer provar?
O objetivo normalmente comporta uma hipótese de trabalho. Um bom
objetivo de pesquisa normalmente terá a forma “demonstrar que a hipótese
x é verdadeira”.
Nem todo objetivo pode ser considerado um bom objetivo de pesquisa.
Por exemplo, algo do tipo “o objetivo deste trabalho é aumentar os meus
conhecimentos na área de estudo” pode até ser muito sincero, mas não
convence ninguém de que algum conhecimento novo para a humanidade
será produzido. Portanto, isso deve ser evitado.
Outro objetivo algumas vezes encontrado é a forma “propor…”. Alguma
coisa é proposta, normalmente um método, uma abordagem, uma técnica,
um algoritmo, uma comparação, ou qualquer outra coisa. A questão é: se o
autor fizer a proposta, então o objetivo estará atingido? Se o aluno se
propõe a propor e propôs, então está proposto! O que for proposto não é
necessariamente melhor ou diferente daquilo que já existia antes. Então, o
estágio da pesquisa neste caso ainda é dos mais ingênuos.
É necessário que o objetivo diga que aquilo que está sendo proposto é
melhor do que alguma outra coisa ou que resolve algum problema que antes
não podia ser resolvido.
Segundo Chinneck (1988), a descrição de um problema de pesquisa tem
três partes:
a) Um enunciado preciso da questão ou problema de que trata a
monografia.
b) Uma explicação por referência direta à bibliografia de que tal questão
de pesquisa ainda não foi tratada.
c) Uma discussão sobre por que é importante tratar essa questão de
pesquisa.
O item (b) falhará se o aluno não conseguir deixar claro que a questão de
pesquisa nunca foi tratada. Uma boa revisão bibliográfica é necessária para
apresentar tal justificativa com suficiente autoridade. Devem ser evitadas
afirmações do tipo “não encontrei nada parecido”. O aluno deve sempre
mostrar o que encontrou nas fontes relevantes que examinou e comparar
aquilo que foi encontrado com aquilo que ele pretende fazer. Se ele disser
que não encontrou nada, a banca examinadora provavelmente pensará que
ou ele não pesquisou direito ou está tratando um problema de pouco
interesse. Em alguns casos pode ocorrer que efetivamente nada de muito
semelhante seja encontrado, mas em todo o caso, sempre existe algum
problema que possa ser considerado o mais próximo possível. Haverá
situações em que serão encontradas abordagens quase idênticas, variando
em poucos detalhes; e, em outros casos, a abordagem mais próxima será tão
distinta que será necessária uma boa dose de explicação para que se possa
entender por que ela é relevante. Leonardo da Vinci não conhecia a
tecnologia utilizada pelos modernos aviões, então baseou seus estudos
sobre máquinas voadoras no modelo mais próximo que estava disponível na
sua época, a estrutura de voo dos pássaros.
Por outro lado, é importante que um trabalho de pesquisa se relacione
principalmente com conhecimentos que sejam inerentes ao estado da arte,
ou seja, que sejam recentes. Não faria muito sentido hoje, com todos os
conhecimentos de engenharia aeronáutica disponíveis, ignorar essas
informações e tentar construir máquinas voadoras baseadas nos modelos de
Leonardo.
Apesar disso, os conhecimentos antigos não devem ser de todo
ignorados. Muitas vezes o conhecimento antigo aliado ao estado da arte
pode produzir resultados muito interessantes. No caso da indústria
aeronáutica, por exemplo, tenta-se hoje produzir aviões flexíveis que, de
certa forma, imitam as estruturas de voo dos pássaros. Mas isso é feito com
base em conhecimentos atuais, não se está reinventando a roda, mas
aperfeiçoando conceitos já existentes.
3.1.1 O Caminho Para A Escolha De Um
Objetivo De Pesquisa
Para que alguém seja capaz de pensar em um objetivo de pesquisa
relevante, essa pessoa deve conhecer a área de pesquisa na qual está
trabalhando. Portanto, o caminho lógico consiste de três passos:
a) Escolher um tema de pesquisa, ou seja, uma área de conhecimento na
qual se vai trabalhar.
b) Realizar a revisão bibliográfica. A não ser que o autor já seja
especialista na área escolhida, ele vai precisar ler muitos trabalhos já
publicados nessa área para saber o que está sendo feito (estado da arte) e
o que ainda precisa ser feito (problemas em aberto).
c) Definir o objetivo de pesquisa. Uma vez feita a revisão bibliográfica, o
objetivo de pesquisa possivelmente será fortemente relacionado com um
dos problemas em aberto verificados no passo anterior.
Em poucos casos, a revisão bibliográfica será feita depois da definição do
objetivo de pesquisa. Não é razoável conceber que alguém decida por um
caminho de pesquisa sem conhecer exatamente a área onde vai atuar. Essa
atitude possivelmente levará a objetivos mal definidos e que precisarão ser
revistos quando o pesquisador perceber que está reinventando a roda.
Mas é possível ainda que os passos (b) e (c) devam ser repetidos algumas
vezes de forma a refinar o objetivo (Figura 3.1). De fato, ao realizar a
revisão bibliográfica sobre um determinado tema, o pesquisador terá ideias
sobre aspectos do tema que ainda não foram explorados, e esses aspectos
darão origem a um objetivo de pesquisa. Mas antes de começar a gastar
energia tentando atingir esse objetivo, o pesquisador deve ainda refinar sua
pesquisa bibliográfica tentando verificar se tal objetivo já não foi
perseguido em trabalhos anteriores e que tipo de resultados foi obtido.
FIGURA 3.1 O caminho lógico para a definição de um objetivo de pesquisa.
Na história da catapulta, o tema de pesquisa foi o rio que cortava a
cidade. Quando foi estabelecido o objetivo de pesquisa “encontrar uma
forma segura de atravessar o rio”, o aluno deveria ter verificado na
literatura os principais trabalhos já publicados sobre travessia de rios. Mas
ele se limitou apenas a informações sobre a composição dos rios e,
portanto, perdeu informações importantíssimas para sua pesquisa, ou seja,
que já existiam métodos para atravessar rios e que ele deveria primeiro
tentar melhorar esses métodos já existentes, ou pelo menos conhecê-los e
seus defeitos, antes de enveredar pela pesquisa de algo totalmente novo. No
extremo desse raciocínio fica a possibilidade de que alguns anos antes
outros pesquisadores já tivessem tentado usar a catapulta para cruzar rios,
sem saber um do outro. A cada vez que o estudo é repetido, esforços são
despendidos, medidas tomadas e conclusões (possivelmente as mesmas) são
obtidas, sem que nenhum avanço ocorra para a ciência.
3.1.2 O Tema
O tema da pesquisa frequentemente depende do interesse do aluno e do
orientador. Não se recomenda, em hipótese alguma, uma pesquisa cujo tema
não seja compatível com os conhecimentos do orientador. No caso do
aluno, recomenda-se que ao passar da graduação ao mestrado e do mestrado
ao doutorado procure trabalhar no mesmo tema, embora, buscando
objetivos distintos. Por que isso? Porque, se o aluno se mantiver no mesmo
tema, o passo de revisão bibliográfica será concluído mais rapidamente ao
passar de um estágio para outro em sua formação. Bastará que ele se
atualize nos últimos desenvolvimentos da área para poder decidir por um
bom objetivo de pesquisa. Se o aluno mudar de tema, então terá de fazer
toda a revisão bibliográfica sobre outro tema, o que lhe tomará muito
tempo.
Não é impossível que uma pessoa com formação em uma área faça
mestrado ou doutorado em uma área totalmente diferente, mas com certeza
essa pessoa terá muito mais trabalho e levará muito mais tempo para
amadurecer os conceitos da nova área do que uma pessoa que já tem a
vivência na área.
O tema pode ser especializado a partir de uma grande área em subáreas
cada vez mais específicas. Por exemplo:
1. Ciência da Computação.
1.1. Inteligência Artificial.
1.1.1. Métodos de busca.
1.1.1.1. Busca heurística.
1.1.1.1.1 Algoritmo A*.
Nessa lista, cada item é uma especialização do item anterior, mas cada
um é apenas um tema de pesquisa, embora cada vez mais específico.
Indo para outra direção, pode-se combinar um tema de pesquisa com uma
área de aplicação. O tema, possivelmente, será mais específico do que geral.
Não faz muito sentido, por exemplo, falar de “aplicação da Ciência da
Computação no problema da pavimentação das estradas”. Faria mais
sentido um tema de pesquisa como “aplicação de busca heurística no
problema do transporte de máquinas para pavimentação de estradas”.
Mesmo assim, em alguns casos encontram-se trabalhos cujo tema é algo
do tipo “aplicação de técnicas de Inteligência Artificial para resolver o
problema x”. O pesquisador deve ter a noção de proporção para saber se o
nível de especificidade do tema de pesquisa é adequado ou não. No
exemplo anterior, ao se falar de Inteligência Artificial, abre-se um leque
enorme de possibilidades (pode-se conferir como a área é extensa no livro
de Russel e Norvig, 1995). Portanto, um tema tão extenso quanto este não é
adequado. Ao se falar de busca heurística, porém, o leque é reduzido a
alguns poucos algoritmos conhecidos, e o tema fica mais viável. Quanto
mais amplo o tema, maior a quantidade de livros e artigos que terão de ser
lidos. Portanto, recomenda-se buscar temas cada vez mais específicos antes
de se propor um objetivo de pesquisa. Quando se escolhe um tema de
pesquisa que tem aplicação em outra área, deve-se tomar cuidado. Quando
se está realizando um mestrado ou doutorado em Ciência da Computação,
deve-se observar que a principal contribuição do trabalho deve ser para a
área da Computação. Ou seja, o problema a ser resolvido deve estar ligado à
não-existência ou inadequação das ferramentas de computação existentes, e
não aos aspectos ou técnicas da área de aplicação (pelo menos não
predominantemente). O aluno, nesse caso, deve evitar a tentação de
contribuir para uma área que ele não conhece ou que conhece muito pouco.
Por exemplo, uma monografia sobre Informática aplicada à Medicina deve
apresentar contribuições em relação às ferramentas de Computação aplicada
à Medicina e às melhorias que podem ser obtidas. Dificilmente o aluno de
Computação irá propor e defender uma nova técnica cirúrgica. Não quer
dizer que seja impossível que isso aconteça, nem quer dizer que o aluno não
seja execrado na banca por algum médico que esteja ali presente, mas é um
risco a ser evitado.
3.1.3 O Problema
Uma monografia deve apresentar uma solução para um problema.
Inicialmente, portanto, um problema deve ser identificado. Seria errado
iniciar a monografia simplesmente resolvendo criar um novo método para
isso ou aquilo.
No caso da catapulta, o aluno propôs e testou um novo método para
cruzar rios. Aqui vem uma questão interessante. Segundo o aluno, o
problema consistia em cruzar o rio. Mas esse problema identificado já não é
mais um problema sem solução, porque existem diferentes abordagens para
cruzar um rio: ponte, balsa, teleférico etc. Então, caso o aluno quisesse
insistir neste tema, teria de indicar quais problemas as soluções existentes
apresentam. Ou seja, quais os problemas encontrados quando se tenta
cruzar um rio com uma ponte ou com uma balsa? Ele poderia descobrir, por
exemplo, que pontes são muito caras e balsas são muito lentas. Se todas as
soluções existentes apresentarem algum tipo de problema, então é possível
que se esteja abrindo caminho para uma nova abordagem. Caso contrário,
as pessoas continuarão a cruzar rios com os meios usuais e não com a nova
abordagem.
Algumas propostas de pesquisa são apresentadas inicialmente sem ter um
problema claramente identificado. Por exemplo: “este trabalho propõe usar
a metáfora de formigueiro para modelar pacotes em uma rede”. Esse tema
até pode vir a ser um trabalho interessante, mas qual é o problema que essa
modelagem vai resolver? O que há de errado com outras formas de
modelagem, sejam elas quais forem, que essa metáfora do formigueiro vai
possivelmente resolver?
Segundo Griffiths (2008), se o autor não consegue estabelecer claramente
qual é o problema tratado em sua monografia, será muito difícil para outras
pessoas especularem sobre os possíveis usos dela. Também será difícil
avaliar se ela obteve sucesso.
3.1.4 Perspectiva Profissional
O tema de pesquisa a ser escolhido, em qualquer nível de formação, além
de ser do agrado do aluno, deve estar relacionado com a sua perspectiva de
desenvolvimento profissional.
Não faz sentido gastar vários anos investindo em uma pesquisa na área
X, para depois trabalhar o resto da vida na área Y. O ideal seria que cada
pesquisa gerassse algum tipo de produto ou uma melhoria a um produto
existente que pudesse, após o final do curso, gerar algum tipo de
perspectiva de trabalho e de renda para o pesquisador.
Isso é mais difícil quando se trata de pesquisa básica, mas mesmo assim
esse tipo de pesquisa pode gerar patentes que em algum momento poderão
se tornar produtos e gerar riquezas para o país. Não é admissível que todo
um esforço despendido durante o mestrado ou mesmo durante um
doutorado acabe sendo depois simplesmente guardado em uma gaveta.
3.2 A Revisão Bibliográfica
A revisão bibliográfica, conforme já comentado, não produz conhecimento
novo, mas apenas supre as deficiências de conhecimento que o pesquisador
tem em uma determinada área. Portanto, ela deve ser muito bem planejada e
conduzida.
Supondo que o pesquisador seja praticamente iniciante em uma
determinada área, ele deveria iniciar a pesquisa lendo algum tipo de survey
sobre o assunto. Não é difícil encontrar artigos ou mesmo livros que
abordem toda uma área de conhecimento na forma de survey. Os livros,
aliás, servem exatamente a esse propósito.
Pode-se iniciar a pesquisa com uma leitura de trabalhos mais abrangentes
que deem uma visão do todo para depois ir se aprofundando cada vez mais
em temas cada vez mais específicos.
Quando se faz uma pesquisa em que alguma técnica de computação é
aplicada a alguma outra área do conhecimento, é necessário que se faça a
revisão bibliográfica sobre a técnica em si, sobre a área de aplicação e, mais
do que tudo, sobre as aplicações que já foram tentadas com essa técnica ou
com técnicas semelhantes na mesma área ou em áreas equivalentes.
Exemplificando, um aluno pretende desenvolver um sistema multiagentes
para auxiliar controladores de voo. Esse aluno deve conhecer
profundamente os sistemas multiagentes e deverá conhecer também os
problemas que os controladores de voo enfrentam para exercer sua
profissão. Porém, ele não deve pensar, como algumas vezes acontece, que
essa é a primeira vez que alguém vai tentar desenvolver um sistema
multiagentes para esse tipo de aplicação. O aluno da catapulta, mencionado
anteriormente, estudou rios e estudou catapultas, mas não procurou saber se
alguém já tinha tentado atravessar um rio usando uma catapulta. Se essa
pesquisa existisse e ele tivesse acesso a ela, teria visto que os resultados não
eram animadores e talvez tivesse escolhido outro tema de pesquisa antes de
ter dedicado a maior parte do seu tempo de mestrado a algo infrutífero.
Uma monografia sobre pesquisa aplicada que apresenta uma boa revisão
bibliográfica da ferramenta de computação e da área de aplicação, mas que
não menciona nenhuma tentativa anterior de aplicação dessa ferramenta na
área sofre da “Síndrome da Intersecção Esquecida”. Uma monografia com
esse problema estará possivelmente “reinventando a roda”.
A Síndrome da Intersecção Esquecida em geral é justificada pelos alunos
com frases do tipo “mas não encontrei nada parecido com o que estou
fazendo”. Esse raciocínio negativo deve ser evitado. Nunca se deve dizer
que não se achou nada semelhante. Algo sempre deve ser apresentado como
referência. Essa referência poderá ser mais semelhante ou menos
semelhante à abordagem usada de um ponto de vista relativo. Mas sempre a
abordagem mais semelhante de todas (por menos semelhante que seja) deve
ser buscada.
Pode ser interessante pensar assim: “Ninguém fez algo parecido com o
que estou fazendo, mas muitas coisas já foram feitas pelos seres humanos
ao longo da sua história. Então, eu poderia classificar as coisas que já foram
feitas em termos de grau de semelhança com aquilo que estou fazendo. As
coisas mais parecidas com o meu trabalho serão minha referência, mesmo
que a semelhança seja pequena”.
Assim, evita-se o fundamento vazio, ou seja, dizer que seu trabalho é
original porque ninguém nunca fez nada parecido. Não se deve fundamentar
todo um trabalho de pesquisa em uma negação. Deve-se mostrar o que
outros fizeram, e depois mostrar que o trabalho feito é diferente ou melhor
do que essas referências.
3.2.1 Fichas De Leitura
Durante todo o processo de leitura, é fundamental que sejam feitas
anotações. Conceitos-chave e ideias novas devem ser anotados sempre que
forem detectados na leitura. É necessário que se saiba de onde tais ideias e
conceitos saíram. Em geral, inicia-se uma ficha de leitura, seja em papel,
seja no computador, escrevendo a referência bibliográfica da obra sendo
consultada. Em seguida são feitas as anotações relevantes.
Essas fichas serão extremamente importantes no futuro para saber de
onde as ideias saíram. Depois de ler algumas dezenas de artigos sobre um
determinado assunto, será difícil lembrar-se de onde saíram determinadas
ideias.
Porém, deve-se ter em mente que o conjunto das fichas de leitura não é o
mesmo que o capítulo de revisão bibliográfica. As fichas são apenas um
registro, com memória, de leituras feitas, que é organizado por fonte
bibliográfica. Esse trabalho normalmente será desenvolvido antes da
definição do objetivo de pesquisa, pois, como foi comentado, consiste
exatamente na busca de informações para que esse objetivo possa ser
definido. Já o capítulo de revisão bibliográfica será organizado após a
execução da pesquisa. Ou seja, após definir o objetivo, definir o método de
trabalho, executar os experimentos, coletar os resultados e esboçar as
conclusões, é que o pesquisador vai organizar o capítulo de revisão
bibliográfica onde ele vai inserir os principais conceitos e trabalhos
correlatos relevantes para a compreensão da sua pesquisa.
Se as fichas de leitura são organizadas por fonte bibliográfica, o capítulo
de revisão bibliográfica não deve ser organizado dessa forma, mas por
conceitos. Ou seja, em vez de dizer tudo o que um autor pensa sobre vários
conceitos, deve-se dizer o que vários autores pensam sobre um conceito de
cada vez.
3.2.2 Tipos De Fontes Bibliográficas
Há vários tipos de fontes bibliográficas. Cada uma terá sua utilidade em
determinados momentos da pesquisa. Os livros normalmente contêm
informação mais completa, didática e bem amadurecida. O objetivo do livro
é justamente apresentar uma determinada área da ciência de forma didática
e bem fundamentada.
Raramente serão encontradas em livros informações sobre trabalhos
futuros, que conduzem a ideias de pesquisa.
Alguns livros se dedicam especificamente à apresentação de problemas
em aberto em determinadas áreas, mas estes não são maioria. Em geral, tais
livros são produto de eventos científicos. A maioria dos livros didáticos
procura apresentar apenas a informação que já está consolidada.
Ideias de pesquisa serão encontradas mais facilmente em artigos curtos
que normalmente são publicados em eventos ou periódicos. A maioria das
ciências exatas preza mais a publicação em periódicos. A área de
Computação, porém, tem características distintas em relação a esse aspecto,
visto que considera publicações em eventos como sendo tão importantes, e
muitas vezes até mais importantes, que publicações em periódicos.
Isso significa que, na área de Computação, bons artigos poderão ser
encontrados tanto em eventos quanto em periódicos. Que diferenças podem
então ser esperadas?
O processo de submissão e publicação em eventos e periódicos é
diferente. Por isso, pode-se esperar diferentes tipos de artigos nesses dois
veículos.
Eventos normalmente têm uma data-limite para entrega de trabalhos. De
um conjunto de trabalhos enviados e avaliados, os melhores são
encaminhados para publicação. Em geral, são sugeridas algumas
modificações, mas dificilmente uma segunda rodada de avaliação é
realizada.
Já no caso de periódicos, não existem datas-limite, a não ser no caso de
edições especiais. Os artigos são submetidos, avaliados, e revisões são
sugeridas. Posteriormente, os artigos são enviados de novo, avaliados e
assim por diante. Esse processo de ida e volta pode acontecer várias vezes e
em geral pode levar alguns anos até que o artigo seja publicado.
Então, a diferença que se pode esperar é a seguinte: os artigos em eventos
terão informações mais atuais, mas poderão variar bastante em termos de
qualidade. Já os artigos em periódicos terão sido arduamente revisados e
lapidados ao longo de iterações entre autores e revisores, mas quando
publicados talvez já não sejam mais tão atuais quanto os artigos em eventos.
Fica a ressalva de que toda regra tem exceção, porque existem periódicos
que publicam artigos rapidamente e eventos cujo índice de exigência é tão
alto que publicará apenas artigos do mais alto grau de excelência.
3.2.3 O Que Deve Ser Necessariamente Lido
O pesquisador iniciante em uma determinada área deverá começar sua
revisão bibliográfica pelos surveys. Livros sobre o assunto também seriam
uma boa escolha nesse momento. Algumas ferramentas de pesquisa
bibliográfica, como citeseer (http://citeseer.nj.nec.com/impact.html),
permitem uma busca específica por artigos do tipo survey. Além disso,
existem publicações especializadas nesse tipo de artigo.
Essas coletâneas apresentam ao pesquisador o estado da arte da área de
pesquisa e sua evolução histórica, indicando diferentes desdobramentos e as
principais realizações.
Na sequência, alguns trabalhos clássicos devem ser buscados,
normalmente destacados nos surveys. Além disso, quando se usa uma
ferramenta de pesquisa bibliográfica eletrônica, é possível, muitas vezes,
solicitar que os trabalhos publicados em uma determinada área sejam
ordenados a partir de sua importância. Um trabalho será mais importante na
medida em que for citado por outros trabalhos. Os trabalhos clássicos são
aqueles que já receberam ao longo do tempo o maior número de citações.
Continuando a pesquisa, deverão ser buscadas as fontes mais recentes
sobre o assunto da pesquisa. Artigos muito atuais dificilmente serão
clássicos, pois ainda não terá havido tempo para que sejam citados em
outras publicações. Porém, é fundamental que um trabalho de pesquisa
tenha como referência também os desenvolvimentos mais recentes na área.
3.2.4 Leitura Crítica
A leitura de trabalhos científicos não deve ser encarada apenas como um
aprendizado. O pesquisador deve exercer, antes de tudo, o espírito crítico,
para questionar a validade de todas as informações registradas nos textos
que estão sendo lidos. A aceitação passiva de tudo aquilo o que é lido não
gera no pesquisador o espírito de busca por novas informações.
Para que o tema de pesquisa se transforme em um objetivo, é necessário
que a cada instante a leitura produza questionamentos. Sem perguntas não
há respostas. Muitas perguntas que o pesquisador fizer a si mesmo ao longo
da leitura de um texto possivelmente ainda não terão respostas e serão,
portanto, excelentes candidatas a objetivo de pesquisa.
Algumas perguntas-chave poderão ajudar o leitor a transformar uma
leitura passiva em uma leitura rica e geradora de ideias para pesquisa. Entre
elas:
a) De onde o autor parece tirar suas ideias?
b) O que foi obtido como resultado deste trabalho?
c) Como este trabalho se relaciona com outros na mesma área?
d) Qual seria um próximo passo razoável para dar continuidade a essa
pesquisa?
e) Que ideias de áreas próximas poderiam ser aproveitadas neste trabalho?
As perguntas geradoras mencionadas também poderiam ser usadas para
avaliar a qualidade do trabalho que está sendo lido. No caso da primeira
pergunta, se não for possível descobrir de onde o autor tira suas ideias,
provavelmente se estará diante de um trabalho fraco, pois as ideias devem
vir de referências bibliográficas, ou da observação de fenômenos, ou então
são hipóteses criadas pelo autor, as quais serão comprovadas ao longo do
trabalho.
Em geral, os autores não podem simplesmente escrever frases como “o
interesse pela Internet tem crescido muito ao longo dos últimos anos”. Uma
afirmação como esta, embora, à primeira vista, seja consensual, não pode
deixar de ter uma base. Essa base pode ser uma referência a outro trabalho,
que tenha realizado uma pesquisa sobre o assunto. A base também pode ser
um levantamento estatístico realizado pelo próprio autor que demonstra a
validade da afirmação. Mais adiante será visto que essa frase específica
ainda comporta vários outros problemas, por exemplo:
a) Como se define e se mede “interesse”?
b) Como se conceitua “crescer muito”?
c) Que período de tempo compreende os “últimos anos”?
Em relação à segunda pergunta geradora, “o que exatamente foi obtido
como resultado deste trabalho em particular?”, se não houver possibilidade
de resumir em poucas palavras a contribuição real do trabalho, então,
possivelmente, o texto será confuso e mal organizado, não deixando clara a
efetiva contribuição do artigo para a comunidade científica.
Em relação à terceira pergunta geradora, “como este trabalho se relaciona
com outros na mesma área?”, espera-se, a princípio, que o próprio artigo
deixe bem claro, citando adequadamente os trabalhos correlatos. Caso isso
não seja feito, o leitor poderá tentar estabelecer as relações entre o trabalho
lido e outras obras. Muitas vezes, aspectos importantes sobre o trabalho
(falhas) são descobertos através dessas comparações.
Em relação à quarta pergunta geradora, “qual seria um próximo passo
razoável para dar continuidade a essa pesquisa?”, a resposta poderá ser um
excelente objetivo de pesquisa. Muitas vezes as questões de pesquisa já
estão colocadas no trabalho pelos autores na esperança de que outros grupos
deem continuidade à pesquisa.
A quinta pergunta, “que ideias de áreas próximas poderiam ser
aproveitadas neste trabalho?”, traz ao pensamento do pesquisador possíveis
melhoramentos ao trabalho sendo estudado em função de conceitos
correlatos de outras áreas de pesquisa, que possivelmente não eram
conhecidos dos autores do trabalho. Dessa forma, o sucesso da aplicação de
algum desses conceitos correlatos no trabalho em questão poderá dar
origem a uma interessante hipótese de pesquisa, que, se tiver uma
justificativa plausível, poderá ser um excelente objetivo de pesquisa.
3.2.5 Exposição À Pesquisa
Além da leitura, o pesquisador, na fase de geração de ideias, deverá estar
constantemente exposto a um ambiente científico. No caso de alunos de
mestrado e doutorado, na fase de elaboração do objetivo de pesquisa, é
fundamental que se tente, pelo menos uma vez por semana, gerar uma ideia
de pesquisa para ser discutida com o orientador.
Regularmente, o pesquisador deverá ler pelo menos os resumos dos
artigos publicados nos principais periódicos e eventos na sua área de
pesquisa. Além dos resumos, deve-se procurar ler pelo menos um ou dois
artigos de maior relevância para a área de pesquisa.
Além disso, sempre que possível, o pesquisador deverá participar de
palestras e seminários nos quais poderá trocar ideias com outros
pesquisadores, além de observar a forma de trabalho de outros grupos de
pesquisa. No caso de alunos de mestrado e doutorado, isso implica também
participar, como ouvinte, do maior número possível de defesas de teses e
dissertações, mesmo que não sejam referentes à sua área de pesquisa
específica.
3.2.6 A Ideia De Pesquisa
A ideia de pesquisa, ou problema, surge a partir da leitura e observação.
Pode-se comparar a ideia de pesquisa a uma semente que germina no solo
da revisão bibliográfica. Com uma revisão bibliográfica superficial ou
inexistente até se pode ter ideias, mas possivelmente serão ideias fracas, que
dificilmente se desenvolverão de forma saudável. Já com uma boa revisão
bibliográfica, tem-se um solo forte para germinação de ideias consistentes.
Portanto, antes de tentar ter ideias, o aluno deve ter experimentado uma
boa carga de leitura relacionada ao tema.
3.2.7 Como Sistematizar A Pesquisa
Bibliográfica
Um dos problemas que os alunos eventualmente encontram, conforme já
mencionado, é justificar que não encontraram nada efetivamente ligado ao
assunto que desejam pesquisar. Buscas desorganizadas dificilmente levarão
a bons resultados e dificilmente darão segurança ao aluno quando lhe for
perguntado “mas será que alguém já não fez isso?”.
Fica aqui então uma sugestão sobre como proceder à pesquisa
bibliográfica de maneira sistemática. Cada aluno poderá mudar essas
sugestões de acordo com suas necessidades ou disponibilidade. Sugere-se
seguir estes passos:
a) Listar os títulos de periódicos e eventos relevantes para o tema de
pesquisa e os títulos de periódicos gerais em computação que
eventualmente possam ter algum artigo na área do tema de pesquisa.
b) Obter a lista de todos os artigos publicados nos últimos cinco (ou mais)
anos nesses veículos.
c) Selecionar dessa lista aqueles títulos que tenham relação com o tema de
pesquisa.
d) Ler o abstract desses artigos e, em função da leitura, classificálos como
relevância “alta”, “média” ou “baixa”.
e) Ler os artigos de alta relevância e fazer fichas de leitura anotando os
principais conceitos e ideias aprendidos. Anotar também títulos de
outros artigos possivelmente mencionados na bibliografia de cada artigo
(mesmo que com mais de cinco anos) e que pareçam relevantes para o
trabalho de pesquisa. Incluir esses artigos na lista dos que devem ser
lidos (inicialmente o abstract e, se for relevante, o artigo todo).
f) Dependendo do caso, ler também os artigos de relevância média e baixa,
mas iniciando sempre pelos de alta relevância.
O conjunto de referências mencionadas no terceiro passo deve ser
efetivamente produzido na forma de uma listagem que possa ser
posteriormente consultada ou até indicada na bibliografia do trabalho como
fonte de pesquisa. Portanto, essa fase do processo deve ser bem
documentada.
Depois do último passo, o aluno poderá decidir se:
a) Já tem material suficiente para elaborar uma ideia de pesquisa
consistente.
b) Precisa expandir a pesquisa examinando artigos mais antigos
(expandindo o passo “b”) ou periódicos menos relevantes (expandindo o
passo “a”).
A decisão sobre se já há material suficiente para finalizar a revisão
bibliográfica usualmente será tomada em conjunto com o orientador.
Uma última técnica ainda para expandir a revisão bibliográfica, quando
necessário, é consultar as referências bibliográficas citadas nos trabalhos
mais importantes consultados.
3.2.8 Como Terminar A Revisão Bibliográfica
Em geral, existe sempre conhecimento novo sendo produzido em todas as
áreas da ciência. A revisão bibliográfica, portanto, praticamente não
termina nunca.
Mas o trabalho de pesquisa deve ter um término claro. E é necessário
saber que, durante o seu desenvolvimento, apenas a revisão bibliográfica
não produz nenhum conhecimento novo.
É necessário, portanto, passar gradualmente da fase de revisão
bibliográfica para a fase de realização propriamente dita do trabalho de
pesquisa, ou seja, a construção de teorias e realização de experimentos para
testar hipóteses.
3.3 O Objetivo
O objetivo da pesquisa deve ser diretamente verificável ao final do trabalho.
Um bom objetivo de pesquisa possivelmente irá demonstrar que alguma
hipótese sendo testada é ou não verdadeira.
Portanto, o objetivo geral e os objetivos específicos do trabalho devem
ser expressos na forma de uma condição não trivial cujo sucesso possa vir a
ser verificado ao final do trabalho. Um objetivo bem expresso em geral terá
verbos como “demonstrar”, “provar”, “melhorar” (de acordo com alguma
métrica definida) etc.
Deve-se tomar cuidado com certos verbos que determinam objetivos cuja
verificação é trivial e, portanto, inadequada. Entre eles pode-se citar
“propor”, “estudar”, “apresentar” etc. Se o objetivo do trabalho é propor
algo, basta que a coisa seja proposta para que o objetivo seja atingido e,
portanto, essa forma é trivial e inadequada, pois a definição do objetivo não
menciona a qualidade daquilo que será proposto.
Se o objetivo do trabalho é estudar algo, então ele terá sido alcançado se
aquilo foi estudado, não importando se alguma nova informação foi
aprendida ou não, sendo, portanto, inadequado como objetivo de pesquisa.
Estudar, normalmente, é o objetivo do aluno e não do trabalho.
Se o objetivo do trabalho consiste em apresentar algo, novamente ele é
trivial e inadequado. Uma simples apresentação não produz
necessariamente conhecimento novo. Por exemplo, “o objetivo deste
trabalho é apresentar os operadores da lógica booleana”; tal objetivo pode
ser alcançado com um pequeno texto explicando os operadores conhecidos,
mas, como não traz informação nova, não é um objetivo de pesquisa.
A proposta, o estudo e a apresentação podem ser justificáveis como
objetivo de pesquisa desde que o objeto da proposta, estudo ou da
apresentação seja algo original.
Segundo Chinneck (1988), uma monografia deve apresentar uma
contribuição original ao conhecimento. Dessa forma, ao final do trabalho, o
estudante deverá ser capaz de mostrar que identificou um problema que
valia a pena ser resolvido, mas que ainda não havia sido. Além disso, o
estudante deverá mostrar que ele resolveu o problema que propôs e
apresentar a solução.
Em função disso, Chinneck conclui que um avaliador, ao ler o texto de
uma monografia, vai procurar responder às seguintes questões:
a) Qual é a questão de pesquisa que o aluno propôs?
b) É uma boa questão? (Já foi respondida alguma vez? Vale a pena
respondê-la?)
c) O aluno conseguiu convencer que a questão foi respondida
adequadamente?
d) O aluno fez uma contribuição adequada ao conhecimento?
A falha em encontrar respostas para alguma dessas questões poderá
colocar o aluno em apuros, sendo que a banca avaliadora provavelmente
exigirá revisões extensas no trabalho ou poderá até reprovar o candidato.
3.3.1 A Extensão Do Objetivo De Pesquisa
Um objetivo de pesquisa, dependendo do nível de formação pretendido
(graduação, especialização, mestrado ou doutorado), não pode ser
demasiadamente trivial nem demasiadamente complexo.
Um objetivo demasiadamente trivial será atingido rapidamente, mas
dificilmente será defensável perante uma banca, pois a cada grau acadêmico
espera-se do aluno não apenas inspiração, mas também transpiração, ou
seja, não basta ter uma boa ideia, é necessário trabalhar sobre ela
demonstrando todos os seus diferentes aspectos dentro do nível de
complexidade exigido pelo grau almejado.
Um objetivo demasiadamente complexo dificilmente será atingido no
tempo disponível para o cumprimento dos requisitos do grau almejado.
Objetivos complexos podem ser colocados como projetos de longo prazo na
carreira de pesquisadores já formados, os quais terão, muitas vezes, décadas
à frente e equipes de pesquisa para buscar esses objetivos.
Alunos de graduação e pós-graduação devem atingir os objetivos
colocados dentro do tempo regulamentar que seus cursos estabelecem, e,
portanto, a complexidade desses objetivos deve ser consistente com esse
tempo. Não basta, para a obtenção de um grau, apresentar uma ideia
complexa que não pode ser demonstrada ou concluída no tempo disponível.
Alegar para a banca que não houve tempo para concluir o trabalho
dificilmente é uma boa desculpa.
Sendo assim, o aluno deverá sempre buscar apoio no seu orientador e a
definição de um objetivo de pesquisa que possa ser buscado no tempo
disponível, de acordo com o curso realizado. Quanto mais experiente for o
orientador, ou seja, quanto mais trabalhos ele tiver orientado com sucesso
em sua vida, mais se pode esperar que seja capaz de apoiar o aluno na
escolha de um objetivo adequado.
3.3.2 Objetivo De Pesquisa Versus Objetivo
Técnico
É aceitável que um trabalho de graduação e mesmo de especialização
tenham objetivos técnicos, ou seja, espera-se nesses graus que os alunos
sejam capazes de demonstrar que aprenderam determinados conceitos e
conseguem colocá-los em prática. Assim, é aceitável que um aluno de
graduação, ao final de seu curso, desenvolva um sistema usando conceitos
aprendidos durante o curso e que apresente o sistema como trabalho final.
Porém, esse tipo de abordagem não é aceitável nos níveis de mestrado e
doutorado. Espera-se que o mestre e o doutor tenham de alguma forma
contribuído para o avanço do conhecimento. Assim, o desenvolvimento de
um sistema, embora possa ser necessário para provar alguma hipótese
previamente estabelecida, não é em si suficiente para a concessão de um
título de mestre ou doutor.
Se o simples desenvolvimento de um sistema ou de um protótipo fosse
suficiente para outorgar um grau acadêmico, então as universidades
deveriam estar conferindo título de mestre a todos os programadores ou
analistas que diariamente desenvolvem sistemas, muitas vezes complexos,
nas suas empresas. Se isso não acontece é porque existe algo mais nas
dissertações e teses que precisa ser buscado. Esse algo mais é o
conhecimento. Uma monografia é um documento que apresenta de forma
organizada uma contribuição para o estado da arte, apresentando, portanto,
informações que não eram conhecidas e que a partir do momento em que
são publicadas passam a integrar o corpo de conhecimento relevante para
quem for atuar em uma determinada área.
Os trabalhos técnicos, que são aceitáveis na graduação e na
especialização, apenas usam o conhecimento já disponível.
Os trabalhos científicos, que devem obrigatoriamente ser desenvolvidos
no mestrado e no doutorado, devem, além de usar o conhecimento já
disponível, criar novos conhecimentos, associandoos dentro de uma
estrutura coerente àqueles que já são conhecidos. Sendo assim, o
desenvolvimento de sistemas ou protótipos servirá apenas como apoio para
demonstrar a aplicabilidade desses novos conhecimentos, se assim for
necessário.
3.3.3 Os Objetivos Específicos
Os objetivos específicos devem ser escolhidos da mesma forma que o
objetivo geral, ou seja, devem ser não triviais e verificáveis ao final do
trabalho. Normalmente, os objetivos específicos não são etapas do trabalho,
mas subprodutos. Deve-se tomar cuidado para não confundir os objetivos
específicos com os passos do método de pesquisa.
A implementação de um protótipo ou a coleta de dados empíricos
possivelmente serão etapas dentro de um trabalho e, portanto, parte do
método de trabalho. Esses passos não são, assim, objetivos específicos.
Deve-se entender, portanto, que os objetivos específicos são
detalhamentos ou subprodutos do objetivo geral. Se o objetivo geral
consiste em provar uma determinada hipótese, os objetivos específicos
podem estabelecer a prova de uma série de condições associadas a tal
hipótese.
3.4 O Método de Pesquisa
Em geral as monografias têm um capítulo ou seção designados como
“metodologia”. Entretanto, metodologia seria o estudo dos métodos. Apesar
do uso corrente, linguisticamente seria mais correto afirmar que um
trabalho científico individualmente tem um método de pesquisa e não uma
metodologia.
Segundo a Wikipédia (2009a), “A Metodologia é o estudo dos métodos.
(…) Tem como finalidade captar e analisar as características dos vários
métodos disponíveis, avaliar suas capacidades, potencialidades, limitações
ou distorções e criticar os pressupostos ou as implicações de sua
utilização.”
Dificilmente um aluno escrevendo uma monografia apresenta uma
metodologia com essas características. O usual é que, dependendo do tipo
de problema, se escolha um método de trabalho e siga utilizando-o até
comprovar ou refutar as hipóteses. Assim, os termos método e metodologia
serão aqui claramente diferenciados.
Ainda segundo a Wikipédia (2009b), “O método científico é um conjunto
de regras básicas para desenvolver uma experiência a fim de produzir novo
conhecimento, bem como corrigir e integrar conhecimentos preexistentes.
Na maioria das disciplinas científicas consiste em juntar evidências
observáveis, empíricas (ou seja, baseadas apenas na experiência) e
mensuráveis e as analisar com o uso da lógica.”
Este livro trata de metodologia porque apresenta um estudo de métodos.
Mas o livro em si teve um método para ser concebido e escrito, o qual não é
aqui descrito. Porém, uma monografia deverá sempre descrever o método
usado para chegar às conclusões.
O método propriamente dito de um trabalho científico só pode ser
estabelecido depois que o objetivo tiver sido definido. Por esse motivo, no
caso da Computação, normalmente a revisão bibliográfica não deveria nem
fazer parte do método. A revisão bibliográfica consiste em um passo do
trabalho no qual o aluno vai iniciar ou aprofundar seus conhecimentos em
um campo do saber para que possa então propor um objetivo que seja
coerente com o grau que deseja obter. Ou seja, a etapa de revisão
bibliográfica não seria parte do método, mas um prerrequisito para
realização do trabalho de pesquisa, pois quem não estudou o assunto não
tem como propor um objetivo válido.
O método consiste na sequência de passos necessários para demonstrar
que o objetivo proposto foi atingido, ou seja, se os passos definidos no
método forem executados, os resultados obtidos deverão ser convincentes.
O método deve então indicar se protótipos serão desenvolvidos, se
modelos teóricos serão construídos, quais experimentos eventualmente
serão realizados, como os dados serão organizados e comparados, e assim
por diante, dependendo do tipo de trabalho.
A definição do método de pesquisa é um passo fundamental a ser
executado logo após a definição do objetivo. Dado o objetivo, o método
descreve o caminho para atingi-lo. Assim, deverá ser suficiente trilhar o
caminho descrito pelo método para se alcançar o objetivo. Se o objetivo e o
método foram coerentes, então grande parte do trabalho de pesquisa já terá
sido executada, restando apenas a execução dos passos descritos no método.
Porém, descrever um conjunto de passos que constitua um método de
trabalho científico aceitável exige alguns conhecimentos sobre o método
científico que serão detalhados nesta seção. A não observância do método
científico pode levar a conclusões erradas ou forçadas.
Propostas metodologicamente ingênuas não são totalmente incomuns em
computação. Coisas como “trabalhar com dois grupos, um com a
ferramenta e outro sem a ferramenta”, até poderia ser parte de um método,
mas não é suficiente. Se a diferença entre as médias dos dois grupos for de
0,5 ponto percentual, pode-se concluir que um grupo foi melhor que o
outro? Ou pode ter sido obra do acaso? E se a diferença for de cinco pontos
percentuais? Como saber? Existem algumas informações trazidas pela
estatística que devem ser do conhecimento de qualquer pessoa que se
aventure a desenvolver pesquisa científica.
Além disso, existe ainda a possibilidade do mau uso da lógica. Os antigos
sofistas eram bastante requisitados entre os gregos para argumentação.
Entretanto, nem sempre a lógica usada por eles era exatamente a que
poderia ser aceita cientificamente. Um exemplo hilário de uso tortuoso da
lógica aparece no filme Monty Python em Busca do Cálice Sagrado,
quando Bedevere propõe um método infalível para determinar a identidade
de uma bruxa. Ao final de uma série de argumentações pseudológicas, ele
conclui que, se a mulher pesar tanto quanto um pato, será uma bruxa.
Basicamente, segundo Bedevere, bruxas queimam e madeira também
queima. Madeira flutua na água assim como os patos. Logo, se a mulher
pesar tanto quanto um pato é feita de madeira e, portanto, é uma bruxa.
3.4.1 Dados Versus Conceitos
O método de pesquisa não consiste apenas em coletar dados para suportar a
hipótese de trabalho. É necessário elaborar um discurso ponderado e
esclarecedor a partir desses dados. O aspecto mais importante de uma
monografia é o pensamento crítico e não apenas a coleta de informações.
Trabalhos acadêmicos que se restringem à realização de pesquisas de
opinião através de questionários com a consequente tabulação dos dados e
apresentação de gráficos não terão validade se não trouxeram consigo
alguma informação nova.
Lakatos e Marconi (2006) identificam o questionário como um
instrumento de pesquisa que dispensa a presença do pesquisador. Porém,
deve-se evitar a distribuição de questionários para serem respondidos se não
se sabe com antecedência qual a informação que se está buscando, ou seja,
qual a hipótese que se está tentando comprovar.
Além disso, em geral respostas diretas e interpretações simplistas não são
as mais interessantes. Por exemplo, há algum tempo pesquisadores
realizaram uma pesquisa na Inglaterra, onde entrevistaram homens e
mulheres perguntando quantos parceiros sexuais haviam tido ao longo da
vida. O resultado médio para as mulheres foi três e o resultado médio para
os homens foi 10. Uma interpretação ingênua e simplista desse fato diria
que o homem em média tem mais parceiros do que as mulheres. Porém,
considerando-se que existe aproximadamente o mesmo número de homens
e mulheres na sociedade, isso é impossível, visto que cada vez que um
homem tem uma nova parceira, uma mulher (a parceira) também tem
automaticamente um novo parceiro. Portanto, as duas médias deveriam ser
praticamente iguais. A conclusão da pesquisa foi, portanto, que ou os
homens mentem para mais, ou as mulheres mentem para menos, ou ambos
mentem quando se trata de quantificar o número de parceiros.
3.4.2 Pesquisa Experimental E Não-
Experimental
Uma das caracterizações clássicas das formas de pesquisa consiste na
classificação da pesquisa experimental e não-experimental.
Basicamente, a pesquisa não-experimental consiste no estudo de
fenômenos sem a intervenção sistemática do pesquisador. Por exemplo, um
pesquisador que estude o dia a dia de uma empresa de desenvolvimento de
software para detectar ali determinadas práticas previamente catalogadas
está fazendo uma pesquisa nãoexperimental, pois ele age apenas
observando e tirando conclusões a partir de um arcabouço teórico
preconcebido.
Já a pesquisa experimental implica que o pesquisador sistematicamente
provocará alterações no ambiente a ser pesquisado de forma a observar se
cada intervenção produz os resultados esperados.
No exemplo anterior, se o pesquisador resolver criar artificialmente
situações de estresse dentro da empresa para verificar como os funcionários
reagem, então ele estará realizando pesquisa experimental.
3.4.3 Objetividade
Uma característica bastante importante da pesquisa científica é a
objetividade. O pensamento humano permite a tirada de conclusões que
nem sempre são objetivas, como no caso das opiniões. Por exemplo, um
desenvolvedor pode considerar que a programação orientada a objetos é
mais fácil de usar do que a programação estruturada. Isso é apenas uma
questão de opinião. Mesmo que o desenvolvedor consiga estabelecer todo
um conjunto de argumentos para justificar essa opinião, ela ainda carece de
objetividade científica. Por quê? Porque a facilidade de uso não é uma
conclusão à qual chegaria qualquer observador independente. Um
programador experimentado em orientação a objetos pode considerar muito
fácil trabalhar com objetos e mensagens, mas um iniciante ou ainda um
programador experimentado em Cobol poderia ter dificuldade com tais
conceitos. Esse último ainda poderia sugerir que Cobol é que é muito mais
fácil de usar.
Segundo Kerlinger (1980), “a condição principal para satisfazer o
critério de objetividade é, idealmente, que quaisquer observadores com um
mínimo de competência concordem com seus resultados”.
Os experimentos e as observações no trabalho científico devem, então,
ser tratados de forma objetiva. Qualquer observação ou grandeza que se
queira avaliar deve ser definida de forma a que leituras possam ser feitas
independentemente do observador que as toma. Por exemplo, o pesquisador
poderia dizer que um sistema é “fácil de usar” se um determinado conjunto
de tarefas predefinido puder ser executado por um usuário com um
determinado grau de treinamento dentro de um período de tempo
predeterminado. A objetividade do conceito passa a ser então a pertinência
a um conjunto discreto.
Ainda é possível definir um fenômeno objetivamente, mas de forma
difusa, isto é, em vez de trabalhar com apenas duas categorias como “fácil”
ou “difícil”, trabalha-se com um grau de dificuldade inerente. Novamente, a
definição objetiva deve considerar uma medição que possa ser realizada de
forma independente por diferentes observadores e ainda assim chegar aos
mesmos resultados. Elaborando sobre o exemplo anterior, então, seria
possível definir o grau de dificuldade como o tempo médio que usuários
com determinado grau de treinamento levam para realizar um conjunto de
tarefas previamente definido usando a ferramenta. Nesse caso, diversas
medições chegarão a valores objetivos e comparações poderão ser feitas
entre sistemas.
Porém, ter uma definição objetiva de um fenômeno não é suficiente para
se produzir um trabalho de qualidade. É necessário observar ainda a
qualidade da própria definição. Ou seja, poderá haver pesquisadores que
não concordem que o tempo médio para realizar um conjunto de tarefas seja
uma boa definição para “facilidade de uso”. Levando o caso a um extremo
para melhor compreensão, se um pesquisador definisse que um sistema é
fácil de usar apenas se puder ser utilizado via Internet, essa definição
dificilmente seria aceita, pois se afasta muito daquilo que em geral se
considera, mesmo intuitivamente, como facilidade de uso.
Então, para trabalhar com observações de fenômenos, o pesquisador deve
definir de maneira objetiva o fenômeno que vai observar e convencer os
demais de que essa definição é razoavelmente intuitiva, mas em especial
útil, para chegar a algum resultado.
3.4.4 Empirismo
Há um ditado que já vem se tornando clássico em computação: “Teoria é
quando o fenômeno é compreendido, mas não funciona. Prática é quando
funciona, mas não se sabe por quê. Na Computação coexistem a teoria e a
prática: nada funciona e não se sabe por quê.”
Essa prática tem sido um dos significados adotados para o termo
“empírico” por desenvolvedores na área de computação. Não importa por
que, basta que funcione. Se funcionar está certo! Esse ponto de vista
pragmático, porém, não corresponde ao significado de empírico dado pela
ciência. Segundo Kerlinger (1980), “empírico significa guiado pela
evidência obtida em pesquisa científica sistemática e controlada”.
A computação, enquanto ciência, fundamenta suas pesquisas no
empirismo e não no princípio da autoridade. Em computação, na maioria
das vezes, pouco importa a opinião deste ou daquele expoente, mas as
conclusões objetivas obtidas empiricamente.
A falta de empirismo pode levar a conclusões erradas. Na idade média
acreditava-se que o homem tinha uma costela a menos do que a mulher, já
que a Bíblia relatava que a mulher havia sido criada a partir de uma costela
do homem. Essa crença poderia ser refutada sem dificuldades caso alguém
usasse de empirismo para simplesmente contar a quantidade de costelas em
um e outro sexo.
Já Descartes (2004) acreditava que o coração batia porque era o lugar
mais quente do corpo, e seu calor inflava o sangue que entrava nele. Essa
conclusão obtida com alguma reflexão mas pouca evidência empírica não
serve para mais nada hoje, pelo menos na área da Medicina.
O empirismo é importante para a ciência, portanto, porque é uma maneira
sensata de olhar o mundo. Não basta acreditar em sua intuição ou nas
palavras dos mestres. É preciso verificar objetivamente se o fenômeno
descrito realmente é verdadeiro.
Antes foi mencionado o fato de que o interesse pela Internet vem
crescendo muito nos últimos anos. Será verdade? Quem disse? E de onde
observou esse fato? É um sentimento comum e intuitivo. Possivelmente
vários livros e artigos sobre Internet têm falado isso ao longo dos anos. Mas
será essa afirmação realmente verdadeira hoje? Não estará o interesse pela
Internet estável ou diminuindo? O leitor provavelmente responderá “claro
que não” a essa última pergunta. Mas como pode ter tanta certeza? Fez
alguma observação empírica? Tem dados? Afinal o que é interesse? Como
se mede?
Essas dúvidas são importantes para o cientista que quer realmente
entender os fenômenos e descobrir novos conhecimentos. Se os médicos
atualmente continuassem acreditando que o coração bate porque aquece o
sangue, baseados na afirmação de Descartes, pouquíssimos avanços da
Medicina teriam sido conseguidos. Duvidar das conclusões de outros
cientistas e duvidar do próprio senso comum, muitas vezes, é a chave para
grandes descobertas.
3.4.5 Variáveis
Foi mencionada anteriormente a existência de fenômenos para os quais
interessa ao cientista realizar medições objetivas. Em geral, tais fenômenos
que podem ser medidos objetivamente são identificados como variáveis.
Uma variável é um nome que se dá a um fenômeno que pode ser medido e
que varia conforme a medição. Se não variasse seria uma constante e não
teria maior interesse para a pesquisa.
Variáveis em experimentos, assim como as variáveis em programas
computacionais possuem um domínio, ou seja, um conjunto de valores
dentro do qual a variável se altera. Por exemplo, uma temperatura em geral
será um número racional limitado inferiormente pelo zero absoluto (o valor
literal dependerá da escala que se use). Uma variável relacionada à
temperatura não poderá assumir o valor “Z” ou “falso”, já que esses não
pertencem ao seu domínio.
O domínio de uma variável pode ser discreto ou contínuo. Variáveis
contínuas assumem valores reais, a ideia de contínuo vem do fato de que
entre dois valores sempre existe um terceiro. Já as variáveis discretas
assumem seus valores em conjuntos cujos elementos podem ser ordenados
ou em conjuntos finitos. O número de participantes de uma
videoconferência é um fenômeno representado em uma variável cujo
domínio é discreto e corresponde ao conjunto dos números naturais. Os
valores desse conjunto podem ser ordenados, e entre o n-ésimo valor e o
(n+1)-ésimo valor não existe uma terceira possibilidade para qualquer n que
seja um número natural.
Algumas variáveis discretas assumem seus valores em conjuntos finitos.
Tais variáveis são denominadas categóricas. Por exemplo, as notas que um
estudante de mestrado na UFSC pode obter em uma disciplina variam no
conjunto {A, B, C, E}. Em ciência, muitas vezes fenômenos observados são
classificados com variáveis categóricas, pois estas são em geral mais fáceis
de compreender do que valores contínuos. Caso se avaliasse alunos com
valores contínuos, seria razoável concluir que um aluno com nota 6,7812 é
melhor do que um aluno com nota 6,7811?
Em alguns casos é possível estabelecer regras de transformação de
valores contínuos para discretos. Esse processo, chamado discretização,
consiste em atribuir um valor discreto diferente para variados intervalos de
valores contínuos. Por exemplo, considerando-se notas arredondadas para
uma casa decimal após a vírgula, pode-se estabelecer uma correspondência
entre o domínio contínuo e a variável categórica da seguinte maneira: notas
de 0,0 a 4,9 poderiam ser consideradas como o conceito E, notas de 5,0 a
6,9, como conceito C, notas de 7,0 a 8,9, como conceito B, e notas de 9,0 a
10,0, como conceito A. Note-se, porém, que quando se aplica o conceito de
arredondamento para uma casa decimal depois da vírgula o domínio da
variável já foi transformado de contínuo em discreto, pois, dessa forma, as
notas possíveis limitam-se a 101 valores: {0,0, 0,1, 0,2, …, 9,8, 9,9, 10,0}.
Na pesquisa científica é importante classificar ainda as variáveis como
medidas ou manipuladas. Uma variável medida é aquela cujo fenômeno
será observado pelo pesquisador. Por exemplo, quantas vezes um usuário de
uma ferramenta vai olhar no manual para obter informações para
desempenhar a tarefa que lhe foi proposta. Essa variável tem como domínio
o conjunto dos números naturais, e seus valores não são determinados pelo
observador, mas simplesmente medidos.
Já a variável manipulada é aquela que o experimentador vai
deliberadamente modificar para realizar seu experimento. Por esse motivo,
tal variável também é chamado de variável experimental. Um exemplo de
variável manipulada poderia ser o número de passos da tarefa repassada aos
usuários. O pesquisador poderia passar a alguns usuários, por exemplo,
tarefas com cinco passos, a outros com 10 passos, a outros com 15 passos
etc. Assim, ao fazer a experimentação, o pesquisador manipula a variável
referente ao número de passos da tarefa e observa o comportamento da
variável medida que consiste em contar quantas vezes o usuário vai olhar o
manual da ferramenta.
Mas por que pesquisadores manipulam uma ou mais variáveis enquanto
observam outras? É porque eles querem encontrar dependências entre essas
variáveis. No exemplo anterior, possivelmente o pesquisador estaria
tentando descobrir se tarefas mais longas implicam ou não o usuário
consultar o manual do sistema mais vezes.
A princípio pode-se testar a dependência entre quaisquer variáveis
manipuladas e observadas. Mas nem sempre esse teste fará sentido. Antes
de analisar uma dependência experimentalmente, o pesquisador em geral
desenvolve uma teoria ou hipótese. No caso anterior, a hipótese poderia ser
que quanto maior a tarefa, maior a consulta ao manual feita pelo usuário.
Outra hipótese possível seria que não importa o tamanho da tarefa, isso não
influenciará no número de vezes que o usuário consulta o manual. É uma
dependência que tanto em um caso quanto no outro parecem valer a pena
testar.
Mas nem sempre dependências que podem ser testadas fazem sentido
enquanto hipótese ou teoria. Por exemplo, manipular a variável “número de
botões na tela do aplicativo” e medir a variável “número de vezes que o
usuário espirra enquanto está usando a ferramenta”, pode até ser divertido,
mas dificilmente haverá uma conexão entre os dois fenômenos. Outro
exemplo seria observar o dia da semana e tentar verificar se programas
rodam mais rapidamente na sexta-feira. O pesquisador até poderia criar
experimentos controlados para mensurar isso. Mas dificilmente encontraria
uma conexão entre o dia da semana e a velocidade dos programas. Até
porque a teoria corrente sobre programas não estabelece nenhuma conexão
entre sua velocidade e o dia da semana. Tal hipótese então se revelaria
falha.
Daí vem a importância de se trabalhar com uma boa teoria em pesquisa.
Não basta realizar experimentos e encontrar relações entre variáveis. É
preciso ter uma teoria que procure explicar o porquê dessas relações.
Há aqui também a caracterização, bastante comum em pesquisa, dos
termos variável dependente e variável independente. A variável
independente é aquela que, se supõe, influencia outra. A variável
dependente é a influenciada.
Uma hipótese de pesquisa científica, então, em geral terá uma associação
de implicação, ou seja, antecedente/consequente, entre uma ou mais
variáveis independentes e uma ou mais variáveis dependentes. Por exemplo,
o número de passos em uma tarefa implica o aumento do número de vezes
que o usuário consulta o manual? Essa seria uma hipótese de pesquisa em
que a variável dependente é o número de consultas ao manual, e a variável
independente é o número de passos da tarefa. Em geral, o pesquisador
manipula a variável independente e mede a dependente. Nesse caso, ainda,
como ambas as variáveis são numéricas, pode-se afirmar que se busca
encontrar uma dependência direta, ou seja, quanto maior o número de
passos, maior o número de consultas. Em outros casos, se poderia pesquisar
dependências inversas, em que o aumento no valor da variável
independente causa uma diminuição na variável dependente.
Ainda existe a dependência linear e não-linear. A linear pode ser
aproximada por um polinômio de primeiro grau. Por exemplo, poderia ser
observado que, para cada passo na tarefa, o usuário faz mais duas consultas
ao manual. Nesse caso, a relação entre o número de passos x e o número de
consultas y poderia ser expressa pela função y = 2x.
Dependências não-lineares usualmente são representadas por polinômios
de grau superior a um ou ainda por equações com exponenciais, raízes ou
logaritmos. Este livro apresentará apenas os conceitos relacionados à
dependência linear. Para o leitor que queira se aprofundar em outras formas
de dependência recomenda-se a leitura de um bom livro de estatística, como
o de Barbetta, Reis e Bornia (2008).
3.4.6 Variância E Desvio-Padrão
Na pesquisa científica, frequentemente o pesquisador defronta-se com o
problema de analisar conjuntos de dados. Por exemplo, ao avaliar um
determinado sistema, o pesquisador contabiliza o tempo de interação de
cada pessoa dentre um conjunto previamente definido. Em geral, a média é
considerada uma medida importante na avaliação de conjuntos de valores.
Por exemplo, se quatro pessoas foram analisadas e os tempos medidos em
minutos foram 10, 12, 14, 9, então se pode dizer que o tempo médio
observado foi de 11,25 minutos.
A média aritmética simples consiste em somar os valores e dividir o
resultado pela quantidade de valores. Por isso, a média acima resultou do
cálculo (10 + 12 + 14 + 9)/4 = 11,25.
Porém, na pesquisa científica há outra medida importante, que é a
variância do conjunto de valores. Considerem-se os três conjuntos1 de
valores a seguir:
{10, 12, 14, 9}
{1, 20, 2, 22}
{11, 11, 11, 12}
É possível notar certa semelhança entre eles? Aparentemente são
conjuntos bem diferentes. Mas todos têm a mesma média: 11,25. A média,
então, passa alguma informação sobre a natureza dos conjuntos de valores,
mas ela sozinha não é a única informação importante.
Qual a diferença notável entre esses conjuntos? O terceiro apresenta
apenas valores muito próximos da média (ou muito próximos entre si). Já o
segundo apresenta valores bastante distanciados da média. O primeiro
conjunto é um caso intermediário.
Essa observação do distanciamento dos elementos em relação à média é
chamada de variância. Então, além da média, o pesquisador deve ficar
atento também à variância do conjunto de valores, já que esta complementa
a caracterização do conjunto.
A variância de um conjunto pode ser definida de forma numérica.
Basicamente deseja-se uma variância alta quando os valores se afastam
muito da média, seja para cima, seja para baixo. Então, a variância pode ser
o cálculo da diferença de cada valor do conjunto em relação à média deste.
No caso dos três exemplos anteriores, subtraindo 11,25 de cada valor o
resultado seria:
{10-11,25, 12-11,25, 14-11,25, 9-11,25} = {-1,25, 0,75, 2,75, -2,25}
{1-11,25, 20-11,25, 2-11,25, 22-11,25} = {-10,25, 8,75, -9,25, 10,75}
{11-11,25, 11-11,25, 11-11,25, 12-11,25} = {-0,25, -0,25, -0,25, 0,75}
O resultado corresponde à intuição: o terceiro conjunto, de baixa
variância, tem valores absolutos pequenos referentes à diferença entre os
valores originais e a média. Já o segundo conjunto tem os valores absolutos
mais altos, e o primeiro tem valores intermediários.
Agora, para obter um valor escalar para a variância se poderia somar os
valores obtidos. Porém, alguns deles são negativos. Não seria intuitivo que
um valor negativo pudesse anular a influência de um valor positivo no
cálculo da variância. Inclusive, pela própria definição até aqui usada, essas
somas invariavelmente resultariam em zero (o leitor pode conferir somando
os valores dos três conjuntos anteriores). Então, a simples soma dos valores
não é uma solução. É preciso somar apenas valores de mesmo sinal para
que se tenha efetivamente um escalar que corresponda à medida da
distância dos valores em relação à média do conjunto.
Uma opção seria trabalhar com o valor absoluto de cada diferença. Mas a
definição oficial de variância eleva os valores das diferenças ao quadrado
como forma de obter apenas valores positivos. Elevar esses valores ao
quadrado também permite aumentar a influência dos valores mais afastados
da média. Essa escolha tem origem em questões cuja explicação foge ao
escopo deste livro.
Então, elevando ao quadrado cada um dos valores dos conjuntos de
diferenças, obtêm-se:
{(-1,25)2, 0,752, 2,752, (-2,25)2} = {1,5625, 0,5625, 7,5625, 5,0625}
{(-10,25)2, 8,752, (-9,25)2, 10,752} = {105,0625, 76,5625, 85,5625,
115,5625}
{(-0,25)2, (-0,25)2, (-0,25)2, 0,752} = {0,0625, 0,0625, 0,0625, 0,5625}
Observa-se que os valores do terceiro conjunto são muito baixos
(próximos de zero), enquanto os do segundo conjunto são altos e os do
primeiro conjunto são intermediários, como se poderia esperar.
O próximo passo é somar os valores obtidos para os elementos de cada
conjunto, ficando-se respectivamente com:
Novamente como esperado, o maior valor, 382,75, fica com o segundo
conjunto, o menor com o terceiro e o intermediário com o primeiro.
Porém, somando-se simplesmente as diferenças, como foi feito antes,
fica-se com um valor de variância que aumenta conforme o tamanho do
conjunto. Isso não é intuitivo. A variância de um conjunto seria a dispersão
média dos elementos em relação à média do conjunto. Então ela não deveria
crescer com o tamanho do conjunto. É necessário então, para eliminar esse
efeito, dividir o valor escalar encontrado pelo número de elementos do
conjunto.
Porém, não é intuitivo dizer que um conjunto com um único elemento
tenha variância. No mínimo dois elementos são necessários para que faça
sentido dizer que eles se afastam da média. Assim, a divisão não será feita
pelo número de elementos no conjunto, mas pelo número de elementos
menos um. Assim, no caso de um conjunto com um elemento, a variância
será o resultado de uma divisão por zero e, portanto, indefinida.
No exemplo anterior, aplicando-se a divisão por três aos valores de
variância obtidos, fica-se com os valores finais de:
14,75/3 = 4,9166…
382,75/3 = 127,5833…
0,75/3 = 0,25
O que se pode concluir aqui é que o segundo conjunto é o que mais varia,
ou seja, seus elementos mais se afastam da média, enquanto o terceiro
conjunto é o que menos varia, ou seja, ele é o que tem os elementos
relativamente mais próximos da média.
A fórmula da variância pode ser então assim definida:
Onde é o símbolo comumente usado para representar a variância de X,
n é o número de elementos do conjunto, representa a média aritmética do
conjunto e xi representa cada um dos elementos do conjunto no somatório.
O desvio-padrão é uma medida também bastante utilizada para analisar
conjuntos e é definido simplesmente como a raiz quadrada da variância, ou
seja:
onde SX é o símbolo comumente usado para representar o desviopadrão.
No exemplo anterior, os valores de desvio-padrão dos três conjuntos são
respectiva e aproximadamente:
3.4.7 Covariância
A variância é uma medida muito importante para a pesquisa científica.
Basicamente pode-se dizer que não haveria muito o que fazer se os
fenômenos não variassem. Se cada variável estudada tivesse variância zero,
então os valores seriam previsíveis e pouco se poderia aprender sobre a
natureza das coisas.
Entretanto, os fenômenos variam, e quanto maior a variância, mais
interessante pode ser o fenômeno. A pesquisa em engenharia de software,
por exemplo, tenta descobrir formas de estimar quanto tempo um programa
levaria para ser desenvolvido. É uma medida difícil porque mesmo que se
tenha uma descrição detalhada de cada função ou caso de uso a ser
desenvolvido, o tempo que o desenvolvedor levaria para programar cada
um desses elementos poderia variar de alguns minutos a várias semanas.
Saber o tempo esperado (ou o tempo médio) ao criar os programas
necessários para realizar um caso de uso2 pode até ser útil ao fazer previsões
para conjuntos de casos de uso, mas médias aritméticas de um conjunto de
valores só costumam ser boas estimativas quando uma quantidade
significativa de valores está em jogo. Saber o tempo médio que se gasta
para programar um caso de uso não permite prever quanto tempo vai-se
levar para programar um dado caso de uso, tomado individualmente.
Similarmente, mesmo sabendo que em 1.000 jogadas de uma moeda,
aproximadamente 500 serão cara e aproximadamente 500 serão coroa, não
há meios de saber qual resultado será obtido em uma jogada específica.
No caso de conjuntos que variam muito, como do tempo que se leva para
programar casos de uso, será que não se trataria de considerar que não se
tem um único conjunto mas sim um certo número de subconjuntos, cada um
dos quais com características distintas? Cada um com sua própria média e
variância?
Voltando ao conjunto de maior variância do exemplo anterior, {1, 20, 2,
22}. Observando-se esse conjunto, não seria possível concluir que talvez se
trate de dois subconjuntos distintos? Ou seja, {1, 2} e {20, 22}. Nesse caso,
o que se tem são dois subconjuntos com médias distintas, e cada um dos
quais com variância bem menor do que a do conjunto original.
Seria necessário, então, construir uma teoria para determinar quais as
causas de certos elementos apresentarem medidas associadas ao primeiro
subconjunto ou ao segundo subconjunto, ou seja, qual a causa da existência
desses dois subconjuntos.
Voltando ao exemplo dos casos de uso. Não seria mais útil imaginar que
seria possível classificar esses casos de uso em, por exemplo, simples,
médios e complexos, para obter conjuntos de medidas com variância menor
e, portanto, mais previsíveis? E se, por exemplo, os casos de uso simples
pudessem ser programados em menos de um dia, os médios entre um dia e
uma semana e os complexos em mais de uma semana? Seria mais fácil
fazer previsões sobre o tempo que se levaria para desenvolver um sistema.
Bastaria contar a quantidade de casos de uso simples, médios e complexos e
multiplicar cada quantidade pela média de tempo associada a cada
subconjunto. A informação seria mais relevante, possivelmente, do que uma
única média aplicada ao conjunto inteiro dos casos de uso, pois com essa
abordagem seriam usadas características dos elementos do conjunto para
reduzir a incerteza sobre eles.
Porém, essa subclassificação introduz outro fator de incerteza: não se
sabe, a priori, se a forma de determinar que um caso de uso é simples,
médio ou complexo realmente classifica os casos de uso em subconjuntos
nos quais os valores de tempo de desenvolvimento tenham variância mais
baixa.
Nesse ponto poderia ser aplicada a experimentação científica para validar
a hipótese de que uma determinada técnica de classificação dos casos de
uso efetivamente classifica a complexidade destes adequadamente, ou seja,
que esse sistema de classificação colocará no conjunto “simples” os casos
de uso que efetivamente sejam mais rápidos de programar, e no conjunto
“complexos” os casos de uso mais difíceis, ficando os demais no conjunto
“médios”.
Para testar essa hipótese é necessário comparar dois conjuntos de valores:
o valor dado a um caso de uso pelo método de classificação e o valor do
tempo que efetivamente se leva para programar o caso de uso. Para efetuar
essa comparação é necessário usar o conceito de covariância, ou seja,
determinar em que grau os dois conjuntos variam conjuntamente.
Espera-se, então, que ao se ter as medidas dos tempos, os maiores tempos
estejam no conjunto “complexos”, os menores tempos no conjunto
“simples” e os demais tempos no conjunto “médios”. Para dar um
tratamento totalmente numérico aos conjuntos é possível denotar os
conjuntos simples, médios e complexos por números. Alguns trabalhos de
referência na área de pontos de caso de uso sugere aplicar valores
numéricos 1, 2 e 3 para casos de uso simples, médios e complexos,
respectivamente. Nesse caso, o que se busca é uma covariância entre esses
valores de pontos de casos de uso e os valores das medidas de tempo
obtidas. Pode ser questionado se a escala é correta. Por exemplo, não seria
mais adequado ter valores como 1, 2 e 5 em vez de 1, 2 e 3? É uma dúvida
válida, mas como a literatura propõe os valores 1, 2 e 3 e não é objetivo
deste exemplo questionar esse aspecto da teoria, então trabalha-se com
esses valores mesmo e não com outros (se esse exemplo fosse um projeto
de pesquisa, o fato de que não será considerada a hipótese de a proporção
ser diferente poderia ser uma limitação do trabalho).
Supondo que o pesquisador queira saber se um determinado método de
estimativa realmente classifica os casos de uso adequadamente, ele poderia
fazer experimentos da seguinte forma: (1) tomar um conjunto de casos de
uso aleatoriamente escolhidos cujo tempo de programação já seja conhecido
(neste caso, trata-se de um benchmark; se o tempo não for conhecido, o
pesquisador terá de efetuar ele mesmo os cálculos, possivelmente
solicitando a um ou mais programadores que desenvolvam os casos de uso
para verificar quanto tempo levam); (2) aplicar o método para classificar
cada caso de uso com os valores 1, 2 ou 3 e verificar se existe covariância
entre os dois conjuntos de valores obtidos. Supondo que os valores obtidos
pelo método de classificação para um conjunto de 10 casos de uso sejam os
que estão apresentados na Tabela 3.1, pode-se verificar intuitivamente que
para os valores mais altos de tempo tem-se a classificação com 3 pontos e
os valores mais baixos de tempo estão classificados com 1 ponto, portanto,
intuitivamente parece haver covariância.
Tabela 3.1
Exemplo de covariância alta e direta
Caso de Uso Tempo conhecido (horas) Pontos de caso de uso
UC1 1 1
UC2 18 2
UC3 4 1
UC4 67 3
UC5 22 2
UC6 12 2
UC7 2 1
UC8 7 1
UC9 18 2
UC10 55 3
A covariância é considerada alta porque efetivamente os menores valores
da coluna “tempo” coincidem com os menores valores da coluna “pontos de
caso de uso”, e os maiores valores da coluna “tempo” coincidem com os
maiores valores da coluna “pontos de caso de uso”. A variância também é
considerada direta ou positiva porque quanto maior o valor da coluna
“tempo”, maior o valor da coluna “pontos de caso de uso”.
Em outra situação, poderia ser observada uma relação inversa, ou seja,
quanto maior o valor numa coluna, menor na outra. Se fosse assim, então a
covariância seria negativa.
Também seria possível que não houvesse nenhuma ou pouca relação
entre os tempos conhecidos e o resultado do método de classificação. Um
método de classificação totalmente arbitrário não poderia, a princípio, gerar
alta covariância, como, por exemplo, um método que atribua aos casos de
uso valores sequenciais 1, 2 e 3 em função da ordem em que estes
aparecem. A Tabela 3.2 apresenta uma comparação entre os tempos
conhecidos e os resultados desse método arbitrário.
Tabela 3.2
Exemplo de baixa covariância
Caso de Uso Tempo conhecido (horas) Pontos de caso de uso
UC1 1 1
UC2 18 2
UC3 4 3
UC4 67 1
UC5 22 2
UC6 12 3
UC7 2 1
UC8 7 2
UC9 18 3
UC10 55 1
Intuitivamente é possível perceber que não existe uma relação bem
definida entre os valores altos da coluna “tempo” e da coluna “pontos” nem
entre os valores baixos da coluna “tempo” e os da coluna “pontos”.
A questão agora consiste em como tratar numericamente a covariância
para que se possa, por exemplo, comparar diferentes métodos de
classificação de casos de uso, decidindo quais são os melhores.
Numericamente, então, a covariância pode ser calculada a partir dos
desvios da média em cada conjunto. Se no primeiro conjunto um valor se
desvia muito para cima da sua média, espera-se que no segundo conjunto o
valor correspondente também se desvie muito para cima da sua própria
média. Por outro lado, se ocorre o inverso, ou seja, se o desvio no segundo
conjunto ocorre para baixo da média, então há uma relação negativa.
No final, se todos os desvios para cima ou para baixo são semelhantes
nos dois conjuntos, haverá covariância alta e positiva. Se os desvios forem
sempre invertidos, ou seja, para cima em um conjunto e para baixo no
segundo e vice-versa, então a covariância também será alta, mas negativa.
Finalmente, se em alguns casos os desvios coincidem e em outros não, têm-
se valores positivos e negativos, levando a uma covariância próxima de
zero e, portanto, baixa.
Assim, para calcular a covariância costuma-se usar o produto das
diferenças de cada elemento em relação à média do conjunto ao qual ele
pertence. Seja X = {x1, x2, …, xn} o primeiro conjunto e Y = {y1, y2, …, yn} o
segundo conjunto, ambos de mesmo tamanho, pois só é possível calcular
covariância se para cada elemento de X corresponde um elemento de Y,
então a covariância é calculada em função dos produtos: .
Dessa forma, cada vez que os elementos correspondentes nos dois
conjuntos se desviam conjuntamente para cima da média ou para baixo da
média, o resultado será positivo. Se um se desvia para cima e outro para
baixo, o resultado será negativo. Quanto mais os dois elementos se desviam
da média, maior o valor absoluto do produto.
A covariância pode então ser calculada simplesmente como o somatório
desses produtos, dividido pelo número de elementos do conjunto de valores
menos um, ou seja:
Onde SXY é o símbolo usual para representar a covariância entre os
conjuntos X e Y.
Agora, conhecendo a definição matemática da covariância pode-se
aplicar esse conceito para identificar entre os dois métodos qual é mais
adequado para fazer estimativas de tempo de desenvolvimento de casos de
uso. A Tabela 3.3 apresenta o cálculo da covariância para o primeiro
método. A média dos tempos conhecidos, , é 20,6 e a média dos valores de
classificação, , é 1,8.
Então, o valor da covariância entre os dois conjuntos consiste na
somatória da última coluna da Tabela 3.3 dividido por n-1, ou seja: 149,2/9
= 16,57777…. Mas o que significa esse número? A partir dele é possível
concluir que os valores de um conjunto são afetados pelos valores do outro
conjunto? A covariância não produz um número normalizado, como será
explicado em seguida. Então, o valor da covariância serve basicamente para
comparar um par de conjuntos com outro par de conjuntos, desde que as
unidades de medida dos dois pares sejam idênticas.
Seguindo esse raciocínio, é de se esperar que o método arbitrário,
apresentado na Tabela 3.2, designado agora como Y’ apresente um valor de
covariância bem mais baixo do que o primeiro método, designado na Tabela
3.3 como Y. A Tabela 3.4 apresenta o cálculo da covariância para o método
arbitrário, levando em conta que a média dos valores obtidos pelo método
arbitrário é 1,9.
Tabela 3.3
Covariância para o primeiro método
Tabela 3.4
Covariância para o método arbitrário
Assim, a covariância entre esses dois conjuntos é a somatória da última
coluna da Tabela 3.4 dividido por 9, ou seja, –70,4/9 = –7,822222…. O
sinal negativo indica que se existe eventualmente alguma covariância, esta é
negativa, mas o valor absoluto obtido para o método arbitrário é menos do
que a metade do valor obtido para o primeiro método. Ou seja, a
covariância do primeiro método em relação aos valores de tempo é maior
do que a covariância do método arbitrário.
3.4.8 Correlação
Como mencionado anteriormente, o valor absoluto da covariância não diz
muita coisa sobre um conjunto estar influenciando o outro ou não. Por esse
motivo usa-se mais frequentemente a correlação. Esta tem basicamente o
mesmo significado intuitivo da covariância, mas o resultado numérico varia
entre –1 e 1, em que perto de –1 significa correlação negativa muito forte,
perto de 1 significa correlação positiva muito forte e perto de 0 significa
ausência de correlação.
Existem vários tipos de cálculo de correlação possíveis. O mais
conhecido é o coeficiente de correlação de Pearson, obtido dividindo-se o
resultado de , que (dividido por n-1) é usado para obter a
covariância, pelo produto do desvio-padrão de cada um dos dois conjuntos
de valores, ou seja:
Retornando ao exemplo anterior, pode-se calcular a correlação do
primeiro método da seguinte forma:
a) Já se tem o valor de que é 149,2.
b) Calcula-se o desvio-padrão do conjunto dos tempos como a raiz
quadrada da variância desse conjunto: SX = 67,94409467.
c) Calcula-se o desvio-padrão do conjunto dos resultados do primeiro
método como a raiz quadrada da variância desse conjunto: SY =
2,366431913.
d) Calcula-se o coeficiente de correlação de acordo com a fórmula
anterior: rXY = 149,2/(67,94409467 * 2,3661913) = 0,928041193.
Para o método arbitrário tem-se:
a) O valor de é −70,4.
b) Desvio-padrão do conjunto dos tempos é o mesmo: SX = 67,94409467.
c) Desvio-padrão dos resultados do método arbitrário: SY = 2,626785107.
d) Coeficiente de correlação é, portanto, rXY = –70,4 / (67,94409467 *
2,626785107) = –0,39445403.
Pode-se tirar duas conclusões desses valores. Em primeiro lugar, o
primeiro método tem um índice de correlação com os tempos conhecidos
bastante próximo a 1 e, portanto, parece ser um método de boa qualidade.
Já o método arbitrário tem uma correlação negativa e mais próxima de 0 do
que de 1, não podendo ser considerado, portanto, como um bom método
para estimativa de tempo.
A intuição, porém, diz que a correlação do método arbitrário deveria ser
ainda mais próxima de zero. O método arbitrário atribui valores sequenciais
que nenhuma relação tem com os tempos dos casos de uso. Por que não é
assim? É que o conjunto de valores examinado é pequeno. Pode-se observar
que em alguns casos há até coincidência entre o primeiro método e o
método arbitrário. Essas coincidências é que podem levar a crer que o
método funcione. Levando a um extremo, se em vez de usar os 10 valores
que foram usados para cada método se tivesse trabalhado apenas com os
dois primeiros valores, os dois métodos dariam exatamente o mesmo
resultado e seriam considerados equivalentes. Mas isso é apenas uma
coincidência devido ao pequeno número de situações analisadas.
Um problema a ser considerado, portanto, quando se faz esse tipo de
experimento para encontrar correlação entre dois conjuntos de valores é
saber se o tamanho da amostra é suficiente para considerar a correlação
como efetivamente significativa ou se o valor foi obtido apenas por
coincidência. Felizmente existe um método para testar isso. Como a
correlação é um índice que deve convergir para um valor à medida que se
aumenta o tamanho do conjunto considerado, então não existe certeza
absoluta sobre o índice, a não ser que o conjunto seja infinito. Porém,
conjuntos infinitos são impossíveis de trabalhar empiricamente.
Trabalhando então sempre com conjuntos finitos, é necessário estabelecer
um índice de confiabilidade aceitável. Em geral, em estatística, trabalha-se
com o índice de 95% de certeza, considerado suficientemente alto para a
maioria das aplicações.
O teste para verificar então se um coeficiente de correlação é ou não
significativo vai considerar o índice de certeza. Se esse índice for
estabelecido em 95%, então, dependendo do tamanho do conjunto
examinado, existirá um valor limite para que um coeficiente de correlação
seja considerado significativo. O cálculo desses valores foge ao escopo
deste livro, mas a Tabela 3.5 apresenta alguns valores que podem ser usados
como referência.
Considerando agora que os experimentos anteriores foram realizados
com 10 casos de uso, o valor mínimo de para que a correlação seja
considerada significativa é, pela Tabela 3.5, de 0.6319 no caso de
correlação positiva e máximo de –0,6319 no caso de correlação negativa.
Então, o primeiro método, com correlação 0,928041193 já pode ser
considerado suficientemente analisado para se concluir que efetivamente
existe uma forte relação entre o número de pontos de caso de uso que ele
produz e o tempo esperado para programar esses casos de uso.
Já o método arbitrário, com correlação de –0,39445403, não atingiu um
valor de correlação suficiente para que possa ser considerado que possui
correlação negativa com os tempos.
Portanto, o resultado é conclusivo para o primeiro método e inconclusivo
para o método arbitrário. Foi demonstrado que o primeiro método atende à
expectativa, mas não foi demonstrado nada a respeito do segundo método.
Caso o pesquisador estivesse tentado demonstrar que o método arbitrário
funciona, ele teria de aumentar o tamanho do conjunto de valores
analisados e calcular um novo índice de correlação, aplicando então outros
valores mínimos de acordo com a Tabela 3.5. Porém, o bom-senso diz que,
considerando-se a natureza totalmente independente entre os valores dos
tempos e os resultados do método arbitrário, por maior que seja o conjunto
de valores nunca se chegará a provar qualquer tipo de correlação entre os
dois conjuntos. No limite haverá tantos elementos no conjunto que o índice
de correlação será praticamente igual a zero.
Tabela 3.5
Valores mínimos de correlação para ser considerada
significativa com 95% de certeza
3.4.9 A Hipótese De Pesquisa
Um aspecto que diferencia o trabalho científico do trabalho técnico é a
existência de uma hipótese de pesquisa. A hipótese é uma afirmação da qual
não se sabe a princípio se é verdadeira ou falsa. O trabalho de pesquisa
consiste justamente em tentar provar a veracidade ou falsidade da hipótese.
Um objetivo sem uma boa hipótese pode ser muito arriscado.
Anteriormente foi dito que o objetivo consiste em tentar produzir algum
conhecimento que ainda não existe. Mas se não houver uma boa hipótese
para justificar esse objetivo, corre-se o risco de realizar a pesquisa sem
obter resultados. Por exemplo, ter como objetivo de pesquisa provar que P
= NP é perfeitamente válido, pois esse problema é relevante à sociedade e o
conhecimento necessário para resolver o problema ainda não existe. Porém,
com que hipótese o pesquisador vai trabalhar? Se o problema de pesquisa
for colocado simplesmente como “provar que P=NP”, o pesquisador poderá
ficar tateando a esmo, e o risco de fracasso será muito grande.
É necessário, portanto, ter uma hipótese.
Segundo Comer (2008), uma tese é uma hipótese ou conjectura. O texto
da tese ou monografia é um documento em que o aluno apresenta
argumentos a favor de sua tese. Daí a confusão que muitas vezes se faz com
o termo “tese”, que pode representar tanto o documento escrito, quanto a
hipótese de pesquisa.
O método, como discutido anteriormente, deverá indicar como os testes
deverão ser feitos. Ao final dos experimentos haverá evidências a favor ou
contra a hipótese inicial. Nesse caso, alguém poderá perguntar, “e se não se
conseguir provar que a hipótese era válida?”. A resposta para essa pergunta
dependerá de quão relevante era a hipótese original. Uma hipótese qualquer
escolhida a esmo, sem nenhum tipo de justificativa, se não for confirmada,
não traz nenhuma informação nova para a área de pesquisa. Mas uma
hipótese sólida e bem justificada, com evidências de validade, que ao final é
invalidada, pode produzir a informação interessante. No pior dos casos
provará que aquilo que eventualmente se poderia aceitar intuitivamente
como verdadeiro não resistiu à prova. É dessa forma que muitos mitos
podem ser derrubados.
Sendo assim, além do objetivo, hipótese e metodologia, é fundamental
que o trabalho de pesquisa tenha como base uma boa justificativa para a
escolha da hipótese. Uma hipótese bem justificada no início do trabalho
aumenta as chances de sucesso. Em primeiro lugar, é mais provável que ela
seja verdadeira do que uma hipótese sem justificativa. Em segundo lugar, se
ela for falsa, o trabalho terá o mérito de ter derrubado algum mito.
O trabalho científico na área de Computação consiste então em formular
uma hipótese e coletar evidências para comprovar a sua validade. Essas
evidências podem ser obtidas basicamente de três formas:
a) Construindo uma teoria, que a partir de fatos aceitos e deduções válidas
prove que a hipótese é verdadeira.
b) Realizando certo número de experimentos controlados, que
estatisticamente comprovem a validade da hipótese. Porém, devese ter
em mente que esse tipo de comprovação é sempre sujeito a erros.
Normalmente se aceita que hipóteses sejam comprovadas com 95% de
certeza.
c) Realizar estudos de caso, comparativos, argumentações, colher opiniões
através de questionários e outras formas que dificilmente constituem
uma prova, mas que podem ser evidências da validade da hipótese.
É possível também realizar um trabalho estruturado sobre combinações
de duas ou três formas anteriores. De qualquer maneira, o importante é que
a partir da formulação da hipótese, o pesquisador esteja engajado no
processo de busca de evidências, e que essas evidências sejam estruturadas
em um discurso coerente, em que ele apresenta a sua argumentação para a
comunidade científica.
Um problema de pesquisa, então, em geral vai perguntar como duas ou
mais variáveis se relacionam, e se existe correlação positiva ou negativa
entre os valores das variáveis. A existência dessas correlações, porém, ainda
não prova causas. Uma teoria consistente que explique causa e efeito
precisa também ser elaborada, além da validação empírica. Isso acontece
porque algumas vezes duas variáveis até se correlacionam com alto índice,
mas as causas envolvidas podem não ser tão diretas.
Cita-se como exemplo o caso de uma empresa que decidiu verificar se
funcionários bem alimentados trabalhavam melhor. A empresa passou a
servir um café da manhã saudável para seus funcionários em todas as filiais
e, em praticamente todas, a produtividade aumentou. Mas será realmente
verdade? Qual a explicação? Será que foi mesmo a alimentação que fez os
funcionários trabalharem mais? Na sequência a empresa testou retirar o café
da manhã saudável para verificar se os trabalhadores retornavam ao ritmo
anterior. Para surpresa de todos, a produtividade cresceu ainda mais.
Como um cientista lidaria com esses dados aparentemente
contraditórios? O caso aqui é que se trata de verificar o real motivo do
aumento de produtividade. Este não ocorreu por conta de uma alimentação
melhor, mas pelo fato de que houve uma significativa modificação no dia a
dia da empresa. Funcionários estão acostumados a perceber que
modificações na empresa em geral implicam demissões. Por isso, cada vez
que se observa uma modificação no ambiente (introdução ou retirada do
café da manhã), os funcionários tendem a trabalhar mais para serem
notados e garantirem seus empregos.
3.5 Justificativa
Foi comentado anteriormente que uma hipótese de trabalho é muito
arriscada se não estiver solidamente apoiada em uma boa justificativa que
apresente evidências de que vale a pena investir tempo e recursos na
tentativa de comprovar a hipótese. Quem em sã consciência se proporia a
trabalhar dois anos para provar que o método arbitrário definido
anteriormente faz boas previsões em estimativa de esforço? Uma boa
hipótese precisa ser justificável.
Em uma monografia, pode-se justificar o tema de pesquisa, mas mais
importante ainda é justificar a escolha do objetivo e da hipótese. Por
exemplo, se o tema de pesquisa é “compactação de texto”, o objetivo de
pesquisa é obter um algoritmo com maior grau de compactação do que os
algoritmos comerciais, e a hipótese de pesquisa pode consistir em utilizar
um determinado modelo de rede neural para realizar essa compactação,
então a justificativa do tema deverá se concentrar em mostrar que é
necessário obter algoritmos de compactação melhores. Adicionalmente, a
justificativa da hipótese deverá se concentrar em apresentar evidências de
que o modelo de rede neural escolhido poderá produzir resultados melhores
do que os algoritmos comerciais.
Em geral, a justificativa do tema aparece na contextualização do trabalho,
em que se tenta justificar ao leitor que o problema escolhido realmente é
relevante (no exemplo anterior, compactação de textos). Mas na maior parte
das vezes esse convencimento é pacífico. Mais difícil é justificar uma
hipótese de trabalho, pois para isso será necessário apresentar alguma
evidência de que uma determinada linha de pesquisa pode levar a bons
resultados quando ainda não se efetuou essa pesquisa (no exemplo anterior,
justificar o uso do modelo específico de redes neurais para compactar
textos). Essas evidências podem ser referências a outros trabalhos que
eventualmente mostraram algum tipo de resultado que aponte para a
viabilidade da hipótese escolhida, ou ainda em dados colhidos
preliminarmente pelo próprio autor do trabalho ou em um estudo de caso.
3.6 Resultados Esperados
Em geral, os resultados esperados são situações que o autor de um trabalho
espera que ocorram, caso seus objetivos sejam atingidos. Os resultados
esperados normalmente fogem ao escopo do trabalho. O autor da pesquisa
não tentará obter os resultados esperados ao final da pesquisa. Eles são
posteriores.
Isso diferencia os resultados esperados dos objetivos. Os objetivos serão
perseguidos pelo autor, e ao final do trabalho ele dirá se foram ou não
atingidos. Os resultados esperados possivelmente ocorrerão após a
conclusão do trabalho.
Por exemplo, o objetivo do trabalho poderá ser definir um método de
cálculo de esforço para desenvolvimento de software mais preciso do que
os métodos do estado da arte. O autor da pesquisa deverá ter uma boa
hipótese para fundamentar esse objetivo em primeiro lugar. Depois, ele
deverá realizar um conjunto de experimentos que, juntamente com uma
base teórica, demonstrarão a validade ou não da hipótese.
Esse autor poderá apresentar, inicialmente, como resultados esperados de
seu trabalho, a adoção do seu método pela indústria e um melhor
desempenho das empresas produtoras de software que venham a utilizar
esse método.
Como se vê aqui, é praticamente impossível que o autor obtenha esses
resultados esperados durante a realização de sua pesquisa. Mas eles poderão
eventualmente ocorrer depois. Também é possível que não ocorram, pois,
por outros motivos quaisquer, poderá acontecer que nenhuma empresa
venha a adotar o seu método.
Assim, pode-se dizer que os objetivos devem ser verificáveis ao final do
trabalho, inclusive os objetivos específicos. Já os resultados esperados são
apenas esperanças e não podem necessariamente ser verificados ao final do
trabalho.
No início do trabalho de pesquisa, uma forma de se tentar determinar
quais são os resultados esperados do trabalho consiste em fazer a pergunta
“o que possivelmente mudaria no mundo se eu atingisse os objetivos da
minha tese/monografia?”.
3.7 Limitações do Trabalho
Ao contrário do que alunos iniciantes muitas vezes pensam, não é possível
resolver todos os problemas da humanidade em dois ou três anos de
trabalho (“síndrome de querer mudar o mundo”, ou “síndrome do Prêmio
Nobel”).
Um trabalho de pesquisa pode começar muitas vezes com um objetivo
demasiadamente amplo e, portanto, inalcançável durante o tempo
disponível para a realização do curso. Sendo assim, muitas vezes é
necessário realizar cortes nos objetivos, ou limitar a forma de persegui-los.
Em vez de demonstrar que uma hipótese é sempre verdadeira, pode-se optar
por demonstrar que ela é verdadeira apenas em determinadas condições,
para as quais foi possível realizar testes convincentes. Por exemplo, o
método de estimativa de esforço mencionado na seção anterior poderia ser
comprovadamente mais preciso apenas para uma determinada classe de
sistemas, como, por exemplo, sistemas baseados em Web. O fato de que o
método não foi testado com outros tipos de sistemas impõe uma limitação
ao trabalho.
As limitações são, portanto, aspectos do trabalho dos quais o autor tem
consciência e reconhece a importância, mas não tem condições de abordar
no tempo disponível.
É importante, em trabalhos de pesquisa, que as limitações conhecidas
sejam claramente identificadas pelo autor desde o início. Isso evitará que o
próprio autor muitas vezes se perca em divagações ou buscando aspectos
que extrapolam os objetivos iniciais. Isso evita também que o leitor crie
expectativas demasiadamente amplas sobre o trabalho, que serão depois
frustradas.
Novamente, espera-se que uma boa interação com o orientador ajude o
aluno a colocar as devidas limitações nos seus objetivos, para que o
trabalho possa ser concluído com sucesso no tempo disponível.
3.8 Discussão
De acordo com o que foi visto neste capítulo, o trabalho de pesquisa deverá
estar enquadrado em um tema que, como área de conhecimento, deverá ser
plenamente conhecido pelo pesquisador. Dentro do tema, o pesquisador
deverá estabelecer um objetivo a ser buscado. Esse objetivo deverá estar
baseado em uma hipótese de trabalho, que deve ter uma boa justificativa
para ter sido escolhida. O método vai esclarecer como a hipótese será
comprovada pelo autor do trabalho, e as limitações deixarão claros quais
aspectos não serão abordados.
É compreensível a dificuldade de muitos alunos que ingressam,
especialmente no mestrado, em compreender essa estrutura e realizar um
trabalho organizado dessa forma. Surgem assim dissertações que muitas
vezes são meramente uma apresentação de um sistema, ou uma proposta
testada em apenas uma ou duas situações, ou, ainda, dissertações que se
concentram em coletar dados e não elaboram adequadamente os conceitos
que os dados representam.
Essa dificuldade deve-se, especialmente, ao fato de que pela primeira
vez, talvez, em sua vida o aluno será colocado diante de um trabalho
individual extenso, em que a sua iniciativa será fundamental para o sucesso.
Trabalhos escolares, mesmo na graduação e na especialização, resumem-se,
muitas vezes, apenas à pesquisa bibliográfica. O aluno simplesmente coleta
material de várias fontes e organiza essa informação de uma maneira
pessoal. A estrutura da pesquisa científica, especialmente no mestrado e no
doutorado, vai muito além da pesquisa bibliográfica, como se procurou
mostrar neste capítulo.
1O conjunto, na matemática, não admite repetição de elementos. No entanto, aqui a palavra
“conjunto” é usada em sentido mais amplo, significando “coleção” ou “multiconjunto” e, portanto,
admitindo repetição de elementos.
2O conceito de caso de uso é descrito de forma compreensível por Wazlawick (2004).
C A P Í T U L O 4
Análise Crítica de Propostas de
Monografia
No curso da disciplina de Metodologia da Pesquisa no Programa de Pós-
Graduação em Ciência da Computação da UFSC, dezenas de alunos
ingressantes foram convidados a apresentar um seminário com uma
proposta de pesquisa. As apresentações foram utilizadas para ajudar os
alunos a perceberem problemas em suas propostas e melhorá-las. Neste
capítulo analisaremos alguns textos contidos nessas propostas antes de sua
melhoria, ou seja, os textos apresentados são material não revisado pelos
alunos. Dessa forma considerou-se apropriado não mencionar os nomes dos
autores deste material, sendo colocado entre aspas o texto que é de
produção dos alunos e os comentários logo em seguida.
4.1. Análise da Contextualização e
Colocação do Problema
Nesta seção são analisados textos referentes à contextualização do
problema. A avaliação verifica se o problema é, de fato, um problema de
pesquisa e se está bem claro. Os resultados são apresentados a seguir.
“Uma das grandes dificuldades que o acadêmico encontra ao
ingressar em uma universidade é confrontar-se com a disciplina
Metodologia da Pesquisa. Desconhece a ABNT e suas normas bem
como as propostas de formatação e estruturação de um relatório de
pesquisa. Para amenizar o problema, pretendese elaborar um sistema
multimídia, utilizando-se de técnicas referentes ao desenvolvimento de
sistemas deste tipo como: ergonomia de software, um método de apoio
para aprimorar a interação usuáriomáquina e a distribuição dos
recursos no sistema.”
Em relação a esse texto, cabem os seguintes comentários: de onde vem a
informação sobre “isto ser uma grande dificuldade”? Observação do autor
(experimentos)? Ou pesquisa bibliográfica? Quem demonstrou que essa
informação é verdadeira?
Mesmo supondo que se trate de um problema real, caberia ainda
perguntar por que o aluno considera que um sistema multimídia será uma
solução. Não existem outras possibilidades? Aqui parece que já se escolheu
a ferramenta sem analisar o problema em si detalhadamente.
Deve-se considerar em casos como esse que a observação do problema
pode estar localizada, como no caso do aluno que observou que o rio que
cruzava a cidade onde ele morava não podia ser atravessado. O problema
referido pode então ser consequência das técnicas de ensino de um
professor em particular, que o aluno tenha observado e não se tratar de
problema generalizado que afeta todas as instituições de ensino.
“No Departamento de Tecnologia da Informação da *** não há um
método específico para gerenciar projetos de desenvolvimento de
software terceirizado. Projetos terceirizados de desenvolvimento de
software têm sido entregues com atrasos e com os requisitos não sendo
plenamente atendidos.”
O problema refere-se a uma empresa específica. Se essa empresa não usa
um método para gerenciar projetos, então a solução é implantar um método
existente que já tenha sido testado, ou seja, trata-se de um trabalho técnico.
Esse problema, da forma como está colocado, não justifica uma proposta
de pesquisa, como, por exemplo, neste caso, em que será proposto o
desenvolvimento de um método para gerenciamento de terceirizados.
“O sistema *** está constituído por 14 instituições (…) de ensino
superior. Não houve um aumento no número destas instituições, mas
as instituições estão se expandindo. O número de alunos matriculados
vem aumentando ano a ano. As informações serão retiradas do
questionário socioeconômico e da secretaria acadêmica que formam
uma grande base de dados, possibilitando a utilização de data mining
nesta base de dados.”
Aqui existe uma oportunidade, não um problema. A oportunidade é a
existência de dados em abundância, portanto, propõe-se fazer data mining
nesses dados. Mas falta informar o que se pretende descobrir ao analisar os
dados ou pelo menos que pista se está seguindo. Como dizem, “se você não
sabe para onde quer ir, qualquer estrada serve”.
“Octrees são usadas para representação espacial de cenários e
objetos. São empregadas por possibilitar a rápida determinação de
partes não visíveis. Necessitam de precisão infinita para representar
curvas (distorcem a realidade).”
Aqui temos um bom exemplo de contextualização. A mensagem é rápida,
mas coloca um problema de forma clara. Mesmo que o leitor não saiba o
que são octrees, o autor informa que elas são usadas para representação
espacial de cenários e objetos. Além disso, o autor informa que elas sofrem
de um problema sério: necessitam de precisão infinita.
“Serviços distribuídos têm sido usados para obter transparência,
desempenho e confiabilidade em sistemas. Dentre os problemas
encontrados, está a dificuldade em se obter alta confiabilidade com
perda mínima de desempenho.”
Aqui o aluno apresenta uma clara relação de custo-benefício: é difícil
melhorar confiabilidade sem perder desempenho. A afirmação inicial,
porém, é um tanto genérica e poderia ser mais bem detalhada.
“Aplicação do Raciocínio Baseado em Casos (RBC) na Previsão
Meteorológica. Utilização de casos passados (tempo) na busca de uma
possível solução (previsão).”
Aqui não foi identificado um problema. Previsão meteorológica é o tema.
Aparentemente o aluno já escolheu a ferramenta (RBC) e agora quer ver
como ela funciona. Mas não especificou o problema nem justificou a
escolha da ferramenta.
“Um sistema elétrico é composto por vários componentes que
necessitam ser desligados para manutenção durante certo período:
geradores, linha de transmissão etc. O funcionamento do sistema
elétrico pode ser representado por equações que representam as
limitações físicas dos componentes. O problema é aplicar a
maximização da carga máxima atendida em vários cenários. O
sistema deve considerar o modelo estocástico relacionado aos
reservatórios.”
Aqui parece que o aluno confunde o problema com o objetivo.
Maximizar a carga atendida parece ser o objetivo desejado, mas qual o
problema de fato? Não existem métodos matemáticos ou sistemas para
fazer essa maximização? Se existem, eles sofrem de quais limitações? Essas
limitações, que possivelmente existem, é que consistiriam no verdadeiro
problema de pesquisa.
“A reflexão computacional é um mecanismo amplamente reconhecido
para adaptar e reconfigurar software em tempo de execução.”
Observe como o advérbio “amplamente” pode ser dispensado da frase
sem lhe prejudicar o sentido. De resto, trata-se de uma informação,
meramente, não de um problema.
“Reconstrução 3D é crítica em vários domínios de aplicação e é
pesquisada hoje quanto à exatidão (acurácia), precisão (completude e
nível de detalhe) e desempenho (velocidade), em que o problema é
encontrar a geometria 3D correspondente a partes da cena observada
ou a toda ela. No atual estado de desenvolvimento da área, não há
uma teoria geral que unifique o problema. Portanto, estudos são feitos
em contextos específicos e aplicando-se restrições. Desse modo,
existem abordagens que usam múltiplas visões da cena, algum
conhecimento prévio do objeto, indexação por aspectos da imagem
etc. A união e melhoramento de algumas dessas abordagens é um
campo promissor de pesquisa.”
A contextualização limita bem o problema. A afirmação de que não há
uma teoria geral da área deve ser justificada por uma bibliografia que faça
essa afirmação ou por um estudo do próprio autor, em que, ao comparar
diversos trabalhos, chega à conclusão de que tal teoria é efetivamente
inexistente. O aluno indica claramente um campo de pesquisa, mas não
necessariamente ainda um problema de pesquisa. Como a área é
caracterizada por várias abordagens que se complementam, é possível tentar
realizar junções e aprimoramentos entre as diversas teorias. Faltaria,
possivelmente, definir quais seriam os ganhos dessas abordagens.
Eficiência? Eficácia? Ou apenas uma organização melhor da área de
conhecimento?
“GIS (Geographical Information System). A integração dos dados
geográficos e alfanuméricos ainda é um grande desafio. Os dados
manipulados comumente fazem parte de um sistema maior. A
interoperabilidade é fundamental.”
O texto originalmente estava estruturado em tópicos. Aqui é possível
perceber claramente um problema; interoperabilidade entre sistemas de
base de dados textuais e sistemas de dados geográficos. Resta caracterizar
isso como um problema de pesquisa e não como problema técnico. Da
forma como está, parece ser apenas um desafio técnico dar solução a esse
caso.
“Grande parte das MPEs não possuem um processo definido.
Limitações de recursos humanos e financeiros para adoção de
processos densos ou serviços de consultoria. Os processos ágeis
prometem simplicidade e desempenho para pequenas equipes, porém
são escassas a evidências empíricas de aplicações em MPEs. Os
processos ágeis não evidenciam de forma clara todos os ciclos de seu
processo.”
A primeira afirmação sobre micro e pequenas empresas (MPE) precisaria
de uma fundamentação bibliográfica ou empírica. A afirmação sobre
escassez de evidências empíricas de aplicações de processos ágeis em MPE
não implica necessariamente um problema de pesquisa. Seria necessário
ainda identificar alguma característica especial dessas MPE que as
tornassem diferentes em outras empresas em relação à adoção de métodos
ágeis.
“XML tem sido utilizada largamente no intercâmbio eletrônico de
dados (EDI), o que tem aumentado o interesse na manipulação de
dados XML persistentes. Pesquisas desenvolvidas em BD’s XML
nativos têm procurado atingir o ‘estado da arte’ na gerência de dados
semiestruturados.”
O alegado aumento de interesse em uma área (que precisaria ser
justificado por evidências bibliográficas recentes) não implica existência de
um problema de pesquisa, mas apenas de um tema de pesquisa.
“Um dos grandes problemas na distribuição de vídeos para
dispositivos móveis é a sua baixa disponibilidade. Usando um tempo
menor na transferência de vídeos se tem um melhor aproveitamento da
banda de conexão e uma economia no consumo das baterias, que
possuem capacidade limitada. O Grid é uma versão segura de Web
Services para o compartilhamento de dados e recursos (Foster, 2001).
Entidades como a OGSI e WSRF definem as especificações para os
tools kit em que temos controle de usuário, segurança e interface
aberta para garantir a compatibilidade. Dessa forma podemos propor
uma malha de servidores de vídeo em que um aplicativo cliente pode
copiar fragmentos de vídeo de diversos pontos fornecendo uma alta
disponibilidade dos recursos e diminuir a sobrecarga existente num
sistema centralizado.”
Existe um problema claramente caracterizado. Porém, não fica claro se a
solução proposta ainda não foi tentada. Se foi, quais os problemas atuais
com as soluções existentes para que uma nova tecnologia seja proposta?
“Alguns processos de integração de fontes de dados XML
heterogêneas definem um esquema conceitual único (esquema global)
representativo do esquema de todas essas fontes. Através desse
esquema global é possível realizar consultas de forma transparente,
uma vez que ele abstrai as complexidades inerentes às fontes de dados,
como diferenças estruturais e semânticas. Trabalhos como [***]
tratam esse problema.”
Embora o texto assim mencione, ele não apresenta um problema, mas
uma solução. O texto referenciado aparentemente apresenta soluções para a
combinação de bases XML heterogêneas. Então, resta ao autor da proposta
de pesquisa identificar um problema, possivelmente no trabalho
referenciado, que merecesse atenção para ser resolvido. Pela simples leitura
do texto anterior não é possível saber qual é o problema que será resolvido
na monografia.
“Em supermercados, por exemplo, existe a necessidade de prever a
quantidade de produtos que serão vendidos em uma faixa de tempo,
para a otimização da quantidade comprada, enxugando custos e
necessidades logísticas. Por isso foi estudada a previsão de séries
temporais, a qual possui modelos estatísticos que vêm sendo utilizados
no mercado. Estes, porém, ora não contemplam perfeitamente os
objetivos, ora exigem muitos recursos para tal, portanto há a
necessidade de se encontrar um modelo que atenda mais
apropriadamente este caso. Alguns estudos em redes neurais sugerem
que há a possibilidade de que seja encontrado este modelo neste
campo de pesquisa.”
O texto coloca um problema real, menciona que as soluções existentes
têm limitações e se propõe a pesquisar uma forma de suplantá-las usando
uma ferramenta que, segundo o autor, a literatura apresenta como uma
tendência. Porém, se redes neurais já têm sido usadas para esse fim, será
absolutamente necessário um trabalho de comparação entre os resultados de
modelos existentes e o modelo definido pelo autor.
“A garantia de QoS é uma preocupação para algumas aplicações
distribuídas, as quais necessitam desta para poder funcionar
corretamente. Assim, torna-se necessário adotar uma técnica que
melhor se encaixe na aplicação de forma a prover os requisitos
necessários podendo com isso superar os problemas que poderão
surgir, como, por exemplo, atraso (delay), extravio de pacotes, entrega
desordenada e prioridades, ou seja, requisitos temporais de qualidade
e de segurança [***].”
O problema é fundamentado corretamente em uma citação bibliográfica.
Esta aponta no sentido da melhoria de vários aspectos relacionados ao tema.
“WebServices têm sido amplamente utilizados com intuito de prover
interoperabilidade entre aplicações. Algumas aplicações necessitam
que os serviços acessados estejam altamente disponíveis, ou seja,
ativos e em funcionamento o máximo de tempo possível.”
Trata-se aqui da descrição de uma necessidade. Para que se torne um
problema de pesquisa é necessário indicar ainda como essa necessidade tem
sido suprida e quais as limitações das técnicas correntes.
“Há um crescente número de máquinas conectadas à internet.
Máquinas de capacidade cada vez maior. Estudos comprovaram que
93% da capacidade de processamento dos computadores permanece
ociosa. Essa capacidade pode ser utilizada para processamento de
projetos que requerem alto desempenho computacional a um baixo
custo operacional. O Ambiente *** é uma alternativa para isto.”
Aqui, a informação apresentada, ociosidade de máquinas na Internet, é
quantificada e embasada em um estudo bibliográfico (embora não seja
explicitamente citado aqui). Porém, esse texto não apresenta um problema
de pesquisa, mas uma oportunidade. Máquinas ociosas são uma
oportunidade para aproveitar seu potencial de processamento, mas falta
estabelecer qual o novo conhecimento que se busca gerar no trabalho.
“Jurisprudência (do Latim: juris prudentia) é um termo jurídico com
diversos significados. O mais comum refere-se à aplicação de estudo
de casos jurídicos na tomada de decisões judiciais. Assim,
‘jurisprudência’ pode referir-se a ‘lei baseada em casos’, ou as
decisões legais que se desenvolveram e que acompanham estatutos na
aplicação de leis em situações de fato. Grande parte do conhecimento
jurídico está formatado em documentos que contêm decisões
proferidas em sentenças ou acórdãos. A pesquisa visa contribuir para
definir um modelo de arquitetura de pesquisa em documentos com
significado semântico incorporado. Criando uma conexão entre a
linguagem técnica jurídica e sua representação utilizando ontologias
aptas para seu processamento em ferramentas que auxiliem no
refinamento do conhecimento.”
Essa contextualização apresenta um tema bem delimitado, mas falha ao
não caracterizar o problema de pesquisa. A proposta é definir um modelo de
arquitetura de pesquisa, mas não estabelece quais são os problemas com as
eventuais arquiteturas de pesquisa existentes. Mesmo a menção de uma
aplicação direta no domínio jurídico não permite concluir pelo ineditismo
desse trabalho, pois esse tipo de aplicação possivelmente já existia no
momento da elaboração dessa proposta. Mesmo que não existisse, deveria
ser deixado claro o que esse domínio tem de diferente em relação a outros, e
por que não funcionariam outros sistemas anteriores a este que será
proposto.
“A atividade de exploração de poços de petróleo envolve um grau de
incerteza muito grande, e essa incerteza gera riscos elevados em
termos de custos. Para fazer essa Análise de Risco, a técnica de
Simulação vem sendo utilizada, necessitando-se conhecer as
distribuições dos valores de tempo das operações. Para a descoberta
dessas distribuições, existem vários métodos que avaliam a aderência
a algum modelo de probabilidade. Mas para isso é necessário que
exista uma série histórica dos tempos de operações semelhantes.
Quando não há esse histórico, como realizar a descoberta dos
modelos de probabilidade?”
Aqui a contextualização apresenta um problema de fato: para realizar
uma simulação é necessário ter uma série histórica. É colocado o problema
de como fazer essa simulação quando uma série não está disponível, o que
de fato pode acontecer.
4.2. Análise de Objetivo Geral
Nesta seção procura-se avaliar se um objetivo geral está bem escrito, se é
um objetivo de pesquisa e se deixa claro que pode ser verificado ao final do
trabalho. Atenção especial é dada ao verbo que apresenta o objetivo.
Analisa-se também se o objetivo apresentado define claramente uma
pesquisa científica ou um objetivo tecnológico, como, por exemplo, a
implementação de um sistema. Os resultados estão apresentados a seguir.
“Elaborar um sistema Hipermídia observando critérios ergonômicos e
princípios de design como apoio ao ensino da Metodologia
Científica.”
O verbo inicial não aponta para um objetivo de pesquisa, mas um
objetivo técnico: elaborar um sistema. Critérios ergonômicos e princípios de
design também são requisitos que qualquer projeto técnico deveria
observar.
“Obter confiabilidade através de replicação com 5 servidores,
obtendo perda máxima de 20% de desempenho comparado a um
sistema sem replicação.”
O objetivo é claro: “obter confiabilidade”. Falta especificar, porém, como
se mede confiabilidade para que se possa concluir ao final o trabalho se ela
foi obtida. A comparação proposta com um sistema sem replicação
implicaria que a técnica em questão ainda não foi explorada em outros
trabalhos.
“O objetivo geral deste trabalho é desenvolver, implantar e avaliar o
impacto de uma abordagem para a gerência de projetos terceirizados
de desenvolvimento de software, em uma empresa transmissora de
energia elétrica.”
Os dois primeiros verbos, desenvolver e implantar, são objetivos técnicos
e não de pesquisa. O terceiro verbo “avaliar” aponta para um objetivo de
pesquisa, mas “impacto” é algo muito subjetivo para ser avaliado. Deveria
haver uma melhor especificação sobre o que se pretende descobrir, caso
contrário, pode-se estar procurando à toa.
“Estudar as técnicas de IA, mais especificamente o RBC. Demonstrar
a eficiência da utilização do RBC na previsão meteorológica.
Desenvolvimento de um protótipo para demonstração de resultados.”
A primeira frase não pode ser um objetivo de pesquisa. Pelo menos não
de pesquisa científica. O aluno vai, sim, estudar técnicas de IA, mas ele faz
isso para suprir conhecimentos que ele próprio não possui ainda. Esses
conhecimentos são, porém, de domínio público. Então, esse estudo não
produz conhecimento novo e não pode ser apresentado como objetivo de
pesquisa.
A segunda frase já está melhor. Algo será demonstrado. Porém, não está
muito claro onde se pretende chegar com esse objetivo. Como medir a
eficiência? Ela deve ser melhor do que alguma outra técnica?
O desenvolvimento do protótipo, apresentado na terceira frase, é parte do
método de trabalho, e o protótipo pode ser um subproduto interessante, mas
não parece ser um objetivo de pesquisa de fato.
“O objetivo é desenvolver um método de refinamento da reconstrução
3D, através de uma memória adaptativa dos objetos já reconstruídos,
de forma que novos objetos analisados são armazenados e aqueles já
conhecidos são refinados. Assim, (hipótese) poderá haver uma maior
completude e um aumento da acurácia da reconstrução, dada a
natureza cumulativa do processo. Trata-se de uma memória com
representação geométrica implícita, mediante indexação/mapeamento
de objetos a partir de aspectos da imagem, como contornos etc.”
Desenvolver um método pode ser um bom objetivo de pesquisa, embora
algumas vezes os alunos confundam método, processo, procedimento,
mecanismo, arquitetura, sistema etc. Nesse caso, de fato trata-se de um
método envolvendo técnicas de Computação Gráfica. Há uma hipótese
clara, que consiste em uma técnica a ser usada: memória adaptativa. Há um
objetivo claro associado a essa hipótese que consiste em obter maior
completude e acurácia na reconstrução 3D. Para que o objetivo esteja
completo, faltaria apenas indicar quanto os métodos atuais conseguem obter
em termo de acurácia e completude para que se possa saber, ao final do
projeto, se a técnica tentada melhorou esses valores.
“Identificar os aspectos mais relevantes que influenciam na
performance de sistemas reflexivos.”
“Identificar” algo pode ser um objetivo de pesquisa desde que esteja bem
claro o que se procura identificar. Não é o caso desse texto, pois ele tem
várias palavras com conotação subjetiva. Por exemplo, como se avalia que
um aspecto é mais relevante do que outro? O que significa influenciar a
performance? A presença de um vírus no computador, por exemplo, é um
aspecto que deveria ser considerado? Ele pode afetar a performance de um
sistema reflexivo assim como outros sistemas. Dessa forma, a quantidade
de aspectos pode ser arbitrariamente grande. Além disso, apenas identificar
algo pode ser insuficiente para que se tenha um resultado concreto e útil. O
objetivo poderia ser complementado com a proposição de alguma técnica
para superar os problemas identificados.
“Classificar os alunos quanto ao seu desempenho acadêmico.
Classificar os alunos quanto a sua carência financeira. Comparar o
desempenho escolar dos egressos pelo SAEM e pelo vestibular.
Predizer o desempenho escolar dos estudantes na universidade.
Predizer casos de mudança de instituição. Auxiliar na tomada de
decisões.”
As três primeiras frases estão bem conectadas e apontam para um
objetivo de pesquisa claro. Porém, esse objetivo não parece ser um objetivo
da área de Ciência da Computação. Possivelmente o aluno tencionava
utilizar sistemas informatizados para fazer a comparação, mas isso não é
suficiente. Deve haver uma produção de conhecimento útil para a área de
Computação. Caso contrário, o mestrado pode e deve ser tentado em outra
área. A terceira e quarta frases parecem não seguir facilmente as três
primeiras. Não fica claro como, a partir do desempenho dos alunos e da sua
situação financeira, será possível predizer o seu desempenho escolar e o que
aconteceria se mudassem de instituição. A última frase está mais para um
resultado esperado do que um objetivo de monografia. Caso o objetivo
colocado nas três primeiras frases fosse obtido, isso possivelmente teria
consequências no processo de tomada de decisão dos administradores das
instituições de ensino, mas como não é algo que o autor da monografia vá
fazer não pode ser considerado como objetivo do trabalho.
“Desenvolver um algoritmo baseado no relaxamento de variáveis
Lagrangeanas para determinar a escala ótima de manutenção de um
sistema elétrico.”
Um algoritmo baseado em relaxamento das variáveis Lagrangeanas
parece uma boa solução para otimizar alguma coisa como, por exemplo, a
manutenção de um sistema elétrico. Mas, por que não outras técnicas?
Existe alguma técnica sendo usada correntemente? Que resultados ela
produz? Quanto se pretende melhorar e em que dimensão?
“Gerar aproximação de superfície em nodos externos da Octree.”
Um objetivo sucinto. Talvez por isso seja difícil determinar se está
adequado como objetivo de pesquisa. A princípio, “gerar” uma
aproximação de superfície não traz novo conhecimento à tona. É uma
atividade, não um objetivo de pesquisa. Poderia ser reescrito talvez como,
“demonstrar que é possível gerar aproximação de superfície...”. Isso se até o
momento da pesquisa nunca tivesse sido feito. Caso contrário, seria
reinventar a roda.
“Desenvolver um sistema de gerenciamento hospitalar que, com base
na tecnologia de workflow, permita a modelagem e execução de
processos médicos, interagindo com servidores de dados no padrão
***.”
Desenvolver um sistema, por melhor que seja, nunca será um objetivo de
pesquisa. O sistema pode ser usado para demonstrar algo, mas ele em si é
um objetivo técnico.
“Oferecer solução para o planejamento de rotas de navegação para
um ambiente semiconhecido. Aplicar essa solução a um sistema de
planejamento neurocirúrgico. Demonstrar que essa solução está
correta através da comparação com outros métodos atualmente
utilizados.(manual!)”
“Oferecer solução” está bom como resultado esperado, mas existem
muitas formas de fazer isso. Pode-se comprar um sistema, pode-se
implementar um algoritmo, pode-se mesmo criar toda uma nova teoria e
prática nessa área, com vistas a fornecer uma solução. Então, isso teria de
ser mais bem definido. A aplicação dessa solução numa determinada área
pode ser interessante, especialmente se os métodos correntes utilizados são
manuais. Deve haver uma referência bibliográfica ou a apresentação de uma
pesquisa que demonstre que de fato a técnica corrente é manual. Uma
rápida observação no hospital local não seria suficiente como justificativa.
“Propor um modelo para identificação de características para um
plano amostral estratificado.”
“Propor” é um verbo que é usado em muitas monografias como objetivo,
mas é um verbo perigoso se não vier acompanhado de um objeto direto
relevante. No caso anterior, o que está sendo proposto é um modelo para
identificação de características. Ok, o modelo pode ser proposto. Mas é
necessário indicar claramente o que sucede com outros modelos que
possivelmente devem existir. Se não existirem, deve-se avaliar por que não
existem e referenciar os modelos mais parecidos com o que se pretende
propor.
Em suma, não se pode chegar e simplesmente propor alguma coisa. É
preciso apresentar uma boa justificativa para tal proposta.
“Portar o Sistema *** para a arquitetura de RSSF da UC Berkeley.”
A não ser que o processo de “portar” apresente desafios que impliquem
construção de novos conhecimentos em computação, o trabalho, como
proposto, é apenas um objetivo técnico que poderia ser executado por um
profissional da área, sem que ele fosse receber ao final disso o título de
mestre.
“O objetivo deste trabalho é apresentar um mecanismo sistemático
que, através dos contratos definidos em notação OCL, gere diagramas
de colaboração, aplicando design patterns.”
Seria necessário conhecer bem a área para saber que o mecanismo
proposto não existe, portanto, o aluno deveria ter dito isso claramente na
contextualização.
4.3. Análise de Objetivos Específicos
Os objetivos específicos devem refletir subprodutos ou um detalhamento do
objetivo principal. Não se deve, a princípio, mencionar como objetivo
específico passos que são meramente intermediários para atingir o objetivo
geral. Vários outros cuidados também devem ser tomados, conforme os
comentários nos exemplos a seguir.
“a) Utilizar critérios de ergonomia de software;
b) Aplicar princípios de design no desenvolvimento de sistemas
multimídia;
c) Elaborar uma interface amigável em sistema multimídia, ou seja, fácil
de usar, aplicar e comunicar;
d) Adequar o sistema a um método de apoio para sistemas de autoria.”
Todo objetivo deve ter um verbo, mas ele deve indicar a produção de
algum conhecimento novo. Isso vale para os objetivos específicos também.
O objetivo (a) é apresentado com o verbo “utiliza”, que não se presta bem a
um objetivo de pesquisa, pois o fato de o autor estar utilizando algo não
quer dizer que esteja produzindo algum tipo de conhecimento novo. O
mesmo vale para o objetivo (b). O objetivo (c) realmente implica algo
sendo feito, possivelmente algo novo. Porém, é difícil mensurar o que
significa ser amigável e fácil de usar. Algum critério de medição dessas
características deveria ser mencionado. O objetivo (d) não parece ser de
pesquisa, mas tecnológico: existe um sistema que será adaptado.
“a) Técnicas para identificar padrões em característica;
b) Técnicas de agrupamento;
c) Categorização de variáveis contínuas;
d) Discretização.”
Para que esses itens correspondam a objetivos específicos deveria
inicialmente haver um verbo em cada item.
“a) Desenvolver método de replicação de dados entre servidores;
b) Mostrar limitações dos métodos existentes para replicação de servidores
com balanceamento de carga.”
Considerando que o objetivo geral desse trabalho era “obter
confiabilidade”, os objetivos específicos podem ser considerados
satisfatórios. Mas ainda assim podem ser questionados. O segundo objetivo
específico consiste em mostrar limitações dos métodos existentes. Mas
pressupõe-se que tais limitações já sejam conhecidas pelo aluno, pois, caso
contrário, por que ele estaria propondo um novo método (primeiro objetivo
específico)? Aqui, o que aparece é um estágio ainda pouco maduro da
pesquisa. O aluno deseja encontrar limitações nos métodos existentes para
que isso justifique a proposição de um novo método.
“a) Analisar métodos de gerência de projetos de software terceirizados;
b) Desenvolver um método customizado para gerenciar os aspectos custo,
prazo, qualidade e risco de projetos;
c) Adaptar ou desenvolver uma ferramenta de software (caso não exista
nenhuma adequada) para dar suporte à aplicação do método;
d) Implantar o método;
e) Coletar e analisar dados empíricos, resultantes da aplicação do método
nos projetos;
f) Propor melhorias no método desenvolvido.”
Aqui aparece claramente a confusão que muitas vezes se estabelece entre
objetivos específicos, metodologia e cronograma de atividades. Os
objetivos específicos deveriam ser resultados finais mensuráveis, em geral
um detalhamento ou subproduto do objetivo geral. Mas o aluno apresenta
praticamente uma sequência de passos que levam ao objetivo geral. Não
chega a ser um método, pois faltaria complementar com outras
informações, mas o que foi apresentado é uma lista de atividades sobre a
qual possivelmente o cronograma de trabalho será construído. Pode-se até
falar em objetivos intermediários de cada etapa do processo de pesquisa,
mas vários deles não são objetivos de pesquisa, mas atividades técnicas.
“a) Implementar o sistema de inicialização e abstrações de hardware para
*** no ***;
b) Definir, implementar, testar e avaliar uma família de protocolos de
comunicação de ***;
c) Definir, implementar, testar e avaliar um sistema de controle de recursos
de energia para ***;
d) Definir e implementar aplicações que permitam avaliar os sistemas
implementados.”
Aqui a divisão do problema em subproblemas é até adequada, mas as
atividades de definir, implementar e testar não são objetivos de pesquisa,
mas objetivos técnicos.
“a) Minimização do problema da oclusão de objetos;
b) Redução do tempo de reconstrução, dada a opção de obter a forma do
objeto por classificação de aspectos 2D, se ele já for conhecido.”
Aqui são dois objetivos específicos válidos. Apenas que, no caso do
primeiro, não está muito claro o que é exatamente o “problema da oclusão”,
nem que tipo de medição será possível para garantir que ele tenha sido
minimizado.
“a) Metodologia de busca de nodos externos de Octrees utilizando
operações conhecidas sobre este tipo de árvore;
b) Determinar pontos de inflexão em Octrees;
c) Gerar bitmaps a partir de nodos de Octree;
d) Determinar vetores normais em nodos de Octree para iluminação.”
O primeiro objetivo destoa dos demais por não ter um verbo associado.
Os demais parecem mais ser atividades a serem executadas na busca do
objetivo geral.
4.4. Análise de Justificativa
A justificativa deve se referir principalmente à hipótese de trabalho, ou seja,
deve-se justificar a escolha de uma hipótese em vez de tentar justificar
apenas a importância do tema da pesquisa. Usualmente a importância do
tema da pesquisa já foi abordada na contextualização do problema. Então
não há necessidade de repetir essa justificativa. A seguir são analisadas
algumas justificativas produzidas em propostas de monografia, com a ideia
de que seriam justificativas de hipótese.
“A eficiência de um plano amostral estratificado depende do
conhecimento empírico e da experiência do pesquisador. O método
proposto auxiliará no desenvolvimento do plano amostral,
identificando estratos que fornecerão maior precisão.”
Aqui o aluno apresenta uma vantagem esperada para o método proposto,
mas não justifica a pesquisa no sentido que seria esperado aqui. Ele deveria
deixar claro a partir da identificação do problema quais foram as tentativas
de solução testadas, onde elas falharam e finalmente, na justificativa,
explicar por que acredita que a abordagem que ele propõe pode ter sucesso.
“Métodos atuais de replicação geram muito tráfego na rede e reduzem
o paralelismo entre eles. Se não houver necessidade de paralelismo, a
replicação pode ser feita de maneira muito mais rápida e com menos
carga na rede.”
É uma boa justificativa, pois apresenta uma limitação relacionada aos
métodos existentes e justifica, com base nisso, uma potencial solução,
explicando por que ela seria adequada.
“Atualmente não existe um método para o acompanhamento dos
projetos terceirizados de desenvolvimento de software adaptado à
realidade das empresas públicas. Com a adoção de um método que
permita o gerenciamento dos projetos de desenvolvimento de software
terceirizados será possível realizar um melhor controle do andamento
dos projetos, permitindo a verificação de desvios e a tomada de
decisões para corrigi-los em tempo hábil.”
Não se recomenda fazer comparações com o vazio. No caso, em vez de
dizer negativamente que “não existe um método...”, o que pode ser
altamente questionável, o aluno deveria ter verificado o que existe de
semelhante e comparado com o que pretende fazer. Ao dizer que não existe
alguma coisa ou que não foi encontrada alguma informação, o aluno pode
passar a impressão de que não pesquisou o suficiente ou que aquilo que ele
busca é tão irrelevante que ninguém nunca se preocupou em procurar.
Assim, em vez de afirmar que algo não existe, o aluno deve mostrar o que
existe de mais parecido com aquilo que ele quer e então trabalhar nas
diferenças entre o existente e o desejado.
“O RBC é utilizado hoje com sucesso em campos como: medicina e
mercado financeiro.”
A frase caracteriza mais a contextualização do problema ou importância
do tema de pesquisa do que a justificativa do objetivo ou hipótese de
trabalho.
“Falta de um software que permita ao especialista modelar o processo
hospitalar com base em sua experiência e que seja capaz de executar e
gerenciar o processo modelado, controlando inclusive a alocação de
recursos. Falta de padronização nos dados médicos dificultando
diagnósticos e comprometendo ou impossibilitando cálculos
estatísticos.”
Aqui novamente o aluno procura justificar seu trabalho pela ausência de
determinadas coisas. Falta software em várias áreas, mas nem sempre a
construção de um software implica uma atividade de pesquisa. O mesmo
vale para padrões.
4.5. Análise de Método de Pesquisa
A seguir são analisadas propostas de método conforme apresentadas. Todas
as análises baseiam-se em versões extremamente resumidas das propostas,
ou seja, suficientes para preencher uma transparência. Então todas elas
carecem de um maior detalhamento ao serem transformadas em texto da
proposta de pesquisa ou do trabalho final. Assim, a análise considerará
questões relacionadas ao método no seu nível mais abstrato.
Inicialmente considera-se recomendável que o método de trabalho só seja
definido quando já se sabe qual o objetivo da pesquisa. Como o objetivo só
é consistentemente definido quando a revisão bibliográfica já está
suficientemente madura, não se considera, para efeito de metodologia em
computação, que a revisão bibliográfica seja parte do método. A revisão
pode ser parte do cronograma do trabalho, mas não do método. O método
deve mostrar como o proponente vai fazer para que sua hipótese de trabalho
seja testada e que ao final se possa concluir se ela é ou não verdadeira.
“a) Levantamento bibliográfico sobre os tópicos abordados neste trabalho
como: Critérios Ergonômicos, Interatividade, Método de Apoio à
autoria e outros;
b) Pesquisa sobre o Método de Apoio a ser utilizado;
c) Definição de recursos audiovisuais a serem utilizados no trabalho;
d) Modelagem do sistema conforme o método de apoio à autoria
escolhido;
e) Elaboração da ferramenta multimídia;
f) Testes do sistema”.
O método inicia com a revisão bibliográfica (itens a e b), quando fica
claro que o aluno ainda não domina suficientemente o tema de pesquisa. Os
passos (c) e (d) ficam atrelados ao que o aluno vier a descobrir na revisão
bibliográfica e, por isso, ainda não podem ser mais específicos. Já os passos
(e) e (f) são tão genéricos que serviriam para uma gama muito grande de
propostas de monografia. A questão é: como a hipótese de pesquisa será
testada. Isso o método não deixa claro.
“a) Desenvolvimento de um mecanismo que não utiliza design patterns
(sem conhecimento);
b) Adição de conhecimento ao mecanismo;
c) Experimentos + pesquisa bibliográfica = monografia.”
Aqui o aluno parece propor um estilo de projeto no qual vai avaliar uma
determinada hipótese (uso de conhecimento ou design patterns) contra a
opção que não utiliza essa hipótese. Trata-se de um trabalho em que o aluno
desenvolve um sistema presumivelmente compatível com o estado da arte e
depois insere nele alguma nova característica para avaliar se melhorou.
Embora não seja a forma mais madura de pesquisa, pois carece de um
benchmark mais universal, é uma forma válida, exceto pelo item (c) que
não informa nada específico sobre o trabalho. Porém, para que o método
fosse mais claro, seria necessário especificar o que significa adição de
conhecimento (a hipótese) e mostrar quais testes seriam feitos para testar a
validade ou não dessa hipótese, além, claro, de uma métrica bem definida
para comparar as duas abordagens.
“a) Utilizar técnicas existentes de replicação e medir desempenho da rede
e do serviço;
b) Implementar técnica proposta para replicação em serviços sem
paralelismo e medir desempenho da rede e serviço.”
A pesquisa proposta aqui é bastante semelhante à imediatamente anterior.
Implementa-se o que seria o estado da arte e compara-se com uma versão
que tenha alguma característica nova.
“a) Levantamento Bibliográfico;
b) Criação do método;
c) Adaptação ou desenvolvimento da ferramenta de software;
d) Planejamento da aplicação do método;
e) Aplicação do método;
f) Avaliação;
g) Conclusão.”
Essa apresentação é particularmente interessante porque ela serve para
quase qualquer monografia de tão genérica que é. Ela consiste praticamente
de um template, a partir do qual o cronograma de trabalho poderia ser
descrito. Para isso seria necessário instanciar cada um desses passos em
atividades concretas e relacionadas com os objetivos do trabalho.
“a) Desenvolvimento de um protótipo das quatro ferramentas englobando
os conceitos de modelagem e gerenciamento de workflow em
conformidade com a padronização ***;
b) Aplicação dessas ferramentas em dois hospitais conveniados ao projeto
com a finalidade de coleta de dados estatísticos para validação.”
Essa proposta tem a vantagem, em relação às anteriores, de mencionar
explicitamente a aplicação da técnica sendo estudada em casos reais
(hospitais). Menciona-se, porém, coleta de dados, sem deixar muito claro
que tipo de dados serão coletados e que tipo de análise será feita.
Dependendo do tipo de dados a ser levantado, deve-se tomar cuidado,
porque estes podem não ter representatividade estatística, como se quer. Um
exemplo extremo seria considerar que se trata de dois hospitais
especializados em cirurgia cardíaca. Se a maioria dos pacientes que ali se
interna tem como objetivo um tratamento cardíaco, essa não é uma
informação que possa ser generalizada para outros hospitais. Trata-se de um
fato verdadeiro apenas naquela realidade, já que existe uma relação entre
causa (o hospital ser especializado em cirurgia cardíaca) e efeito (um maior
número de tratamentos cardíacos naquele hospital). Outras relações bem
mais sutis podem ocorrer. Então o termo “estatístico” deve ser usado com
muito cuidado.
Um último exemplo:
“a) Design
a. Application Oriented System Design
b) Testes de Corretude
a. Técnicas de Depuração para Software Embutido
c) Testes de Performance
a. Executado via Testes Comparativos
b. Métricas
i. Tamanho de Código
ii. Tempo de Execução de Tarefas
iii. Energia gasta na Execução
1. Tempo de Operação de Componentes de Hardware
iv. Throughput de Rede
1. Simulação
2. Testes de Campo.”
A descrição do método em si deixa muita coisa subentendida, mas tem o
mérito de mencionar explicitamente quais são as métricas buscadas nos
testes comparativos.
C A P Í T U L O 5
Escrita da Monografia
A escrita de uma monografia depende fundamentalmente da existência de
algum conteúdo a ser apresentado. O Capítulo 3 apresenta um caminho para
a busca desse conteúdo. Esse caminho se inicia na escolha de um tema,
seguido pela revisão bibliográfica, escolha de um objetivo com uma
hipótese justificada, definição de um método de trabalho e execução do
método assim proposto para a coleta de resultados que serão posteriormente
analisados.
5.1 Como os Capítulos de uma Monografia
São Ordenados
Para quem lê pela primeira vez uma monografia, pode ficar a impressão de
que o trabalho foi escrito sequencialmente da mesma maneira como se
apresenta. Porém, normalmente este não é o caso.
A ordem física usual dos capítulos de uma monografia é a seguinte:
a) Resumo.
b) Introdução.
c) Revisão bibliográfica.
d) Desenvolvimento.
e) Conclusões.
f) Referências.
Dependendo do trabalho, a revisão bibliográfica e o desenvolvimento
poderão ocupar mais de um capítulo cada. Mas normalmente a ordem em
que as seções se apresentam é essa.
Esta é a ordem em que o trabalho será lido por alguém que esteja
iniciando a pesquisa nessa área de conhecimento. Primeiramente, é
necessário conhecer o resumo para saber de que se trata o trabalho. A
introdução apresenta objetivos, limitações e metodologia do trabalho, além
de situar o trabalho resumidamente no estado da arte. Será necessário ler a
revisão bibliográfica para que se conheça algo sobre outros trabalhos
similares, bem como os conceitos fundamentais para a compreensão do
trabalho propriamente dito que é apresentado no capítulo do
desenvolvimento. Finalmente, o leitor observará as conclusões, e, se quiser
aprender mais sobre o assunto, consultará as referências listadas.
Porém, essa não é necessariamente a ordem em que o trabalho será lido
pela banca examinadora.
5.2 Como uma Monografia poderá ser Lida
pela Banca Examinadora
Deve-se presumir que a banca seja composta por especialistas no assunto do
trabalho, os quais já conhecem suficientemente os principais conceitos e
trabalhos correlatos. Esses especialistas possivelmente farão uma leitura em
ordem distinta, procurando obter inicialmente as informações mais
relevantes sobre a contribuição do aluno, para em seguida analisar os
aspectos mais triviais do trabalho. Os especialistas vão direto ao cerne da
questão, deixando os complementos para avaliar em um segundo momento.
A forma como um avaliador lê uma monografia depende da
personalidade e experiência do avaliador, porém, uma sequência de leitura
muito interessante pode ser definida da seguinte forma:
a) Resumo.
b) Referências.
c) Introdução.
d) Conclusão.
e) Desenvolvimento.
f) Revisão bibliográfica.
O especialista inicialmente lê o resumo para saber do que trata o trabalho.
Ele verifica se o resumo é compatível com o título do trabalho. Ele espera
que o resumo apresente o problema sendo tratado, uma justificativa para a
hipótese escolhida e, principalmente, uma descrição rápida dos resultados
obtidos ou contribuições.
Um trabalho cujo resumo não indique claramente a existência de
contribuições relevantes possivelmente não será bem avaliado. Deve-se
evitar, portanto, que o resumo apresente apenas informações do tipo “Este
trabalho apresenta um estudo sobre...”, ou “Este trabalho propõe um
método para...”.
É necessário que o resumo apresente alguma informação do tipo “O
principal resultado obtido a partir deste trabalho é...”. Esse resultado, supõe-
se, deve ser relevante, no sentido que foi comentado anteriormente, ou seja,
deve corresponder a algum conhecimento que não estava disponível antes
da execução do trabalho e que foi descoberto durante a sua elaboração. Não
será suficiente, por exemplo, escrever “O principal resultado obtido a partir
deste trabalho foi o estudo de...”, pois, como foi dito, o estudo é um
objetivo pessoal do aluno e não o objetivo propriamente dito do trabalho de
pesquisa.
Na sequência, tendo o especialista compreendido o resumo e conhecido a
real contribuição do trabalho, vai verificar se a alegada contribuição
realmente foi obtida. Inicialmente ele verificará as referências citadas pelo
aluno para ver se os principais trabalhos da área estão ali. Verificará
também a existência de artigos recentes em eventos e periódicos, bem como
a relevância desses mesmos eventos e periódicos.
É possível reprovar um aluno em função das referências citadas no
trabalho dele? No nível de mestrado e doutorado, sim. Por exemplo,
considere-se uma monografia sobre XML que apresente como referências
12 trabalhos, sendo três livros técnicos de XML e nove páginas na Internet
que consistem em manuais técnicos de XML. Nesse caso, não há evidência
de trabalho científico, mas apenas de trabalho técnico. O aluno pode até ter
feito uma implementação muito bonita de alguma coisa com XML, mas
possivelmente não terá valor científico se não estiver fundamentado em
trabalhos relatados em eventos ou periódicos.
Estando as referências adequadas, o avaliador observará o capítulo de
introdução com atenção. Neste capítulo ele entenderá com mais detalhes o
problema sendo resolvido, a técnica usada para resolução e a forma como
os resultados foram validados. O avaliador estará especialmente atento aos
objetivos do trabalho, incluindo os objetivos específicos, que ele procurará
identificar claramente nas conclusões.
Ao ler as conclusões, um bom avaliador esquadrinhará o texto buscando
um comentário conclusivo sobre cada um dos objetivos do trabalho. A falta
dessa ligação direta entre objetivos e conclusões certamente dará margem a
críticas.
Após verificar as conclusões, o avaliador desviará sua atenção ao
capítulo de desenvolvimento, a fim de verificar como o aluno chegou
àquelas conclusões. As conclusões terão de ser todas consequências de
avaliações feitas no capítulo de desenvolvimento. Não se admite, por
exemplo, que um aluno conclua que seu sistema é fácil de usar, se no
desenvolvimento testou apenas a eficiência do sistema, sem checar a
usabilidade. Concluir algo que não foi testado ao longo do trabalho é
denominado “conclusão forte”, sendo inaceitável em trabalhos científicos.
Tendo compreendido a real contribuição do aluno, o avaliador finalmente
dará uma vista de olhos no capítulo da revisão bibliográfica para ver se os
principais conceitos foram bem apresentados e se os trabalhos correlatos
estão adequadamente descritos.
A forma de leitura descrita parece ir das pontas para o centro da
monografia. O especialista concentra-se primeiro nos pontos críticos do
trabalho, para depois ler as partes menos sujeitas a problemas.
5.3 Como uma Monografia poderia ser
Escrita
Já a ordem sugerida para escrever os diferentes capítulos de uma
monografia difere das duas anteriores. Pode-se escrever a monografia
exatamente na ordem em que os capítulos se apresentam. Mas essa
abordagem tem alguns inconvenientes, como, por exemplo, produzir uma
revisão bibliográfica desnecessariamente longa (por não saber quais
conceitos realmente serão usados no texto, colocase tudo sobre o que se
leu), e, por vezes, deixa o aluno cansado na hora de escrever o mais
importante: as conclusões. Quantas pessoas já não entregaram seu trabalho
ao orientador dizendo “Está pronto! Só faltam as conclusões”. Porém, o
mais importante num trabalho científico são as conclusões. O resto é apenas
um meio convincente para se chegar a elas.
Comer (2008) diz “the easiest way to build a dissertation is inside-out.
Begin by writing the chapters that describe your research (…). Collect
terms as they arise and keep a definition for each. Define each technical
term, even if you use it in a conventional manner.”1
Recomenda-se que só se inicie a escrita do texto final depois de ter
concluído pelo menos a maior parte dos experimentos. Nada impede a
escrita de rascunhos, mas esses textos não precisam ainda ter a preocupação
de formatação de um texto finalizado.
Então, quando o aluno terminar os experimentos e já tiver uma ideia
muito clara do que fez e quais resultados obteve, ele vai transformar seus
rascunhos em um texto acabado. Mas em que ordem ele deveria escrever
esse texto? Segue uma sugestão:
a) Introdução.
b) Desenvolvimento.
c) Conclusões.
d) Revisão Bibliográfica.
e) Referências.
f) Resumo.
Recomenda-se iniciar pela introdução porque possivelmente é o rascunho
que estará mais próximo da forma final neste momento. O capítulo de
introdução frequentemente é uma reescrita da proposta de monografia.
Troca-se o tempo futuro pelo tempo presente e a monografia passa a ter
objetivo, justificativa, hipóteses etc., que eram os mesmos, muitas vezes, da
proposta de pesquisa.
Em seguida, o desenvolvimento deve ser escrito porque os experimentos
ainda estarão fresquinhos para serem relatados. Esse é um capítulo
importante, por isso deve ser escrito com muita atenção.
As conclusões deveriam ser escritas logo depois. Após terminar o relato
do desenvolvimento e já tendo o capítulo de introdução sido revisado com
seus objetivos claramente colocados, a conclusão deverá ser uma
consequência daquilo que foi relatado no desenvolvimento, bem como ter
ligação com cada um dos objetivos, conforme já observado.
Na sequência escreve-se então a revisão bibliográfica e listam-se as
referências. Deve-se evitar colocar na revisão bibliográfica a totalidade das
fichas de leitura, pois isso não serve a um objetivo claro. Deve-se colocar,
isso sim, as comparações com trabalhos correlacionados e os conceitos
principais usados no capítulo de desenvolvimento. Um conceito que não é
usado no capítulo de desenvolvimento, por mais interessante que seja, não
precisa estar na revisão bibliográfica. As referências vão mencionar apenas
os trabalhos efetivamente citados. Por isso é importante que essas duas
sessões sejam verificadas em conjunto.
Finalmente, escreve-se o resumo, que, como o nome diz, resume o
trabalho. Mais adiante será discutido o que deveria ser dito nesta seção do
trabalho.
5.4 O Título
O título do trabalho é o primeiro meio para chamar a atenção de um
potencial leitor. Um título deve descrever a principal contribuição do
trabalho de forma sintética. Alguns títulos, por serem muito genéricos, não
motivam a leitura. Por exemplo, “um estudo sobre redes semânticas”. Para
que fosse um bom título, seria melhor dizer que tipo de resultado esse
estudo produziu. Outro exemplo de um título não motivador é “XYZ: uma
nova técnica de modelagem de dados”. Novamente, seria mais interessante
se o título pudesse esclarecer que tipo de vantagem essa nova técnica teria
em relação a outras. Apenas o fato de ser nova não garante que seja
interessante.
Seguem alguns exemplos de bons títulos obtidos na Biblioteca Digital da
Sociedade Brasileira de Computação, SBC
(http://bibliotecadigital.sbc.org.br/?subject=144):
a) Formal Approaches to Ensuring the Safety of Space Software.2
b) Automação de Métodos e Técnicas para Teste Funcional de
Componentes.
c) Electric Wheelchair Simulator for Rehabilitation of Persons with Motor
Disability.3
d) Análise Comparativa dos Dicionários LBG e SOA sob o Ponto de Vista
da Complexidade Computacional Envolvida na Fase de Codificação da
Quantização Vetorial.
O título deve apresentar, então, claramente, a ideia ou contribuição
central do trabalho. Porém, o título não pode ser muito longo. A
apresentação mais detalhada da ideia ou contribuição central será feita
então no resumo do trabalho, que normalmente aparece logo após o título.
5.5 O Resumo
O resumo de uma monografia não é, como alguns parecem pensar, um
trailer de um filme, em que se começa a contar uma história, mas não se
conta o final. O resumo de um trabalho científico deve contar o final da
história, ou seja, o leitor vai querer saber, em primeiro lugar, qual foi o
resultado científico a que esse trabalho chegou. Se ele achar o resultado
interessante no resumo, vai querer ler o resto para ver como o aluno chegou
a tal resultado.
Centenas de monografias em Computação são defendidas a cada ano
apenas no Brasil. Se contarmos outros países, ainda teremos uma infinidade
de material científico disponível cujo índice de produção aumenta cada vez
mais. Esperar que alguém leia uma monografia cujo resumo diz “Este
trabalho apresenta um estudo sobre bancos de dados” é esperar demais.
Afinal, essa frase diz muito pouco. O que efetivamente esse “estudo”
poderia ter gerado em termos de informação nova que poderia interessar a
alguém que trabalhe com bancos de dados?
Seria muito mais informativo um resumo que dissesse algo do tipo “Este
trabalho demonstra que as sete formas normais de bancos de dados não são
suficientes para evitar um problema de inconsistência dos dados
identificado aqui como...”. Se o leitor está acostumado a trabalhar com as
sete formas normais e acha que elas explicam como deve ser um bom banco
de dados relacional, então ele ficará curioso para ver que caso estranho é
esse que não é atendido pelas formas conhecidas. Ao longo do texto, mais
detalhes serão dados, mas a atenção do leitor já foi conquistada.
Portanto, o resumo da tese ou monografia é efetivamente o lugar para
vender o peixe. Se o autor não conseguir deixar um leitor interessado no
resumo, não conseguirá fazer com que ele leia sua monografia quando há
tanto outro material de boa qualidade disponível. Além disso, sistemas de
indexação em bases de dados de abstracts também não vão identificar o
trabalho adequadamente.
Alguém poderia argumentar que o resumo, usualmente com menos de
uma página, é um espaço muito pequeno para apresentar uma grande
contribuição obtida em mais de dois anos de trabalho. Mas o problema é o
seguinte: se o autor não consegue explicar a contribuição de seu trabalho
em uma página (resumo), então deve haver algo muito errado no seu
trabalho, ou na sua capacidade de ser sucinto.
Uma coisa que não se faz no resumo é revisão bibliográfica. A não ser
que seja vital para a compreensão do trabalho, não se deve fazer citações
bibliográficas no resumo. Não é razoável perder valiosas linhas citando
trabalhos de outras pessoas. Esse espaço é reservado para o autor da
monografia dizer a que veio e o que trouxe.
O resumo deve conter uma explicação bastante clara sobre o real
problema abordado no trabalho, pois pessoas com problemas semelhantes
poderão se interessar. Além disso, um esboço da solução usada deve ser
também apresentado, pois pessoas que usem tecnologias parecidas poderão
também se interessar em ver uma possível nova classe de problemas sendo
resolvidos por essa tecnologia.
Segundo Rugaber (1995), o propósito de uma monografia é a
apresentação de uma tese. Então, faz sentido apresentar essa tese o mais
cedo possível, ou seja, no resumo. A tese é definida como sendo uma
afirmação, que se procura comprovar verdadeira. Se um trabalho em nível
de mestrado ou doutorado não puder ser definido a partir de uma tese, que
possa ser expressa em uma frase, então possivelmente algo está errado na
concepção do trabalho.
5.6 A Introdução
O capítulo de introdução apresentará de forma mais detalhada o tema e o
problema de pesquisa. Em relação ao tema, espera-se uma descrição geral
da área e da abrangência do estudo. Deve-se evitar, porém, introduções
muito longas, por exemplo, iniciando na pré-história, para chegar a explicar
que o tema do trabalho é relativo a redes de computadores.
A introdução deve conter os elementos que já foram mencionados no
projeto de pesquisa, ou seja, os objetivos geral e específicos, resultados
esperados, limitações do trabalho, metodologia utilizada e justificativa. Em
geral, o capítulo de introdução é fechado por uma descrição sucinta dos
demais capítulos do trabalho.
5.7 O Capítulo de Revisão Bibliográfica
O capítulo de revisão bibliográfica contém trabalhos de outros autores que
de alguma forma se relacionam com o texto da monografia. Neste capítulo é
importante ser objetivo na apresentação, pois a quantidade de textos a
serem consultados na maioria das áreas é muito grande. Não se recomenda
fazer grandes digressões sobre trabalhos que não sejam diretamente
relacionados ao tema da monografia. Por exemplo, se o trabalho trata da
comparação entre técnicas de mutação em algoritmos genéticos, então não
seria necessário neste capítulo abordar uma revisão bibliográfica sobre
robótica ou redes semânticas, que, embora sejam temas diretamente ligados
à Inteligência Artificial, são colaterais ao tema do trabalho.
O capítulo de revisão bibliográfica deve, isso sim, abordar os principais
conceitos da área de pesquisa para que possam servir de referência a
eventuais leitores que não sejam exatamente especialistas no assunto.
Recomenda-se que esses conceitos sejam, se possível, citados a partir de
mais de uma fonte, e que a forma de organização não seja copiada de um
único trabalho. Por exemplo, se os autores A, B e C apresentam os
conceitos 1, 2 e 3, em vez de citar os conceitos 1, 2 e 3 de acordo com A,
seguido dos conceitos 1, 2 e 3 de acordo com B e finalmente 1, 2 e 3 de
acordo com C, sugere-se que sejam citados o conceito 1, de acordo com A,
B e C, se possível com alguma comparação feita pelo próprio autor;
posteriormente citam-se as definições para o conceito 2, de acordo com A,
B e C, e finalmente o conceito 3, de acordo com A, B e C.
Assim, o capítulo de revisão bibliográfica organiza-se por conceitos e
não por autores. A exceção a essa regra se dá apenas no caso da
apresentação de trabalhos correlatos. A seção de trabalhos correlatos deve
descrever pesquisas semelhantes àquela do autor.
A comparação do trabalho atual com trabalhos correlatos pode ser feita
em dois momentos: na revisão bibliográfica e/ou nas considerações finais.
No final do capítulo de revisão bibliográfica pode ser comparada a hipótese
do trabalho com as hipóteses de trabalhos correlatos. Ainda não se têm
dados efetivos do trabalho porque esses dados vão aparecer apenas no
capítulo de desenvolvimento. Mas já é possível discutir sobre vantagens e
desvantagens das diferentes hipóteses de pesquisa de cada um dos
trabalhos.
O segundo momento em que a comparação pode ser feita é no final do
documento, em geral, no final do capítulo de desenvolvimento ou no
capítulo de conclusão ou considerações finais. Nesse ponto já se têm os
resultados do trabalho em questão, os quais podem ser comparados com os
resultados de outros trabalhos correlatos. Tratase, portanto, nesse caso, de
uma comparação bem mais objetiva.
Um ponto a ser sempre mencionado é a questão do plágio. Em hipótese
alguma pode-se utilizar textos escritos por outra pessoa, mesmo em um
trabalho de cunho eminentemente escolar, sem colocar o texto citado entre
aspas e, quando possível, mencionar a fonte de consulta. Utilizar o trabalho
de outro como se fosse seu é considerado crime de plágio pela legislação
brasileira.
Mesmo traduções devem ser evitadas. Se for o caso de mencionar algum
texto em outra língua, recomenda-se que seja mantido no original entre
aspas e com a fonte citada. Opcionalmente pode-se colocar em nota de
rodapé uma tradução. Se a fonte de consulta for a obra traduzida, então
pode-se citar conforme a língua em que foi traduzida (no caso Português),
mas se a tradução for feita pelo próprio autor do trabalho, recomenda-se
manter o original e utilizar a nota de rodapé para a tradução, visto que não
se trata de uma tradução oficial e, portanto, o sentido da tradução não pode
ser atribuído ao autor do texto original.
Rugaber (1995) afirma que a seção de revisão bibliográfica em geral é
maçante e mal usada. Isso acontece porque o aluno, ao escrever, perde a
oportunidade de usar o trabalho de outros autores para motivar o seu
próprio estudo. Em vez disso, muitas vezes perdese tempo e espaço fazendo
um estafante e desnecessário inventário de tudo o que foi lido ou ainda uma
sequência de citações de outros autores que não levam a lugar nenhum.
Ainda segundo Rugaber, uma boa seção de revisão bibliográfica inclui
uma ontologia e uma ontogenia. A ontologia vai apresentar os principais
conceitos utilizados no trabalho. Já a ontogenia mostra como as diferentes
ideias evoluíram com o passar do tempo até chegar ao estado da arte. O
final da ontogenia naturalmente vai incluir o trabalho sendo desenvolvido,
mostrando como ele se encaixa na evolução da área.
5.8 O Capítulo de Desenvolvimento
O capítulo de desenvolvimento marca o início da contribuição pessoal do
autor do trabalho. Portanto, não se deve fazer do capítulo de
desenvolvimento uma nova revisão bibliográfica. De preferência, todos os
conceitos que serão necessários nesse capítulo já devem ter sido citados no
capítulo de revisão bibliográfica. Se alguma comparação for feita com
trabalhos correlatos nesse capítulo, então apenas a comparação objetiva
deve ser feita aqui, sendo que a apresentação pura e simples dos trabalhos
correlatos já terá ocorrido no capítulo anterior.
O capítulo de desenvolvimento deve apresentar a construção da teoria,
modelo ou proposta, seja de que natureza for. Conceitos criados pelo autor
da monografia devem ser descritos aqui e não na revisão bibliográfica. Na
sequência, o autor deve trabalhar as evidências de que sua hipótese é
verdadeira. Serão então apresentados dados, gráficos, testes, provas
formais, estudos de casos, transcrição de entrevistas ou quaisquer outros
meios julgados adequados para provar o seu ponto, ou seja, para mostrar
que a hipótese é verdadeira.
Deve-se evitar sempre transformar o capítulo de desenvolvimento em
uma apresentação de um sistema computacional. Se um sistema foi
desenvolvido, foi para servir a algum propósito de descobrir novo
conhecimento. A monografia deve ser sobre o conhecimento gerado, não
sobre o sistema em si. Apresentações detalhadas sobre telas de software,
incluindo telas de login, menu principal etc., são enfadonhas e
desnecessárias em um trabalho científico. O seguinte texto, do Prof. John
W. Chinneck (1988), resume tudo: “The purpose of your thesis is to clearly
document an original contribution to knowledge. You may develop
computer programs, prototypes, or other tools as a means of proving your
points, but remember, the thesis is not about the tool, it is about the
contribution to knowledge. Tools such as computer programs are fine and
useful products, but you can’t get an advanced degree just for the tool. You
must use the tool to demonstrate that you have made an original
contribution to knowledge; e.g., through its use, or ideas it embodies.”4
5.8.1 Definições Constitutivas E
Operacionais
No capítulo de desenvolvimento frequentemente o pesquisador precisará
definir termos que esteja usando. Existem duas formas clássicas de criar
definições: as definições constitutivas e as operacionais. Dependendo do
tipo de variável, será necessário usar uma ou outra.
Trabalhos eminentemente formais tendem a usar mais as definições
constitutivas. Segundo Kerlinger (1980), “definições constitutivas são
definições de dicionário”. As definições constitutivas procuram definir um
termo em função de seus constituintes. Uma gramática formal, por
exemplo, pode ser definida como um conjunto de regras de produção; uma
regra de produção pode ser definida como duas sequências de símbolos e
assim por diante.
Porém, pesquisas que utilizem termos não formais como “facilidade”,
“adequação”, “flexibilidade” etc. dificilmente poderão utilizar apenas
definições constitutivas para esses termos, até porque em geral tais
definições sequer existem.
É necessário, nesses casos, utilizar uma definição operacional que,
segundo Kerlinger (1980): “atribui significado a um constructo ou variável
especificando as atividades ou ‘operações’ necessárias para medi-lo ou
manipulá-lo”. A definição operacional é, então, uma definição pragmática.
Ela não define a natureza de um fenômeno, mas os meios para obter uma
medição e caracteriza o resultado dessa medição como sendo o próprio
fenômeno.
Por exemplo, o termo “facilidade” pode ser definido como o número de
toques no teclado ou mouse para realizar uma determinada tarefa. O termo
“adequação” pode ser definido como a nota obtida em um teste padrão
aplicado por especialistas. O termo “flexibilidade” pode ser definido como
o tempo médio que um programador leva para introduzir um conjunto
predefinido de características.
Mas esses são apenas exemplos do que poderia ser feito. Não se pretende
aqui fornecer definições operacionais para esses termos. Cada trabalho
usará as definições que forem mais adequadas ao objetivo da pesquisa.
O importante aqui é enfatizar que no caso de variáveis que representem
características não formais é necessário utilizar definições operacionais para
que o fenômeno associado à variável possa efetivamente ser medido. Sem
isso o trabalho seria apenas especulativo.
5.9 O Capítulo de Conclusões
O capítulo das conclusões é, em geral, a pedra no sapato do estudante.
Aparentemente tudo já foi dito sobre o trabalho no capítulo de
desenvolvimento; então o que escrever nesse capítulo final?
A primeira dica é observar os objetivos geral e específicos do trabalho no
capítulo de introdução e colocar no capítulo das conclusões um comentário
sobre como o desenvolvimento apresentado ajudou a chegar a cada um
desses objetivos, ou seja, como o trabalho de pesquisa permite concluir que
cada um dos objetivos foi atingido.
Outro ponto importante é apresentar não apenas os pontos positivos do
trabalho, mas também os negativos. Não se espera de nenhum trabalho
científico que ele resolva todos os problemas do mundo. Pelo contrário,
espera-se que o pesquisador seja suficientemente honesto para descrever de
forma clara as fraquezas e limitações de seu próprio trabalho.
A seguinte máxima segue implacavelmente das leis da lógica: “Se você
não for o maior crítico de seu próprio trabalho, outra pessoa será”.
Outro tópico a ser abordado no capítulo de conclusões são as lições
aprendidas. O aluno passou dois anos ou mais estudando um tema e
realizando experimentos com ele. Além dos objetivos do trabalho,
claramente colocados e atingidos, ele deve ter aprendido muita coisa no
processo. Talvez essa informação possa ser útil a outras pessoas. Então se
deve descrever no capítulo de conclusões quais foram essas lições
aprendidas ao longo do trabalho.
Pode-se descrever também outras situações nas quais se imagina que
essas lições possam ser aplicadas. Por exemplo, ao comparar o resultado de
questionários aplicados em uma empresa com a situação real observada in
locu, um aluno percebeu que, por conta do medo de retaliações por parte da
chefia, a maioria dos funcionários procurava apresentar nos questionários
uma situação mais bonita do que realmente era. Dessa forma, o aluno
aprendeu que questionários não são fontes confiáveis de informação se não
houver uma validação das respostas no ambiente de estudo. Essa lição
aprendida teria de ser colocada no capítulo de conclusões.
(1988), o capítulo final de uma monografia deve ter pelo menos três
partes: a conclusão, as contribuições e os trabalhos futuros.
Na conclusão o aluno fará de forma concisa uma referência ao problema
examinado e resolvido. A conclusão propriamente dita teria o seguinte
formato: “o problema descrito na seção x foi resolvido como demonstrado
nas sessões y a z, em que foi desenvolvido um
algoritmo/método/abordagem etc. para tratar as situações mencionadas”
(Chinneck, 1988).
Ainda segundo Chinneck, o resumo das contribuições, que viria em
seguida, deve ser organizado em ordem decrescente de sua importância, por
exemplo:
a) Desenvolveu-se um algoritmo muito mais rápido para problemas de
Zylon de grande porte.
b) Demonstrou-se pela primeira vez o uso do mecanismo de Grooty para
os cálculos de Zylon.
c) Etc.
As contribuições mais importantes do trabalho serão aquelas que geraram
conhecimento novo. Ferramentas, protótipos e outros artefatos tecnológicos
usualmente são contribuições secundárias.
Artigos publicados e relatórios de pesquisa não são contribuições, nesse
sentido da palavra, mas relatos da pesquisa. Portanto, tais referências não
deveriam ser mencionadas aqui.
Finalmente, os trabalhos futuros são a contribuição que o aluno deixa
para que outros possam continuar sua pesquisa. Trabalhos futuros também
devem tratar de futuras contribuições ao conhecimento com mais ênfase do
que futuras contribuições às ferramentas, protótipos etc., que eventualmente
possam ser desenvolvidas.
5.9.1 Trabalhos Futuros
Espera-se sempre que uma monografia não seja apenas o final de uma
pesquisa, mas também o início de uma caminhada. Assim, a seção final das
conclusões normalmente é dedicada a deixar para os leitores ideias de
oportunidades de pesquisa com as quais o autor se deparou ao longo do seu
trabalho, mas que não teve tempo ou possibilidade de perseguir.
Nessa seção esperam-se dicas sobre trabalhos de pesquisa futura, e não
trabalhos técnicos futuros. Por exemplo, o leitor terá pouco interesse em
saber que o autor pretende futuramente implementar o sistema em Java, já
que a versão atual está em C. Isso é apenas uma questão técnica. O leitor
vai querer saber, sim, quais situações não foram testadas com a ferramenta
atual e que poderiam ser relevantes para compreender seu comportamento.
Isso seria um trabalho futuro de pesquisa relevante.
5.10 Seção de Bibliografia ou Referências
Bibliográficas
Não é objetivo deste livro apresentar normas de citação bibliográfica, já que
estas encontram-se disponíveis em qualquer biblioteca que se preze. Como
existem diferentes padrões de citação, sugere-se que se siga as normas
estabelecidas pelo curso, periódico ou evento no qual o trabalho será
publicado. Como referência pode-se consultar na Internet o trabalho de
Alves e Arruda (2007), baseado na NBR 6023/2002.
Apenas uma dica: após colocar todas as referências bibliográficas, deve-
se verificar se cada uma delas é citada no texto e se todas as que são citadas
no texto aparecem na lista de referências.
5.11 A Forma do Texto Científico
Comer (2008) apresenta uma série de recomendações sobre a forma do
texto científico. Primeiramente, ele deve comunicar uma ideia de pesquisa e
seus resultados. Isso, claro, é uma questão semântica. Mas há uma série de
pequenos vícios que muitos alunos têm, e que, por serem tão comuns, estão
sendo citados aqui para que possam ser evitados.
Esta seção não tem a intenção de ensinar a escrever português correto,
nem a formatar trabalhos monográficos ou artigos. O objetivo da seção é
apresentar e discutir erros frequentes, cometidos por alunos de computação
em seus trabalhos, que podem ser facilmente minimizados.
Primeiramente, uma monografia deve evitar sempre que possível o uso
de advérbios. Estranho, não? O advérbio é uma palavra que modifica um
verbo e é bastante comum na língua portuguesa. Porém, o uso do advérbio
no texto científico frequentemente estraga uma frase que sem ele poderia
ficar bem melhor. Embora o advérbio possa ser muito útil no texto
dissertativo, como, por exemplo, neste livro, para enfatizar ideias, no texto
científico, o uso do advérbio deve ser minimizado, pois pode reforçar
desnecessariamente certas afirmações. Por exemplo, dizer que “a
experiência demonstra que as abordagens são equivalentes” é uma coisa,
mas dizer “a experiência demonstra definitivamente que as abordagens são
equivalentes” dá um ar de prepotência ao texto, o que não é necessário para
a frase em questão. Pode-se notar que as duas frases têm o mesmo sentido,
mas a primeira soa bem melhor do que a segunda.
Algo a ser evitado em um texto científico também são as brincadeiras,
piadas ou ironia. Eventualmente, periódicos científicos até publicam textos
com esse tipo de expediente, mas nesses casos, usualmente o autor é algum
“Papa” da área. Quem não é o “Papa” deve se abster de usar esses recursos
no texto científico.
Em um texto científico não se espera que o autor utilize julgamento de
valor sobre temas que não podem ser avaliados como ruim ou bom de
forma maniqueísta. Dizer, por exemplo, que orientação a objetos é bom
enquanto projeto estruturado é ruim para o desenvolvimento de software é
uma questão de opinião. Em vez de dizer que algo é bom, deve-se procurar
salientar uma das qualidades que se julga boa. Em vez de dizer que algo é
ruim, deve-se apresentar uma explicação baseada em fatos verificáveis
sobre os defeitos que se julga serem um problema.
Nunca se deve dizer que alguma coisa é “perfeita”, porque na natureza
nada é.
Expressões como “hoje em dia” e “atualmente” também devem ser
evitadas no texto científico, porque a monografia é um trabalho atemporal.
Então não se deveria evitar dizer que “atualmente a Internet é bastante
usada”. Pode-se dizer, em vez disso, que em 2009, tantos milhões de
pessoas usam a Internet. Dessa forma, a frase ficará mais precisa e dará
melhor embasamento científico a qualquer outra informação que se for
apresentar em seguida.
Não se deve usar expressões do tipo “ficamos surpresos ao perceber
que...”. Não é da conta de ninguém se o aluno ficou surpreso. Deve-se
apenas dizer o que foi percebido e, de preferência, mostrar como isso foi
percebido de forma que também possa ser percebido por outras pessoas.
Afirmações como “uma nova abordagem”, “uma técnica diferente” etc.
devem ser evitadas a todo o custo. Qualquer abordagem que estiver sendo
proposta será nova e diferente das outras, caso contrário, não seria tema de
uma monografia. Não faria sentido propor algo que seja velho ou igual ao
que já existe, não? Então, devese evitar qualificar o trabalho como novo e
diferente, pois isso já é o que todos esperam. É melhor apenas dizer, afinal
de contas, qual é o trabalho e em que ele é diferente ou melhor que os
anteriores.
Usar palavras como “obviamente” ou “claramente” pode insultar o leitor,
pois o autor diz estar falando algo que é óbvio. Se for óbvio, não precisa ser
dito, se não é óbvio então não se deve dizer que é. Então, obviamente, deve-
se evitar usar esse termo.5
Sempre que o texto usar a expressão “na verdade” pode dar a impressão
de que aquilo que foi escrito antes era mentira. Então, na verdade, essa não
é uma boa escolha.6
Deve-se evitar sempre o uso da primeira pessoa, mesmo o plural
majestático, reservado apenas ao Papa e aos reis, bem como a segunda
pessoa no texto científico. A monografia é impessoal. Ela não é narrativa,
para que se pudesse usar primeira ou segunda pessoa. Então o impessoal
sempre deve prevalecer.
Quando for usado um dos pronomes “todos”, “muitos”, “alguns” ou
“nenhum”, deve-se ter certeza de que se tem uma evidência ou prova de que
a afirmação efetivamente possa ser assim qualificada. Não se pode dizer,
por exemplo, que “muitos estudantes têm problemas com a monografia”,
em um texto científico, sem ter havido um estudo, observação ou medição
sobre isso. Outra possibilidade é usar uma citação. Dizer “segundo Fulano
(200x), muitos alunos têm problemas com a monografia” está correto,
porque passa o problema de provar a afirmação para o autor do texto citado.
No entanto, nesse caso, é preciso verificar se a referência é um trabalho
confiável publicado em um bom veículo.
Outras recomendações são: usar a voz ativa ao invés da passiva, escrever
sempre no tempo presente e colocar negações no início da frase. Essas
recomendações de estilo ajudam a facilitar a compreensão do texto. Seria
difícil ler uma frase longa na qual se vai afirmando uma série de coisas e no
final se usa uma expressão para indicar que tudo o que estava sendo dito é
falso. Se o objetivo é negar algo, então é preferível iniciar negando. Assim
ficará mais fácil compreender o texto. Em todo o caso, sempre é preferível
usar frases afirmativas quando possível. Por exemplo, em vez de dizer
“nenhum programa rodou em menos de dez segundos” é preferível dizer
“todos os programas rodaram em dez segundos ou mais.
Chinneck (1988) apresenta algumas dicas interessantes para o texto:
a) Ter sempre em mente o background do leitor. Deve-se saber qual a
capacidade de compreensão que o leitor-alvo do texto terá. O texto deve
ser então suficientemente informativo a esse leitoralvo. Não detalhar
demais conceitos que seriam triviais e não deixar de explicar conceitos
que não são provavelmente de conhecimento do leitor-alvo.
b) Não fazer com que o leitor tenha de dar duro. Sabendo quais são as
obrigações do aluno no texto (deixar claro o problema de pesquisa,
mostrar que ele ainda não tinha sido resolvido, mostrar que valia a pena
resolver o problema e mostrar que o aluno efetivamente resolveu o
problema), deve-se deixar o texto o mais acessível possível. Quanto
mais dificuldade os avaliadores tiverem para encontrar as respostas às
questões fundamentais sobre o trabalho, pior será sua impressão sobre o
texto e maior a probabilidade que exijam grandes mudanças no texto
final.
c) Escrever de forma que seja impossível ser mais claro. Devese escrever
cada frase com muito cuidado, verificar se ela faz sentido e se apresenta
alguma informação útil de forma clara. Deve-se verificar se cada termo
usado em cada sentença já foi devidamente explicado no nível de
compreensão do leitor-alvo e se todas as possíveis ambiguidades foram
eliminadas.
d) Lembrarse de que a monografia não é uma história. Ela não é uma
cronologia das coisas que o aluno tentou fazer, mas um documento
formal que apresenta resultados de uma pesquisa.
e) Evitar declarações fortes como “o software é a parte mais importante de
um sistema computacional”, as quais são apenas uma opinião e não uma
informação substanciada na literatura corrente. Os examinadores
provavelmente pegarão frases como essas e perguntarão “você pode
demonstrar que o software é a parte mais importante de um sistema
computacional?”.
Moro (2009) apresenta os sete pecados capitais do texto científico:
a) “Frases longas (repletas de vírgulas ou não!)”. Sempre que forem
detectadas frases muito longas com várias orações coordenadas, deve-se
procurar dividi-las em frases menores, usando pontos para isso. Mas
deve-se cuidar para que cada frase lida individualmente faça sentido,
tendo sujeito, verbo e objeto, quando for o caso.
b) “Erros ortográficos”. Nada desqualifica mais um autor do que erros
ortográficos, ou seja, palavras mal escritas. Um bom conteúdo pode até
passar despercebido se o autor cometer erros desse tipo.
c) “Tradução literal e imbromation”. Um autor que não domine a língua
inglesa deve procurar a ajuda de um tradutor e, na maioria dos casos
também, de um revisor profissional dessa língua. Textos em inglês que
são traduções literais do português como, por exemplo, “the cow went to
the swamp”,7 “between hundred beat”8 e “I am with you and don´t
open”9 são motivo de piada.
d) “Imagens/tabelas ilegíveis”. Letras muito pequenas ou borradas servem
para comunicar alguma coisa? Legendas que coloridas são perfeitas,
mas quando impressas em preto e branco ficam indistinguíveis também
devem ser revisadas e evitadas.
e) “Erros gramaticais (paralelismo, concordância, conjugação, crase)”.
Erros de concordância acabam sendo muito comuns devido a revisões
malfeitas do texto. Algumas vezes muda-se o sujeito de uma frase do
masculino para o feminino ou do singular para o plural e deixa-se o
verbo ou complementos como estavam. Por exemplo, a frase original
estava assim: “o método foi devidamente demonstrado”. Uma revisão
trocou o termo “método” por “passos” e o texto final ficou assim: “os
passos foram devidamente demonstrado”. O erro aparece apenas na
última palavra.
f) “Cópia literal”. Se houver cópia literal de outros textos sem uso de aspas
e citação da fonte incorre-se em plágio.
g) “Blábláblá (encher linguiça)”. Quantas páginas deve ter uma
monografia? Algumas vezes alunos que acham que seu trabalho está
curto e resolvem preencher páginas com textos que não informam nada
apenas para dar mais sensação de volume.
Além disso, Moro (2008) apresenta algumas dicas para a produção de
textos de boa qualidade. Entre elas destacam-se:
a) Usar revisores automáticos de texto, embora nada substitua uma leitura
atenta por parte do autor, seu orientador e eventualmente por terceiros
também.
b) Dividir os parágrafos cuidadosamente. Cada parágrafo deve apresentar
uma ideia central que pode ser introduzida e comentada no mesmo
parágrafo. Mas quando se introduz uma nova ideia, usualmente inicia-se
um novo parágrafo. Parágrafos longos demais devem ser evitados.
c) Uma seção ou capítulo devem ser formados por mais de um parágrafo.
Sessões numeradas são formadas por texto. É um erro de estilo criar
uma seção (por exemplo, “3.2.1 Exemplos de algoritmos”) e preenchê-
la apenas com uma lista de itens. A seção sempre inicia com um texto.
Listas de itens podem ser parte da seção, mas nunca sua totalidade.
d) Cada frase deve ter um sujeito e um verbo. Apenas os títulos de sessões,
figuras e tabelas podem ser compostos por sentenças sem verbo (por
exemplo, “Testes Finais”). Mas frases incluídas no texto devem sempre
ter pelo menos um verbo. Por outro lado, o texto de uma seção não pode
ser continuação do título da seção. Por exemplo, seria errado dar a uma
seção o título “3.2.1. Testes Finais” e iniciar o parágrafo imediatamente
seguinte por “Foram realizados a contento”. O correto seria iniciar o
parágrafo com uma frase com sujeito e verbo que possa ser lida
independentemente do título da seção, no caso, “Os testes finais foram
realizados a contento”.
e) Siglas esclarecidas. Sempre que for usada uma sigla pela primeira vez,
ela deve ser definida por extenso. Mesmo que ela apareça na lista de
abreviações no início da monografia, deve ainda assim ser apresentada
por extenso no texto na primeira vez em que for usada. Isso vale
inclusive para siglas bastante famosas em determinadas áreas (como,
por exemplo, XP ou RUP no caso de engenharia de software).
Hexsel (2004) acrescenta mais algumas sugestões:
a) Destacar termos usando itálico e não negrito, pois o primeiro tem efeito
mais agradável do que o segundo.
b) Usar gráficos planos, que são mais claros do que os
pseudotridimensionais.
c) Evitar anglicismos sempre que possível, por exemplo, usando “enlace”
ou “ligação” em vez de link.
d) Inserir as referências bibliográficas de forma que não atrapalhem o
fluxo do texto, por exemplo, no final de frases (antes do ponto).
Devido ao costume de trabalhar com linguagens de programação, por
vezes, alunos de computação também esquecem como usar
apropriadamente os sinais de pontuação. Em um texto nunca se coloca
espaço antes de um sinal de pontuação, mas sempre se coloca espaço após o
sinal se houver uma palavra em seguida. Veja a seguir exemplos e
contraexemplos.
a) Esta é uma frase.O ponto final da frase anterior deveria ter um espaço
depois dele.
b) Esta é uma frase. O ponto final da frase anterior tem um espaço antes
que não deveria existir.
c) Esta é uma frase. O ponto final está bem colocado.
No caso de parênteses, colchetes e chaves, nunca deve haver espaço na
parte interna desses símbolos. Se do lado de fora houver uma palavra, então
se usa espaço. Porém, se após um fecha parêntese ou similar houver um
sinal de pontuação, então não se usa espaço. Exemplos a seguir:
a) Este texto (corretamente formatado) está entre parênteses.
b) Este outro(mal formatado) ficou com o abre parêntese colado na palavra
anterior.
c) Este aqui (mal formatado) tem um espaço a mais depois do abre
parêntese.
d) Finalmente (bem formatado), este aqui suprime o espaço após o fecha
parênteses devido à vírgula.
Na dúvida, o aluno sempre deve procurar ler bastante e ver como os
textos são formatados e não inventar formatações novas.
Um último aspecto que consiste em erro bastante comum em
monografias em computação é o uso inadequado de letras maiúsculas no
início de palavras. No geral, há duas regras que devem ser observadas. Em
primeiro lugar, títulos de capítulos ou seções do texto usualmente não
levam sinal de pontuação no final, mas os substantivos, adjetivos e a
maioria dos verbos devem iniciar em maiúscula. Seguem exemplos:
Título do Trabalho com Letras Maiúsculas Corretamente Usadas
Título do Trabalho com Ponto Final que não Deveria Existir.
Título do trabalho sem as letras que deveriam estar maiúsculas
Exceções são os verbos de ligação ser, estar, ter etc. que não devem
iniciar em maiúscula quando aparecerem no meio de um título.
Um título somente terá pontuação final se for uma interrogação ou
exclamação. Por exemplo:
Como fazer um título correto?
Agora, em relação ao uso da letra maiúscula no texto em geral, usa-se
apenas no início de frases (novo parágrafo ou após um ponto), ou no caso
de nomes próprios, ou ainda no caso de substantivos que representem
conceitos com um único exemplar, como, por exemplo, Humanidade e
Universo. Outro caso em que se usa maiúscula é para nomear as ciências,
como Ciência da Computação, Física, Matemática etc.
É errado então usar letra maiúscula aleatoriamente, como muitos alunos
fazem. Veja estes exemplos:
a) O Sistema que foi desenvolvido... (“sistema” deveria estar em
minúscula).
b) A Engenharia de Software trata de conceitos... (está correto, pois
Engenharia de Software pode ser considerada uma ciência).
c) Esta Dissertação foi escrita... (“dissertação” deveria estar em
minúsculas).
Essas são regras de estilo que em geral não afetam o conteúdo de um
trabalho, mas ajudam a torná-lo mais agradável de ler.
1Tradução: A maneira mais fácil de construir uma dissertação é de dentro para fora. Comece
escrevendo os capítulos que descrevem sua pesquisa (…). Colecione termos à medida que eles
surgem e mantenha uma definição para cada um deles. Defina cada termo técnico, mesmo se você o
usar da maneira convencional.
2Tradução: Abordagens Formais para Garantir a Segurança de Software Espacial.
3Tradução: Simulador de Cadeira de Rodas Elétrica para Reabilitação de Pessoas com Deficiência
Motora.
4Tradução: “O propósito da sua monografia é documentar claramente uma contribuição original ao
conhecimento. Você pode desenvolver programas de computador, protótipos e outras ferramentas
como forma de provar suas ideias, mas lembre-se, a monografia não é sobre a ferramenta, é sobre a
contribuição ao conhecimento. Ferramentas tais como programas de computador são produtos bons e
úteis, mas você não pode obter um título de pós-graduação somente pela ferramenta. A ferramenta
deve ser usada para demonstrar que você fez uma contribuição original ao conhecimento; por
exemplo, através de seu uso, ou pelas ideias que através dela são materializadas.” Tradução de
Américo E. de Oliveira Costa e Vitória Pureza, disponível em
http://www.sce.carleton.ca/faculty/chinneck/thesis/ThesisPortuguese.html.
5Sugere-se que o leitor releia a frase sem a palavra em itálico.
6Sugere-se que o leitor releia a frase sem a expressão em itálico.
7Tradução literal: “A vaca foi pro brejo”.
8Tradução literal: “Entre sem bater”.
9Tradução literal: “Estou contigo e não abro”.
C A P Í T U L O 6
Escrita de Artigo Científico
O artigo científico é a forma academicamente reconhecida de divulgação de
um trabalho de pesquisa. No nível de mestrado, e especialmente no nível de
doutorado, espera-se, e em alguns casos, exige-se, a publicação de um
artigo em um evento ou periódico de boa qualidade. Este capítulo apresenta
algumas dicas sobre escrita de artigos e finaliza com comentários sobre o
sistema brasileiro de avaliação da qualidade de veículos de publicação em
Ciência da Computação, o Qualis-CC, definido por uma comissão de
especialistas vinculada ao Ministério da Educação.
Todas as recomendações relativas ao texto da monografia valem também
para artigos científicos. Adiciona-se ainda a recomendação de que o artigo
deve ser muito mais sucinto do que a monografia. Então a clareza e
objetividade são muito mais críticos em um artigo do que em uma
monografia.
6.1 Autores
Ao contrário da monografia, que é um trabalho individual, o artigo
científico muitas vezes será um trabalho colaborativo. Em países como o
Brasil, considera-se estranho que um artigo publicado a respeito de uma
monografia não possua o respectivo orientador como co-autor.
Segundo Moro (2008), não existe um consenso sobre qual deve ser a
ordem em que os autores devem aparecer no artigo. Em alguns casos
recomenda-se, por simplicidade, o uso da ordem alfabética.
Porém, o primeiro autor de um artigo costuma ser considerado o mais
importante. E o uso da ordem alfabética pode criar certa confusão. Pode ser
difícil, no caso de trabalhos cooperativos entre pesquisadores ou
instituições, chegar a uma conclusão sobre quem é o autor principal. Mas
no caso de artigos inspirados em monografias essa decisão é bem mais
simples:
a) Em primeiro lugar, deve aparecer o nome do aluno que foi o autor da
monografia em questão, visto que esse é considerado como o autor
principal do trabalho monográfico que deu origem ao artigo.
b) Em segundo lugar, deve aparecer o nome do orientador, já que este tem
também uma grande responsabilidade sobre o trabalho original, bem
como sua revisão final.
c) Em terceiro lugar, poderão aparecer, se houver, co-orientadores, colegas
ou outros pesquisadores que tenham de alguma forma contribuído com
o texto.
O usual é que sejam considerados co-autores apenas pessoas que
participaram da confecção do texto, embora algumas vezes acabem sendo
citadas também pessoas que tenham ajudado na coleta de dados ou na
implementação dos protótipos que deram origem ao trabalho. Não se
recomenda, entretanto, uma lista muito grande de co-autores, porque pode
dar a impressão de que se tenta artificialmente melhorar o currículo de
alguém.
6.2 Motivação para Escrever
Não se deve escrever um artigo se você não souber o que vai dizer. Parece
senso comum, mas às vezes estudantes começam assim um trabalho.
Primeiramente o candidato a autor deve pensar em uma frase que resuma
a contribuição do artigo e então desenvolver essa frase apresentando
antecedentes, detalhamento e consequências dessa ideia. Caso não consiga
pensar em uma frase que resuma o artigo, então o autor estará em maus
lençóis. Talvez seja interessante parar e pensar mais um pouco, ou ainda,
desenvolver melhor a pesquisa, organizar as ideias, procurar o orientador e
então tentar novamente.
Um artigo consiste na comunicação de uma ideia. Não se deve falar por
falar. Não se deve escrever à toa, nem desperdiçar preciosas linhas com
informação irrelevante ou desconexa.
Um artigo científico em geral é um texto curto, com 8 a 12 páginas.
Raramente um artigo terá mais do que 16 páginas. Então, o artigo não pode
e não deve ser um tratado sobre uma área do conhecimento, mas a
transcrição objetiva e precisa de uma ideia de pesquisa, do desenvolvimento
que a validou e das suas consequências no mundo.
Assim, o artigo deve enfatizar o resultado concreto obtido na pesquisa.
Importante também é mostrar ao leitor como o autor chegou nesse resultado
e, afinal de contas, qual é o problema real que o resultado resolve.
Para a melhor compreensão do assunto, o leitor deve receber, no início do
artigo, um resumo dos principais conceitos, apenas aqueles imprescindíveis
para compreender os resultados. Nota-se que estabelecer quais são os
conceitos necessários para a compreensão do artigo depende muitas vezes
do tipo de veículo de publicação. Por exemplo, para escrever um artigo
sobre redes neurais aplicadas a sistemas de previsão de cotações da bolsa e
publicar em um evento de Computação, não é necessário definir o que são
redes neurais, basta mencionar qual modelo foi usado, por que foi escolhido
e colocar uma citação bibliográfica. Por outro lado, os conceitos de
Economia usados possivelmente terão de ser mais detalhadamente
explicados para que um leitor da área de Computação possa entender a
pesquisa. Por outro lado, se a publicação for ocorrer em um evento de
Economia, acontece o contrário. Deve-se explicar claramente o que é uma
rede neural e como ela funciona e pode-se ser mais econômico em relação
aos conceitos de Economia.
Snyder (1991) propõe que o autor de um artigo faça a si mesmo algumas
perguntas antes de submeter o artigo a um evento. A primeira dessas
perguntas é: “por que estou escrevendo este artigo?”. Se a resposta for “para
documentar o que tenho feito nos últimos dois anos”, o autor corre um sério
risco de ter seu trabalho rejeitado. Poucas pessoas estarão interessadas em
saber o que alguém fez nos últimos dois anos. Se o objetivo for documentar
essas atividades, o autor deveria escrever um relatório de pesquisa, não um
artigo.
Outra resposta errada seria “para melhorar meu currículo”. Essa até
poderia ser a motivação inicial para alguém escrever um artigo, mas
dificilmente motivará outros a aceitarem o texto para publicação. Então
outra resposta tem de ser buscada.
A resposta correta para a questão estaria na linha de “comunicar uma
ideia a alguém”. Então, ainda segundo Snyder, as questões seguintes
seriam: “O que o meu artigo está tentando comunicar?” e “Qual é o
público-alvo de meu artigo?”. Se o autor não conseguir responder
categoricamente a essas duas questões, então há uma grande chance de ser
um artigo fraco.
Outra questão é que um artigo focado tem mais chance de ser bom do
que um artigo disperso. É melhor tomar uma ideia e trabalhá-la claramente
no artigo do que passar superficialmente sobre um conjunto de grandes
ideias que o autor teve ao longo da vida. No caso de várias ideias, é melhor
escrever vários artigos.
Depois de saber claramente o que o artigo está comunicando, o autor
ainda deveria se perguntar se vale a pena apresentar essa comunicação, ou
seja, ele está realmente comunicando uma nova ideia ou é apenas uma nova
maneira de apresentar uma velha ideia, que já é bastante conhecida? É uma
ideia relevante ou é trivial? É apenas uma conjectura ou uma informação
baseada em sólidas evidências?
6.3 Trabalhos Correlacionados
Não só um artigo, como também a monografia final deverão mencionar
trabalhos correlacionados. Não se aceitam desculpas do tipo “ninguém
nunca fez algo parecido” (pois “parecido” é um termo difuso e bastante
flexível), ou “não encontrei nada na bibliografia sobre isso” (pois o leitor
vai sempre pensar que não se procurou o suficiente). Um aluno inteligente
vai evitar cair nessa armadilha!
Mas, o que fazer se efetivamente não for encontrado nada? Por exemplo,
se alguém está pesquisando as aplicações de redes neurais na bolsa e por
mais que procure não encontra outro trabalho sobre esse assunto. Como
escapar dessa armadilha?
A primeira dica é delimitar claramente o escopo da pesquisa
bibliográfica. Em vez de dizer “procurei e não achei nada”, o que é um
suicídio acadêmico, deve-se usar uma abordagem sistemática, como a
apresentada anteriormente: escolher os melhores periódicos e eventos na
área de redes neurais e/ou de bolsa de valores, no caso, fixar um período de
tempo razoável para realizar as pesquisas nesses veículos, por exemplo, os
últimos cinco ou dez anos, e finalmente fazer a pesquisa sistematicamente
nesses veículos no período de tempo delimitado verificando título e resumo
dos artigos. Os artigos podem então ser classificados em “não relacionado”,
“moderadamente relacionado” e “fortemente relacionado”. Se o aluno não
encontrar nenhum artigo fortemente relacionado, então ele pode mencionar
no seu trabalho os moderadamente relacionados. Ele deve dizer sempre
onde pesquisou. Pode dizer, por exemplo, “Ao proceder à revisão
bibliográfica nos periódicos x, y e z de 2003 a 2009 não foram encontrados
trabalhos que abordassem o uso de redes neurais para previsões da bolsa de
valores. Porém os seguintes trabalhos moderadamente relacionados foram
encontrados: (a) Fulano de tal (200x) apresenta uma abordagem que utiliza
redes neurais para prever a demanda de energia em transformadores
elétricos de rua, (b) etc.”.
Agindo dessa forma o leitor fica mais tranquilo. Ninguém pode ser
culpado por não ter encontrado um artigo sobre o assunto que
eventualmente tenha sido publicado em um obscuro evento na Groenlândia
ou no Marrocos, pois ninguém é capaz de saber tudo, não? Mas o aluno
estará bem respaldado se esse artigo existir e se algum avaliador o
mencionar, pois ele delimitou sua revisão bibliográfica aos melhores
periódicos e eventos da área. Se aquele trabalho da Groenlândia ou
Marrocos é realmente bom, por que não foi submetido aos bons veículos de
publicação reconhecidos pela comunidade?
6.4 A Contribuição do Artigo
Sobre a contribuição do artigo pode-se recomendar o seguinte:
a) Não ser modesto!
b) Não exagerar!
Para Platão (2006), os vícios estão nos extremos, e a virtude, no
equilíbrio. Então o autor deve ser realista em relação aos resultados e à
contribuição de seu artigo.
O autor deve convencer o comitê avaliador de que seus resultados estão
corretos. Não se deve esperar que eles simplesmente acreditem ou
simpatizem com as ideias. Eles precisam ser convencidos. O comitê
avaliador fará uma leitura crítica do artigo, procurando por quaisquer lapsos
que possam invalidar o trabalho. Para ser publicado, o trabalho precisa
passar por esse crivo. Então, um convencimento crítico é necessário. Deve-
se apresentar provas, evidências e exemplos que possam ajudar.
Finalmente, a contribuição do artigo deve estar clara desde o abstract ou
resumo. Ela não pode ser deixada para o final. Os resultados devem ser
apresentados logo no início do artigo para interessar o leitor. Depois o autor
pode ir explicando como chegou a eles.
6.5 Tipos de Artigos
Há vários tipos ou estilos de artigos, cada um dos quais com suas próprias
características e seus próprios veículos de publicação. Esta seção destaca
alguns.
6.5.1 Artigo Teórico
Um artigo teórico basicamente apresenta um conjunto de definições,
conhecido como “teoria”, e posteriormente passa a provar propriedades
lógicas desse conjunto. Exemplos de técnicas de prova usadas neste tipo de
artigo são indução (matemática ou estrutural) e redução ao absurdo.
Existem bons livros de lógica que podem ajudar o leitor interessado a
estruturar seu trabalho de acordo com esse paradigma.
Em um artigo teórico, cada afirmação precisa ser colocada
cuidadosamente, e todas precisam ser fundamentadas. Pode-se fundamentar
uma afirmação através de referência bibliográfica, prova lógica, relato de
observação direta, ou ainda como hipótese ou definição.
Porém, não adianta fazer apenas a abordagem teórica de uma questão. É
preciso mostrar qual o problema real que essa teoria resolve. Então não
adianta criar uma teoria bonita que não sirva para nada. Mesmo um artigo
teórico deve ter algum tipo de consequência no mundo real.
6.5.2 Relato De Experiência
Um relato de experiência conta uma história informativa sobre um
experimento e suas observações. Este relato deve mostrar como a situação
observada se reflete em situações mais gerais. Ou seja, o relato de
experiência deve, sempre que possível, não se fixar à instância específica
sendo observada, mas apresentar a possível generalização das observações
para outras situações.
Deve-se evitar entrar em detalhes irrelevantes sobre o experimento.
Apenas as informações necessárias para compreender ou validar o relato
devem ser incorporadas.
O relato deve se concentrar nas ideias, e não no experimento em si. Ou
seja, o relato de experiência não é uma narrativa sobre todos os passos que
o autor deu no caminho da observação, mas uma estruturação das ideias
aprendidas durante a observação. Essa estruturação, então, raramente será
apresentada de forma temporal narrativa, mas sim de forma dissertativa,
organizada por conceitos e suas implicações.
6.5.3 Artigos Sobre Métodos
Artigos sobre métodos são especialmente comuns na Ciência da
Computação. Um bom artigo sobre método não pode ser simplesmente uma
apresentação do método. Ele deve se concentrar nas vantagens que o
método sendo apresentado tem sobre outros anteriormente propostos para o
mesmo problema ou problemas semelhantes.
Um artigo sobre métodos deve ter um objetivo informativo bastante
claro, ou seja, o novo método deve ter um ponto focal. O artigo deve
relacionar as vantagens do novo método sobre abordagens anteriores. Então
aqui, a comparação bibliográfica é fundamental para a aceitação do artigo.
Recomenda-se que um artigo sobre métodos permita a aplicação do
método em um projeto real. Quando isso não for possível, uma referência a
um texto mais completo pode ajudar. Além disso, como o artigo deve conter
uma comparação com métodos anteriores, ele deve deixar bem claro qual a
métrica usada para a comparação. Uma comparação subjetiva terá pouco
valor, especialmente se o autor não deixar claro de onde vieram os
resultados. Por exemplo, uma tabela de características, na qual se
comparam diversos métodos avaliando cada um com o valor “atende”, “não
atende” ou “atende parcialmente”, não terá muito valor a não ser que o
autor deixe bastante claro como essas avaliações foram obtidas, de forma
que possam ser repetidas por observadores independentes.
O artigo deve ser mais do que uma apresentação do método com
explanação. O importante não é listar os procedimentos operacionais do
novo método, mas apresentar as ideias que o novo método incorpora.
Além do mais, o artigo deve ser equilibrado. Novas abordagens
normalmente não são a panaceia universal. Se o novo método tem
vantagens, possivelmente também terá limitações, que devem ser descritas e
analisadas no artigo.
6.6 Veículos de Publicação
Os resultados de uma pesquisa podem ser publicados em uma série de
veículos reconhecidos pela comunidade científica. Quanto maior o impacto
do veículo, ou seja, o número de pessoas que ele efetivamente atinge, maior
a dificuldade relativa de se conseguir publicar um artigo ali.
Então, dependendo da real contribuição e inovação do trabalho,
diferentes veículos de publicação deverão ser escolhidos. O estudante não
deve ficar desestimulado se sua primeira tentativa de publicação for
frustrada. Usualmente avaliações críticas consistentes sobre o trabalho são
entregues explicando os motivos da recusa. Essas avaliações podem e
devem ser usadas como um estímulo e um guia para produzir uma versão
melhorada do artigo visando à publicação em outro veículo.
Existem veículos que são bastante específicos de cada área, como, por
exemplo, o Simpósio Brasileiro de Qualidade de Software ou o IEEE
Transactions on Software Engineering. Mas estes não são os únicos
veículos em que se pode publicar. Há periódicos e eventos mais genéricos
que em geral aceitam artigos de todas as subáreas da Computação, como,
por exemplo, o SEMISH, que ocorre junto ao Congresso da Sociedade
Brasileira de Computação e o periódico Communications of ACM. Ambos
são considerados bons veículos.
Em relação ao estilo de veículo, pode-se fazer as seguintes distinções:
a) Periódico: É considerada a publicação mais importante por todas as
áreas da ciência. Os melhores artigos usualmente são destinados aos
periódicos mais reconhecidos dentro de cada área. A Ciência da
Computação no mundo todo, entretanto, conta com poucos periódicos
quando comparada a outras áreas do conhecimento. No Brasil,
periódicos de qualidade em Ciência da Computação são praticamente
inexistentes.
b) Eventos ou conferências: A Ciência da Computação privilegia a
publicação em conferências, o que muitas vezes cria problemas em
relação à avaliação relativa com outras áreas como Física e Química,
cujos pesquisadores publicam quase que exclusivamente em periódicos.
Embora não tão valorizados quanto periódicos por outras áreas, as
conferências em Computação podem ter peso relativo bastante relevante
na produção científica de um pesquisador.
c) Workshops e seminários: Em geral, são eventos satélites de conferências
maiores. Como são normalmente muitíssimo restritos em termos de
abrangência temática e número de participantes, são considerados
publicações de menor impacto, embora alguns workshops tenham se
firmado como boas conferências ao longo de uma história consistente
de boas edições.
d) Livros e Capítulos de Livros: Embora bastante valorizados, livros e
capítulos de livros são publicações que usualmente não resultam de
teses e monografia (com poucas exceções), visto que, em geral, o
objetivo desse tipo de publicação é apresentar um conteúdo didático
para compreensão por parte de um público bem mais amplo do que o
conjunto de pesquisadores de uma determinada área da ciência.
Existe uma diferença fundamental no estilo de processo de revisão de
eventos e periódicos. Como os eventos ocorrem em data predeterminada, as
publicações em geral são submetidas até um determinado prazo (deadline) e
então avaliadas por um comitê de programa. Trata-se normalmente de um
processo competitivo em que os melhores artigos são aceitos para
publicação, com algumas poucas sugestões de modificação no texto. A
maioria dos eventos, especialmente os mais bem conceituados, aceitará uma
porcentagem relativamente pequena dos artigos submetidos. Então, no caso
de envio de artigo a um evento, o autor terá apenas uma chance de publicar.
O artigo deve estar pronto e em condições de concorrer com outros artigos.
Se estiver entre os melhores, será publicado, caso contrário, será rejeitado.
Já o processo de revisão em periódicos acontece de forma diferenciada.
Exceto no caso de números especiais temáticos, os periódicos funcionam
com regime de envio contínuo, ou seja, não há deadline. Assim, um artigo
eventualmente aceito no periódico entra em uma fila e será publicado
quando chegar a sua vez. O processo de revisão, então, pode ser bem mais
interativo do que no caso de eventos.
Um artigo submetido será revisado pelo comitê editorial, e,
possivelmente, várias sugestões serão feitas ao texto antes que este possa
ser aceito para publicação. Poderão, inclusive, acontecer várias rodadas de
avaliação do texto, em que os revisores solicitam modificações e os autores
as incorporam ao texto, se possível. Esse processo interativo de revisão de
um texto pode até levar anos, em alguns casos, mas procura garantir que o
material final estará adequado ao público leitor do periódico, de acordo com
os critérios do comitê editorial.
Deve-se ter em mente também que o processo de revisão em periódicos é
muito mais detalhado do que em conferências. No caso de conferências, os
revisores trabalham com deadlines, e às vezes recebem um grande fardo de
avaliações para fazer, estando, dessa forma, mais sujeitos a cometer erros de
avaliação. No caso de periódicos, a revisão é feita com mais tempo e,
portanto, é bem mais detalhada.
Além do tipo e publicação, a abrangência também deve ser considerada.
Todos os diferentes veículos têm uma abrangência estimada, que pode ser:
a) Internacional: veículos publicados em língua inglesa que são
distribuídos ou que contam com a participação de autores de vários
países, sem predominância de nenhuma nação, como, por exemplo, a
maioria dos periódicos e conferências da IFIP, ACM e IEEE.
b) Nacional: não são apenas os veículos publicados no Brasil, como se
poderia pensar. Existem periódicos e eventos de abrangência nacional
publicados em outros países. Caracteriza-se como um veículo nacional
aquele que é publicado em uma língua diferente do inglês ou que,
embora publicado em inglês, tenha participantes predominantemente de
um único país ou região, por exemplo, a Conferência Latino-americana
de Informática (CLEI) e a maioria dos simpósios da SBC.
c) Regional: são veículos que abrangem apenas uma fração de um país,
por exemplo, um estado brasileiro e ou região geográfica. Exemplos
desse tipo de veículo são os anais da Escola Regional de Bancos de
Dados e o Seminário Catarinense de Imagens Médicas.
d) Local: são veículos publicados por uma única universidade ou
faculdade. Em geral, contam com um comitê avaliador local ou de
pouca abrangência, e a maioria dos autores de artigos pertence à própria
instituição. Ex.: Semana de Informática da Universidade de Água Suja
do Norte.
Existem então as combinações entre os diversos tipos de publicação e sua
abrangência, como, por exemplo, periódico internacional, ou evento
regional etc. O documento de área da Ciência da Computação na CAPES
distingue os seguintes tipos: Periódico Internacional (PI), Periódico
Nacional (PN), Conferência Internacional (CI), Conferência Nacional (CN),
Livro Científico Nacional (LCN), Livro Didático Nacional (LDN), Livro
Científico Internacional (LCI), Livro Didático Internacional (LDI), Capítulo
de Livro Nacional (CLN) e Capítulo de Livro Internacional (CLI).
Deve-se prestar atenção ao seguinte: algumas conferências publicam seus
anais como livros, com ISBN, inclusive. Não existe consenso na
comunidade sobre se isso caracteriza uma publicação em livro ou se ainda
seria publicação em evento. Porém, pela lógica, deveria ser considerada
como um livro apenas a obra literária que foi proposta e construída com
esse propósito. Um livro tem uma estrutura sequencial e lógica, o que não
ocorre normalmente com conferências, porque estas publicam os melhores
artigos. Mas estes são submetidos de forma independente pelos seus
autores, baseado no trabalho de pesquisa que tenham efetuado, sem uma
sequência lógica predeterminada.
A era da informática, entretanto, tem facilitado tanto a criação de
publicações que possivelmente as fronteiras claras que havia antigamente
entre os diferentes tipos de publicação talvez não mais existam no futuro.
6.7 Ética no Envio de Artigos
Ao enviar um ou mais artigos, o autor deve estar atento aos aspectos éticos
considerados pela comunidade científica.
Em primeiro lugar, a publicação de um artigo em um evento ou periódico
implica um compromisso de não enviar ou publicar novamente esse mesmo
artigo ou partes dele em outro local.
Outro aspecto não tão evidente, mas também importante, é que um
artigo, mesmo que ainda não tenha sido publicado, deve ser submetido a
apenas um veículo de cada vez. Ou seja, não se deve cair na tentação de
enviar o mesmo artigo a vários eventos ao mesmo tempo na esperança de
que um deles vai aceitar. Snyder (1993) aponta que “simultaneous
submission without notice is considered highly unethical.”1 Alguns eventos
ou periódicos até aceitam envio simultâneo a outro veículo, desde que seja
explicitamente informado.
A forma correta de se tentar uma publicação é, portanto, enviar uma
primeira versão do artigo a um veículo e aguardar o resultado. Sendo
aprovado para publicação, ótimo! Caso contrário, os avaliadores enviarão
juntamente com a informação da recusa de publicação uma lista de motivos.
Essa lista vai conter sugestões para melhoria do trabalho que poderão ser
usadas pelo autor de modo a aprimorar o artigo antes de enviá-lo a outro
veículo.
Ainda outro aspecto a ser considerado é o caso da publicação de dois ou
mais artigos semelhantes sobre o mesmo assunto. Não é considerado ético
fazer várias versões de um mesmo artigo e enviá-las a diferentes veículos.
Cada artigo apresenta uma ou mais ideias de pesquisa que foram avaliadas.
Assim, artigos, mesmo que diferentes na forma, mas que apresentam as
mesmas ideias, são considerados uma forma de autoplágio, e, portanto,
antiéticos. É possível, por outro lado, publicar vários artigos a partir do
mesmo trabalho de pesquisa, desde que cada um trate de aspectos diferentes
do trabalho, ou seja, cada artigo deve explorar uma ideia de pesquisa
diferente ou, no caso de publicações mais antigas, pode-se gerar um novo
artigo aprofundando ou estendendo os resultados já apresentados.
Não se pode copiar diretamente o texto de um artigo já publicado em
outro, mesmo em se tratando do próprio autor. Uma vez que o texto tenha
sido publicado, ele pode ser citado em um novo artigo através de referência
bibliográfica, entre aspas, como se fosse outro texto qualquer. Cada artigo
deve, portanto, ser escrito com texto 100% original.
6.8 Qualis2
A Coordenação de Aperfeiçoamento de Pessoal de Nível Superior
(CAPES), órgão do Ministério da Educação do Brasil, publica uma “lista de
veículos utilizados para a divulgação da produção intelectual dos programas
de pós-graduação stricto sensu (mestrado e doutorado), classificados quanto
ao âmbito de circulação (Local, Regional, Nacional, Internacional) e à
qualidade (A, B, C), por área de avaliação”. Essa lista, denominada Qualis,
é usada pela CAPES para fundamentar o processo de avaliação do Sistema
Nacional de Pós-Graduação.
O Qualis é organizado por área do conhecimento. Na área de Ciência da
Computação, a lista denomina-se Qualis-CC e é organizada por um comitê
de especialistas. Um mesmo veículo de publicação pode estar classificado
em mais de uma área de conhecimento, às vezes, inclusive, com uma
avaliação diferente em termos da qualidade. Isso acontece porque cada área
define os seus próprios critérios de qualidade.
Na sequência serão apresentados os critérios de qualidade usados pela
comissão de Ciência da Computação.
6.8.1 Periódicos
Na área de Ciência da Computação, são considerados os índices de impacto
registrados no ISI/JCR (Journal of Citation Records) e no CiteSeer
Computer Science Citation Index.
Os periódicos que constam no JCR são divididos em três grupos de
acordo com o índice de impacto:
a) Nível A: 60% superior.
b) Nível B: 30% médio.
c) Nível C: 10% inferior.
Os periódicos que constam no CiteSeer também são divididos em três
grupos:
a) Nível A: 40% superior.
b) Nível B: 40% médio.
c) Nível C: 20% inferior.
No caso de periódicos que constam nos dois índices, é considerada a nota
mais alta entre os dois.
Além dessa regra, baseada em índices de impacto, considerase que os
periódicos das sociedades científicas internacionais ACM, IEEE,
INFORMS e SIAM, mesmo que não apareçam em nenhum índice, são
classificadas como B.
Periódicos nacionais só são considerados se forem indexados. Por uma
deferência especial da comissão, o JCBS, Journal of the Brazilian
Computer Society, é avaliado como Internacional C.
Periódicos de áreas afins com interface com a Ciência da Computação
recebem a maior avaliação dentre as áreas afins. São consideradas áreas
afins: Engenharia Eletrônica, Matemática, Matemática Aplicada, Pesquisa
Operacional e Estatística.
6.8.2 Eventos Internacionais
Os principais fatores de avaliação de um evento internacional são, segundo
o comitê, o índice de impacto, a tradição do evento, a sociedade promotora,
a avaliação por comitê de programa internacional, sem predominância de
nenhum país, e por artigo completo (eventos que avaliam artigos a partir de
resumos não são bem classificados).
O JCR não avalia o impacto de eventos. Apenas o CiteSeer tem
informação sobre eventos. Assim, o índice de um evento será dado
basicamente por dois critérios, o CiteSeer e uma combinação das qualidades
mencionadas. No caso de atribuição de notas divergentes por esses dois
critérios, prevalece a mais alta.
Para a avaliação pelo CiteSeer são usados os mesmos pontos de corte
indicados anteriormente. O critério de combinação de qualidades do evento
é aplicado assim:3
a) Um evento é de nível A se for “patrocinado (i.e., sponsored) por
Sociedades Científicas Internacionais como: IEEE, IFIP, ACM, SIAM,
INFORMS, W3C etc., desde que a publicação seja artigo completo (full
paper) e tenha avaliação por revisores (i.e., referees) e conferência de
tradição. Conferências de tradição devem ter tido pelo menos quatro
edições. O Comitê tem constatado uma grande variabilidade na
qualidade dos eventos que publicam seus anais (i.e., proceedings) como
Lectures Notes. Sendo assim, o Comitê irá julgar caso a caso a
qualidade desses eventos para efeitos de classificação”.
b) Um evento é de nível B “se os critérios anteriores são satisfeitos, mas a
conferência é considerada ainda recente, i.e., menos de quatro edições”.
c) Um evento é de nível C se avalia artigo completo (full paper) utilizando
revisores e cujas publicações são impressas pelas Sociedades Científicas
como IEEE, ACM IFIP, SIAM etc., embora não sejam patrocinados por
essas sociedades. Também são de nível C “conferências patrocinadas
por Sociedades Científicas, mas com caráter claramente regional... (por
exemplo, Asian International Conference, Pacific-rim conference,
Latin-american Conference)”. Finalmente, “workshops e similares
associados a Conferências Internacionais QUALIS A patrocinadas (i.e.,
sponsored) por Sociedades Científicas Internacionais como: IEEE, IFIP,
ACM, SIAM, INFORMS, W3C etc., com trabalho completo, recebem
classificação internacional C”, sendo, porém, analisados caso a caso.
Veículos de publicação que não aparecem no Qualis não são
necessariamente ruins. O Qualis-CC não é uma lista de todos os veículos de
Ciência da Computação. Apenas os eventos e periódicos reportados pelos
programas de pós-graduação aparecem no índice. Novos veículos são
adicionados anualmente quando algum programa informa que um de seus
pesquisadores ali publicou. Assim, eventos ou periódicos que não aparecem
no Qualis podem receber uma boa classificação quando da revisão do
índice. Porém, quando veículos aparecem no Qualis-CC, mas não têm nota
(nem A, nem B e nem C), é porque já foram avaliados, mas não foram
encontrados indícios de que possam receber nota A, B ou C.
6.8.3 Eventos Nacionais
A avaliação dos eventos nacionais é feita de forma mais subjetiva. Em
primeiro lugar, porque estes não aparecem, normalmente, nos indexadores
internacionais. Em segundo lugar, porque a maioria dos eventos nacionais
considerados são aqueles que ocorrem no Brasil, sendo, portanto,
conhecidos, e seu número não é tão grande.
Ao contrário dos eventos internacionais, espera-se que todos os eventos
brasileiros de bom nível já estejam no Qualis-CC, justamente pela
proximidade e pelo pequeno número destes.
Os eventos nacionais são classificados de acordo com os seguintes
critérios (do documento de área):
a) Características do evento.
b) Comitê de programa.
c) Número de envios.
d) Percentual de aceitação.
e) Apoio de entidades científicas.
f) Tradição do evento.
Em relação às características do evento, espera-se que este seja
representativo de uma subárea da Computação. Eventos com abrangência
temática genérica e abrangência geográfica limitada dificilmente terão uma
boa avaliação. Espera-se que o evento seja realizado no âmbito de uma
sociedade científica, como, por exemplo, a Sociedade Brasileira de
Computação (SBC). Eventos ligados a empresas nem sempre têm caráter
científico. De preferência, eventos de nível A devem ter abrangência
internacional, com comitê de programa sem predominância de brasileiros,
página na Internet em inglês e anais publicados por uma editora
internacional.
Em relação ao comitê de programa, espera-se que seja constituído de
pesquisadores reconhecidos na área do evento e que se distribuam em
vários países.
Em relação ao número de envios, espera-se que seja compatível com o
tamanho da área de pesquisa. Um evento com poucos envios indica pouca
procura e pouco interesse por parte da academia, o que não é um bom
indicativo de qualidade.
O percentual de aceitação é a razão entre o número de artigos aceitos
para publicação e o número de artigos enviados ao evento. Espera-se que
eventos de nível A tenham menos de 35% de aceitação, e que eventos de
nível B tenham entre 35% e 55% de aceitação.
O apoio de sociedades científicas internacionais como ACM e IEEE deve
ser uma constante para eventos de nível A.
Finalmente, um evento novo, mesmo que bem organizado, dificilmente
terá conceito máximo. Para que um evento obtenha nível A, em geral, deve
ter tido pelo menos três edições anteriores organizadas regularmente e com
boa qualidade. Por esse motivo também, eventos pontuais, ou seja, que não
acontecem regularmente, dificilmente serão classificados.
São examinados caso a caso os workshops ligados a eventos nacionais de
nível A, podendo receber nível C ou até superior, dependendo do caso.
1Tradução: “Envios simultâneos sem aviso são considerados altamente antiéticos.”
2No momento em que este livro estava sendo escrito, a CAPES estava realizando uma revisão do
sistema Qualis. Possivelmente algumas das regras aqui mostradas já tenham mudado. Recomenda-se
consultar www.capes.gov.br para obter uma versão atualizada dessas regras.
3Fonte www.capes.gov.br.
C A P Í T U L O 7
Plágio
Plágio é a apropriação indevida de ideias ou textos de outras pessoas. A
prática da cópia do trabalho alheio era comum e aceita entre os escribas
antigos e os músicos da renascença e do barroco, mas, com o passar do
tempo e com a consolidação do direito à propriedade e sua exploração, o
plágio adquiriu status de procedimento antiético. Porém, sempre continuou
acontecendo. Na era da Internet, nunca foi tão fácil copiar o trabalho alheio,
porém, também nunca foi tão fácil detectar essas cópias.
Independentemente da questão da exploração comercial de direitos
autorais, o plágio, no meio acadêmico, é extremamente nocivo se não for
detectado, pois o plagiador apresenta um resultado que não é de sua autoria
e recebe um título que não merece. Nessa condição, ele próprio pode ser
prejudicado, ao não dominar conhecimentos que seriam necessários para
exercer sua profissão, ou, pior ainda, se exercer sua profissão, prejudicará a
terceiros, por apresentar soluções inadequadas, de acordo com sua própria
incompetência.
Há pelo menos duas formas de plágio: a cópia literal de textos de outras
pessoas constituindo integral ou parcialmente um trabalho que deveria ser
do autor, e a cópia de ideias, em que o autor, apesar de não repetir as
palavras como foram escritas, apresenta as mesmas ideias, na mesma
sequência lógica, como se fossem suas.
Não é considerado plágio o uso de ideias de terceiros, desde que a fonte
apareça claramente identificada. No caso de cópias literais, devem aparecer
entre aspas.
Conta-se que certa vez um estudante de doutorado plagiou uma tese,
copiando o texto integral de outro autor e trocando apenas o nome do autor
original pelo seu próprio nome. Durante a defesa, um dos membros da
banca, o convidado externo, elogiou copiosamente o trabalho durante vários
minutos. No final acrescentou: “mas você não pode obter o doutorado com
esta tese, porque este trabalho é meu”. O plagiador foi tão displicente que
sequer olhou o nome de quem estava plagiando e acabou convidando essa
pessoa para a banca.
Neste capítulo serão discutidos casos de plágio e suas consequências, e
serão mostradas também algumas situações nas quais fica caracterizado o
desvio de conduta dos plagiadores e seus apologistas.
7.1 Antecedentes
Até a invenção da imprensa, as obras escritas eram reproduzidas por
escribas e copiadores profissionais. Naquela época, apenas esses
profissionais da cópia é que eram remunerados pelo seu trabalho. Ao autor
cabia apenas o mérito pela obra (mas às vezes nem isso).
Com a invenção da imprensa, no século XV, a cópia de textos se tornou
uma atividade de massa e, por esse motivo, suscitou a questão da proteção
jurídica ao trabalho do autor. Não apenas a questão de proteger o direito ao
patrimônio da obra, mas também da proteção à sua integridade.
No início, a censura caminhou junto com a proteção ao direito autoral.
Em 1662, por exemplo, na Inglaterra, o Licensing Act proibia a impressão
de qualquer livro que não tivesse sido previamente autorizado.
Já o Copyright Act, de 1709, protegia por até 21 anos a propriedade
intelectual e patrimonial de obras impressas.
Na França, após a Revolução de 1789, os valores iluministas passaram a
imperar e, com isso, a primazia do autor sobre a obra intelectual. A
proteção do direito autoral passou a ser por toda a vida do autor e inclusive
transmitida aos seus herdeiros legais.
No Brasil, a primeira menção sobre proteção dos direitos autorais surge
em 1827, na lei que criava os cursos jurídicos. Em 1830 a matéria é
regulamentada através da promulgação do código de direito criminal.
7.2 Proteção aos Direitos Autorais
O Brasil tem uma das legislações mais fortes em relação a direitos autorais
no mundo. Nos Estados Unidos, por exemplo, a proteção ao direito autoral
depende de registro. No Brasil, o registro não é precondição para a proteção
do direito autoral. Basta a prova da autoria. Pode-se, por exemplo, lacrar a
obra literária ou técnica em um envelope do correio e remetê-la para si
mesmo ou para uma pessoa de sua confiança. Não se deve abrir esse
envelope, exceto em juízo. O carimbo do correio é uma prova da data da
produção, ou pelo menos de que na data do envio a produção estava com a
pessoa em questão. Assim, no caso de um processo por plágio, o autor tem
como provar que o texto estava com ele numa determinada data. Se essa
data for anterior à produção tida como plágio, então boa parte do processo
terá sido resolvido em favor do autor.
Nos cursos de graduação e programas de pós-graduação, é grande a
preocupação com o plágio. Em especial, porque nunca foi tão fácil copiar
textos usando a Internet. Por outro lado, também, nunca foi tão fácil
detectar cópias. Sequer são necessárias ferramentas sofisticadas para isso.
Basta um site de busca e uma cópia da monografia. Três ou quatro palavras
são escolhidas aleatoriamente em qualquer ponto da monografia e pesquisa-
se no site de busca. Dificilmente a ocorrência dessas palavras juntas em um
texto será mera coincidência. Com esse recurso é possível descobrir a
grande maioria dos casos de plágio.
Textos traduzidos de outras línguas para o português são mais difíceis de
detectar, mas nem tanto. Normalmente, o próprio estilo de escrita permite
perceber que um texto é uma tradução e não um texto originalmente escrito
em português. Por exemplo, brasileiros dificilmente usam a palavra
“eventualmente”, ou “fornece” em textos científicos quando escrevem em
português, mas traduzem essas palavras literalmente a partir de textos em
inglês, em que são mais comuns (no caso, respectivamente, “eventually” e
“provides”).
Acredita-se que boa parte do plágio acadêmico ocorria porque os alunos
não eram corretamente orientados em relação ao que podia e o que não
podia ser copiado. Então, para que não haja dúvidas, aqui vai a resposta:
nada pode ser copiado, a não ser que seja colocado entre aspas e com a
citação da fonte bibliográfica. Mesmo assim, deve-se agir com parcimônia,
pois as citações não podem predominar em um trabalho científico. É
necessário haver a contribuição do autor.
Certa vez um aluno de especialização entregou uma monografia com 20
páginas. Na primeira página ele escreveu algo como “Outro dia li um artigo
interessante na Internet:”. Em seguida ele abria aspas e incluía o dito artigo
literalmente na sua monografia. Vinte páginas depois, após fechar aspas, ele
concluía dizendo: “Por isso achei o artigo tão interessante”. O aluno foi
reprovado. Ele questionou dizendo que, como tinha colocado o texto entre
aspas e citado a fonte, isso não era plágio. Mas foi reprovado mesmo assim,
pois tirando o que estava entre aspas não sobrava praticamente nada do
trabalho dele. Assim, o trabalho foi considerado insuficiente para a
obtenção do título.
7.3 A Lei Brasileira
É interessante saber o que diz a lei brasileira. A principal referência, no
caso de plágio, é a Lei número 9.610, de 19 de fevereiro de 1998. Essa lei
altera, atualiza e consolida a legislação sobre direitos autorais.
Uma pergunta frequente na área de Computação é se o governo, ao
subvencionar um projeto, torna-se detentor do direito autoral sobre este. Por
exemplo, se o aluno recebe uma bolsa da CAPES ou CNPq para fazer sua
monografia, esses órgãos têm algum direito sobre a monografia e seus
produtos? A lei é clara em seu artigo 6ª: “ Não serão de domínio da União,
dos estados, do Distrito Federal ou dos municípios as obras por eles
simplesmente subvencionadas.”
Já o artigo 7ª estipula quais são as obras protegidas pela lei
(literalmente):
a) Os textos de obras literárias, artísticas ou científicas.
b) As conferências, alocuções, sermões e outras obras da mesma natureza.
c) As obras dramáticas e dramático-musicais.
d) As obras coreográficas e pantomímicas, cuja execução cênica se fixa
por escrito ou por outra qualquer forma.
e) As composições musicais, tenham ou não letra.
f) As obras audiovisuais, sonorizadas ou não, inclusive as
cinematográficas.
g) As obras fotográficas e as produzidas por qualquer processo análogo ao
da fotografia.
h) As obras de desenho, pintura, gravura, escultura, litografia e arte
cinética.
i) As ilustrações, cartas geográficas e outras obras da mesma natureza.
j) Os projetos, esboços e obras plásticas concernentes à Geografia,
Engenharia, Topografia, Arquitetura, Paisagismo, Cenografia e Ciência.
k) As adaptações, traduções e outras transformações de obras originais,
apresentadas como criação intelectual nova.
l) Os programas de computador.
m) As coletâneas ou compilações, antologias, enciclopédias, dicionários,
bases de dados e outras obras, que, por sua seleção, organização ou
disposição de seu conteúdo, constituam uma criação intelectual.
No caso de programas de computador, especificamente, o § 1ª desse
artigo estabelece que eles ainda são objeto de uma lei específica.
Por outro lado, o artigo 8ª estabelece quais as obras que não são
protegidas por essa lei:
a) As ideias, procedimentos normativos, sistemas, métodos, projetos ou
conceitos matemáticos como tais.
b) Os esquemas, planos ou regras para realizar atos mentais, jogos ou
negócios.
c) Os formulários em branco para serem preenchidos por qualquer tipo de
informação, científica ou não, e suas instruções.
d) Os textos de tratados ou convenções, leis, decretos, regulamentos,
decisões judiciais e demais atos oficiais.
e) As informações de uso comum tais como calendários, agendas,
cadastros ou legendas.
f) Os nomes e títulos isolados.
g) O aproveitamento industrial ou comercial das ideias contidas nas obras.
Segundo a lei, o autor de uma obra será sempre a pessoa física que a
gerou, não a pessoa jurídica. A proteção à pessoa jurídica poderá, porém,
também ser concedida em casos previstos em lei.
A duração da proteção ao direito autoral perdura por 70 anos, a contar do
dia primeiro de janeiro do ano subsequente à morte do autor. Os direitos
patrimoniais sobre a obra são herdados pelos legítimos herdeiros, obedecida
a ordem estabelecida pela Lei Civil.
Segundo o artigo 46 da mesma lei, não constitui ofensa aos direitos
autorais a reprodução:
a) Na imprensa diária ou periódica, de notícia ou de artigo informativo,
publicado em diários ou periódicos, com a menção do nome do autor, se
assinados, e da publicação da qual foram transcritos.
b) Em diários ou periódicos, de discursos pronunciados em reuniões
públicas de qualquer natureza.
c) De retratos, ou de outra forma de representação da imagem, feitos sob
encomenda, quando realizada pelo proprietário do objeto encomendado,
não havendo a oposição da pessoa nele representada ou de seus
herdeiros.
d) De obras literárias, artísticas ou científicas, para uso exclusivo de
deficientes visuais, sempre que a reprodução, sem fins comercias, seja
feita mediante o sistema Braile ou outro procedimento em qualquer
suporte para esses destinatários.
e) De um só exemplar de pequenos trechos, para uso privado do copista,
desde que feita por este, sem intuito de lucro.
f) Da citação em livros, jornais, revistas ou qualquer outro meio de
comunicação, de passagens de qualquer obra, para fins de estudo, crítica
ou polêmica, na medida justificada para o fim a atingir, indicando-se o
nome do autor e a origem da obra.
g) Do apanhado de lições em estabelecimentos de ensino por aquelas a
quem se dirigem, vedada sua publicação, integral ou parcial, sem
autorização prévia e expressa de quem as ministrou.
h) De obras literárias, artísticas ou científicas, fonogramas e transmissão
de rádio e televisão em estabelecimentos comerciais, exclusivamente
para demonstração à clientela, desde que esses estabelecimentos
comercializem os suportes ou equipamentos que permitam a sua
utilização.
i) Da representação teatral e execução musical, quando realizadas no
recesso familiar ou, para fins exclusivamente didáticos, nos
estabelecimentos de ensino, não havendo em qualquer caso intuito de
lucro.
j) De obras literárias, artísticas ou científicas para reproduzir prova
judiciária ou administrativa.
k) De pequenos trechos, em quaisquer obras, de obras preexistentes, de
qualquer natureza, ou de obra integral, quando de artes plásticas, sempre
que a reprodução em si não seja o objetivo principal da obra nova e que
não prejudique a exploração normal da obra reproduzida nem cause um
prejuízo injustificado aos legítimos interesses dos autores.
Portanto, a regra é copiar apenas o essencial de outros trabalhos, desde
que seja realmente necessário para colocar uma informação sobre esses
trabalhos ou traçar um comparativo, lembrando sempre que o trecho
copiado deve constar entre aspas e com citação da fonte para que nunca
haja dúvida sobre se tratar ou não de plágio.
O plágio no Brasil é considerado crime, e a Lei prevê pena de multa e
prisão. Portanto, não vale a pena transgredir essa lei. Também não existe
plágio mais sério ou menos sério. Plágio é crime perante a Lei e
academicamente é uma falta ética gravíssima. Houve um caso em que um
estudante plagiou apenas o capítulo de método (metodologia) de sua
monografia, copiando-o de outra monografia. Ele realmente fez o trabalho,
realizou a pesquisa, obteve os dados e gerou as conclusões. Mas pela falta
ética de ter copiado parte do trabalho, esse estudante teve seu diploma
cassado, independentemente de outros fatores.
Areal (1997) apresenta em seu site uma série de comentários de
plagiadores, que são pérolas que evidenciam o tipo de raciocínio ou
ignorância que muitas vezes está por trás desse tipo de atitude. Algumas
dessas pérolas são transcritas a seguir para exemplificar:
a) “(…) você deveria esta orgulhoso de ver sue trabalho em um grade
sucesso que não é ocasso da sua pagina” (sic). O plagiador sequer
consegue escrever corretamente…
b) “(…) o que de maneira nenhuma constitui-se na ação citada em no
assunto (subject) de seu e-mail, o qual refere-se a crime de coação sob
utilização de arma branca ou de fogo para obtenção de propriedade
alheia. Acusação, aliás, que pode perfeitamente ser objeto de processo
judicial por calúnia e difamação (considerando que várias pessoas
possuem cópia testemunhal do seu delito criminal)” (sic). Aqui o
plagiador acusa o autor de difamação…
c) “Pensei que você fosse ficar orgulhoso”.
d) “se voce nao quiser que ninguem copie, nao ponha na Internet. E’
bobagem achar que vai ter exclusividade sobre o conteudo na Internet.
Besteira pura (…) isso e’ a Internet, cara. O jeito correto de lidar com
a situacao nao e’ falar de (…) de lei de direito autoral, e sim relaxar e
aproveitar enquanto a internet ainda e’ nossa” (sic).
e) “Achei super interessante sua abortagem sobre plagio na rede, porem,
constatei que na sua pagina existe alguns gifs (imagens) que acho que
nao sao de sua autoria. Seria melhor que os mesmo fossem retirados,
pois, e contraditorio falar de plagio e fazer o mesmo, mesmo sendo gifs
de dominio publico” (sic). Bem, se é de domínio público pode usar,
não?
Em relação a usar materiais de domínio público ou com autorização do
autor, apenas deve-se tomar certo cuidado em verificar se a pessoa que
autoriza o uso é realmente o autor. Há casos de sites que se apropriam de
materiais de terceiros e autorizam seu uso por outras pessoas, mas não
teriam autoridade para isso.
C A P Í T U L O 8
Níveis de Exigência do Trabalho de
Conclusão
Dependendo do nível do curso, deve variar o nível de exigência em relação
ao trabalho de conclusão. Embora Eco (1989) defina a monografia como
um texto com 100 a 400 páginas, tamanho não é documento. O que se
avalia é o grau e o tipo de contribuição que o estudante apresentou no
trabalho.
A estrutura do ensino superior brasileiro identifica diferentes tipos de
cursos. Inicialmente os cursos de graduação, que podem ser cursados pelos
egressos do Ensino Médio. Há vários tipos e modalidades: bacharelado,
engenharia, licenciatura são considerados cursos de graduação plena.
Cursos de graduação mais rápidos são os cursos de tecnologia, que formam
o tecnólogo, e os cursos sequenciais, ainda mais rápidos.
Já a pós-graduação caracteriza-se por dois tipos de curso, o lato sensu e o
stricto sensu. Os cursos lato sensu, usualmente denominados
“especialização”, ou seguindo modismos do norte, MBA (Master in
Business Administration), são de cunho mais técnico e de complementação
da formação técnica profissional.
Já os cursos stricto sensu, em seus dois níveis, mestrado e doutorado,
procuram formar pesquisadores e docentes de ensino superior. São cursos,
portanto, com características bastante diferentes dos cursos de graduação e
lato sensu.
Há ainda o mestrado profissionalizante, que busca formar um
pesquisador em uma área bastante próxima da aplicação profissional. Não
se trata de um meio-termo entre a especialização e o mestrado científico,
assim como a informática médica não é um meio termo entre a informática
e medicina. É simplesmente uma forma diferente de conceber um curso de
mestrado, com aplicação direta do conhecimento gerado na indústria.
Em geral, basta ter um diploma de graduação plena para poder ingressar
em um programa de mestrado, embora algumas universidades tenham já
aceitado tecnólogos.
Para ingresso no mestrado não é necessário ter especialização, embora
algumas vezes isso possa valorizar o currículo do candidato no processo
seletivo. Algumas universidades também validam algumas disciplinas
cursadas em nível de especialização ao aluno que ingressa no mestrado.
Deve-se verificar caso a caso como a universidade procede.
Para ingresso no curso de doutorado não é necessário ter o mestrado. Mas
é praxe na maioria dos programas de doutorado não admitir alunos sem
mestrado. A prática é possível, mas os programas dificilmente se arriscam.
O doutorado é considerado como a titulação plena e definitiva em termos
acadêmicos. O título de PhD nada mais é do que um doutorado obtido em
país de língua inglesa (Eco, 1989). Existem outros títulos equivalentes
também no exterior, e às vezes deve-se tomar cuidado em não confundi-los
com os títulos outorgados no Brasil.
Por exemplo, existem países na Europa com cursos de mestrado de um
ano, em que o aluno apenas cursa disciplinas e entrega um trabalho escrito,
constando basicamente de revisão bibliográfica. Esses cursos não são
considerados equivalentes ao mestrado brasileiro, mas a cursos de
especialização.
Para que um diploma no exterior seja reconhecido no território brasileiro
é necessário que seja revalidado por uma universidade brasileira com
delegação de poderes do Ministério da Educação para tal fim (em geral, as
universidades federais). Por mais conceituado que seja o diploma obtido no
exterior, ele só terá validade no Brasil mediante esse processo de
revalidação. Tal processo é na maior parte das vezes demorado, pois a
universidade brasileira que tenha um programa stricto sensu na área da
monografia apresentada irá constituir uma banca avaliadora que verificará
se o trabalho teria qualidade para ser aprovado no próprio programa. Tendo
qualidade, o título é revalidado e recebe um carimbo no verso do diploma,
atestando sua validade no Brasil. Caso contrário, o pedido é recusado. Mas
o interessado pode ainda procurar outra universidade e tentar o processo
novamente.
No caso de cursos à distância, deve-se verificar, antes de mais nada, se a
instituição tem autorização expressa do Ministério da Educação para
oferecer esse tipo de curso (www.mec.gov.br). No caso de instituições
estrangeiras que oferecem cursos à distância no Brasil também deve se
tomar especial cuidado, pois o diploma é emitido no exterior e não tem
validade automática no Brasil.
8.1 Graduação
O que se espera de um trabalho de conclusão em um curso de graduação?
Neste nível podem ser feitos dois tipos de trabalho: o tecnológico e o
científico.
O trabalho científico deve seguir as linhas metodológicas descritas neste
livro.
Já o trabalho tecnológico consiste usualmente em o aluno ser capaz de
mostrar que sabe aplicar as técnicas que aprendeu ao longo do curso. O
desenvolvimento de um sistema interessante pode ser um bom exemplo de
trabalho de final de curso, desde que o aluno o desenvolva usando técnicas
aprendidas durante o curso e apresente um relatório mostrando isso.
8.2 Especialização
Os cursos de especialização já foram encarados como um degrau para
chegar ao mestrado. Hoje em dia, porém, são vistos muito mais como uma
complementação ou atualização profissional. Pela lei brasileira, todo curso
de especialização requer a elaboração e defesa pública de uma monografia.
Essa monografia pode até ser um trabalho de pesquisa, feito nos moldes
metodológicos apresentados neste livro. Mas é aceitável também, em
muitos cursos, que o aluno desenvolva apenas um estudo bibliográfico e
que apresente as ideias aprendidas com alguma pequena contribuição
pessoal, consistindo normalmente de comentários à bibliografia ou ao
resultado de experimentos simples. Normalmente não se exige nesses casos
provas de hipóteses ou uma contribuição científica mais relevante.
Isso, porém, varia muito de curso para curso. O aluno deve estar atento às
exigências colocadas pelo curso em que ele está matriculado.
8.3 Mestrado e Doutorado
A maioria das recomendações deste livro se aplica ao mestrado e ao
doutorado. Em ambos os casos, espera-se que o aluno apresente uma
contribuição à ciência que seja relevante, ou seja, que não seja trivial, que
seja útil e que esteja correta.
A diferença entre o que se espera no mestrado e no doutorado reside mais
no nível de exigência da contribuição do que na forma. Em ambos os casos,
exige-se a aplicação de metodologia científica, comparação com trabalhos
correlatos, elaboração de uma hipótese de pesquisa e sua comprovação ou
refutação. A diferença está então no impacto esperado dessa contribuição.
Para o mestrado, em geral, basta que o aluno apresente uma informação
nova sobre algum tema, que seja relevante para a área. No caso do
doutorado, essa informação nova tem de ter importância suficiente para
mudar o modo como as pessoas em todo o mundo encaram aquela área de
pesquisa. Ou seja, espera-se que um doutorado produza uma contribuição
que de fato modifique o estado da arte.
Comer (2008) ainda acrescenta que uma tese deve ser “original” e
“substancial”. É difícil muitas vezes avaliar isso. Cabe aos orientadores,
com sua experiência, direcionar os alunos de forma a escolher um objetivo
que seja compatível com o nível do curso que está obtendo.
Chinneck (1998) afirma que a diferença entre o mestrado e o doutorado
não está na forma do documento nem na apresentação, mas apenas na
profundidade e na dificuldade do problema sendo tratado. Segundo ele, uma
tese de doutorado exige a resolução de um problema mais difícil e,
consequentemente, mais contribuições significativas.
No Brasil costuma-se usar os termos “tese de doutorado” e “dissertação
de mestrado”. Mas em inglês, ambos os termos são usados para designar os
trabalhos de mestrado e doutorado. Rugaber (1995) diferencia os termos
“tese” e “dissertação”, afirmando que a tese é uma afirmação que se procura
provar e a dissertação é um texto descritivo sobre a tese.
O Engenheiro de Materiais Angelo Fernando Padilha é graduado pela
Universidade Federal de São Carlos, em 1974. É Mestre em Engenharia
Metalúrgica pela EPUSP, em 1977, e Doktor-Ingenieur pela Universidade de
Karlsruhe da Alemanha, em 1981. Trabalhou mais de uma década no IPEN-
CNEN/SP. Foi Pesquisador Visitante no Instituto Max Planck para Pesquisa
em Metais (Stuttgart) e Professor Visitante no Instituto de Materiais da Uni-
versidade do Ruhr de Bochum. Deu assessoria para várias empresas. É autor
de cerca de 100 trabalhos publicados no Brasil e no exterior e de 4 livros.
Desde 1988, é Docente do Departamento de Engenharia Metalúrgica e de
Materiais da EPUSP, onde fez Livre-Docência e é Professor Titular.
10
Apresentação
O presente texto tem caráter introdutório. Embora um autor não possa e
nem deva determinar ou escolher seus leitores, ele foi escrito visando interes-
sados que estão se iniciando no estudo da Ciência dos Materiais. Eles tanto
podem ser estudantes de graduação dos três primeiros anos de Engenharia
Metalúrgica ou de Engenharia de Materiais, como graduados em outras áreas,
tais como Física, Química, Engenharia Mecânica, Engenharia Química e
Odontologia, que estejam se iniciando na área de materiais.
A matéria é desenvolvida em 20 capítulos concisos. Nos capítulos inici-
ais é discutida a organização dos átomos na matéria (ligações químicas,
sólidos cristalinos, sólidos amorfos e sólidos parcialmente cristalinos). Nos
capítulos intermediários são abordados (com considerável detalhe) os defei-
tos cristalinos. Na parte final são discutidas as principais propriedades dos
materiais. No decorrer de todo o texto procura-se relacionar a composição e a
estrutura dos materiais com suas propriedades e usos.
A abordagem apresenta algumas ênfases. Por exemplo, os materiais
cristalinos são tratados em maior detalhe que os amorfos e parcialmente
cristalinos. Os materiais metálicos ocupam maior espaço que os cerâmicos,
poliméricos e compósitos. As propriedades mecânicas são discutidas em mai-
or detalhe que todas as outras. Estas ênfases foram ditadas pela importância
econômica e pelas aplicações.
O leitor também poderá notar algumas lacunas e ausências. Não apre-
senta um tratamento termodinâmico dos fenômenos abordados, nem sequer
os diagramas de fases dos materiais discutidos são apresentados. Também
não é dada maior atenção para as transformações que ocorrem durante o
processamento dos materiais. Estas ausências foram intencionais e são justi-
ficadas pela abordagem e pelo caráter introdutório do texto. Isto não signifi-
ca, porém, que os tópicos não tratados sejam de menor importância. O autor
planeja inclusive tratá-los em um outro volume, denominado Processamento
11
e Transformações dos Materiais. As técnicas de análise microestrutural, im-
portantíssimas em Ciência dos Materiais, também não foram tratadas com
maior detalhe, pois são o tema central de outro volume de nossa co-autoria.
Não foi incluída nenhuma micrografia real no presente volume. Todas as
microestruturas apresentadas são esquemáticas e simples.
Acredito que os três volumes, o presente texto, o livro de técnicas de
análise microestrutural, cuja segunda edição revista e ampliada está em pre-
paração e o volume sobre processamento e transformações dos materiais
(ainda em fase de concepção), deverão oferecer em conjunto uma visão razo-
ável da Ciência dos Materiais.
O Autor
São Paulo, janeiro de 1997
12
Os Materiais de Engenharia
Segundo Morris Cohen, conceituado cientista de materiais do não me-
nos conceituado Massachusetts Institute of Technology (MIT), materiais são
substâncias com propriedades que as tornam úteis na construção de máqui-
nas, estruturas, dispositivos e produtos. Em outras palavras, os materiais do
universo que o homem utiliza para “fazer coisas”.
Os materiais sólidos são freqüentemente classificados em três grupos
principais: materiais metálicos, materiais cerâmicos e materiais poliméricos
ou plásticos. Esta classificação é baseada na estrutura atômica e nas ligações
químicas predominantes em cada grupo. Um quarto grupo, que foi incorpora-
do nesta classificação nas últimas décadas, é o grupo dos materiais compósi-
tos. Em seguida, descreveremos brevemente os quatro grupos acima mencio-
nados.
Materiais metálicos
Os materiais metálicos são normalmente combinações de elementos
metálicos. Eles apresentam um grande número de elétrons livres, isto é,
elétrons que não estão presos a um único átomo. Muitas das propriedades dos
metais são atribuídas a estes elétrons. Por exemplo, os metais são excelentes
condutores de eletricidade e calor e não são transparentes à luz. A superfície
dos metais, quando polida, reflete eficientemente a luz. Eles são resistentes
mas deformáveis. Por isto são muito utilizados em aplicações estruturais.
Entre os quatros grupos de materiais mencionados anteriormente, os
materiais metálicos, e em particular os aços, ocupam um lugar de destaque
devido à sua extensiva utilização. Cerca de 70 dos 92 elementos da tabela
periódica encontrados na natureza têm caráter metálico preponderante. Os
1
13
metais mais tradicionais, tais como cobre, ouro e ferro são conhecidos e
utilizados há alguns milênios.
No período entre 5000 e 3000 a.C., ou seja, dois milênios após a intro-
dução da agricultura, surgiu uma série de invenções importantes. O homem
desenvolveu o forno de “alta temperatura”, onde ele aprendeu a fundir os
metais e a empregá-los para dominar os animais. Ele inventou o arado, a
carroça, as embarcações, a vela e a escrita. No início da era cristã o homem
conhecia sete metais: cobre, ouro, prata, chumbo, estanho, ferro e mercúrio.
Embora a civilização clássica da Grécia tenha explorado quase comple-
tamente as possibilidades oferecidas pelos metais e outros materiais disponí-
veis desde eras precedentes, na produção de cerâmicas, joalheria, esculturas e
arquitetura, eles pouco fizeram para inovar o campo dos materiais. O mesmo
pode-se dizer dos romanos, que adquiriram uma grande reputação como en-
genheiros. Por outro lado, foram os romanos que disseminaram no seu vasto
império o ferro como material propulsor da economia.
Um fato importante ocorreu em Mainz (Alemanha), onde Johannes Gu-
tenberg (c.1397-1468) iniciou experiências com a fundição de tipos ou carac-
teres metálicos (chumbo) durante a década de 1440. Por volta de 1445, ele e
seus colaboradores foram capazes de imprimir a “Bíblia de Gutenberg”. Sa-
bemos muito mais sobre os processos de produção de materiais no século
XVI do que em épocas anteriores, devido à imprensa.
Em 1540, o italiano Vannocio Biringuccio publicou sua obra clássica
De La Pirotechnia. No seu livro ele trata da fundição e conformação de
metais, além da fabricação de vidro e de pólvora.
Em 1556, foi publicada a obra também clássica de George Bauer (em
latim, Georgius Agricola), denominada De Re Metallica. Ele viveu nas re-
giões da Boemia e Silésia e descreve detalhadamente no seu livro operações
de mineração e de fundição.
Outro avanço significativo na produção e utilização de materiais metáli-
cos ocorreu com a fabricação dos aços com teor de carbono mais baixo e no
estado líquido. Antes da década de 1860, o ferro maleável tinha sido sempre
consolidado em temperaturas abaixo de seu ponto de fusão. Isto levava inevi-
tavelmente à heterogeneidade na distribuição do carbono e ao aprisionamento
de escória e outras inclusões. Esta descoberta, feita por Henry Bessemer em
1856, permitiu a produção de aço em grande escala e inaugurou uma nova
fase na história da humanidade; a idade do aço. Quase todos os desenvolvi-
mentos do século XIX se dirigiram para a produção mais eficiente dos mate-
riais conhecidos há séculos.
14 CAPÍTULO 1
Até o século XIX praticamente nenhum uso dos materiais havia explo-
rado algo além de suas qualidades mecânicas e ópticas ou sua resistência à
corrosão. As únicas propriedades físicas amplamente medidas e relatadas
quantitativamente na literatura científica eram ponto de fusão, densidade,
dilatação térmica e calor específico. Propriedades mecânicas (exceto as cons-
tantes elásticas) pareciam ser muito variáveis para terem algum significado
fundamental. A microestrutura das ligas era praticamente desconhecida. A
metodologia de estudo das ligas consistia basicamente em atacar quimica-
mente com ácidos as diversas composições de um determinado sistema biná-
rio. Desta maneira, Karl Karsten noticiou em 1839 a descontinuidade na
reatividade química de ligas com composição aproximadamente equiatômi-
cas do sistema binário cobre-zinco. Mais tarde, descobriu-se que se tratava do
composto intermetálico CuZn, conhecido como latão beta.
Mas a grande revolução estava a caminho: a observação microscópica
da microestrutura dos materiais e correlação com suas propriedades. Isto
começou no grande centro produtor de aço, em Sheffield, na Inglaterra. Hen-
ry Clifton Sorby, em 1863/64, observou a estrutura de rochas e de aços ao
microscópio óptico. A superfície destes materiais tinha sido polida e atacada
levemente com reagentes químicos.
Em 1895, eram descobertos os raios x. A difração de raios x, que
possibilitou a determinação da estrutura cristalina dos materiais, foi desco-
berta em 1911/12.
De posse da metalografia óptica, da difração de raios x e de algumas
técnicas indiretas como dilatometria e análise térmica, os metalurgistas pude-
ram caracterizar as transformações de fase e as microestruturas delas decor-
rentes. A correlação das microestruturas com as propriedades foi uma conse-
qüência natural. O advento da microscopia eletrônica possibilitou melhores
resoluções e a observação de detalhes e espécies não observáveis com o
microscópio óptico.
A maioria dos elementos químicos foi descoberta nos últimos 250 anos
(vide figura 1.1). Empregamos atualmente nos processos industriais a grande
maioria dos elementos químicos, ao passo que, até um século atrás, com
exceção de uns 20 deles, os mesmos eram curiosidades nos laboratórios de
química.
MATERIAIS DE ENGENHARIA 15
Materiais cerâmicos
Os materiais cerâmicos são normalmente combinações de metais com
elementos não metálicos. Os principais tipos são: óxidos, nitretos e carbone-
tos. A esse grupo de materiais também pertencem os argilo-minerais, o ci-
mento e os vidros. Do ponto de vista de ligações químicas, eles podem ser
desde predominantemente iônicos até predominantemente covalentes. Eles
são tipicamente isolantes térmicos e elétricos. São também mais resistentes à
altas temperaturas e a ambientes corrosivos que os metais e polímeros. Eles
são muito duros, porém frágeis.
A argila foi o primeiro material estrutural inorgânico a adquirir proprie-
dades completamente novas como resultado de uma operação intencional
realizada por seres humanos. Esta operação foi a “queima” (sinterização) que
tornou possível a obtenção de potes, panelas e outros utensílios cerâmicos,
Ano (D.C.)
Número de elementos descobertos
Figura 1.1
— Evolução do número cumulativo de elementos
químicos descobertos nos últimos dois milênios.
16 CAPÍTULO 1
com enorme impacto na vida e nos hábitos do homem. Segundo Kranzberg e
Smith, este foi talvez o começo da engenharia de materiais. Estima-se que
isto tenha ocorrido no oitavo milênio a.C.
A cerâmica vermelha (telhas, tijolos e manilhas) e a cerâmica branca
(azulejos, sanitários e porcelanas) são constituídas principalmente de silica-
tos hidratados de alumínio, tais como caulinita, haloisita, pirofilita e
montmorilonita. O óxido de ferro é que confere a cor avermelhada de muitos
produtos cerâmicos.
A argila é usualmente plástica após ser suficientemente pulverizada e
umedecida e é nesta condição conformada. Após a secagem, ela se torna
rígida e adquire alta dureza após a queima em temperaturas elevadas. As
cerâmicas tradicionais à base de sílica, alumina ou magnésia são também
muito utilizadas como refratários em fornos e dispositivos utilizados na fusão
e tratamentos térmicos dos metais e ligas.
Enquanto as cerâmicas tradicionais são obtidas a partir de matérias
primas naturais tais como argilo-minerais e areia; as cerâmicas avançadas são
feitas a partir de óxidos, nitretos, carbonetos e boretos de alta pureza, têm
composição definida e o tamanho, a forma e a distribuição das partículas são
controlados. Por outro lado, o mercado mundial de cerâmicas tradicionais é
pelo menos uma ordem de grandeza maior que o de cerâmicas avançadas.
Os vidros tradicionais são misturas de óxidos e devem ser classificados
como materiais cerâmicos. Eles também são materiais bastante antigos. Por
volta do ano 4000 antes de Cristo já existiam vidros decorativos no Egito. Em
1500 a.C., a produção de vidros já estava relativamente estabelecida.
Em 1200 d.C., Veneza era a “capital do vidro”. Para proteger sua tecno-
logia contra ingleses e franceses, os venezianos transferiram em 1292 a pro-
dução de Veneza para a ilha de Murano.Os vidros desta época eram basica-
mente misturas de sílica, cal e soda. Pequenas adições de íons de cobalto,
cromo, cobre, manganês e ferro causam grandes mudanças de cor. Por exem-
plo, a adição de apenas 0,15% de CoO confere ao vidro de carbonato de
sódio a cor azul escura.
O próximo grande desenvolvimento ocorreu com os chamados vidros
ópticos. Em 1846, o mecânico Carl Zeiss e o professor de física Ernst Abbe
montaram uma oficina de óptica em Jena, na Alemanha. Os estudos de Abbe
mostraram que havia uma limitação básica para a resolução em um sistema
óptico, relacionada ao diâmetro da lente e ao comprimento de onda da luz.
Em 1882, o químico recém-doutorado Friedrich Otto Schott juntou-se a
eles. Schott havia concluído seu trabalho de doutorado com vidros de alta
pureza e procurava para eles uma aplicação. Vidros de melhor qualidade e a
MATERIAIS DE ENGENHARIA 17
assessoria de um especialista em materiais era exatamente o que estava fal-
tando aos produtos da oficina de Zeiss e Abbe. Os três dominaram o desen-
volvimento das lentes modernas e dos instrumentos óticos.
Nas últimas décadas do atual século ocorreram dois outros desenvolvi-
mentos importantes na indústria do vidro, relacionados com a utilização de
materiais reforçados com fibras de vidro e com as fibras ópticas usadas na
transmissão de informações.
A grande maioria (99%) da produção atual, em peso, de vidros pertence
aos três tipos: SiO 2(sílica) - Na 2O(soda) - CaO(cal); PbO - SiO 2 e B 2O 3 -
SiO 2 - Na 2O - CaO.
Dentre os tipos mencionados acima, o único desenvolvido no século
XX foi o vidro à base de boro.
Os vidros inorgânicos apresentam ausência de ordem de longo alcance
(são amorfos), têm propriedades isotrópicas, são transparentes à luz visível,
podem ser formulados para absorver ou transmitir determinados comprimen-
tos de onda, são isolantes térmicos e elétricos e amolecem antes de fundir,
permitindo a conformação por sopro de formas intrincadas.
Em 1960, foram produzidos pela primeira vez por Pol Duwez ligas
metálicas amorfas; os chamados vidros metálicos. Estes materiais são estru-
turalmente similares aos vidros inorgânicos, mas apresentam as propriedades
impostas pela ligação metálica.
Materiais poliméricos
Os polímeros são constituídos de macromoléculas orgânicas, sintéticas
ou naturais. Os plásticos e borrachas são exemplos de polímeros sintéticos,
enquanto o couro, a seda, o chifre, o algodão, a lã, a madeira e a borracha
natural são constituídos de macromoléculas orgânicas naturais.
Os polímeros são baseados nos átomos de carbono, hidrogênio, nitrogê-
nio, oxigênio, flúor e em outros elementos não metálicos. A ligação química
entre átomos da cadeia é covalente, enquanto a ligação intercadeias é fraca,
secundária, geralmente dipolar.
Os materiais poliméricos são geralmente leves, isolantes elétricos e
térmicos, flexíveis e apresentam boa resistência à corrosão e baixa resistência
ao calor.
Os polímeros naturais foram usados por milênios. Materiais naturais de
origem animal ou vegetal, como madeira, fibras têxteis, crinas e ossos, são
18 CAPÍTULO 1
todos polímeros. Por outro lado, o desenvolvimento dos plásticos modernos
ocorreu principalmente depois de 1930. Para que os plásticos modernos pu-
dessem ser desenvolvidos, a química orgânica teve que ser criada.
Até a década de 1820, predominava a chamada teoria da força vital: os
compostos orgânicos só existiriam nas coisas vivas, enquanto os compostos
inorgânicos seriam os constituintes de todos os minerais.
A síntese da uréia feita por Woehler, em 1828, a partir de compostos
inorgânicos, liquidou com a teoria da força vital. Hoje em dia, existem mais
de um milhão de substâncias orgânicas sintetizadas artificialmente, mas na-
quela época químicos importantes como Berzelius (1779-1848) receberam
com ceticismo o anúncio feito pelo jovem químico Woehler. Por uma ironia
da história, a expressão polímero foi criada por Berzelius, em 1832, em
contraposição à isômero, para designar compostos de pesos moleculares múl-
tiplos, ou de mesmo peso molecular, respectivamente. O termo polímero vem
do grego e significa muitas partes.
A baquelita, descoberta em 1905, por Leo Hendrik Baekeland, foi a
primeira da série dos plásticos sintéticos. Em 1935 , M.W.Perrin e J.C.
Swallow descobrem o polietileno. Em 1938, R.J. Plunkett descobre o polite-
traflúoretileno (PTFE). A maioria dos polímeros foi descoberta no período
entre 1930 e 1950, mas a indústria dos polímeros não chegou à sua maturida-
de antes dos anos 60. O desenvolvimento foi, a partir daí, exponencial.
Existem vários tipos de macromoléculas:
• macromoléculas sintéticas orgânicas. Exemplos: polietileno, policlore-
to de vinila, nailon e muitos outros “plásticos”.
• macromoléculas naturais orgânicas. Exemplos: algodão, madeira, lã,
cabelo, couro, seda, chifre, unha e borracha natural.
• macromoléculas naturais inorgânicas. Exemplos: diamante, grafite, sí-
lica e asbesto.
• macromoléculas sintéticas inorgânicas. Exemplos: ácido polifosfórico
e policloreto de fosfonitrila.
O petróleo e o gás natural são as duas principais matérias primas para a
produção de plásticos. Na destilação fracionada do petróleo são obtidas di-
versas frações de hidrocarbonetos. A fração de maior importância na produ-
ção de plásticos é a nafta. Por exemplo, de cada 100 toneladas de petróleo
pode-se obter cerca de 20 toneladas de nafta e pouco mais de 5 toneladas de
polietileno.
Os polímeros podem ser classificados em três grupos principais:
MATERIAIS DE ENGENHARIA 19
• termoplásticos. Podem ser repetidamente conformados mecanicamente
desde que reaquecidos. Portanto, não só a conformação a quente de
componentes é possível, mas também a reutilização de restos de produ-
ção, que podem ser reintroduzidos no processo de fabricação (recicla-
gem). Muitos termoplásticos são parcialmente cristalinos e alguns são
totalmente amorfos. Exemplos típicos de termoplásticos são: polietile-
no, policloreto de vinila (PVC), polipropileno e poliestireno.
• termorígidos. São conformáveis plasticamente apenas em um estágio
intermediário de sua fabricação. O produto final é duro e não amolece
mais com o aumento da temperatura. Uma conformação plástica poste-
rior não é portanto possível. Não são atualmente recicláveis. Os termo-
rígidos são completamente amorfos, isto é, não apresentam estrutura
cristalina. Exemplos típicos de termorígidos são: baquelite, resinas epo-
xídicas, poliésteres e poliuretanos.
• elastômeros (borrachas). São também materiais conformáveis plastica-
mente, que se alongam elasticamente de maneira acentuada até a tem-
peratura de decomposição e mantém estas características em baixas
temperaturas. Os elastômeros são estruturalmente similares aos termo-
plásticos, isto é, eles são parcialmente cristalinos. Exemplos típicos de
elastômeros são: borracha natural, neopreno, borracha de estireno, bor-
racha de butila e borracha de nitrila.
O consumo de polímeros em um país industrializado, como a Inglaterra,
é predominantemente de termoplásticos (55%), depois vem as borrachas
(27%) e em seguida os termorígidos (10%) e outros produtos poliméricos
(8%).
Os maiores produtores mundiais de polímeros são: Estados Unidos
(29%), Japão (12%), Alemanha (10%), Ex-URSS (6%), França (5%) e outros
(38%).
O nível de desenvolvimento industrial de um país ou continente pode
ser avaliado pelo consumo de plásticos, conforme ilustra a tabela 1.1.
20 CAPÍTULO 1
Tabela 1.1 — Consumo de plásticos em diversos países e regiões.
Região Total
(milhões de toneladas) Por habitante (kg)
Europa Ocidental 22 63
Estados Unidos 21 89
Canadá 2 80
Japão 7 58
Índia 1 1,3
América do Sul 3 7,5
África 1 2
África do Sul 0,7 21
Ex-URSS 7 17,5
Materiais compósitos
Os materiais compósitos são materiais projetados de modo a conjugar
características desejáveis de dois ou mais materiais.
Um exemplo típico é o compósito de fibra de vidro em matriz poliméri-
ca. A fibra de vidro confere resistência mecânica, enquanto a matriz polimé-
rica, na maioria dos casos constituída de resina epoxídica, é responsável pela
flexibilidade do compósito.
A matriz pode ser polimérica, metálica ou cerâmica. O mesmo vale para
o reforço, que pode estar na forma de dispersão de partículas, fibras, bastone-
tes, lâminas ou plaquetas.
Os materiais compósitos são também conhecidos como materiais con-
jugados ou materiais compostos.
A madeira é um material compósito natural, em que a matriz e o reforço
são poliméricos. O concreto é outro compósito comum. Neste caso, tanto a
matriz como o reforço são materiais cerâmicos. No concreto, a matriz é
cimento Portland e o reforço é constituído de 60 a 80% em volume de um
agregado fino (areia) e de um agregado grosso (pedregulho). O concreto pode
ainda ser reforçado com barras de aço.
A grande expansão no desenvolvimento e no uso dos materiais compó-
sitos iniciou-se na década de 1970, conforme mostra a figura 1.2.
MATERIAIS DE ENGENHARIA 21
Outros grupos ou tipos de materiais
Além dos quatros grupos principais mencionados anteriormente, exis-
tem alguns grupos emergentes de materiais, tais como: materiais semicondu-
tores, materiais supercondutores, polímeros condutores e silicones.
Os materiais semicondutores têm propriedades elétricas intermediárias
entre condutores e isolantes. Além disto, as características elétricas destes
materiais são extremamente sensíveis à presença de pequenas concentrações
de impurezas. Os semicondutores tornaram possível o advento dos circuitos
integrados, que revolucionaram as indústrias eletrônica e de computadores
nas últimas duas décadas. Os semicondutores podem ser elementos semi-me-
tálicos puros como o silício e o germânio ou compostos como GaP, GaAs e
InSb.
Os materiais supercondutores apresentam resistência elétrica desprezí-
vel abaixo de uma certa temperatura, denominada temperatura crítica. Eles
podem ser tanto materiais metálicos como materiais cerâmicos. Os melhores
supercondutores metálicos são geralmente compostos intermetálicos, tais
como Nb 3Sn e Nb 3Ge ou soluções sólidas tais como Nb-Ti e Nb-Zr. Mesmo
os melhores supercondutores metálicos têm temperatura crítica muito baixa,
menor que 23 K. Os condutores cerâmicos, descobertos recentemente, são
óxidos mistos e apresentam temperatura crítica por volta de 100 K, mas a
quantidade de corrente conduzida (corrente crítica) é muito baixa.
Enquanto os polímeros condutores encontram-se em fase de desenvolvi-
mento, os silicones já são amplamente utilizados na forma de óleos, borra-
chas e resinas.
Produção
Ano
Figura 1.2 — Evolução da produção de alguns materiais nos EUA.
22 CAPÍTULO 1
Materiais tradicionais e materiais avançados
As transições da pedra para o bronze, e do bronze para o ferro foram
revolucionárias pelo seu impacto, mas foram relativamente lentas em termos
de escala de tempo.
As mudanças na inovação e na aplicação dos materiais ocorridas no
último meio século, entretanto, ocorreram em intervalos de tempo que foram
revolucionárias ao invés de evolucionárias.
A despeito disto, os materiais podem ser classificados em quatro níveis,
conforme o grau de conhecimento científico utilizado no seu desenvolvimen-
to.
Esta classificação é apresentada abaixo:
I. Materiais naturais. Exemplos: madeira, couro, diamante, cobre, ligas fer-
rosas provenientes de meteoritos e borracha.
II. Materiais desenvolvidos empiricamente. Exemplos: bronze, aço comum,
ferro fundido, cerâmicas sílico-aluminosas, vidro, cimento e concreto.
III. Materiais desenvolvidos com auxílio qualitativo de conhecimentos cientí-
ficos, isto é, as considerações científicas orientaram seus descobrimentos e a
interpretação qualitativa de suas propriedades. Exemplos: ligas mais antigas
de alumínio, de titânio e de magnésio, metal duro, aços inoxidáveis, aços
microligados, termoplásticos, termorígidos, elastômeros e ferritas.
IV. Materiais projetados (novos ou aperfeiçoados) quase que exclusivamente
a partir de conhecimentos científicos e cujas propriedades podem ser quanti-
tativamente previstas. Exemplos: semicondutores, materiais para reatores nu-
cleares, aços de ultra-alta resistência mecânica, materiais compósitos reforça-
dos com fibras, ligas com memória de forma e vidros metálicos.
Neste ponto deve-se destacar que velho ou novo nem sempre tem rela-
ção direta com tradicional ou avançado. Por exemplo, um aço maraging,
contendo um total de cerca de 30% em vários elementos de liga e que após
sofisticados tratamentos termomecânicos, apresenta um limite de escoamento
acima de 3 GPa, é um material muito avançado, embora as ligas de ferro
tenham mais de 5 milênios de história. Por outro lado, a simples combinação
de dois ou três compostos exóticos raramente leva a um material avançado.
Finalmente, é importante destacar que o grau de conhecimento científi-
co empregado no desenvolvimento de um material tem efeito determinante
no seu preço e a capacidade de produzi-los é uma medida do grau de desen-
volvimento tecnológico (e independência) de uma nação.
MATERIAIS DE ENGENHARIA 23
O preço dos materiais e dos produtos acabados
O preço talvez seja a principal característica de um material. Ao seleci-
onar os materiais para um determinado produto acabado, além das exigências
em termos de propriedades, o engenheiro tem que levar em conta o preço.
A tabela 1.2 apresenta o preço por quilo de alguns produtos acabados.
Tabela 1.2 — Custo por quilo de alguns produtos acabados
(unidade monetária européia, ECU)
Produto Custo
Casas 1
Navios 5
Automóveis 10
Bicicletas 15-25
Aparelhos eletrodomésticos 40-100
Calçados esportivos 15-60
Aeronave civil 1000
Satélites 15000
A análise da tabela acima mostra claramente que, por exemplo, na
seleção de materiais para a construção civil, o fator preço é essencial. Inúme-
ros materiais apresentam propriedades muito interessantes para utilização em
construção civil, mas têm sua utilização inviabilizada pelo preço.
Por outro lado, na construção de satélites, o preço dos materiais empre-
gados pode ficar em segundo plano, em comparação com suas propriedades.
Em outras palavras, neste caso, as propriedades dos materiais é que predomi-
nam dentre os critérios de seleção.
A tabela 1.3 apresenta o preço de numerosos materiais de engenharia.
A análise da tabela 1.3 revela vários aspectos importantes. Um deles é
que o preço de um material está relacionado com sua pureza, processamento
e características. Isto pode ser notado claramente nos casos do carboneto de
silício e do silício propriamente dito. Outro aspecto digno de ser mencionado
é que a cerâmicas avançadas e materiais compósitos reforçados com fibra de
carbono ainda são materiais muito caros. Por outro lado, o aço comum, o
concreto e a madeira deverão ainda por muito tempo predominar como mate-
riais de construção.
24 CAPÍTULO 1
Tabela 1.3 — Preço de alguns materiais de engenharia.
Material Preço (US$/tonelada)
Diamante industrial de alta qualidade 500.000.000
Platina 16.500.000
Ouro 14.500.000
Tungstênio 19.500
Titânio 8.300
Latão (60%Cu - 40%Zn) 3.750
Alumínio 2.400
Aço inoxidável 2.700
Aço doce 350
Carboneto de silício (cerâmica avançada) 27.500
Carboneto de silício (abrasivos) 1.400
Carboneto de silício (refratários) 750
Vidro 750
Borracha sintética 1.400
Borracha natural 870
Polietileno 1.100
PVC 1.000
Fibra de vidro 1.500
Fibra de carbono 45.000
Resina epoxídica 6.000
Madeira compensada dura 1.650
Madeira dura estrutural 530
Madeira mole estrutural 350
Vigas de concreto reforçado 330
Cimento 70
Silício monocristalino (“Wafers”) 10.000.000
Silício metalúrgico 1.300
A comparação dos valores da tabela 1.2 com 1.3, embora as unidades
monetárias sejam ligeiramente diferentes, mostra claramente que muitos ma-
teriais foram selecionados para suas atuais aplicações por critério de preço.
Pense por exemplo, na construção de navios ou de carroçarias de automóveis
com aço inoxidável.
MATERIAIS DE ENGENHARIA 25
A tabela 1.4 compara importantes materiais de construção em termos
do custo relativo de cada unidade de resistência mecânica (N/mm 2).
Tabela 1.4 — Preço relativo da unidade de resistência mecânica
(resistência à tração) de vários materiais de construção.
Material Resistência
(N/mm 2 )
Densidade
(g/cm3
)
Custo
relativo
Aço de construção (chapas) 370 7,8 1
Ferro fundido cinzento 120* 7,3 3
Liga de alumínio 200 2,7 3,5
PVC 40 1,4 4
Fibra de vidro em matriz polimérica 500 1,9 10
Polietileno 10 0,9 12
Concreto 40* — 0,2
* Resistência à compressão
Energia e materiais
A demanda, a produção e o preço dos materiais estão estreitamente
relacionados com o consumo de energia. O consumo de energia na produção
de materiais é da ordem de 15 a 25% de toda a energia primária utilizada nas
economias industrializadas. Quase todos os metais ocorrem na natureza com-
binados com outros elementos químicos, isto é, na forma termodinamicamen-
te mais estável. A sua extração e purificação (refino), assim como todo o seu
processamento, exigem grandes quantidades de energia. A produção de me-
tais consome aproximadamente 10% da produção total de energia. Apenas 5
metais (ferro, alumínio, cobre, titânio e zinco) consomem na sua produção
mais de 80% desta energia. Os custos de energia representam uma parcela
considerável do custo total de produção dos metais primários. Por exemplo,
os custos de energia variam de 15% para o chumbo e atingem 45% para o
níquel. Os materiais poliméricos sintéticos também exigem grandes quantida-
des de energia na sua produção. A tabela 1.5 apresenta valores de energia
necessária para a produção de vários materiais.
A reciclagem é um parâmetro muito importante na indústria dos materi-
ais, tanto do ponto de vista energético como do ambiental. O ganho energéti-
26 CAPÍTULO 1
co obtido com a reciclagem de alguns metais, como é o caso do alumínio e
do cobre, ultrapassa 85%. Em outras palavras, a energia requerida para pro-
cessar uma certa quantidade destes metais a partir de material reciclado
representa 15% da energia necessária para obter a mesma quantidade de
metal a partir de fontes primárias. A economia de energia ou ganho energéti-
co é significativa para numerosos materiais: alumínio (92%), cobre (85%),
borracha (71%), ferro e aço (65%), chumbo (65%), papel (64%) e zinco
(60%).
Além do aspecto energético, a reciclagem permite a economia de maté-
rias primas e possibilita a diminuição de rejeitos utilizados na lavra e no
processamento de minerais. Por exemplo, cada tonelada de alumínio recicla-
do possibilita a preservação de 4 toneladas de bauxita que seriam necessárias
para a obtenção de alumínio primário metálico.
Tabela 1.5 — Energia necessária para a produção de alguns materiais
(segundo R.C. de Cerqueira Leite e colaboradores).
Material Energia necessária.
MATERIAIS DE ENGENHARIA 27
Finalmente, é importante mencionar que o dispêndio global de energia,
com relação aos materiais, não depende apenas da sua produção mas também
está relacionado com a sua aplicação. Por exemplo, a substituição do aço por
plásticos e alumínio nos automóveis diminui o consumo de combustível,
compensando a utilização de materiais que requerem maior energia na sua
produção.
Conceituação de ciência e engenharia de materiais
Pode-se afirmar que a divisão dos materiais em diversos grupos e sub-
grupos tem origem industrial e que esta abordagem dos materiais em tipos
estanques foi então absorvida pelas universidades. Boa parte dos cursos de
engenharia metalúrgica, assim como das organizações e publicações técnicas
e científicas ainda classificam os materiais metálicos em aços, ferros fundi-
dos e metais não ferrosos.
Os materiais cerâmicos, por sua vez, eram e ainda são freqüentemente
subdivididos em cerâmica vermelha, cerâmica branca, vidros e cerâmicas
especiais.
A abordagem dos materiais por grupos e subgrupos tem naturalmente
vantagens e desvantagens. A principal vantagem é o estudo dos problemas e
características específicos de cada material e a principal desvantagem é que
esta abordagem confere uma visão isolada de cada grupo.
Do ponto de vista científico, esta visão isolada “se esquece” de que as
características e os fenômenos fundamentais, tais como termodinâmica, cris-
talografia, defeitos cristalinos e difusão, têm muito de comum em pratica-
mente todos os grupos de materiais.
Do ponto de vista de aplicações, ela não fornece a necessária visão
geral em termos de seleção de materiais.
Em termos de ensino, as disciplinas têm caráter mais descritivo e infor-
mativo. Esta abordagem será denominada enciclopédica neste texto.
Por volta de 1950, começou a se firmar uma conceituação mais fenome-
nológica da metalurgia, começando pelos princípios básicos e indo até aos
processos de fabricação e aplicações.
28 CAPÍTULO 1
I. distribuição eletrônica ⇒ bandas de energia ⇒ fônons e fótons ⇒ proprie-
dades térmicas, ópticas, elétricas e magnéticas.
II. defeitos cristalinos ⇒ mecanismos de deformação plástica ⇒ proprieda-
des mecânicas ⇒ conformação mecânica.
III. difusão no estado sólido ⇒ transformações de fases ⇒ mecanismos de
endurecimento ⇒ tratamentos térmicos.
IV. termodinâmica e cinética ⇒ físico-química metalúrgica ⇒ processos
metalúrgicos e corrosão.
Deve-se mencionar ainda que estes quatros ramos não são estanques,
mas sim fortemente interligados. Por exemplo, os tratamentos termomecâni-
cos são decorrentes de uma combinação de II com III.
Esta conceituação fenomenológica tem um embasamento mais científi-
co e formativo que a conceituação enciclopédica, que é mais empírica e
informativa. A conceituação fenomenológica significou um grande avanço na
medida em que ela considera que os fenômenos fundamentais tais como
difusão, deformação plástica, diagramas de fases e termodinâmica dos sóli-
dos são similares nos metais e ligas como um todo.
Estas duas conceituações, a enciclopédica e a fenomenológica, convi-
vem até hoje, de maneira complementar, na maioria dos nossos cursos de
engenharia metalúrgica. Nos currículos de engenharia metalúrgica as disci-
plinas enciclopédicas, tais como “metalografia e tratamentos térmicos dos
metais ferrosos”, “metalografia e tratamentos térmicos dos metais não ferro-
sos”, “siderurgia” e “metalurgia extrativa dos metais não ferrosos”, convivem
com as disciplinas fenomenológicas como “diagramas de fases”, “cristalogra-
fia e difração”, “transformações de fases”, “físico-química metalúrgica” e
“corrosão”.
A ciência dos materiais surgiu na década de sessenta e estendeu a con-
ceituação fenomenológica da metalurgia para os outros grupos de materiais.
Pode-se afirmar também que a ciência dos materiais se afastou ainda mais da
descrição enciclopédica dos materiais e se aproximou de outras ciências corre-
latas tais como física da matéria condensada, cristalografia, mineralogia, quí-
mica, físico-química, mecânica dos meios contínuos e mecânica da fratura.
Neste ponto é pertinente questionar se realmente existe uma ciência dos
materiais e, em caso positivo, se esta nova ciência tem um núcleo inde-
pendente das ciências correlatas ou auxiliares mencionadas acima. Na opi-
nião do cientista de materiais alemão Erhard Hornbogen (Instituto de Mate-
MATERIAIS DE ENGENHARIA 29
riais da Universidade do Ruhr de Bochum), existe uma ciência dos materiais
e esta ciência pode ser definida da seguinte maneira:
A ciência dos materiais se ocupa com as relações entre a microestrutura e as
propriedades dos materiais. O núcleo desta ciência é o estudo da microestrutu-
ra dos materiais.
A microestrutura dos materiais (cristalinos) é, na maioria dos casos,
constituída de fases cristalinas e de defeitos cristalinos tais como contornos
de grãos, contornos de subgrãos, contornos de maclas, defeitos de empilha-
mento, interfaces, discordâncias e defeitos puntiformes. Alguns materiais,
como as cerâmicas tradicionais, apresentam na sua microestrutura frações
volumétricas consideráveis de fase vítrea (amorfa) e de poros.
O conhecimento da estrutura, composição, quantidade, tamanho, mor-
fologia, relações de orientação e distribuição das fases, assim como da natu-
reza, quantidade e distribuição dos defeitos cristalinos, são de extrema valia
para o entendimento e, às vezes, até para a previsão de numerosas proprieda-
des dos materiais.
Muitas propriedades dos materiais, tais como limite de escoamento,
limite de resistência, tenacidade à fratura, resistência ao desgaste e resistên-
cia à corrosão são fortemente dependentes da microestrutura.
Outras propriedades, tais como ponto de fusão, módulo de elasticidade,
densidade e coeficiente de dilatação térmica, são fracamente dependentes da
microestrutura. Estas propriedades são mais dependentes da distribuição ele-
trônica, do tipo de ligação química predominante, e da estrutura cristalina.
A microestrutura dos materiais é determinada basicamente pela sua
composição e pelo seu processamento. Por exemplo, a microestrutura de uma
liga metálica (e grande parte das suas propriedades) depende da sua composi-
ção química, do teor de impurezas, das condições de solidificação (da tecno-
logia de fundição empregada), do processo de conformação mecânica, dos
tratamentos térmicos e assim por diante.
A caracterização da microestrutura dos materiais exige naturalmente a
utilização de numerosas técnicas complementares de análise microestrutural
tais como difração de raios x, microscopia óptica, microscopia eletrônica de
varredura, microscopia eletrônica de transmissão, microssonda eletrônica e
numerosas técnicas indiretas.
A ciência dos materiais é o elo de ligação entre as ciências básicas e a
engenharia de materiais. A transformação dos conhecimentos fundamentais
da ciência dos materiais em tecnologia leva então à engenharia dos materiais,
que trata do levantamento das propriedades macroscópicas e das aplicações
30 CAPÍTULO 1
objetivas dos materiais. No currículo dos cursos de engenharia de materiais, o
estudo da ciência dos materiais ocupa um lugar de destaque.
Deve-se a Morris Cohen, conceituado cientista de materiais do MIT, a
seguinte definição:
Ciência e Engenharia de Materiais (CEM) é a área da atividade humana
associada com a geração e com a aplicação de conhecimentos que relacionem
composição, estrutura e processamento às suas propriedades e usos.
Um modelo conveniente para representar a CEM é apresentado na figu-
ra 1.3. Ele utiliza um tetraedro, no qual os quatro vértices representam:
síntese e processamento, estrutura e composição, propriedades e desempe-
nho.
Exercícios
1 Compare os três grupos (tipos) de materiais (metálicos, cerâmicos e poli-
méricos) quanto às seguintes propriedades: ponto de fusão, dureza, maleabili-
dade, densidade e resistividade elétrica.
2. Por que o desenvolvimento dos plásticos modernos ocorreu tardiamente
em comparação com os materiais cerâmicos e metálicos ?
3. O que é microestrutura de um material ?
4. O que são materiais avançados ?
Figura 1.3 — Representação da CEM com auxílio de um tetraedro.
MATERIAIS DE ENGENHARIA 31
5. Faça uma lista dos principais fatores que influenciam o preço de um
material. Ordene a sua lista de fatores em ordem decrescente de importância.
6. Compare o preço das cerâmicas tradicionais com o preço das cerâmicas
avançadas. Justifique a diferença.
7. Descreva com suas palavras e em não mais que 20 linhas a sua conceitua-
ção de ciência dos materiais.
8. O termo novos materiais é muito utilizado na imprensa, em artigos de
divulgação científica e até em programas de governo. Você acha este termo
adequado ? Justifique.
9. Qual a importância da reciclagem dos materiais ? Discuta pelo menos três
aspectos.
10. Discuta a importância da disponibilidade do chumbo e do ferro para a
construção das prensas de Gutenberg.
Bibliografia consultada
CYRIL STANLEY SMITH; A metalurgia como uma experiência humana, Tradução
de José Roberto Gonçalves da Silva, UFSCar, São Carlos, 1988.
MORRIS COHEN (Editor) e JOSÉ ROBERTO GONÇALVES DA SILVA (Tradu-
tor); Ciência e engenharia de materiais: sua evolução, prática e perspectivas.
Parte II: A ciência e engenharia de materiais como uma multidisciplina, Segun-
da edição, UFSCar, São Carlos, 1987.
MELVIN KRANZBERG e CYRIL STANLEY SMITH; Materiais na história e na
sociedade. Em: Ciência e engenharia de materiais: sua evolução, prática e
perspectivas. Morris Cohen ( Editor), J. R. Gonçalves da Silva ( Tradutor ),
UFSCar, São Carlos, 1988.
WILLIAM D. CALLISTER JR.; Materials science and engineering, Third Edition,
John Wiley & Sons, New York, 1994.
ERHARD HORNBOGEN; Werkstoffe, fünfte Auflage, Springer-Verlag, Berlin,
1991.
Y. FARGE; Materiais do futuro: Uma evolução progressiva, Metalurgia & Materiais
ABM, vol. 47, p. 322-330, 1991.
ROGÉRIO C. DE CERQUEIRA LEITE e colaboradores; Nióbio uma conquista
nacional, Livraria Duas Cidades Ltda, São Paulo, 1988.
WILSON TRIGUEIRO DE SOUSA; “Substituição do aço por polímeros e compósi-
tos na indústria automobilística do Brasil: determinantes e conseqüências para o
mercado de minério de ferro”, Tese de doutoramento, EPUSP, São Paulo, 1995.
32 CAPÍTULO 1
Estrutura Cristalina
A palavra estrutura vem do latim structura, derivada do verbo struere,
construir. No sentido mais geral, ela significa organização das partes ou dos
elementos que formam um todo.
A suspeita de que as formas externas de um cristal poderiam estar
relacionadas com sua ordem interna é relativamente antiga.
Robert Hooke (1635-1703), no seu livro Micrographia publicado em
1665, foi um dos primeiros a estabelecer relações entre a forma externa de
um cristal e sua estrutura interna.
Em 1784, o francês René Just Haüy (1743-1822) deu um passo além e
propôs, no seu livro Essai d’une théorie sur la structure des cristaux, que os
cristais poderiam ser entendidos como um empacotamento de unidades rom-
boédricas que ele denominou “molécules intégrantes”.
A evidência experimental inequívoca da existência de estrutura cristali-
na nos cristais só aconteceu em 1912 com a difração de raios x, conforme
será discutido em capítulo posterior.
Um cristal é geralmente definido como um sólido com seus átomos
arranjados em um reticulado periódico tridimensional.
Idealmente, o arranjo mais estável dos átomos em um cristal será aquele
que minimiza a energia livre por unidade de volume ou, em outras palavras,
aquele que:
• preserva a neutralidade elétrica;
• satisfaz o caráter direcional das ligações covalentes;
• minimiza as repulsões íon-íon e, além disto,
• agrupa os átomos o mais compactamente possível.
A grande maioria dos sólidos é cristalina. Os cristais encontrados na
natureza tiveram um crescimento muito lento ao longo dos processos geoló-
gicos e são geralmente muito maiores que os produzidos sinteticamente.
4
59
Por outro lado, nem todos os sólidos são cristalinos. Alguns, como os
vidros e as resinas termorígidas são totalmente amorfos. Outros, como mui-
tos termoplásticos apresentam regiões cristalinas em uma matriz amorfa.
Do ponto de vista estrutural, não existem diferenças significativas entre
um sólido amorfo e um líquido. Por convenção, a viscosidade é utilizada para
distinguir um vidro de um líquido. Acima de 10 15 poises, a substância é
considerada amorfa.
Os gases e a grande maioria dos líquidos não apresentam periodicidade
nos seus arranjos atômicos. Alguns líquidos, denominados cristais líquidos,
apresentam moléculas longas e pouco espessas que podem estar alinhadas
paralelamente como em um cristal.
A figura 4.1 apresenta a distribuição dos átomos em um gás (a), em um
líquido (c), em um sólido amorfo (e) e em um cristal (g). Na mesma figura
são apresentadas as funções probabilidade de se encontrar um átomo em
função da distância, W(r), para os quatro casos mencionados.
Um gás, nas condições normais de pressão e temperatura, contém cerca
de 1019 átomos/cm3. A partir de uma determinada distância δ, denominada
livre caminho médio, a probabilidade de se encontrar um átomo vizinho é
constante.
Um líquido contém cerca de 1022 átomos/cm 3. Tanto no caso do líquido
como no do sólido amorfo existe uma distância para a qual W(r) é máxima.
Esta distância está relacionada com a ordem de curto alcance existente nos
dois casos.
Um cristal contém cerca de 1023 átomos/cm3. A função W(r) apresenta
neste caso valores máximos para determinadas posições. Para as posições
entre os máximos, a função W(r) se iguala a zero.
As substâncias cristalinas exibem anisotropia de várias propriedades
tais como, constantes elásticas, constantes ópticas, condutividade elétrica,
condutividade térmica, dilatação térmica e até a reatividade química de suas
superfícies depende da orientação cristalina.
As substâncias amorfas são habitualmente isotrópicas.
Os reticulados de Bravais
O primeiro trabalho sistemático descrevendo e enumerando os reticula-
dos espaciais é devido ao alemão Moritz Ludwig Frankenheim (1801-1869).
Em 1835, Frankenheim propôs 15 reticulados espaciais.
60 CAPÍTULO 4
Em 1848, o matemático e professor de física francês Auguste Bravais
(1811-1863) mostrou que Frankenheim havia contado duplamente dois reti-
culados cristalograficamente equivalentes.
Um reticulado espacial é um arranjo infinito, tridimensional, de pontos
e no qual todo ponto tem a mesma vizinhança e se chama ponto do reticula-
do. É importante destacar que a cada ponto do reticulado pode estar associa-
do mais de um átomo.
Segundo Bravais, os pontos do reticulado podem estar arranjados de 14
maneiras diferentes, denominadas reticulados de Bravais envolvendo 7 siste-
mas diferentes, chamados sistemas de Bravais (vide figura 4.2).
Figura 4.1 — Distribuição dos átomos no espaço e suas respectivas
funções.
62 CAPÍTULO 4
Os reticulados da figura 4.2 podem ser classificados em 5 tipos: primiti-
vos (P), de corpo centrado (I), de faces centradas (F), de bases centradas (C)
e o romboédrico (R). Os reticulados primitivos apresentam pontos reticulares
apenas nos vértices da célula. Os reticulados de corpo centrado apresentam
pontos reticulares no interior da célula. A designação I, neste caso, tem
origem na língua alemã (“innenzentrierte”). Os reticulados do tipo F apresen-
tam pontos reticulares no centro das suas faces. A designação C para os
reticulados de base centrada se deve ao fato de que eles apresentam pontos
reticulares nas faces perpendiculares ao eixo c.
Os diferentes tamanhos e formas dos reticulados da figura 4.2 podem
ser descritos em termos de até 3 parâmetros de reticulado ou de rede (a, b, c)
e de até 3 ângulos (α, β, γ). A tabela 4.1 apresenta os parâmetros de rede e os
ângulos característicos para cada um do 7 sistemas de Bravais.
Tabela 4.1 — Parâmetros de rede e ângulos dos 7 sistemas de Bravais
Sistema Parâmetros de rede Ângulos
cúbico a = b = c α = β = γ = 90°
tetragonal a = b ≠ c α = β = γ = 90°
ortorrômbico a ≠ b ≠ c α = β = γ = 90°
romboédrico a = b = c α ≠ β ≠ γ ≠ 90°
hexagonal a = b ≠ c α = β = 90°; γ = 120°
monoclínico a ≠ b ≠ c α = γ = 90°; β > 90°
triclínico a ≠ b ≠ c α ≠ β ≠ γ ≠ 90°
Os cristais metálicos
Os átomos metálicos podem ser considerados esferas rígidas e disto
decorre a grande propensão que eles têm à cristalização. A sua grande maio-
ria se cristaliza com estruturas cristalinas muito simples, conforme ilustra a
tabela 4.2. Existem também vários casos de metais com estruturas mais com-
plexas. Um exemplo é o urânio , que apresenta estrutura ortorrômbica. Um
outro extremo é o caso do polônio α, que se cristaliza com estrutura cúbica
simples.
ESTRUTURA CRISTALINA 63
Tabela 4.2 — Estrutura cristalina dos principais metais puros.
Estrutura Metal
CFC Ag, Al, Au, Ca, Co-β, Cu, Fe-γ, Ni, Pb, Pd, Pt, Rh, Sr
HC Be, Cd, Co-α, Hf-α, Mg, Os, Re, Ru, Ti-α, Y, Zn, Zr-α
CCC Ba, Cr, Cs, Fe-α, Fe-δ, Hf-β, K, Li, Mo, Na, Nb, Rb, Ta, Ti-β, V, W, Zr-β
Vários elementos apresentam no estado sólido diferentes estruturas
cristalinas. A denominação para isto é alotropia. Quando o sólido é uma
substância composta, a denominação habitualmente usada é polimorfismo.
Estas mudanças de estruturas geralmente ocorrem em função de variações de
temperatura e pressão. Elas causam variações de volume de alguns porcentos,
isto é, muito altas para serem acomodadas elasticamente em um sólido crista-
lino. Em outras palavras, estas transformações acarretam deformação plástica
(permanente).
A figura 4.3 apresenta as células unitárias cúbica de faces centradas (a)
e cúbica de corpo centrado (b), supondo-se serem os átomos esferas rígidas.
Se os parâmetros de rede (a) das duas estruturas da figura 4.3 forem
conhecidos, isto é, determinados experimentalmente (vide Capítulo VI),
pode-se definir e determinar o raio dos átomos (r) ou raio atômico.
Figura 4.3 — Células unitárias, supondo-se serem os átomos esferas rígi-
das: a) cúbica de faces centradas e b) cúbica de corpo centrado.
64 CAPÍTULO 4
Considerando-se a diagonal da face na estrutura CFC obtém-se a relação:
a√2 = 4r ou r = a√2
4
Tomando-se a diagonal do cubo na estrutura CCC obtém-se a relação:
a√3 = 4r ou r = a√3
4
Os valores do parâmetro de rede e do raio atômico são diferentes em
cada caso. Em outras palavras, o raio atômico depende não só do elemento
ou substância mas também da sua estrutura cristalina. Para um mesmo ele-
mento químico, quanto maior for o seu número de vizinhos mais próximos,
maior será seu raio atômico, devido às forças de repulsão entre os seus
elétrons.
O número de vizinhos mais próximos de um átomo em uma determina-
da estrutura é denominado número de coordenação. Os números de coorde-
nação das estruturas CFC e CCC da figura 4.3 são 12 e 8, respectivamente.
O grau de ocupação e quantidade de vazios (interstícios) também é
diferente para as duas estruturas da figura 4.3. Este grau de ocupação é
denominado fator de empacotamento atômico (FEA) e é definido da seguinte
maneira:
FEA = volume dos átomos da célula
volume da célula
Os diferentes planos das estruturas da figura 4.3 não apresentam graus
de ocupação ou densidades atômicas idênticas.
Uma maneira conveniente de se visualizar os cristais é por meio do
empilhamento dos seus planos mais compactos.
A figura 4.4 ilustra a “obtenção” de um cristal com estrutura hexagonal
compacta (HC) pelo empilhamento dos seus planos basais, os quais são
planos de máxima densidade atômica. Note que o empilhamento neste caso é
do tipo ABABAB....
De maneira similar, a estrutura CFC também pode ser obtida pelo empi-
lhamento de seus planos mais compactos. Os planos mais compactos da
estrutura CFC são aqueles que contém as diagonais do cubo, conforme ilustra
a figura 4.5. Neste caso, a seqüência de empilhamento é do tipo AB-
CABCABC....
ESTRUTURA CRISTALINA 65
Tanto um cristal com a estrutura HC como outro com a estrutura CFC
podem ser descritos ou obtidos pelo empilhamento de planos de máxima
densidade atômica. Os planos de máxima densidade atômica das duas estru-
turas são idênticos. A principal diferença é a seqüência de empilhamento. Por
esta razão, as duas estruturas apresentam o mesmo fator de empacotamento
atômico.
A estrutura CCC não apresenta planos de máxima densidade atômica
como as estruturas CFC e HC. Por esta razão, a descrição ou representação
de cristais com estrutura CCC por meio do empilhamento de planos cristali-
nos é menos freqüente, mas não impossível. A estrutura CCC também apre-
senta planos, que embora não sejam de máxima densidade atômica, apresen-
tam maior densidade atômica que os outros. Para identificá-los basta ligar
duas arestas paralelas (vide figura 4.3 b) e diagonalmente opostas. O empi-
lhamento destes planos na seqüência ABABAB.... gera a estrutura CCC.
Figura 4.4 — Cristal com estrutura HC: a) arranjo dos átomos no reticulado;
b) seqüência de empilhamento dos seus planos de máxima densidade
atômica (planos basais).
66 CAPÍTULO 4
Os cristais iônicos
A ligação predominante na maioria dos materiais cerâmicos é a iônica.
Suas estruturas cristalinas são compostas de íons ao invés de átomos eletrica-
mente neutros, como no caso dos metais. Portanto, nos materiais cerâmicos
iônicos, além do tamanho relativo dos cátions e ânions, deve-se ter neutrali-
dade elétrica.
Figura 4.5 — Cristal com estrutura CFC:
a) arranjo dos átomos no reticulado; b) e c) seqüência de
empilhamento dos planos de máxima densidade atômica.
ESTRUTURA CRISTALINA 67
Os cátions, geralmente metais que cedem elétrons, são habitualmente
menores que os ânions. A tabela 4.3 apresenta uma coletânea de raios iôni-
cos.
Os cristais iônicos são geralmente mais complexos que os cristais metá-
licos. Os materiais cerâmicos iônicos são compostos por elementos metálicos
e não metálicos, havendo freqüentemente vários átomos (íons) presentes.
Estruturas cerâmicas estáveis são formadas quando os ânions que envol-
vem os cátions estão em contato entre si. O número de coordenação, que
neste caso é o número de ânions envolvendo um cátion, depende da relação
entre o raio iônico do cátion (rc) e o raio iônico do ânion (ra); rc/r a. A tabela
4.3 relaciona o número de coordenação com a relação entre os raios dos
cátions e dos ânions.
Em seguida, serão apresentados alguns exemplos de cristais iônicos. O
primeiro exemplo que será apresentado (vide figura 4.6) e discutido é o do
cloreto de césio (CsCl).
Tomando-se os valores dos raios iônicos do Cs + (0,170 nm) e do Cl -
(0,181 nm) da tabela 4.3 obtém-se para a relação rc/r a o valor 0,94. De
acordo com a tabela 4.4, o número de coordenação esperado é 8.
Deve-se acentuar que a estrutura mostrada na figura 4.6 é cúbica sim-
ples e não cúbica de corpo centrado, pois a estrutura é neste caso definida
pelos ânions. Algumas fases intermetálicas, tais como NiAl e latão β (Cu-Zn)
também se cristalizam com esta estrutura. Neste caso ela é considerada CCC.
Figura 4.6 — Célula unitária cúbica simples do cloreto de césio (CsCl).
ESTRUTURA CRISTALINA 69
O segundo exemplo que será apresentado é o do cloreto de sódio (NaCl)
ou sal gema. A relação entre o raio iônico do cátion e o raio iônico do ânion é
neste caso 0,56. De acordo com a tabela 4.4, o número de coordenação
esperado é 6. A figura 4.7 mostra a célula unitária do NaCl, onde pode-se
notar que realmente 6 ânions rodeiam ou envolvem cada cátion.
Figura 4.8 — Célula unitária cúbica de faces centradas do BaTiO 3.
Figura 4.7 — Célula unitária cúbica de faces centradas do cloreto de sódio.
70 CAPÍTULO 4
Os ânions e os cátions da figura 4.7 formam duas células cúbicas de
faces centradas interpenetrantes. Vários materiais cerâmicos tais como MgO,
FeO, LiF, MnS, TiN, TiC e NbC apresentam estrutura CFC do tipo NaCl.
Alguns materiais cerâmicos apresentam mais de um tipo de ânion. Um
exemplo típico é a estrutura perovsquita do titanato de bário (BaTiO 3), mos-
trada na figura 4.8.
O titanato de bário apresenta estrutura cúbica acima de 120°C. Abaixo
desta temperatura sua célula é levemente tetragonal. Vários compostos piezo-
elétricos tais como BaTiO 3, SrZrO 3 e SrSnO 3, apresentam este tipo de estru-
tura.
Outro grupo importante de materiais cerâmicos é o dos espinélios. Eles
têm fórmula geral M2+ M23+ O 4, onde M pode ser Mn, Fe, Co ou muitos
outros íons de metais de transição ou não. M 2+ e M3+ podem ser dois metais
diferentes ou um mesmo metal em dois estados de oxidação diferentes. Por
exemplo, os óxidos Fe 3O 4 e Mn3O 4 são espinélios e suas fórmulas podem ser
escritas de forma mais explícita, respectivamente como Fe 2+ Fe 23+ O 4 e Mn2+
Mn23+ O 4. Um exemplo de espinélio com íons metálicos diferentes é o alumi-
nato de magnésio (MgAl 2O 4). Os ânions O 2- formam uma estrutura CFC. Os
interstícios tetraédricos da estrutura CFC são ocupados pelos cátions Mg 2+,
enquanto os cátions Al 3+ ocupam os interstícios octaédricos.
Os cristais covalentes
Numerosos materiais cerâmicos têm um determinado caráter covalente
nas suas ligações químicas. Para alguns, principalmente nitretos e carbone-
tos, este caráter covalente é predominante.
O exemplo mais familiar de cristal covalente é o diamante, em que cada
átomo de carbono está ligado (por ligações covalentes) a quatro outros áto-
mos de carbono, conforme ilustra a figura 4.9.
Outros elementos do grupo IV A da tabela periódica apresentam este
tipo de estrutura: germânio, silício e estanho cinza, o qual é estável abaixo de
13°C.
O carboneto de silício β (β - SiC ) é outro exemplo típico de cristal
cerâmico predominantemente covalente. Na sua estrutura CFC, cada átomo
de silício tem quatro átomos de carbono como vizinhos, e cada átomo de
carbono tem também quatro átomos de silício como vizinhos, conforme ilus-
tra a figura 4.10.
ESTRUTURA CRISTALINA 71
Figura 4.9 — Estrutura cúbica do diamante.
Figura 4.10 — Célula unitária cúbica de faces centradas do β - SiC.
72 CAPÍTULO 4
As regiões cristalinas dos termoplásticos também são constituídas de
cristais covalentes. A figura 4.11 apresenta a estrutura ortorrômbica do polie-
tileno. Note que cada posição do reticulado é ocupada por vários átomos.
Os quase-cristais
Em meados da década de 1980, alguns pesquisadores observaram figu-
ras de difração de elétrons com simetria icosagonal, ao analisar no microscó-
pio eletrônico de transmissão, ligas alumínio-manganês resfriadas ultra-rapi-
damente a partir do estado líquido.
Estas figuras de difração causaram grande sensação no meio científico,
pois este tipo de simetria não pode ser justificado com nenhum dos 14 reticu-
lados de Bravais. Estudos mais detalhados mostraram que na verdade a figura
de difração obtida pode ser explicada supondo-se que os átomos estão deslo-
cados, com relação a uma estrutura cristalina “perfeita”, em uma condição de
organização no espaço, intermediária entre um cristal e um sólido amorfo.
Materiais nesta condição são atualmente denominados quase-cristais (vide
figura 4.12).
Figura 4.11 — Estrutura ortorrômbica do polietileno.
ESTRUTURA CRISTALINA 73
Exercícios
1. Justifique as seguintes afirmações:
a) os metais têm pequena propensão para formarem sólidos amorfos ao se
solidificarem;
b) os metais apresentam diminuição de volume (contração) ao se solidifica-
rem;
c) alguns semi-metais apresentam aumento de volume ao se solidificarem.
2. Qual o número de coordenação para metais com as estruturas CCC, CFC e
HC?
3. Determine o fator de empacotamento para metais com as estruturas CS,
CCC, CFC e HC.
4. Compare e justifique os valores do número de coordenação e do fator de
empacotamento obtidos para as estruturas CFC e HC dos exercícios acima.
5. A estrutura CFC de um metal apresenta interstícios octaédricos e interstí-
cios tetraédricos: a) localize-os na célula unitária; b) se os átomos metálicos
têm raio atômico R, calcule o raio r dos vazios tetraédricos em função de R;
c) faça o mesmo para os vazios octaédricos.
Figura 4.12 — Arranjo dos átomos em um quase-cristal (esquemático).
74 CAPÍTULO 4
6. A estrutura CCC de um metal apresenta interstícios octaédricos e interstí-
cios tetraédricos: a) localize-os na célula unitária; b) se os átomos metálicos
têm raio atômico R, calcule o raio r dos vazios tetraédricos em função de R;
c) faça o mesmo para os vazios octaédricos.
7. O ferro tem estrutura CCC, raio atômico = 0,124 nm e peso atômico =
55,9 g/mol. Calcule sua densidade e compare-a com a densidade determinada
experimentalmente (7,87 g/cm 3
).
8. O molibdênio tem densidade 10,22 g/cm 3
, massa molecular 95,94 g/mol e
raio atômico 0,1363 nm. A estrutura cristalina do molibdênio é CCC ou
CFC?
9. O ferro muda de estrutura CCC para CFC a 912°C. Próximo desta tempe-
ratura, os raios atômicos do ferro nas duas estruturas são respectivamente,
1,26 Å e 1,29 Å. Qual a porcentagem de variação volumétrica causada por
esta transformação polimórfica ou alotrópica? Como você justifica a diferen-
ça de raios atômicos nas duas estruturas?
10. Demonstre que a relação c/a ideal para a estrutura HC é 1,633.
11. O magnésio tem estrutura HC e relação c/a = 1,624. Sabendo-se que a
densidade do magnésio é 1,74 g/cm3
, calcule seu raio atômico. A massa
molecular do magnésio é 24,305 g/mol.
12. Demonstre que para o número de coordenação 3 o valor de rc/r a mínimo
é 0,155.
13. Calcule a densidade do NaCl e compare-a com a densidade determinada
experimentalmente (2,16 g/cm 3
).
Dados:
peso atômico do sódio = 22,99 g/mol
peso atômico do cloro = 35,45 g/mol
raio iônico do sódio = 0,102 nm
raio iônico do cloro = 0,181 nm
ESTRUTURA CRISTALINA 75
Bibliografia consultada
ROGER BASTIDE (Coordenador); Usos e sentidos do têrmo “estrutura”, Tradução
de Maria Heloiza Schabs Cappellato, Editôra da Universidade de São Paulo, São
Paulo, 1971.
CHRISTOPHER HAMMOND; Introduction to crystallography, Revised Edition,
Oxford University Press, Royal Microscopical Society, Oxford, 1992.
WERNER SCHATT; Einführung in die Werkstoffwissenschaft, 6ª Auflage, Dr. Alfred
Hüthig Verlag, Heidelberg, 1987.
WILLIAM D. CALLISTER, Jr.; Materials science and engineering, Third Edition,
John Wiley & Sons, Inc, New York, 1994.
76 CAPÍTULO 4
Direções e Planos Cristalográficos
No capítulo anterior foram apresentados diversos tipos de materiais
cristalinos. Ao estudá-los é freqüentemente necessário especificar determina-
das direções e determinados planos cristalinos. Para esta finalidade é utiliza-
do um sistema proposto por William Hallowes Miller (1801-1880). Em 1839,
Miller publicou o seu livro A Treatise on Crystallography, no qual ele propu-
nha um novo sistema de indexação de direções e planos. O sistema proposto
apresentava algumas vantagens algébricas, que foram reconhecidas pelos
seus contemporâneos. Só mais tarde, depois da interpretação da difração de
raios x pelos Bragg e outros, é que toda a potencialidade do sistema de
índices proposto por Miller tornou-se evidente. É interessante mencionar que
os índices de Miller foram propostos antes dos sistemas de Bravais.
Índices de Miller: direções cristalográficas
Uma direção cristalográfica é definida como sendo uma linha entre dois
pontos, ou um vetor. As seguintes etapas devem ser seguidas para se determi-
nar os índices de Miller referentes à uma direção cristalográfica:
• O vetor deve passar pela origem do sistema (um vetor pode sofrer
translação e manter-se inalterado desde que o paralelismo seja observa-
do);
• Determina-se a projeção do vetor em cada um dos três eixos. Elas são
medidas em termos dos parâmetros a, b e c da célula unitária;
• Estes números são multiplicados e divididos por fatores comuns e redu-
zidos a mínimos inteiros;
• Os três índices (números inteiros) são apresentados dentro de colchetes
e não são separados por vírgulas, por exemplo [u v w].
5
77
x y z
Projeção a/2 b 0c
Projeção em termos de a, b, c 1/2 1 0
Redução a mínimos inteiros 1 2 0
Notação [120]
Na figura 5.1 é apresentado um exemplo de indexação de uma direção
cristalográfica.
Em seguida serão feitas algumas observações relevantes referentes aos
índices de Miller para direções cristalográficas.
Os índices negativos são representados por uma barra superior: [110].
A troca de sinal de todos os índices inverte o sentido do vetor.
Para algumas estruturas, várias direções não paralelas e com índices
diferentes apresentam arranjos atômicos idênticos. Estas direções são deno-
minadas equivalentes. Por exemplo, no sistema cúbico, as direções [100],
[100], [010], [010], [001] e [001] são equivalentes. Já no sistema tetragonal
as direções [100] e [010] são equivalentes mas as direções [100] e [001] não
são equivalentes.
Uma família de direções é representada por <100>.
Figura 5.1 — Exemplo de indexação de uma direção
cristalográfica no sistema proposto por Miller.
78 CAPÍTULO 5
Índices de Miller: planos cristalográficos
As seguintes etapas devem ser seguidas para se determinar os índices de
Miller referentes a um plano cristalográfico:
• Determina-se os interceptos dos planos com os eixos em termos dos
parâmetros a, b e c da célula unitária. Caso o plano passe pela origem, é
necessária uma translação ou a fixação de uma nova origem.
• Tomam-se os recíprocos dos interceptos. Caso o plano seja paralelo ao
eixo (ou aos eixos), considera-se o intercepto infinito. Neste caso, o
recíproco é zero.
x y z
Interceptos a b/2 c
Interceptos em termos de a, b, c 1 1/2 1
Recíprocos 1 2 1
Recíprocos reduzidos 1 2 1
Notação (121)
Figura 5.2 — Exemplo de indexação de um plano
cristalográfico no sistema proposto por Miller.
DIREÇÕES E PLANOS CRISTALOGRÁFICOS 79
• Estes números são multiplicados (e não divididos) por fatores comuns
obtendo-se números inteiros (e não necessariamente mínimos).
• Os três índices (números inteiros) são apresentados dentro de parênte-
ses e não são separados por vírgulas, por exemplo (h k l ).
Em seguida, serão apresentados três exemplos de indexação de planos
cristalográficos, em ordem crescente de dificuldade.
x y z
Interceptos a b ∞c
Interceptos em termos de a, b, c 1 1 ∞
Recíprocos 1 1 0
Recíprocos reduzidos 1 1 0
Notação (110)
Figura 5.3 — Exemplo de indexação de um plano
cristalográfico no sistema proposto por Miller.
80 CAPÍTULO 5
Em seguida serão feitas algumas observações relevantes referentes aos
índices de Miller para planos cristalográficos.
Índices negativos são representados por uma barra superior, por exem-
plo (012).
Planos paralelos são equivalentes e têm índices idênticos ou múltiplos.
No sistema cúbico, planos e direções de mesmo índice são perpendicu-
lares.
Uma família de planos, por exemplo (111), (1 1 1), (111), (111), (111),
(1 1 1), (111) e (1 1 1), é representada por {111}.
Planos de uma zona são planos não paralelos contendo uma reta co-
mum, denominada eixo da zona. Se o eixo da zona tem índices [u v w],
o plano (h k l) pertencente a esta zona deve satisfazer a relação:
hu + kv + lw = 0.
Se dois planos, (h1 k1 l1) e (h2 k2 l2), pertencem à uma zona de
eixo [u v w], então valem as relações: u = k1l2 − k2l1; v = l1h2 − l2h1 e
w = h1k2 − h2k1.
Figura 5.4 — Exemplo de indexação de um plano
cristalográfico no sistema proposto por Miller.
x y z
Interceptos ∞a -b c/2
Interceptos em termos de a, b, c ∞ -1 1/2
Recíprocos 0 -1 2
Recíprocos reduzidos 0 -1 2
Notação (012)
DIREÇÕES E PLANOS CRISTALOGRÁFICOS 81
Distâncias e ângulos entre planos
A tabela 5.1 apresenta as relações entre o espaçamento interplanar (d),
os parâmetros de reticulado (a, b, c), os ângulos entre planos (α, β, γ) e os
planos (h k l).
DIREÇÕES E PLANOS CRISTALOGRÁFICOS 83
Triclínico:
cosφ = d1d2
V2 [S11h1h2 + S22k1k2 + S33l1l2
+ S239k1l2 + k2l1) + S13(l1h2 + l2h1) + S12(h1k2 + h2k1)]
Índices de Miller-Bravais: direções cristalográficas
No sistema hexagonal, algumas direções cristalográficas equivalentes
não têm os mesmos índices de Miller. Este problema é contornado utilizan-
do-se um sistema de quatro eixos, denominado sistema de Miller-Bravais.
Neste sistema, três eixos (a1, a2 e a3) estão contidos no plano basal e fazem
ângulos de 120° entre si. O quarto eixo (z ou c) é perpendicular ao plano
basal (vide figura 5.5).
Uma determinada direção cristalográfica representada pelos índices de
Miller [u′ v′ w′] pode ser convertida para o sistema de Miller-Bravais com
índices [u v t w] com auxílio das seguintes equações:
u = 1⁄3 (2u′ − v′) ⋅ n
v = 1⁄3 (2v′ − u′) ⋅ n
t = −(u + v)
Figura 5.5 — Sistema de coordenadas para cristais hexagonais,
segundo Miller-Bravais.
84 CAPÍTULO 5
w = w′ ⋅ n
onde n é número inteiro.
Por exemplo, os índices de Miller [010] é convertido em índices de
Miller-Bravais [1210]. A figura 5.6 apresenta vários exemplos desta conver-
são.
Índices de Miller-Bravais: planos cristalográficos
A utilização do sistema de Miller-Bravais também faz com que planos
equivalentes tenham os mesmos índices. Os índices de Miller-Bravais de um
plano são representados por (hkil ). Estes índices são os recíprocos dos inter-
ceptos sobre os eixos a1, a2, a3 e z, respectivamente. Como apenas três eixos
não coplanares são necessários para especificar um plano no espaço, os qua-
tro índices não podem ser independentes.
Figura 5.6 — Alguns exemplos de conversão de índices de Miller
em índices de Miller-Bravais.
DIREÇÕES E PLANOS CRISTALOGRÁFICOS 85
A conversão dos índices de Miller (hkl ) em índices de Miller-Bravais
(hkil ) é muito mais simples do que no caso de direções cristalográficas:
i = −(h + k)
A figura 5.7 dá alguns exemplos de planos cristalográficos no sistema
de Miller-Bravais.
Na estrutura hexagonal existem alguns planos que recebem denomina-
ção especial:
• Plano basal, {0001};
• Plano prismático do tipo I, {1010};
• Plano prismático do tipo II, {1120};
• Plano piramidal do tipo I, {1011};
• Plano piramidal do tipo II, {1121}.
Exercícios
1. Quais das seguintes direções pertencem ao plano (110)?
[112]; [110]; [001]; [112] e [889].
2. Demonstre que o produto de [uvw] por (hkl ) é nulo quando a direção
pertence ao plano.
Figura 5.7 — Exemplos de planos no sistema de Miller-Bravais.
86 CAPÍTULO 5
3. Em um cristal tetragonal encontre direções equivalentes para:
a) [001] b) [110]
4. Desenhe em uma célula cúbica as seguintes direções:
[100]; [001]; [110]; [111]; [110] e [210].
5. Desenhe em uma célula cúbica os seguintes planos cristalográficos:
(100); (001); (110); (111); (110) e (210).
6 O chamado tetraedro de Thompson é formado por quatro planos {111} da
estrutura CFC. Identifique em uma célula cúbica cada um destes planos pelos
seus índices de Miller. Identifique também as seis arestas do tetraedro por
meio de índices de Miller.
7. Calcule a fração de área ocupada por átomos (denominada densidade
planar por alguns autores) para os planos {100}, {110} e {111} da estrutura
CFC.
8. Calcule a densidade planar para os planos {100}, {110} e {111} da estru-
tura CCC.
9. Mostre que os planos (110), (121) e (312) pertencem à zona de eixo [111].
10. Represente em células unitárias hexagonais as seguintes direções cristalo-
gráficas:
[0001]; [1100]; [1120]; [1012]; [1011] e [1121].
11. Represente em células unitárias hexagonais os seguintes planos cristalo-
gráficos:
(0001); (1011); (1010); (1121); (1122); (1120); (1012) e (1011).
12. A direção [1120] é normal ao plano (1120). Entretanto, a direção [1012]
não é perpendicular ao plano (1012). Mostre isto geometricamente em uma
célula hexagonal.
13. Calcule o espaçamento entre os planos (111) do níquel. O níquel tem
estrutura CFC e seu parâmetro de rede é 3,5239 Å.
14. Na temperatura ambiente, o urânio tem estrutura ortorrômbica com parâ-
metros de rede a = 2,8538 Å, b = 5,8697 e c = 4,9550. Calcule o espaçamen-
to entre os planos (111) do urânio.
15. Na temperatura ambiente, o titânio tem estrutura HC com parâmetros de
rede a = 2,9512 Å e c = 4,6845 Å. Calcule o ângulo entre o plano basal e o
plano piramidal (1011).
16. Na tabela de ângulos entre planos do sistema cúbico seguinte existe um
erro. Descubra-o.
DIREÇÕES E PLANOS CRISTALOGRÁFICOS 87
Bibliografia consultada
WILLIAM D. CALLISTER, Jr.; Materials science and engineering, Third edition,
John Wiley, New York, 1994.
B.D. CULLITY; Elements of x-ray diffraction, 2nd edition, Addison-Wesley, Rea-
ding,Mass., 1978.
CHRISTOPHER HAMMOND; Introduction to crystallography, Revised edition,
Oxford University Press, Oxford, 1992.
88 CAPÍTULO 5
Defeitos Puntiformes e
Soluções Sólidas
Os materiais cristalinos foram considerados isentos de defeitos até aqui
neste texto. Mesmo os cristais crescidos cuidadosamente em laboratório
apresentam defeitos cristalinos. Na realidade, cristais perfeitos não existem,
pois como veremos neste capítulo, acima de 0 K sempre existe uma determi-
nada concentração de defeitos puntiformes em equilíbrio termodinâmico den-
tro dos cristais. Portanto, os materiais cristalinos apresentam uma microestru-
tura.
A microestrutura dos materiais cristalinos é constituída basicamente de
defeitos cristalinos e constituintes microestruturais tais como fases e inclu-
sões. A microestrutura de um material é determinada principalmente pela sua
composição química e pelo seu processamento (solidificação, conformação
mecânica, tratamentos térmicos e etc.). Algumas vezes a microestrutura do
material se modifica durante sua utilização.
Principais tipos de defeitos cristalinos
Os defeitos cristalinos podem ser classificados em puntiformes (lacu-
nas, intersticiais e combinações deles), lineares (discordâncias) e bidimensio-
nais (defeitos de empilhamento, contornos de macla, contornos de sub-grão,
contornos de grão, contornos de antifase e interfaces entre fases diferentes).
Todos estes defeitos serão discutidos detalhadamente em seguida, neste e nos
próximos capítulos. A figura 7.1 dá uma idéia do tamanho dos defeitos crista-
linos.
Os defeitos existentes em um material real apresentam tamanhos em
uma ampla faixa, além de características diferenciadas. Para seu estudo é
7
103
necessário um conjunto de técnicas complementares. Dentre as técnicas utili-
zadas destaca-se a microscopia. Atualmente, existem vários tipos de micros-
cópio, sendo mais conhecidos o microscópio óptico, o microscópio eletrônico
de varredura, o microscópio eletrônico de transmissão, o microscópio de
campo iônico e o microscópio de tunelamento eletrônico. Com auxílio destes
diversos tipos de microscopia pode-se observar as características, determinar
a quantidade e estudar a distribuição dos defeitos cristalinos. A seguir são
apresentadas as faixas de aumento típicas em cada tipo de microscópio:
• microscópio óptico: 50 a 3000 vezes;
• microscópio eletrônico de varredura: 5 a 50000 vezes;
• microscópio eletrônico de transmissão: 5000 a 300000 vezes;
• microscópio de campo iônico: 1000000 vezes;
• microscópio de tunelamento eletrônico: 300000000 vezes.
Além de faixas de aumento diferentes, eles apresentam características
diferentes e propiciam a obtenção de informações complementares sobre a
microestrutura dos materiais. Os defeitos cristalinos alteram várias proprie-
dades dos materiais e isto torna possível o estudo destes defeitos por meio do
estudo da variação destas propriedades. Por exemplo, os defeitos puntiformes
podem ser estudados com auxílio de determinações de resistividade elétrica.
Figura 7.1 — Dimensões aproximadas dos defeitos encontrados
nos materiais (segundo M.A. Meyers e K.K. Chawla).
104 CAPÍTULO 7
Principais tipos de defeitos puntiformes em metais
A figura 7.2 apresenta os principais tipos de defeitos puntiformes exis-
tentes nos metais e ligas. Ao contrário dos sólidos iônicos, os metais não têm
sua neutralidade elétrica alterada pela presença de defeitos cristalinos. Os
defeitos puntiformes presentes nos sólidos iônicos serão apresentados no
final deste capítulo.
Uma posição desocupada do reticulado é denominada lacuna. As lacu-
nas desempenham um papel muito importante na movimentação atômica
(difusão). Quando um átomo ocupa uma posição que não é uma posição da
rede ele é denominado intersticial ou auto-intersticial.
Átomos estranhos, de impurezas ou adicionados intencionalmente, tam-
bém são considerados defeitos puntiformes (vide figura 7.3). Dependendo do
seu tamanho, ele pode ocupar uma posição substitucional ou intersticial. Os
Figura 7.2 — Defeitos puntiformes em um plano (001) da estrutura cúbica
simples: (a) lacuna; (b) intersticial.
Figura 7.3 — Defeitos puntiformes causados por impurezas: (a) átomos de
impureza substitucional; (b) átomos de impureza intersticial.
DEFEITOS PUNTIFORMES... 105
átomos de soluto dissolvidos no metal desempenham um papel importante na
deformação plástica, dificultando-a e causando o chamado endurecimento
por solução sólida. Todos os defeitos puntiformes mencionados acima cau-
sam distorções na rede cristalina influenciando as propriedades do material.
Lacunas
A presença de defeitos cristalinos dentro de um material causa aumen-
tos da energia interna (U) do mesmo e da sua entropia (S).
A grande maioria dos defeitos cristalinos encontra-se fora de equilíbrio
termodinâmico dentro do material. Eles aumentam muito a energia interna e
tendem a desaparecer quando o material é recozido.
Nos casos das lacunas e dos intersticiais, o aumento da energia interna
ou da entalpia (H = U + PV ) é compensado pelo aumento da entropia. Por-
tanto, existe uma concentração de equilíbrio de lacunas e de intersticiais (ao
contrário dos outros defeitos cristalinos) que é função da temperatura e do
material.
Em seguida, calcularemos a concentração em equilíbrio de lacunas.
Faremos esta análise à pressão e temperatura constantes. Nestas condições,
isto é, à P e T constantes, o equilíbrio termodinâmico é atingido quando a
energia livre de Gibbs (G = H − TS) é mínima.
Inicialmente, calcularemos G em função do número de lacunas e depois
determinaremos o ponto de mínimo desta função. Antes disto, deve-se menci-
onar que as variações de P e V nas transformações do estado sólido são muito
pequenas e H ≈ U.
Suponha um cristal contendo N posições atômicas e n lacunas. O au-
mento de energia interna ou de entalpia do cristal pode ser considerado uma
função linear do número de lacunas, isto é, ∆H = n H f, onde Hf é a energia de
formação de uma lacuna.
Vamos agora calcular a contribuição entrópica das lacunas. A entropia
configuracional é dada pela termodinâmica estatística como sendo S = k ln w,
onde k é a constante de Boltzmann e w é o número de arranjos possíveis de n
lacunas em N posições atômicas. Portanto,
w = N!
Para valores grandes de x vale a seguinte aproximação, denominada
aproximação de Stirling: ln x! = x ⋅ ln x − x. Por exemplo, já para x = 50,
quando ln 50! = 148,47, obtém-se pela aproximação de Stirling: 50 ln 50 –
50 = 145,60. Como o número de lacunas dentro de um cristal é várias ordens
de grandeza maior que 50, a aproximação de Stirling é neste caso muito boa.
Substituindo-se os logaritmos de fatorial pela aproximação de Stirling
na expressão.
Agora vamos determinar o ponto de mínimo da função acima, derivan-
do-a em função de n e igualando a primeira derivada a zero:
DEFEITOS PUNTIFORMES... 107
Portanto, ficou demonstrado que existe um número de lacunas em equi-
líbrio dentro do cristal, o qual é função da temperatura e do material. Cada
material tem um valor de H f característico.
A figura 7.4 apresenta as variações de energia livre de Gibbs, entalpia e
de entropia em função do número de lacunas.
A energia ou entalpia de formação de lacunas varia de material para
material. De um modo geral, pode-se afirmar que quanto mais forte forem as
ligações entre os átomos, mais difícil será a formação de lacunas e maior será
o valor de H f. No próximo capítulo veremos que as lacunas estão intimamen-
te ligadas com a movimentação atômica e que também existe uma energia
para migração de lacunas (H m).
A tabela 7.1 apresenta valores de H f e de H m em função do ponto de
fusão para alguns metais. Devido à imprecisão nas determinações, são apre-
sentadas faixas de valores, ao invés de um único valor.
Figura 7.4 — Variação da energia livre de Gibbs, da entalpia e da entropia
em função do número de lacunas.
108 CAPÍTULO 7
Tabela 7.1 — Valores de
H f e de
H m em função do ponto de fusão.
Metal Hf (eV) Hm (eV) P.F. (°C)
Al 0,74-0,79 0,50-0,60 660
Au 0,96-1,0 0,55-0,80 1063
Ag 1,02-1,10 0,83-0,88 961
Cu 1,00-1,40 0,70-1,20 1083
Pt 1,20-1,40 1,10-1,50 1769
W 1,20-1,40 1,10-1,50 3410
Lacunas (e átomos da rede em posições intersticiais) podem ser criadas
nos materiais por deformação plástica ou por meio de irradiação com partícu-
las de alta energia (nêutrons, elétrons ou íons). Uma alta concentração de
lacunas também pode ser retida em um cristal por meio de resfriamento
rápido a partir de altas temperaturas (“quenching”). Se o resfriamento não for
muito rápido, as lacunas em excesso em relação à quantidade de equilíbrio
para cada temperatura migrarão para a superfície externa do cristal ou para
outros defeitos cristalinos internos e desaparecerão. Muitas vezes, é energeti-
camente favorável o agrupamento de lacunas formando dilacunas, trilacunas
e assim por diante. Lembre-se que as lacunas podem migrar nos cristais
trocando de lugar com átomos vizinhos. Esse mecanismo possibilita também
a movimentação dos átomos da rede.
Intersticiais
Os autointersticiais ou simplesmente intersticiais também são defeitos
de equilíbrio, isto é, para cada material existe uma concentração de equilíbrio
de intersticiais, a qual aumenta com o aumento da temperatura.
A energia de formação de intersticiais de um material é muito maior
que a energia de formação de lacunas para o mesmo material. Por exemplo,
enquanto a energia de formação de lacunas no cobre é cerca de 1,2 eV, a
energia de formação de intersticiais é 4 eV para o mesmo metal. Por isto, a
concentração de equilíbrio de intersticiais numa dada temperatura para um
dado material é muito menor que a concentração de lacunas. Lembre-se que a
DEFEITOS PUNTIFORMES... 109
energia de formação é expoente da função exponencial. Os intersticiais de-
sempenham um papel muito menos importante que as lacunas.
Os intersticiais também podem ser criados por deformação plástica,
irradiação ou resfriamento rápido.
O agrupamento de intersticiais formando segmentos de planos de áto-
mos é muitas vezes favorável energeticamente. A recombinação de lacunas
com intersticiais, eliminando os dois defeitos, também é possível.
A experiência de Simmons e Balluffi
A presença de defeitos puntiformes causa variação de volume nos sóli-
dos. A presença de lacunas causa aumento de volume, enquanto os interstici-
ais causam diminuição. Em 1960, os pesquisadores americanos R. Simmons
Figura 7.5 — Variações de comprimento (∆
L⁄
L ) e de parâmetro de rede (∆
a⁄
a)
do alumínio em função da temperatura
(segundo R. Simmons & R. Balluffi, Phys. Rev. , 117,1960, 52).
110 CAPÍTULO 7
e R. Balluffi conseguiram comprovar este fato experimentalmente. Eles aque-
ceram um corpo de prova de alumínio até próximo do seu ponto de fusão e
durante o aquecimento (ou resfriamento) mediram a variação de comprimen-
to ∆L⁄L (com auxílio de um dilatômetro de precisão) e a variação do parâmetro
de reticulado ∆a⁄a (com auxílio de difração de raios x). Estes resultados estão
apresentados na figura 7.5.
A figura 7.5 mostra que, para altas temperaturas, a variação de compri-
mento é maior que a variação de parâmetro de rede. Esta diferença é devida
às lacunas. Quando um pedaço de metal é aquecido seu comprimento aumen-
ta. Esta expansão é devida ao afastamento dos planos atômicos do cristal e
também à criação de lacunas. Enquanto a difração de raios x mede apenas o
afastamento dos planos atômicos, o dilatômetro mede a variação total de
comprimento.
É interessante mencionar que, se o número de intersticiais criados du-
rante o aquecimento fosse maior que o número de lacunas criadas, o valor de
∆a⁄a seria superior ao valor de ∆L⁄L para cada temperatura.
Soluções sólidas
Existem basicamente três tipos de soluções sólidas: substitucionais,
intersticiais e ordenadas. Quando os átomos de soluto têm tamanho aproxi-
madamente igual ao tamanho do solvente e não têm preferência acentuada
por determinadas posições da rede, eles formam soluções sólidas substitucio-
nais. Exemplos típicos são Si, Mn, Cr, Mo e Ni no Fe. Quando os átomos de
soluto são muito menores que o solvente, eles geralmente ocupam posições
intersticiais. Algumas soluções sólidas com composição próxima de propor-
ções estequiométricas, tais como AB, A 2B ou A 3B, podem se rearranjar e
formar uma solução sólida ordenada. Isto, geralmente só é possível abaixo de
uma certa temperatura, denominada temperatura crítica.
Dados dois elementos químicos, existem determinadas regras (regras de
Hume-Rothery) que prevêem a propensão deles formarem soluções sólidas
substitucionais:
• Tamanho atômico. Os raios atômicos dos dois elementos não devem
diferir entre si de mais de 15%.
• Estrutura cristalina. O tipo de estrutura cristalina deve ser o mesmo.
• Valência química. As valências dos dois elementos não devem diferir de
mais de uma unidade.
DEFEITOS PUNTIFORMES... 111
• Eletronegatividade. As eletronegatividades devem ser quase iguais. Em
caso contrário, poderá formar-se um composto, em conseqüência da
diferença de afinidade por elétrons.
Alguns pares de elementos satisfazem muito bem as regras de Hume-
Rothery e são completamente solúveis ou miscíveis no estado sólido. Exem-
plos típicos de sistemas binários com solubilidade total no estado sólido são
cobre-níquel e nióbio-tântalo. Compostos também podem ser completamente
miscíveis entre si no estado sólido. Por exemplo, os carbonetos NbC e TiC
são completamente miscíveis entre si, assim como os óxidos UO 2 e ThO 2.
Em seguida analisaremos as soluções sólidas intersticiais.
A estrutura CFC apresenta dois tipos de interstícios: octaédricos (maio-
res) e tetraédricos (menores), conforme mostra a figura 7.6.
Na estrutura CFC, a razão entre o raio do interstício octaédrico (r) e o
raio do átomo da rede (R) é:
r
R = 2 − √2
√2 = 0,4142.
Para o ferro, cujo raio atômico é 1,26 Å, a maior esfera que cabe no interstí-
cio octaédrico tem raio 0,52 Å.
Figura 7.6 — Interstícios na estrutura CFC: (a) interstício octaédrico e
(b) interstício tetraédrico (segundo C. Barret e T.B. Massalski).
112 CAPÍTULO 7
Para os interstícios tetraédricos da estrutura CFC vale a relação:
r⁄R = 0,223. Neste caso a maior esfera que cabe nestes interstícios tetraédricos
tem raio 0,28 Å.
A estrutura CCC também apresenta dois tipos de interstícios, conforme
ilustra a figura 7.7. Neste caso, os tetraédricos são maiores que os octaédri-
cos.
Na estrutura CCC, a razão entre o raio do interstício tetraédrico (r) e o
raio do átomo da rede (R) é r⁄R = 0,286. No caso do ferro, a maior esfera que
cabe neste tipo de interstício tem raio 0,36 Å.
Para os interstícios octaédricos da rede CCC vale a relação r⁄R = 0,15.
No caso do ferro, a maior esfera que cabe neste tipo de interstício tem raio
0,19 Å.
Comparando-se as estruturas CFC e CCC, pode-se notar que embora a
estrutura CFC seja mais compacta (maior fator de empacotamento), os seus
interstícios são maiores.
A estrutura HC também apresenta interstícios octaédricos e tetraédri-
cos, conforme ilustra a figura 7.8. Como vimos em capítulos anteriores, as
estruturas CFC e HC são muito parecidas. Na estrutura HC, à exemplo da
estrutura CFC, os interstícios octaédricos são maiores que os tetraédricos.
Figura 7.7 — Interstícios na estrutura CCC: (a) interstício octaédrico e
(b) interstício tetraédrico (segundo C. Barret e T.B. Massalski).
DEFEITOS PUNTIFORMES... 113
Os átomos intersticiais causam grande distorção na rede cristalina. Eles
causam acentuadas expansão no parâmetro de rede. O seu efeito nas proprie-
dades mecânicas é também muito maior que o efeito dos átomos substitucio-
nais, para a mesma concentração.
As soluções sólidas intersticiais são em geral mais diluídas que as solu-
ções sólidas substitucionais. Raramente são encontradas soluções sólidas
com mais de 10% (em átomos) de soluto intersticial.
As soluções sólidas e compostos ordenados são relativamente freqüen-
tes nas ligas metálicas. Neste caso, os átomos ocupam posições preferenciais
no reticulado cristalino. Um exemplo típico é a liga 50% Cu-50% Zn. Esta
liga forma uma fase com estrutura CCC, denominada β′, em que os átomos
de cobre ocupam a posição central da célula (1/2, 1/2, 1/2) e os átomos de
zinco ocupam as posições dos vértices da célula. Outro exemplo é o do
composto intermetálico Cu3Au. Neste caso, a estrutura é CFC. Os átomos de
cobre ocupam as posições do centro da face e os átomos de ouro ocupam as
posições dos vértices da célula. Conforme já foi mencionado, em geral, as
114 CAPÍTULO 7
fases ordenadas são estáveis abaixo de uma determinada temperatura, deno-
minada temperatura crítica. Acima da temperatura crítica elas se tornam de-
sordenadas, mantendo a cristalinidade.
Defeitos puntiformes em sólidos iônicos
Os compostos iônicos (materiais cerâmicos) podem ser classificados em
duas classes: compostos estequiométricos e compostos não estequiométricos
ou com estruturas defeituosas. Um exemplo típico de composto estequiomé-
trico é o NaCl. Por outro lado, grande parte dos óxidos não apresenta estequi-
ometria definida. Os tipos de defeitos puntiformes nas duas classes de com-
postos são ligeiramente diferentes.
Os principais tipos de defeitos puntiformes nos compostos estequiomé-
tricos são: lacuna catiônica, lacuna aniônica e cátion em posição intersticial.
Estes três tipos de defeito são mostrados na figura 7.9.
No caso de sólidos iônicos, as posições atômicas são ocupadas por íons
e a neutralidade elétrica do composto deve ser mantida. Observe como isto
ocorre nos chamados defeitos de Schottky e de Frenkel, na figura 7.10.
Repare que a formação de um defeito de Schottky ou de Frenkel não
altera a relação cátion/ânion. Em outras palavras, o material ou composto é
Figura 7.8 — Interstícios na estrutura HC: (a) interstício octaédrico e
(b) interstício tetraédrico (segundo C. Barret e T.B. Massalski).
DEFEITOS PUNTIFORMES... 115
Figura 7.9 — Representação esquemática de lacuna catiônica,
lacuna aniônica e cátion em posição intersticial (segundo W.D. Callister, Jr.).
Figura 7.10 — Representação esquemática dos defeitos de Schottky e de
Frenkel em um sólido iônico (segundo W.D. Callister, Jr.).
116 CAPÍTULO 7
dito ser estequiométrico. Em geral, é mais provável que se formem mais
defeitos de Schottky do que de Frenkel, pois são poucas as estruturas que
apresentam interstícios suficientemente grandes para dissolver cátions sem
distorcer consideravelmente a rede.
Os compostos não estequiométricos ocorrem em certos materiais cerâ-
micos que apresentam dois estados de valência.Um exemplo típico é o óxido
de ferro denominado wustita (Fe <1O). A wustita tem estrutura CFC do tipo
NaCl, com os cátions de ferro ocupando as posições do sódio e os ânions de
oxigênio ocupando as posições do cloro. Na wustita existe um certo número
de íons férricos de acordo com o equilíbrio representado pela reação
Fe ++ = Fe +++ + e -. A neutralidade elétrica é mantida pela presença de vazios
catiônicos ( ). Para cada dois íons Fe +++ deve existir um vazio catiônico:
3Fe ++ = 2Fe +++ + , conforme mostra a figura 7.11.
Fe2+ O 2- Fe2+ O2- Fe2+ O2- Fe3+
O 2- Fe2+ O 2- Fe2+ O 2- O 2-
Fe2+ O 2- Fe2+ O 2- Fe3+ O 2- Fe2+
O 2- Fe2+ O 2- Fe2+ O2- Fe2+ O 2-
Fe3+ O 2- Fe2+ O 2- Fe2+ O2- Fe2+
O 2- O 2- Fe2+ O2- Fe2+ O 2-
Fe2+ O 2- Fe3+ O 2- Fe2+ O 2- Fe2+
Figura 7.11 — Representação esquemática mostrando a presença de
lacunas catiônicas e a manutenção da neutralidade elétrica.
A presença de defeitos (e impurezas) altera muitas propriedades e ca-
racterísticas do material. No caso wustita são alteradas também as caracterís-
ticas que dependem da mobilidade atômica (iônica) tais como sinterabilida-
de, cinética de redução do óxido e outras propriedades, como mostra a tabe-
la 7.3.
DEFEITOS PUNTIFORMES... 117
Tabela 7.3 — Influência da estequiometria no parâmetro de rede e na
densidade da wustita.
Composição Parâmetro de rede (Å) Densidade (g/cm3).
As impurezas nos sólidos cristalinos iônicos podem formar tanto solu-
ções sólidas intersticiais como soluções sólidas substitucionais, conforme
ilustra a figura 7.12. Para que tenha solubilidade apreciável, o átomo estra-
nho, de impureza ou adicionado intencionalmente, deve ser similar em tama-
nho e em valência ao átomo que está sendo substituído.
Os defeitos e as impurezas modificam bastante as propriedades ópticas
dos sólidos iônicos e em particular a cor. Isto será discutido no capítulo
referente à propriedades ópticas dos materiais.
Figura 7.12 — Representação esquemática de impurezas intersticiais e
substitucional em sólido iônico (segundo W.D. Callister, Jr.).
118 CAPÍTULO 7
Exercícios
1. Calcule a concentração de lacunas (em % de posições da rede) para o
alumínio (H f = 0,76 eV) a 600°C, 200°C e 25°C. O valor da constante de
Boltzmann é k = 8,614 ⋅ 10−5 eV/K.
2. Qual a relação entre a concentração de lacunas no alumínio (H f = 0,76 eV)
e no cobre (H f = 1,2 eV) a 600°C.
3. Apresente uma curva de ponto de fusão versus energia de formação de
lacunas para os metais. Valores recentes de energia de formação de lacunas
podem ser obtidos no livro Diffusion in solids, Paul G. Shewmon, Second
edition, TMS, Warrendale, 1989.
4. Calcule a relação entre o número de lacunas (H f = 1,2 eV) e o número de
intersticiais (H f = 4 eV) para o cobre a 1000°C.
5. A estrutura CCC, com fator de empacotamento 0,68, é menos compacta
que a estrutura CFC, que tem fator de empacotamento 0,74. No entanto, o
carbono tem maior solubilidade na austenita (ferro γ; CFC) do que na ferrita
(ferro α; CCC). Justifique.
6. O nitrogênio tem maior solubilidade que o carbono na austenita e na
ferrita. Justifique.
7. Deduza a razão r⁄R entre o raio máximo possível dos intersticiais (r) e o
raio dos átomos da rede (R) para os interstícios tetraédricos e octaédricos das
estruturas CFC, CCC e HC.
8. O Cr, Nb, Mo e W têm maior solubilidade na ferrita do que na austenita.
Justifique.
9. A solubilidade do Cr na ferrita é maior que as solubilidades do Nb, Mo ou
W na mesma. Justifique.
10. O Mn, Ni e Cu têm maior solubilidade na austenita do que na ferrita.
Justifique.
11. As solubilidades do Mn e do Ni são maiores que a solubilidade do Cu na
austenita. Justifique.
12. Como você espera que varie a solubilidade com a temperatura no estado
sólido?
13. Os seguintes sistemas binários apresentam solubilidade completa (100%):
Ag-Au; Ag-Pd; Ag-Pt; Au-Cu; Au-Ni; Au-Pd; Au-Pt; Cu-Ni; Cu-Pd; Cu-Pt;
Ni-Pd; Ni-Pt e Pd-Pt. Os seguintes sistemas binários apresentam solubilidade
limitada (<100%): Ag-Al; Ag-Cu; Ag-Ni; Ag-Pb; Au-Th; Cu-Pb; Ni-Pb; Pb-
DEFEITOS PUNTIFORMES... 119
Pd e Pb-Pt. Todos os elementos mencionados têm estrutura CFC. Justifique
os comportamentos de solubilidade nos diversos sistemas com auxílio das
regras de Hume-Rothery. Retire de uma boa tabela periódica os dados que
necessitar.
14. Como você justifica que fases ordenadas em temperaturas baixas se tor-
nem desordenadas em temperaturas mais altas?
15. Justifique a influência da estequiometria no parâmetro de rede e na densi-
dade da wustita (tabela 7.3).
Bibliografia consultada
MARC A. MEYERS & KRISHAN K. CHAWLA; Princípios de metalurgia mecâni-
ca, Editora Edgard Blücher Ltda., São Paulo, 1982.
CHARLES BARRET & T. B. MASSALSKI; Structure of metals, 3rd revised edition,
Pergamon Press, Oxford, 1993.
WILLIAM D. CALLISTER, Jr.; Materials science and engineering, Third edition,
John Wiley & Sons, New York, 1994.
120 CAPÍTULO 7
Difusão no Estado Sólido
Processos termicamente ativados
Numerosos fenômenos em ciência dos materiais ocorrem mais rapida-
mente quando a temperatura é aumentada. Em muitos casos, a dependência
da velocidade de reação ou transformação (V) segue uma equação do tipo
Arrhenius (1859-1927).
onde:
V é a velocidade da reação ou transformação;
c é uma constante;
Q é a energia de ativação;
R é a constante dos gases e
T é a temperatura absoluta.
A equação de Arrhenius é uma equação empírica, que descreve a velo-
cidade de uma reação ou transformação em função da temperatura e da
barreira de energia que se opõe à reação. A energia de ativação é a altura da
barreira de energia que se opõe à ocorrência da reação ou transformação e
deve ser vencida (nos processos termicamente ativados) por excitação térmi-
ca. A figura 8.1 (a) representa esquematicamente um processo termicamente
ativado. Note que o estado 2 é mais estável que o estado 1, ou seja, o estado 2
tem energia mais baixa. Todavia, a passagem do estado 1 para o estado 2
exige que a barreira energética Q seja superada. A figura 8.1 (b) apresenta
uma representação gráfica típica da equação de Arrhenius. Por meio da deter-
8
121
minação da declividade da reta pode-se determinar a energia de ativação do
processo.
Quando uma reação ou transformação compreende uma sucessão de
etapas, a etapa controladora é a etapa mais lenta.
A difusão no estado sólido, tema deste capítulo, é um exemplo típico de
fenômeno termicamente ativado.
Mecanismos de difusão em
metais puros e soluções sólidas
Os átomos de um metal puro não estão em repouso. Conforme destaca
Corrêa da Silva (Engenheiro Metalurgista, Ex-Professor da EPUSP e um dos
principais nomes na área de difusão): “À primeira vista poderia parecer que a
mudança de posição de um átomo no reticulado cristalino de um metal sólido
devesse ser um fenômeno relativamente pouco freqüente, uma vez que a um
corpo sólido se associa geralmente a idéia de rigidez e de ausência de movi-
mento das partículas elementares de que é composto”. A realidade é entretan-
to bastante diferente. Acima de 0 K, os átomos vibram em torno das suas
posições de equilíbrio no reticulado e, além disto, trocam freqüentemente de
posição entre si. Este último fenômeno é denominado autodifusão.
Figura 8.1 — (a) Representação esquemática de um processo
termicamente ativado. (b) Apresentação da equação de
Arrhenius em escalas convenientes.
122 CAPÍTULO 8
Os metais com estruturas cristalinas CFC e HC, próximos dos seus
pontos de fusão, vibram com uma freqüência, denominada freqüência de
Debye, da ordem de 10 13 a 10 14 s -1. Por outro lado, cada átomo muda de
posição 100 milhões de vezes em um segundo. Portanto, mesmo próximo do
ponto de fusão, os átomos passam a maior parte do tempo oscilando ao redor
de suas posições de equilíbrio no cristal.
A figura 8.2 apresenta vários mecanismos possíveis de autodifusão. Um
primeiro mecanismos seria a troca de lugar com o átomo vizinho. Uma
segunda possibilidade é o mecanismo do anel. Estes dois mecanismos exi-
gem movimento coordenado de átomos e são bastante improváveis de acon-
tecer. Uma terceira possibilidade seria o átomo da rede tentar “passar” entre
os átomos da rede, numa espécie de difusão intersticial. Isto também é bas-
tante improvável. O mecanismo mais provável de autodifusão é a troca de
lugar com lacunas.
O mecanismo de troca de lugar com lacunas também parece ser o mais
provável para explicar a movimentação atômica nas soluções sólidas substi-
tucionais, conforme ilustra a figura 8.3.
No caso das soluções sólidas intersticiais, a passagem do átomo intersti-
cial entre os átomos da rede é muito mais provável do que nos casos anterio-
res. Nós veremos posteriormente que a difusão de átomos intersticiais é
muito mais rápida que a difusão de átomos substitucionais, para o mesmo
metal base. O mecanismo de difusão intersticial é apresentado na figura 8.4.
Além dos mecanismos descritos, existe a possibilidade de difusão ao
longo dos defeitos cristalinos tais como: superfície externa do cristal, contor-
nos de grãos e defeitos lineares. A contribuição destes defeitos para o proces-
Figura 8.2 — Mecanismos de difusão em um metal.
DIFUSÃO NO ESTADO SÓLIDO 123
so global só é importante em algumas situações, uma vez que eles ocupam
um volume relativamente pequeno do cristal. A figura 8.5 representa esque-
maticamente a difusão na superfície externa, ao longo dos contornos de grãos
e no volume (no interior dos grãos).
As equações de difusão
Em 1855, o austríaco Adolf Fick tratou matematicamente a difusão de
maneira praticamente definitiva. Este tratamento pode ser resumido na forma
de duas leis de Fick.
O fluxo (J, em kg/m2s) de matéria (M, em kg) que se difunde através de
uma unidade de área (A, em m2 ) na unidade de tempo (t, em s) é definido
como.
Figura 8.3 — Mecanismo de difusão em uma solução sólida
por troca de lugar com lacunas.
124 CAPÍTULO 8
Figura 8.4 — Mecanismo de difusão intersticial.
Figura 8.5 — Representação esquemática da difusão
no reticulado e ao longo de defeitos.
DIFUSÃO NO ESTADO SÓLIDO 125
Esta equação vale para condições estacionárias. Isto é, ela vale para
condições em que o gradiente de concentração dentro da placa de área A não
se altera com o tempo.
Na figura 8.6 é apresentada uma placa metálica que está sendo atraves-
sada por um gás. Isto pode realmente acontecer. Por exemplo, a purificação
do hidrogênio é feita por meio da difusão do mesmo através de uma lâmina
de paládio. O paládio (Pd) tem estrutura CFC, raio atômico 1,376 Å e é um
metal muito caro (4000 US$/kg). O hidrogênio é um átomo muito pequeno
(raio atômico 0,46 Å) e se difunde relativamente rápido nos metais.
A primeira lei de Fick define o fluxo J x através da placa como sendo.
Na maioria dos casos, a difusão não ocorre em condições estacionárias
mas sim em condições transitórias. Em outras palavras, o perfil de concentra-
ção não é constante e varia com o tempo, conforme ilustra a figura 8.7.
Para as condições da figura 8.7, vale a seguinte equação:
Se considerarmos o coeficiente de difusão D independente da composi-
ção, a expressão acima se transforma em:
A equação acima é conhecida como segunda lei de Fick.
126 CAPÍTULO 8
Figura 8.6 — (a) Difusão em estado estacionário através de
uma placa. (b) Perfil linear de concentração na placa.
Figura 8.7 — Perfis de concentração para condições transitórias.
DIFUSÃO NO ESTADO SÓLIDO 127
Algumas soluções da segunda lei de Fick
Obter soluções para a equação diferencial da segunda lei de Fick signi-
fica obter funções que relacionem a composição em função da distância e do
tempo para uma dada temperatura. Estas soluções são obtidas a partir da
fixação de condições de contorno e do conhecimento do significado físico
das condições de contorno fixadas.
Em seguida, discutiremos uma solução importante da segunda lei de
Fick: o caso de difusão em um sólido semi-infinito. Neste caso, uma segunda
espécie se difundirá em um sólido e a concentração desta segunda espécie na
interface (CS) será mantida constante. Este é o caso, por exemplo, de cemen-
tação (aumento do teor de carbono) de uma camada superficial de uma peça
de aço (por exemplo, uma engrenagem) para torná-la mais dura e resistente
ao desgaste. Uma maneira de manter a concentração da espécie que vai se
difundir (carbono, no caso da cementação) aproximadamente constante na
interface é manter a pressão parcial do gás cementante constante. As seguin-
tes condições de contorno ou hipóteses devem ser assumidas neste caso:
Figura 8.8 — Condições de contorno para difusão em um sólido
semi-infinito (segundo J.H. Brophy, R.M. Rose e J. Wulf).
128 CAPÍTULO 8
1. Para t = 0, C = C 0 para ∞ ≥ x ≥ 0;
2. Para t > 0, C = C S na posição x = 0 e C = C 0 para x = ◊.
Estas condições de contorno estão representadas na figura 8.8.
A aplicação das condições de contornos mencionadas leva à seguinte
solução.
onde x
2√Dt é a variável z.
Quando C 0 e C s são conhecidos e além disto o coeficiente de difusão D,
que é função da temperatura, também é conhecido, C x deve ser uma função
de x√Dt . Por exemplo, se desejarmos dobrar a espessura da camada cementa-
da, o tempo deve ser 4 vezes maior.
Os valores da função de erro de Gauss são tabelados e podem ser
facilmente encontrados (vide tabela 8.1).
Uma situação freqüente e muito importante em ciência dos materiais é
aquela em que uma liga metálica tem sua região superficial empobrecida em
um elemento de liga durante o recozimento em altas temperaturas. Um exem-
plo clássico é a descarbonetação da superfície de peças de aço. Outro exem-
plo é a dezincificação (perda de zinco) dos latões. Nestes casos, a solução da
segunda lei de Fick é muito parecida com a solução discutida acima. A
figura 8.9 apresenta os perfis de concentração correspondentes.
Repare que, também neste caso a concentração na interface é mantida
constante. A solução é dada abaixo:
Tabela 8.1 — Tabulação da função de erro de Gauss.
Figura 8.9 — Variação da concentração
com a distância na descarbonetação.
130 CAPÍTULO 8
Uma terceira solução para a segunda lei de Fick é a chamada solução
para um filme fino. Suponha uma barra longa de um metal puro e que na sua
secção reta foi depositado um filme fino de espessura b. Este filme contém
uma concentração C 0 do soluto que vai se difundir na barra. O produto bC 0
pode ser substituído pela quantidade total de átomos do soluto que vai se
difundir. Agora, imagine que uma outra barra do mesmo metal puro e com a
mesma secção é unida à barra que contém o filme na sua extremidade. Desta
maneira, fizemos um “sanduíche” com o filme. O soluto vai se difundir nas
duas barras. Esta experiência está esquematizada na figura 8.10.
Suponha que a origem seja fixada no filme. A concentração de soluto
em função da posição x e do tempo t é dada pela fórmula:
No exemplo acima, o filme poderia ser do mesmo metal das barras.
Neste caso, o filme poderia ser de um isótopo do metal da barra. Desta
maneira, ele poderia ser detectado pela sua radioatividade. Este tipo de expe-
rimento é muito utilizado para se determinar coeficientes de difusão e é
Figura 8.10 — Ilustração esquemática do princípio
de difusão de traçadores radioativos (segundo A.G. Guy).
DIFUSÃO NO ESTADO SÓLIDO 131
denominado método do traçador radioativo. Além disto, a solução anterior
tem bastante aplicação em metalurgia. Por exemplo, após solidificação, as
ligas metálicas apresentam heterogeneidades de composição, denominadas
segregação. Estas segregações são indesejáveis e devem ser diminuídas por
difusão em um tratamento térmicos denominado de homogeneização. Os
tempos e temperaturas necessários podem ser estimados com o auxílio da
solução do filme fino.
O coeficiente de difusão
O coeficiente de difusão ou difusividade D da maioria dos materiais
obedece a equação de Arrhenius:
D 0 é o fator pré-exponencial independente da temperatura (m2
/s);
Q é a energia de ativação para difusão (J/mol; cal/mol ou eV/átomo);
R é a constante dos gases (8,31 J/mol K; 1,987 cal/mol K ou
8,62 10 -5 eV/átomo) e
T é a temperatura absoluta (K).
Próximo do ponto de fusão, a maioria dos metais com estrutura CFC ou
HC apresenta coeficiente de autodifusão por volta de 10-8 cm 2/s. A tabela 8.2
apresenta coeficientes de autodifusão para alguns metais. De uma maneira
geral, a difusão nas estruturas mais compactas como a CFC e a HC é mais
lenta que a difusão nas estruturas menos compactas como a CCC. Além
disto, a difusão de átomos intersticiais é muito mais rápida do que a difusão
de átomos substitucionais.
É interessante observar que em alguns metais não cúbicos, o coeficiente
de difusão perpendicular ao eixo c (D⊥) é diferente do coeficiente de difusão
paralelo ao eixo c (D//). Em outras palavras, em metais não cúbicos a difusi-
vidade não é isotrópica, conforme ilustra a tabela 8.3.
Tabela 8.2 — Coeficientes de difusão de alguns sistemas.
DIFUSÃO NO ESTADO SÓLIDO 133
O coeficiente de difusão no reticulado, também denominado coeficiente
de difusão no volume, é menor que o coeficiente de difusão ao longo de
contornos de grãos, que por sua vez, é menor que o coeficiente de difusão na
superfície externa do cristal. Este comportamento é apresentado na figura
8.11, para a difusão do tório no tungstênio. O fato da difusividade ao longo
de defeitos cristalinos ser maior que a difusividade na rede é explicada em
termos da maior disponibilidade de espaço para a movimentação atômica nas
vizinhanças dos defeitos. As energias de ativação para difusão no volume,
nos contornos de grãos e na superfície externa estão geralmente na proporção
4:3:2 ou na proporção 4:2:1. Normalmente, a difusão ao longo de defeitos
cristalinos só é significativa em situações em que a difusão no volume é
muito lenta. Isto pode ocorrer em temperaturas mais baixas, quando a difusão
no volume é desprezível.
O coeficiente de difusão depende também da composição da liga. Por
exemplo, suponha uma liga cobre-níquel (os dois elementos formam soluções
sólidas para qualquer concentração). O coeficiente de difusão do cobre na
liga ou do níquel na liga depende da composição da liga.
Figura 8.11 — Coeficientes de difusão do tório no tungstênio.
134 CAPÍTULO 8
O efeito Kirkendall
Em 1947, nos EUA, os pesquisadores A. D. Smigelskas e E. O. Kirken-
dall realizaram uma experiência muito interessante. Eles prepararam um par
de difusão conforme ilustra a figura 8.12.
Sobre uma barra de latão, eles depositaram cobre eletrolítico (cobre
puro). Para marcar a posição inicial da interface latão/cobre eles utilizaram
fios (inertes) muito finos de molibdênio. Em seguida, eles colocaram o par de
difusão em um forno a 834°C, permitindo que a difusão ocorresse por deze-
nas de horas. Ao retirar o par do forno e medir, com auxílio de um microscó-
pio óptico, a distância entre os marcadores da face superior e os da face
inferior, eles constataram que as duas haviam se aproximado! Esta aproxima-
ção era tanto maior, quanto mais longo era o tempo que o par permanecia no
forno. A explicação para isto, é que os átomos de zinco se difundem ( por
troca de lugar com lacunas) no cobre muito mais rapidamente que os átomos
de cobre. Em outras palavras, os átomos de zinco do latão estão deixando a
barra de latão mais rápido e em maior quantidade do que átomos de cobre da
camada externa estão penetrando no latão. Por esta razão, o latão se “enco-
lhe”. Este experimento, além de provar que o mecanismo de difusão predo-
minante é o de troca de lugar com lacunas, revolucionou as idéias que se
tinha na época sobre difusão e mostrou que o fenômeno era mais complexo
do que se imaginava, conforme palavras de Corrêa da Silva, que viveu e
Figura 8.12 — Secção do par de difusão usado por Smigelskas e Kirkendall.
DIFUSÃO NO ESTADO SÓLIDO 135
participou ativamente das pesquisas sobre difusão nesta época. (Leia mais
sobre o efeito Kirkendall no Transactions A.I.M.E., vol. 171, p. 130, 1947).
Vamos detalhar um pouco mais este assunto utilizando um par de difu-
são ouro/níquel, conforme ilustra a figura 8.13.
Após recozimento a 900°C, o níquel se difunde no ouro e o ouro se
difunde no níquel, estabelecendo o perfil de concentração mostrado na figura.
O ouro se difunde no níquel mais rapidamente que o níquel no ouro. Isto
causa um deslocamento relativo dos marcadores. A interface dos marcadores
é chamada interface de Kirkendall. Uma outra interface é a de Matano, em
homenagem ao pesquisador japonês C. Matano (Proceedings of the Physical
and Mathematical Society of Japan, vol. 15, p. 405, 1933). A interface de
Matano é definida no diagrama concentração versus distância e ela se locali-
za na posição em que as áreas A1 e A2 são iguais. Do exposto pode-se
concluir que existe um coeficiente de difusão do níquel no ouro (DNi) e um
coeficiente de difusão do ouro no níquel (DAu). É possível definir um coefici-
ente de difusão clássico ou da liga ou ainda coeficiente de interdifusão (D)
em função dos coeficientes de difusão intrínsecos como sendo:
D = XAu DNi + XNi DAu
Figura 8.13 — Ilustração do efeito Kirkendall para um par de difusão Au/Ni
(segundo W.D. Callister, Jr.).
136 CAPÍTULO 8
onde
XNi é a fração molar de níquel e
XAu é a fração molar de ouro.
A equação anterior é conhecida como equação de Darken, em homena-
gem ao pesquisador americano L. Darken, que a propôs em 1948.
Finalmente, é interessante mencionar que quando um dos coeficientes
de difusão é muito maior que o outro, aparecem vazios (devido ao acúmulo
de lacunas) em um dos lados do par de difusão. Estes pequenos vazios são
denominados porosidade de Kirkendall.
Difusão em não metais
A difusão em sólidos cerâmicos também ocorre. Por exemplo, a perme-
ação de vidros pelo gás hélio é bastante conhecida.
A difusão nos compostos estequiométricos, como o NaCl, apresenta
algumas complicações adicionais, em comparação com os metais e ligas. Por
exemplo, se a difusão ocorre pela troca de posição entre um cátion de sódio e
um ânion de cloro, os dois íons ficarão circundados por íons de mesmo sinal.
Isto aumenta consideravelmente a energia eletrostática local e este tipo de
difusão na realidade não ocorre. Para que a difusão ocorra em um sólido
iônico estequiométrico e a neutralidade elétrica seja mantida, dois tipos de
defeitos de sinais opostos devem ser criados. Por exemplo, se uma lacuna
aniônica e uma lacuna catiônica são criadas simultaneamente, a neutralidade
elétrica é preservada e a difusão é facilitada.
Nos compostos iônicos não estequiométricos tais como óxidos semi-
condutores (exemplos CoO, NiO, TiO 2, Nb 2O 5, FeO e Fe 3O 4), a concentra-
ção de defeitos está relacionada com estequiometria e com a difusividade. A
tabela 8.4 apresenta coeficientes de difusão (ou difusividades) para alguns
cristais não metálicos.
A difusão em polímeros pode ser dividida em duas grandes classes. A
primeira envolve somente moléculas da cadeia longa ou macromolécula. Esta
classe de difusão é que é responsável pelas transformações estruturais que
ocorrem durante a cristalização, o recozimento e a trefilação de fibras. A
segunda classe de difusão é a difusão de uma pequena molécula em um
polímero. Esta classe é denominada difusão penetrante. Este é, por exemplo,
o caso da permeação de um polímero por um penetrante gasoso. Neste caso,
DIFUSÃO NO ESTADO SÓLIDO 137
a estrutura do polímero praticamente não é afetada e as moléculas do gás se
difundem de acordo com as leis de Fick e com um valor constante de coefici-
ente de difusão.
Difusão em líquidos
A disponibilidade de dados experimentais sobre difusão no estado líqui-
do é muito pequena. Existem pelo menos duas razões para isto: a falta de
conhecimento da estrutura dos líquidos e a ocorrência de convecção natural
dificulta a determinação dos coeficientes de difusão. Por outro lado, é espera-
do que a difusão no estado líquido seja algumas ordens de grandeza mais
rápida que no estado sólido.
Os coeficientes de difusão nos líquidos também são habitualmente
apresentados na forma de uma equação de Arrhenius. A despeito das diferen-
Íon que se difunde Cristal em que a
difusão ocorre
D0
m 2 s -1
Q
J mol -1
Ag + α-Cu 2S 38 × 10 -9 19.100
Cu+ α-Ag 2S 12 × 10 -9 13.300
Ag + α-Cu 2Te 2,4 × 10 -4 87.300
Cu+ α-AgI 16 × 10 -9 9.420
Li+ α-AgI 50 × 10 -9 19.100
Se- - α-Ag 2S 17 × 10 -9 83.850
Pb ++ PbCl 2 7,8 × 10 -4 150.000
Pb ++ PbI2 10,6 × 10 -4 126.000
O - - Fe 2O 3 1 × 10 +7 611.000
Fe+++ Fe 2O 3 4 × 10 +1 469.000
Co++ CoO 2,15 × 10 -7 144.000
Ni ++ NiO 1,83 × 10 -7 192.000
O - - NiO 1,0 × 10 -9 226.000
Cr +++ Cr 2O 3 1,37 × 10 -5 256.000
Tabela 8.4 — Difusividades em alguns cristais não metálicos.
138 CAPÍTULO 8
ças entre os vários líquidos metálicos, seus coeficientes de difusão (D) apre-
sentam valores numa faixa relativamente estreita: de 10-8 até 10 -9 m2/s. As
energias de ativação para difusão (Q) apresentam valores na faixa de 4 até 16
kJ/mol. Em solventes aquosos e orgânicos apresentam coeficiente de difusão
da ordem de 10 -9 m 2/s.
Difusão em gases
A difusão nos gases é ainda mais rápida que a difusão nos líquidos. Os
coeficientes de difusão nos gases estão geralmente na faixa entre 10-5 e
10 -3 m2/s.
Com base na teoria cinética dos gases é possível deduzir expressões
para o coeficiente de difusão. Por exemplo, para a autodifusão de átomos
esféricos em um gás A puro pode-se deduzir a expressão.
Expressão similar pode ser deduzida com auxílio da teoria cinética dos
gases para a interdifusão de espécies esféricas A e B, com tamanhos diferen-
tes.
DIFUSÃO NO ESTADO SÓLIDO 139
Exercícios
1. Uma barra de cobre foi endurecida por deformação a frio (encruamento).
O tempo necessário (em segundos) para se amaciar de 50% o cobre deforma-
do (com o grau de encruamento empregado) é dado por.
Pergunta-se:
a) Quanto tempo o cobre levará para se amaciar de 50% a 1000°C?
b) Se o cobre for deixado na temperatura ambiente, quanto tempo será neces-
sário para ele amolecer de 50%?
2. O tempo que decorre antes que se obtenha qualquer evidência da reação
A → B foi determinado em função da temperatura:
Tempo Temperatura (°C)
77minutos e 50 segundos 327
13,8 segundos 427
0,316 segundo 527
1 milisegundo 727
Pergunta-se:
a) Qual é a energia de ativação desta reação?
b) Em que temperatura a reação começa após 1 minuto?
3. A purificação do hidrogênio é feita por meio da difusão através de uma
lâmina de paládio. Considere uma lâmina de 5 mm de espessura com área de
0,2 m2 a 500°C. Considere o coeficiente de difusão do hidrogênio no paládio
a 500°C como sendo 10-8 m2
/s. As concentrações de hidrogênio nos dois
lados da lâmina são respectivamente: 2,4 e 0,6 kg/m 3
. Considere que o estado
estacionário foi atingido e calcule a quantidade de hidrogênio que passa pela
placa em 1 hora.
4. Os coeficientes de difusão do cobre no alumínio a 500 e a 600°C são
4,8 10-14 e 5,3 10 -13 m2
/s, respectivamente. Determine o tempo aproximado
que produza a 500°C o mesmo resultado de difusão (em termos de concentra-
140 CAPÍTULO 8
ção de cobre em algum ponto dentro do alumínio) que um tratamento térmico
de 10 horas a 600°C.
5. Determine o tempo necessário para que um aço contendo 0,2% em peso de
carbono tenha, numa posição 2 mm abaixo da superfície, um teor de carbono
de 0,45%. Durante o tratamento de cementação realizado a 1000°C, o teor de
carbono na superfície foi mantido em 1,3%. O coeficiente de difusão do
carbono na austenita deste aço é dado pela expressão.
6. Se um aço contendo 0,9% em peso de carbono for mantido 10 horas a
950°C em uma atmosfera descarbonetante que mantém a concentração de
carbono da superfície no valor 0,1%, a que profundidade o teor de carbono
será 0,8%? Use o coeficiente de difusão do carbono do problema anterior.
7. Considere um par de difusão constituído de cobre puro e de uma liga
cobre-níquel. O par é aquecido a 1000°C por 30 dias. A concentração de
níquel no cobre em uma posição distante 0,50 mm da interface inicial com a
liga é 10,0% em peso. Determine a composição original da liga. O coeficien-
te de difusão do níquel no cobre em m2
/s é dado pela expressão.
Calcule, responda e justifique fisicamente:
a) a difusividade dos átomos de ferro é maior a 850 ou a 950°C?
b) a difusividade dos átomos de cobre é maior a 850 ou a 950°C?
c) a difusividade a 950°C é maior no cobre ou no ferro?
(Lembre-se que a temperatura de transformação α → γ do ferro é 910°C ).
142 CAPÍTULO 8
Bibliografia consultada
PAUL G. SHEWMON; Diffusion in solids, second edition, TMS, Warrendale, USA,
1989.
D. R. POIRIER & G. H. GEIGER; Transport phenomena in materials processing,
TMS, Warrendale, USA, 1994.
LUIZ COELHO CORRÊA DA SILVA; Princípios básicos de metalurgia, Ponto 20:
Difusão, ABM, 1966.
LUIZ COELHO CORRÊA DA SILVA; Generalidades sôbre o fenômeno de difusão,
Boletim da Associação Brasileira de Metais (ABM), N o 28, vol. 8, p. 235-250,
1952.
WILLIAM D. CALLISTER, Jr.; Materials science and engineering (Chapter 5:
Diffusion), Third edition, John Wiley, New York, 1994.
A. G. GUY; Ciência dos materiais (Tradução: José Roberto Gonçalves da Silva),
LTC/EDUSP, São Paulo, 1980.
JERE H. BROPHY; ROBERT M. ROSE & JOHN WULFF; Ciência dos materiais 2:
propriedades termodinâmicas (tradução: Juarez Távora Veado), Capítulo 4 (Ve-
locidades das reações) e Capítulo 5 (Difusão), Livros técnicos e científicos Edi-
tôra Ltda., Rio de Janeiro, 1972.
DIFUSÃO NO ESTADO SÓLIDO 143
Defeitos de Linha (Discordâncias)
Introdução histórica ao conceito de discordância
A deformação plástica ou permanente de um cristal perfeito (isento de
defeitos cristalinos) pode ocorrer pelo deslocamento de planos de átomos em
relação aos planos paralelos adjacentes. Em princípio, o deslocamento do
plano deve ocorrer por meio do movimento simultâneo e cooperativo de
todos os átomos (do plano que está deslizando) de uma posição atômica de
equilíbrio para a posição vizinha, conforme ilustra a figura 9.1.
9
Figura 9.1 — Deformação plástica de um cristal perfeito.
145
A tensão de cisalhamento ou cisalhante necessária para que o processo
da figura 9.1 ocorra foi calculada pela primeira vez em 1926 por J. Frenkel. A
análise de Frenkel leva à uma tensão teórica cisalhante máxima:
τt = b
a
G
2π
onde
G é o módulo de cisalhamento e
a e b estão definidos na figura.
Supondo-se b = a e assumindo-se o valor de 80650 N/mm 2 para o
módulo de cisalhamento do ferro puro, obtém-se um valor de τt = 12836
N/mm 2 para o referido metal. Embora este cálculo seja aproximado, o valor
medido experimentalmente para a tensão necessária para iniciar a deforma-
ção plástica do ferro é várias ordens de grandeza menor. Por exemplo, os
aços de construção civil utilizados hoje em dia, que são aços relativamente
simples e baratos, têm limite de escoamento (limite elástico) cerca de 1/20 do
valor calculado acima. O limite de escoamento de cristais de ferro de alta
pureza é da ordem de 10 N/mm 2. De um modo geral, os cristais reais come-
çam a deformar-se plasticamente em tensões entre 1/1000 e 1/10000 da ten-
são teórica calculada por Frenkel.
A conclusão inevitável da comparação do valor da tensão calculado por
Frenkel com os valores medidos experimentalmente é que o modelo de defor-
mação plástica considerado por Frenkel não reflete o comportamento dos
cristais reais. Por exemplo, os cristais reais contém defeitos que reduzem a
sua resistência mecânica. Já em 1921, o inglês A.A. Griffith havia postulado
a presença de fissuras microscópicas para justificar a baixa resistência mecâ-
nica dos sólidos frágeis (sólidos que pouco se deformam plasticamente, como
os vidros). As microfissuras postuladas por Griffith podem ser observadas
facilmente nos vidros mas são extremamente raras nos cristais metálicos.
Em 1934, E. Orowan, M. Polanyi e G. I. Taylor propuseram, em traba-
lhos independentes, a existência de um defeito cristalino linear denominado
“Versetzung”, em alemão, por Orowan e Polanyi, e “dislocation”, por Taylor.
Este defeito será denominado discordância neste texto, embora alguns gru-
pos de pesquisa no Brasil prefiram o termo deslocação.
O conceito de discordância, na verdade de discordância em cunha, pode
justificar a discrepância entre as tensões calculada e medida nos sólidos
cristalinos.
146 CAPÍTULO 9
O conceito de discordância em hélice, que será apresentado no próximo
item, foi introduzido por J. M. Burgers somente em 1939, junto com os
conceitos de vetor e circuito, hoje conhecidos como vetor de Burgers e cir-
cuito de Burgers.
A discordância é a fronteira entre a parte do cristal que deslizou ou
escorregou e a parte que ainda não escorregou, conforme ilustra a figura 9.2.
Ela não pode terminar no interior do cristal.
Agora podemos afirmar que a deformação plástica ocorre pelo movi-
mento de discordâncias “varrendo” os planos de escorregamento. O movi-
mento das discordâncias envolve o rearranjo de apenas alguns átomos ao seu
redor e não mais o movimento simultâneo e cooperativo de todos os átomos
de um plano cristalino, conforme supõe o modelo de Frenkel. Os planos de
escorregamento, isto é, os planos onde as discordâncias se movimentam, são
normalmente aqueles de maior densidade atômica. A movimentação atômica
ao redor de uma discordância em cunha em movimento é mostrada na figu-
ra 9.3.
Figura 9.2 — Vista tridimensional de um cristal
contendo uma discordância em cunha.
DEFEITOS DE LINHA (DISCORDÂNCIAS) 147
Intuitivamente, é evidente que a deformação plástica causada pela mo-
vimentação de uma discordância exige uma tensão muito menor que a neces-
sária para movimentar um plano de átomos como um todo. É muito freqüente
fazer-se a analogia do tapete ou da lagarta (vide figura 9.4) para justificar o
movimento facilitado pela presença de discordâncias.
Figura 9.3 — (a) Movimentos atômicos perto da discordância em cunha,
durante a deformação. (b) Movimentação da discordância.
Figura 9.4 — Analogia do movimento de discordâncias
com o movimento de (a) uma lagarta e (b) um tapete.
148 CAPÍTULO 9
O cálculo da tensão necessária para movimentar uma discordância foi
feito, pela primeira vez, por R. E. Peierls em 1940 e seus cálculos foram
corrigidos e refinados por F. R. N. Nabarro, em 1947. A chamada força
(tensão) de Peierls-Nabarro é dada pela fórmula:
τPN = 2G
1 − υ exp [− 2πa
b (1 − υ)]
onde
υ é uma constante elástica do material, denominada módulo
ou razão de Poisson.
Tomando-se o valor de υ = 0,291 e supondo-se a = b, obtém-se para o
ferro puro, com auxílio da expressão acima, τPN = 32,2 N/mm 2. Este valor
está bem mais próximo do valor medido (10 N/mm 2) que o valor obtido
utilizando-se a expressão de Frenkel (12836 N/mm 2).
Nas décadas de 1930, 1940 e 1950, a teoria de discordâncias foi desen-
volvida de uma maneira quase completa. Deve-se mencionar que praticamen-
te toda teoria de discordâncias foi desenvolvida sem que os cientistas pudes-
sem observá-las diretamente. Isto só foi possível com o advento da microsco-
pia eletrônica de transmissão. Em 1949, R. D. Heidenreich observou pela
primeira vez, utilizando microscopia eletrônica de transmissão, discordâncias
e arranjos de discordâncias (contornos de subgrãos) em lâminas finas de
alumínio. Nas décadas de 1950 e 1960, as principais previsões da teoria de
discordâncias foram confirmadas com auxílio de microscopia eletrônica de
transmissão.
Se a deformação plástica é enormemente facilitada por meio da movi-
mentação de discordâncias, duas possibilidades decorrem imediatamente
para aumentar a resistência mecânica de um material:
• reduzir drasticamente a densidade de discordâncias do material, se pos-
sível eliminando-as e
• dificultar o movimento das discordâncias.
As duas possibilidades foram concretizadas experimentalmente. A pri-
meira alternativa foi concretizada pela obtenção de cristais filamentares, de-
nominados “whiskers”. O número de discordâncias nestes cristais é muito
baixo, sendo que, em alguns casos, elas estão praticamente ausentes. Em
1952, Herring e Galt, pesquisadores do Bell Telephone Laboratories dos
EUA, determinaram a resistência mecânica de whiskers de estanho. O valor
DEFEITOS DE LINHA (DISCORDÂNCIAS) 149
medido era muito próximo do valor previsto pela teoria de Frenkel. Estes
cristais têm, conforme esperado, resistência mecânica muito alta. Por exem-
plo, já foram obtidos whiskers de ferro com orientação [111] e com limite de
escoamento por volta de 12000 N/mm 2. Para ter resistência mecânica muito
maior que os materiais convencionais, estes whiskers devem ter diâmetro
menor que 10 μm. O comprimento máximo dos whiskers também é bastante
limitado. Estas restrições dificultam extraordinariamente a utilização dos
whiskers como material estrutural.
Para concretizar a segunda alternativa e dificultar o movimento das
discordâncias, vários tipos de obstáculos podem ser utilizados, muitas vezes
simultaneamente. Esta área da ciência dos materiais é denominada mecanis-
mos de aumento de resistência mecânica ou simplesmente mecanismos de
endurecimento. Os seguintes obstáculos ou mecanismos de endurecimento
são mais utilizados:
• outras discordâncias (endurecimento por deformação ou encruamento);
• átomos de soluto (endurecimento por solução sólida);
• precipitados coerentes com a matriz (endurecimento por precipitação);
• partículas incoerentes com a matriz (endurecimento por dispersão) e
• contornos de grão e de subgrão (endurecimento por refino de grão).
Estes mecanismos serão discutidos detalhadamente em capítulo posteri-
or.
A segunda alternativa de se obter materiais de altíssima resistência é o
projeto de ligas (“alloy design”) e de tratamentos termomecânicos combinan-
do de maneira otimizada os diversos mecanismos de endurecimento mencio-
nados. Por este caminho foram desenvolvidas ligas à base de ferro, por exem-
plo os aços “maraging”, com limite de escoamento acima de 3 GPa (vide
figura 9.5).
Em seguida, neste capítulo, serão apresentados os principais aspectos da
teoria de discordâncias.
Descrição de discordâncias
As discordâncias dentro de um cristal raramente são ou estão retas,
embora esta seja a configuração de menor energia. Apesar disto, vamos supor
inicialmente que as discordâncias sejam retas. A figura 9.6 apresenta a for-
150 CAPÍTULO 9
mação de dois tipos característicos de discordâncias a partir de um cristal
perfeito.
Em seguida vamos estudar um pouco melhor estes dois tipos de discor-
dâncias. As figuras 9.7 e 9.8 apresentam os arranjos atômicos ao redor de
uma discordância em cunha e de uma discordância em hélice, respectivamen-
te. A movimentação da discordância, conforme vimos no item anterior, causa
escorregamento ou deslizamento de planos cristalinos, ou seja deformação
plástica. A direção do escorregamento é dada por um vetor, denominado
vetor de Burgers. O vetor de Burgers é sempre o mesmo, independente da
posição da linha de discordância. Existem duas convenções para se definir o
sentido do vetor de Burgers utilizando o chamado circuito de Burgers:
Figura 9.5 — Limite de escoamento de vários materiais à base de ferro
(segundo E. Hornbogen).
DEFEITOS DE LINHA (DISCORDÂNCIAS) 151
FS/RH (Finish-Start/Right-Hand) e SF/RH (Start-Finish/Right-Hand). Na fi-
gura 9.7 é utilizada a convenção FS/RH, ou seja fim-começo/sentido horário.
De uma maneira geral, esta será a convenção adotada neste texto. Se o vetor
de Burgers é perpendicular à linha de discordância (figura 9.7), diz-se que a
discordância é do tipo cunha (⊥); se ele for paralelo (figura 9.8), diz-se que a
discordância é do tipo hélice (ä). O caso mais geral é a linha de discordância
e o vetor de Burgers formarem um ângulo qualquer entre si. Neste caso
diz-se que a discordância é mista, pois ela pode ser decomposta (geometrica-
mente) em um componente cunha e outro hélice. O plano de deslizamento é
determinado geometricamente pela linha de discordância e pelo seu vetor de
Burgers. Evidentemente a linha de discordância está contida no plano de
deslizamento.
Figura 9.6 — Obtenção de uma discordância em cunha (lado esquerdo) e
de uma discordância em hélice (lado direito) a partir de um cristal perfeito.
152 CAPÍTULO 9
Figura 9.7 — Arranjo dos átomos ao redor de uma discordância em cunha.
Figura 9.8 — Arranjo dos átomos ao redor de uma discordância em hélice.
DEFEITOS DE LINHA (DISCORDÂNCIAS) 153
Movimento de discordâncias
O movimento das discordâncias pode ser conservativo ou não conserva-
tivo. Quando a discordância se movimenta no plano de deslizamento, que são
normalmente os planos de maior densidade atômica (e a direção de desliza-
mento também é geralmente a de maior densidade atômica), diz-se que o
movimento é conservativo. Se o movimento da discordância se der fora do
plano de deslizamento, perpendicularmente ao vetor de Burgers, diz-se que
ele é não conservativo ou de escalada.
Ao movimentar-se em um plano de escorregamento ou de deslizamento,
a discordância passa sucessivamente por posições de máximo (equilíbrio ins-
tável) e de mínimo (equilíbrio estável). Pode-se deduzir uma espécie de
“força de atrito” entre a discordância e o plano de deslizamento. Esta força,
já mencionada anteriormente, é denominada força de Peierls-Nabarro. Este
tipo de movimento conservativo também é ativado termicamente, isto é, a movi-
mentação de discordâncias é tanto mais fácil quanto maior for a temperatura.
Vimos no item anterior que o plano de deslizamento é determinado pelo
vetor de Burgers e pela linha de discordância. No caso de uma discordância
em cunha, este plano é único. Por outro lado, no caso de uma discordância
em hélice, inúmeros planos atômicos podem conter a linha de discordância e
o vetor de Burgers. Imagine que uma discordância em hélice está se movi-
mentando no plano (111) de um cristal CFC. Suponha que seu vetor de
Burgers tenha a direção do vetor [101]. Se esta discordância se deparar com
um obstáculo intransponível, uma das maneiras para ela continuar seu movi-
mento (conservativo) seria ela mudar de plano de deslizamento. Uma possibi-
lidade seria o plano (111), também de máxima densidade atômica e que
contém o vetor de Burgers. Esta maneira que a discordância em hélice tem de
evitar ou de “desviar” dos obstáculos realmente ocorre e é denominada es-
corregamento com desvio.
No caso de uma discordância em cunha não existe a possibilidade da
discordância mudar de plano de deslizamento conservativamente. Por outro
lado, a discordância em cunha pode movimentar-se perpendicularmente ao seu
vetor de Burgers. Para que isto ocorra é necessária a interação da discordância
com defeitos puntiformes, conforme ilustra a figura 9.9. Como este tipo de
movimento envolve movimentação de lacunas e de átomos, diz-se que ele é
não conservativo. A ocorrência de escalada é fortemente dependente da tempe-
ratura, na medida em que a concentração de defeitos puntiformes e a mobilidade
atômica aumentam exponencialmente com o aumento da temperatura.
154 CAPÍTULO 9
Regra da mão direita
Dada uma discordância, existem quatro direções importantes associadas
à ela:
• direção e sentido da linha de discordância;
• vetor de Burgers, que dá o módulo e a direção do escorregamento;
• direção do movimento da linha e
• direção do fluxo ou movimento do material. Esta direção é sempre
paralela à direção do vetor de Burgers, mas não tem necessariamente o
mesmo sentido dele.
As direções mencionadas acima não são independentes e estão “amarra-
das” na chamada regra da mão direita.
Segundo a regra da mão (aberta) direita:
• o dedo indicador deve apontar na direção da linha de discordância;
• o polegar deve estar voltado para o lado em que o fluxo ou movimento
do material ocorre no mesmo sentido do vetor de Burgers e
• o dedo médio, o qual deve fazer um ângulo reto com o indicador, indica
então a direção do movimento da linha de discordância.
Vamos aplicar a regra da mão direita na discordância em hélice da
figura 9.10.
Figura 9.9 — Escalada, positiva (lado esquerdo) e negativa
(lado direito) de uma discordância em cunha.
DEFEITOS DE LINHA (DISCORDÂNCIAS) 155
Se assumirmos que a linha da discordância da figura 9.10 está orientada
de A para A’, o dedo indicador terá esta direção e sentido. O polegar deverá
estar voltado para cima, pois a parte de cima ou superior do cristal está
deslocando da esquerda para a direita, isto é, no mesmo sentido do vetor de
Burgers. Conseqüentemente, o dedo médio indica a direção e o sentido da
linha de discordância, isto é, perpendicular à AA’ e no sentido de AA’ para
BB’. Note que, se o sentido da linha de discordância for invertido, o sentido
do movimento da linha também o será. De uma maneira geral, o sentido da
linha de discordância não é indicado nos livros textos, mas na maioria dos
casos ele pode ser rapidamente determinado com auxílio da regra da mão
direita. Procure determinar como exercício, o sentido das discordâncias nos
textos que você utilizar.
Campo de tensões em torno de discordâncias
Ao observar atentamente as figuras 9.7 e 9.8 pode-se constatar que os
átomos ao redor da discordância estão fora das suas posições de equilíbrio,
ou seja, o reticulado cristalino está distorcido. Pode-se notar também que as
distorções são diferentes e dependem do tipo de discordância. À estas distor-
ções (deformações) pode-se associar campos elásticos de tensão.
Figura 9.10 — Discordância em hélice em
movimento da posição AA’ para BB’.
156 CAPÍTULO 9
Antes de analisar os campos elásticos de tensão ao redor das discordân-
cias, deve-se definir uma notação para as tensões normais e cisalhantes. Para
isto é conveniente considerar um cubo unitário (uma unidade de volume), que
está em equilíbrio sob ação de um estado tridimensional de tensões. A figura
9.11 apresenta um cubo unitário submetido ao estado de tensões mencionado.
A figura 9.12 apresenta as deformações do cristal ao redor de uma
discordância em hélice.
Com auxílio da teoria da elasticidade, abordada nos cursos de resistên-
cia dos materiais, pode-se deduzir o seguinte estado de tensões ao redor da
discordância em hélice.
Figura 9.11 — Cubo unitário sob ação de tensões normais e cisalhantes.
DEFEITOS DE LINHA (DISCORDÂNCIAS) 157
Note que o material foi considerado isotrópico e quando x e y tendem a
zero as tensões tendem a infinito. Como a teoria da elásticidade é baseada na
hipótese que as tensões e as deformações são pequenas, é claro que a região
do núcleo da discordância deve ser excluída.
Figura 9.13 — Distorções do cristal ao redor
de uma discordância em cunha.
Figura 9.12 — Distorções do cristal ao redor de uma discordância em hélice.
158 CAPÍTULO 9
A figura 9.13 apresenta as deformações ao redor de uma discordância
em cunha.
O estado de tensões neste caso é dado pelas seguintes equações.
Energia da discordância
A presença de uma discordância no reticulado cristalino causa um au-
mento da energia interna. Esta energia tem duas parcelas: a energia do núcleo
da discordância e a energia elástica. Pode-se notar nas figuras 9.12 e 9.13 a
presença de um raio r 0, o qual delimita o núcleo da discordância. Dentro do
núcleo, as deformações do reticulado são muito grandes, impossibilitando o
uso da teoria da elasticidade, pois as deformações elásticas nos sólidos crista-
linos são em geral bem menores que 1%. Fora do núcleo, isto é, fora de r 0
pode-se calcular a energia da discordância com auxílio da teoria da elastici-
dade. Dentro do núcleo, o cálculo da energia é extremamente complexo. Por
outro lado, pode-se confirmar experimentalmente que a energia do núcleo da
discordância representa menos de 5% do valor total.
A energia elástica por unidade de comprimento de linha para uma dis-
cordância em hélice é dada pela expressão.
A energia elástica por unidade de comprimento de linha para uma dis-
cordância em cunha é dada pela expressão.
Para a maioria dos metais e ligas vale a relação.
Portanto, a seguinte expressão pode ser obtida.
De uma maneira genérica, pode-se afirmar que a energia elástica de
uma discordância é aproximadamente igual a:
E = α G b2
O valor da constante α depende da natureza da discordância e varia
entre 0,5 e 1,0.
Reações entre discordâncias
Em seguida, neste e nos próximos itens, trataremos de vários tipos de
interação entre discordâncias. Um tipo muito freqüente é a reação entre dis-
cordâncias. Por exemplo, duas discordâncias podem reagir entre si e formar
uma única discordância ou uma única discordância pode se decompor em
duas outras. Para que uma reação ocorra duas condições devem ser satisfei-
tas:
• a reação deve estar vetorialmente correta e
• e ela deve ser energeticamente favorável.
Considere, por exemplo, a reação entre duas discordâncias do tipo a/2
<111> que se movimentam em planos de deslizamentos não paralelos, mas
ambos do tipo {110}, de um cristal CCC:
b1 + b2 → b3
a
2 [1 1
_ 1
_] + a
2 [111] → a [100]
160 CAPÍTULO 9
Você pode verificar que a reação, representada pela soma vetorial dos
seus vetores de Burgers, está vetorialmente correta. Resta saber se ela é
energeticamente favorável. Vimos no item anterior que a energia de uma
discordância é proporcional ao quadrado do seu vetor de Burgers. Portanto, a
segunda condição para que a reação ocorra é:
(b1)2 + (b2)2 > (b3)2
> a2 (1 + 0 + 0)
Como se vê, a reação leva à uma diminuição de energia e realmente
tende a ocorrer.
Numerosas reações entre discordâncias são possíveis e algumas delas
serão discutidas em itens posteriores deste capítulo.
Forças entre discordâncias
De uma maneira, geral pode-se afirmar que discordâncias de sinais
opostos se atraem e discordâncias de mesmo sinal se repelem.
Considere duas discordâncias em cunha, paralelas e contidas no mesmo
plano de deslizamento, conforme mostra a figura 9.14 (a). Quando as duas
discordâncias estão muito distantes, a energia elástica total das duas vale
Quando as duas discordâncias estão muito próximas, pode-se, de ma-
neira simplificada, considerá-las como sendo uma única, porém com vetor de
Burgers 2b. Neste caso a energia desta discordância seria:
Portanto, pode-se concluir que quando elas se aproximam a energia
aumenta e por isso elas se repelem. Analisando-se os sinais dos campos de
tensão ao redor das discordâncias pode-se chegar às mesmas conclusões. Por
exemplo, as duas discordâncias da figura 9.14 (b) se atraem para minimizar
DEFEITOS DE LINHA (DISCORDÂNCIAS) 161
seus campos elásticos de tensão. O mesmo ocorre para as duas da figura 9.14
(c) e o resultado final está ilustrado na figura 9.14 (d).
As forças entre discordâncias paralelas em hélice são mais simples do
que aquelas entre discordâncias em cunha, pois o campo de tensão ao redor
de uma discordância em hélice tem simetria radial. A força será neste caso:
F r = Gb2
2πr
A força mencionada será de atração se as discordâncias tiverem sinais
opostos e de repulsão se elas forem de mesmo sinal.
Figura 9.14 — Arranjos de discordâncias em cunha com vetor de Burgers
paralelos: (a) de mesmo sinal e contidas no mesmo plano; (b) de sinais
opostos e contidas no mesmo plano; (c) de sinais opostos e contidas em
planos paralelos e (d) combinação das duas discordâncias de
(c) deixando uma fileira de lacunas.
162 CAPÍTULO 9
Tensão de linha
Uma discordância tem uma tensão de linha, a qual é análoga à tensão
superficial de uma bolha de sabão. Esta tensão existe porque a energia de
uma discordância é proporcional ao seu comprimento, ou seja, qualquer au-
mento de comprimento de uma discordância causa aumento de sua energia. A
tensão de linha é definida como a energia da linha por unidade de compri-
mento aumentado. Suponha que a discordância é uma mola helicoidal. Para
que a discordância (ou a mola) seja mantida encurvada é necessário aplicar
uma força sobre ela. Retirando-se esta força, a tendência é que ela minimize
seu comprimento e energia tornando-se reta.
A figura 9.15 apresenta um segmento de discordância dS que é mantido
encurvado pela ação de uma força F. Sob ele atua uma tensão de linha T.
Esta tensão, que é sempre tangencial à linha, procura tornar o segmento de
discordância retilíneo.
Se a linha está em equilíbrio então:
Figura 9.15 — Tensão de linha de uma discordância.
DEFEITOS DE LINHA (DISCORDÂNCIAS) 163
A fórmula anterior mostra que quanto menor o raio R, maior será a
força necessária para manter a discordância encurvada.
Influência de forças externas
Do exposto nos tópicos anteriores, pode-se concluir que a deformação
plástica dos cristais ocorre quando o material é submetido à forças externas e
as discordâncias se movimentam. Portanto, pode-se supor que ao submeter o
cristal a um estado de tensões externas, estas tensões ocasionam o apareci-
mento de forças nas discordâncias fazendo-as se movimentarem. Alguns tex-
tos chegam a deduzir expressões para a força (F) supondo estados muito
simples de tensões. Por exemplo, se uma tensão cisalhante σ, paralela ao
vetor de Burgers b, atua sobre uma discordância em cunha, o valor da força é:
F = σb
Para situações mais gerais e complexas, a força que atua na discordân-
cia pode ser calculada com auxílio de uma expressão deduzida em 1950 (M.
Peach & J. S. Koehler, Phys. Rev., vol. 80, pag. 436, 1950 ) e denominada
expressão de Peach-Koehler.
Suponha uma discordância qualquer com vetor de Burgers de compo-
nentes bx, by e bz e com vetor de linha de componentes t x, ty e tz submetida a
um estado de tensões completamente geral contendo as componentes σxx,
σyy, σzz , σxy, σxz, σyx, σyz , σzx e σzy. Neste caso a força F será dada por:
F = (t zG y - t yG z)i + (t xG z - t zG x)j + (t yG x - t xG y)k
onde
G x = σxxb x + σxyby + σxz bz ;
G y = σyxb x + σyyby + σyz bz e
G z = σzxbx + σzy by + σzzbz.
A força F pode também ser obtida pela expressão abaixo:
164 CAPÍTULO 9
A força F é sempre perpendicular à linha de discordância, devido ao
produto vetorial.
Intersecção de discordâncias
Considere uma discordância movimentando-se em um plano de desliza-
mento de um cristal e que o plano de deslizamento em questão seja intercep-
tado ou “furado” por discordâncias perpendiculares a este plano. Estas dis-
cordâncias realmente existem e são denominadas discordâncias floresta (“fo-
rest dislocations”). Neste item será discutida a intersecção destas discordân-
cias.
A figura 9.16 ilustra a intersecção de duas discordâncias em cunha
movimentando-se em planos ortogonais. O vetor de Burgers (b2) da discor-
dância AB é paralelo à discordância XY, enquanto o vetor de Burgers (b 1) da
discordância XY é perpendicular à discordância AB. Como resultado da
intersecção, a discordância AB adquiri um degrau (“jog”) PP’ paralelo ao
vetor de Burgers b 1. Repare que o plano de deslizamento do degrau PP’ é
diferente do plano de deslizamento da discordância AB, mas não impede o
movimento da mesma. De uma maneira geral, a presença de degraus em
discordâncias em cunha puras não afeta o posterior movimento deste tipo de
discordância. O mesmo não ocorre com as discordâncias em hélice.
A figura 9.17 apresenta uma discordância em hélice contendo um de-
grau com caráter de cunha. O plano de deslizamento do degrau é PRR’P’. Se
a discordância em hélice se deslocar no plano P’Q’B’R’, o movimento do
degrau no plano PQQ’P’ não será conservativo e requer a ocorrência de
escalada. Portanto, conforme já foi mencionado, a mobilidade de discordân-
cias em hélice contendo degraus é restringida. Pode-se imaginar que durante
a deformação plástica as discordâncias vão adquirindo degraus e a sua mobi-
lidade vai se tornando cada vez mais dificultada. Esta explicação foi proposta
por P. B. Hirsch e N. F. Mott, no início da década de 1960, para explicar o
aumento da resistência de uma material a medida que ele vai sendo deforma-
do (encruamento).
O movimento de discordâncias em hélice contendo degraus é um dos
mecanismos responsáveis pela geração de lacunas (e de intersticiais) durante
a deformação plástica, conforme ilustra a figura 9.18. No capítulo anterior,
onde foram discutidos os defeitos puntiformes, vimos que pode-se criar e
reter em baixa temperatura este tipo de defeito por meio de resfriamento
DEFEITOS DE LINHA (DISCORDÂNCIAS) 165
Figura 9.16 — Intersecção de discordâncias e formação de degraus.
Figura 9.17 — Discordância em hélice contendo
um degrau com caráter de cunha.
166 CAPÍTULO 9
rápido a partir de altas temperaturas. Duas outras possibilidades são: irradiar
o cristal com partículas de alta energia (por exemplo nêutrons, elétrons e
íons) ou deformá-lo plasticamente.
Multiplicação de discordâncias
Antes de discutirmos os mecanismos de multiplicação de discordâncias,
vamos demonstrar com um cálculo relativamente simples a necessidade de
sua ocorrência durante a deformação plástica.
Suponha um cristal recozido de cobre (estrutura cristalina CFC, com
parâmetro de rede a = 3,607 Å) com geometria cúbica e volume de 1 cm3.
Figura 9.18 — Movimento de uma discordância em hélice contendo
degraus. (a) Discordância retilínea na ausência de tensão aplicada.
(b) Discordância se curva sob ação da tensão de cisalhamento aplicada.
(c) Movimento da discordância e emissão de lacunas pelos degraus
(segundo D. Hull e D.J. Bacon).
DEFEITOS DE LINHA (DISCORDÂNCIAS) 167
Este cristal recozido deve conter cerca de 106 cm/cm3 de discordâncias.
Considere que estas discordâncias são retilíneas e estão contidas em planos
paralelos do tipo (111). Como o espaçamento entre estes planos é a⁄√3 , ou
seja, 2,08 Å, existem cerca de 4,8 107 planos (111) paralelos em um cristal
CFC de 1 cm3. Portanto, podemos imaginar uma única discordância em cada
plano e ainda sobram muitos planos sem discordância. Imagine agora que
estas discordâncias se movimentam, deixando o cristal e causando deforma-
ção plástica, conforme mostra a figura 9.19. A deformação total γ é dada pela
tangente do ângulo, ou seja N b/1, onde N é o número de discordâncias e b é
o vetor de Burgers. O vetor de Burgers neste caso é o módulo do vetor a⁄2
[110], ou seja 2,55 10 -8 cm, conforme será tratado no próximo item. O
produto da densidade de discordâncias pelo vetor de Burgers dividido pela
aresta do cristal leva a um valor de γ = 0,025, ou seja, apenas 2,5%. Os
cristais metálicos recozidos, em particular os de cobre, podem ser deforma-
dos plasticamente mais de 10 vezes que o valor que acabamos de calcular.
Portanto, durante a deformação plástica, além das discordâncias abandona-
rem o cristal, elas se multiplicam. Isto pode ser confirmado medindo-se a
densidade de discordâncias após a deformação. A densidade de discordâncias
dos cristais deformados plasticamente é várias ordens de grandeza maior que
a densidade inicial no cristal recozido. Estes cálculos e considerações mos-
tram a necessidade da ocorrência de multiplicação de discordâncias durante a
deformação plástica, caso contrário não conseguimos, por exemplo, justificar
a alta plasticidade dos metais.
Figura 9.19 — Deformação cisalhante causada pela passagem
de
N discordâncias com vetor de Burgers
b.
168 CAPÍTULO 9
Em 1950, em uma conferência em Pittsburgh, nos EUA, F. C. Frank e
W.T. Read propuseram independentemente um mecanismo de multiplicação
de discordâncias. Este mecanismo, que ficou conhecido com a denominação
de fonte de Frank-Read, é apresentado na figura 9.20. Embora existam vários
outros mecanismos propostos para justificar a multiplicação de discordân-
cias, a fonte de Frank-Read é provavelmente o mais conhecido e aceito.
Discordâncias na estrutura CFC
Um cristal CFC pode ser “obtido” por meio do empilhamento de planos
de máxima densidade atômica do tipo {111}, sendo que a seqüência de
empilhamento é do tipo ABCABCABC.....
A passagem de uma discordância por um plano deste tipo causa defor-
mação plástica e não deve causar alteração da estrutura original do cristal.
Este tipo de discordância é denominada discordância unitária ou perfeita.
Quando a estrutura original não é mantida, a discordância é denominada
discordância parcial ou imperfeita. O processo de deformação plástica de um
cristal CFC está representado na figura 9.21.
Figura 9.20 — Fonte de Frank-Read.
DEFEITOS DE LINHA (DISCORDÂNCIAS) 169
A figura 9.21 mostra que a passagem de uma discordância unitária com
vetor de Burgers b1 = a⁄2 [110] não altera a seqüência de empilhamento. No
entanto, o mesmo resultado final pode ser obtido de maneira mais fácil, desde
que o movimento seja feito em duas etapas, em ziguezague. Neste caso, o
deslocamento é representado por duas discordâncias parciais, denominadas
parciais de Shockley, com vetor de Burgers b2 = a⁄6 [211] e b3 = a⁄6 [121
_],
respectivamente. O processo todo pode ser representado pela seguinte reação
de discordâncias:
b1 → b2 + b3 ou seja a⁄2 [110] → a⁄6 [211] + a⁄6 [121
_]
A decomposição de uma discordância unitária em parciais de Shockley
é representada na figura 9.22.
As parciais de Shockley se repelem com uma força
F = G b2 ⋅ b3
2πd
onde
Figura 9.21 — Deformação plástica de um cristal CFC.
170 CAPÍTULO 9
b2 ⋅ b3 é o produto escalar e
d é a distância entre as parciais.
Se as parciais mantiverem-se separadas (dissociadas), a sequência de
empilhamento na região externa às parciais será ABCABCABC.... e numa
faixa, dentro das parciais, a seqüência de empilhamento será alterada para
ABCACABC..... Esta região é denominada defeito de empilhamento. O de-
feito de empilhamento é um defeito bidimensional e será discutido no próxi-
mo capítulo.
Outro tipo de discordância parcial são as chamadas parciais de Frank.
As discordâncias parciais de Frank podem ser criadas pela remoção ou pela
inserção de um plano de átomos do tipo {111}, conforme ilustra a figura
9.23. A seqüência de empilhamento será alterada nos dois casos.
Figura 9.22 — Decomposição de uma discordância unitária em
duas parciais.
Figura 9.23 — Discordâncias parciais de Frank: (a) intrínseca ou simples;
(b) extrínseca ou dupla.
DEFEITOS DE LINHA (DISCORDÂNCIAS) 171
O defeito de empilhamento é delimitado pela discordância parcial. O
vetor de Burgers deste tipo de discordância é normal ao plano {111} e tem
módulo igual ao espaçamento entre estes planos, ou seja a⁄√3 , isto é, o vetor
de Burgers destas discordâncias é do tipo a⁄3 [111]. Como o vetor de Burgers
não está no plano de deslizamento, estas discordâncias são imóveis.
172 CAPÍTULO 9
Um tipo de reação entre discordâncias muito importante é o que leva à
formação das barreiras ou travas de Lomer-Cottrell. Considere duas discor-
dâncias unitárias contidas em planos do tipo {111} e paralelas à linha de
intersecção entre os dois planos, conforme ilustra a figura 9.24 (a).
Estas duas discordâncias unitárias podem dissociar-se em parciais, as
quais delimitam defeitos de empilhamento, conforme ilustra a figura 9.24 (b).
Se duas destas parciais reagirem, conforme ilustra a figura 9.24 (c), a discor-
dância parcial formada é do tipo cunha, situa-se na intersecção dos planos,
tem vetor de Burgers fora dos dois planos e não pode movimentar-se neles.
Esta discordância é uma barreira (ou trava) ao movimento das outras discor-
dâncias. O encruamento dos metais e ligas com estrutura CFC também pode
ser atribuído à formação de barreiras de Lomer-Cottrell durante a deforma-
ção plástica.
As discordâncias do sistema CFC e suas reações podem ser mais facil-
mente representadas e estudadas com o auxílio de um tetraedro proposto por
N. Thompson, em 1953. Neste tetraedro regular de vértices A (0,1,1), B
(1,0,1), C (1,1,0) e D (0,0,0), todas as faces são planos do tipo {111} e as
arestas são direções do tipo <110>. Os centros das faces opostas recebem as
letras α (oposta ao vértice A), β (oposta ao vértice B), γ (oposta ao vértice C)
e δ (oposta ao vértice D), conforme mostra a figura 9.25.
Por exemplo, no tetraedro de Thompson, a discordância unitária
a⁄2 [11
_1] corresponde a AB. Ela pode ser decomposta em parciais conforme a
reação:
AB → Aγ + γB
a⁄2 [11
_0] → a⁄6 [21
_1] + a⁄6 [1 2
_ 1
_]
Figura 9.25 — Tetraedro de Thompson (vide texto).
DEFEITOS DE LINHA (DISCORDÂNCIAS) 173
Outra alternativa para a decomposição da discordância unitária AB é:
AB → Aγ + γB
De maneira similar, podemos decompor as unitárias BC, AC, AD, BD e
CD em parciais de Shockley.
No tetraedro de Thompson, as discordâncias parciais de Frank são re-
presentadas por Aα, Bβ, Cγ e Dδ.
A seqüência de eventos que leva à formação da barreira de Lomer-Co-
ttrell (vide figura 9.24) também pode ser descrita com auxílio do tetraedro de
Thompson. As discordâncias unitárias DA e BD dissociam-se nos planos β e
α, respectivamente:
DA → Dβ + βA
BD → Bα + αD
Duas destas parciais de Shockley reagem para formar a parcial de Lo-
mer-Cottrell segundo a reação:
αD + Dβ → αβ
Discordâncias no sistema HC
Nos metais HC, tais como magnésio, zinco e cádmio, os planos de
máxima densidade atômica são do tipo {0001}, denominado plano basal, e as
direções mais compactas são do tipo <1120>. A deformação plástica ocorre
principalmente pela movimentação de discordâncias de vetor de Burgers
a⁄3 [112
_0] nos planos basais. Este modo de deformação tem sido observado
em todos os metais com estrutura HC.
Outros sistemas de escorregamento (sistema de escorregamento = plano
de escorregamento + direção de escorregamento) são ativados quando o es-
corregamento no plano basal é dificultado ou em outras situações especiais.
Nestas situações, o escorregamento também pode ocorrer em planos pirami-
dais, (1011) [1210], e em planos prismáticos, (1010) [1210].
174 CAPÍTULO 9
Discordâncias no sistema CCC
Os metais CCC, tais como ferro, molibdênio, tungstênio, cromo, vaná-
dio, nióbio, tântalo, sódio e potássio, não dispõe de planos de máxima densi-
dade atômica como os planos {111} dos metais CFC e os planos {0001} dos
metais HC. O escorregamento nos metais CCC ocorre nas direções de máxi-
ma densidade atômica do tipo <111>. O vetor de Burgers é do tipo a⁄2 <111>.
Vários planos de deslizamento têm sido observados: {110}; {112} e
{123}. Estes planos contém a direção de deslizamento. É interessante desta-
car que três planos do tipo {110}, três do tipo {112} e seis do tipo {123} se
interceptam ao longo de uma mesma direção <111>. Isto facilita a ocorrência
de escorregamento com desvio.
Discordâncias em materiais não metálicos
Os materiais cristalinos não metálicos, tenham eles caráter iônico ou
covalente predominante, apresentam em geral plasticidade muito baixa. Em
geral, eles rompem de maneira frágil, por clivagem, na temperatura ambiente.
Nestas condições, a densidade de discordâncias nestes materiais é muito
baixa. Em temperaturas altas e principalmente se a velocidade de deformação
for baixa, vários materiais cerâmicos apresentam considerável plasticidade.
Este é o caso, por exemplo, do óxido de magnésio. Nestas condições, a
densidade de discordâncias é quase tão alta como em um metal deformado.
As fases intermetálicas apresentam comportamento mecânico mais parecido
com os materiais cerâmicos do que com os materiais metálicos. Os cristais
orgânicos poliméricos também apresentam baixa plasticidade, embora dis-
cordâncias possam ser encontradas no seu interior.
Técnicas experimentais utilizadas
para observar discordâncias
As discordâncias, além de serem as principais responsáveis pela defor-
mação plástica dos cristais, têm efeito marcante nas suas propriedades. Desta
maneira, a densidade de discordâncias (e até a sua distribuição) está relacio-
DEFEITOS DE LINHA (DISCORDÂNCIAS) 175
nada e pode ser estimada por meio da variação de numerosas propriedades
tais como limite de escoamento, limite de resistência, dureza, resistividade
elétrica e várias outras.
Materiais cristalinos bem recozidos, isto é, contendo relativamente pou-
cos defeitos cristalinos, podem ter suas densidades de discordâncias determi-
nadas pela técnica de cavidades de corrosão (“etch pits”). Neste caso, faz-se a
contagem da quantidade de locais onde as discordâncias “furam” a superfície
do cristal. Estes locais são regiões de alta energia, que são corroídos prefe-
rencialmente por determinados reagentes químicos. A figura 9.26 ilustra esta
técnica.
A principal técnica utilizada para observar discordâncias é a microsco-
pia eletrônica de transmissão ( MET ).
Um microscópio eletrônico de transmissão consiste de um feixe de
elétrons e um conjunto de lentes eletromagnéticas encerrados em uma coluna
evacuada com uma pressão de cerca de 10-5 mm de Hg. A figura 9.27 mostra
a secção esquemática vertical de um aparelho que utiliza 100 kV como
diferença de potencial máxima de aceleração do feixe de elétrons.
Um microscópio de transmissão moderno possui cinco ou seis lentes
magnéticas, além de várias bobinas eletromagnéticas de deflexão e aberturas
localizadas ao longo do caminho do feixe eletrônico. Entre estes componen-
tes, destacam-se os três seguintes pela sua importância com respeito aos
fenômenos de difração eletrônica: lente objetiva, abertura objetiva e abertura
seletiva de difração. A função das lentes projetoras é apenas a produção de
um feixe paralelo e de suficiente intensidade incidente na superfície da amos-
tra.
plano de escorregamento
cavidades de corrosão
Figura 9.26 — Revelação de discordâncias pela
técnica de cavidades de corrosão.
176 CAPÍTULO 9
As amostras utilizadas em MET devem ter uma espessura de 500 a
5000 Å (dependendo do material e da tensão de aceleração utilizada) e super-
fície polida e limpa dos dois lados. Existem várias técnicas de afinamento de
amostras para MET.
Os elétrons saem da amostra pela superfície inferior com uma distribui-
ção de intensidades e direção controladas principalmente pelas leis de difra-
ção impostas pelo arranjo cristalino dos átomos da amostra. Em seguida, a
Figura 9.27 — Microscópio eletrônico de transmissão esquemático.
DEFEITOS DE LINHA (DISCORDÂNCIAS) 177
lente objetiva entra em ação, formando a primeira imagem desta distribuição
angular dos feixes eletrônicos difratados. Após este processo importantíssimo
da lente objetiva, as lentes restantes servem apenas para aumentar a imagem
ou diagrama de difração para observação na tela ou na chapa fotográfica.
Deve-se destacar que, embora existam em operação no mundo alguns
aparelhos cuja tensão de aceleração é de 1000 kV, a maioria dos equipamen-
tos utilizados no estudo de materiais dispõe de tensão máxima de aceleração
na faixa de 100 a 200 kV.
A figura 9.28 apresenta esquematicamente uma lâmina fina contendo
discordâncias e sua imagem projetada. Quando uma linha-teste de compri-
mento L é colocada sobre a imagem projetada, é equivalente a amostrar a
estrutura tridimensional com um plano-teste de dimensões L  t, onde t é a
espessura da lâmina. A densidade de discordâncias (comprimento total de
linhas de discordâncias por unidade de volume da amostra) de um material
pode ser determinada com auxílio de relações da estereologia quantitativa
(também conhecida como metalografia quantitativa) contando-se o número
de discordâncias interceptadas pela linha-teste e conhecendo-se a espessura
da amostra.
Finalmente, deve-se mencionar que a resolução de um microscópio ele-
trônico de transmissão está por volta de 3 Å e permite observar a maioria dos
defeitos cristalinos.
Figura 9.28 — Equivalência entre uma linha-teste na imagem
projetada em MET e um plano de teste na lâmina fina.
178 CAPÍTULO 9
Exercícios
1.Existe uma concentração (“densidade”) de discordâncias de equilíbrio para
cada temperatura como no caso das lacunas? Justifique.
2. Como você explica que um lingote de aço com dimensões de metros seja
transformado por deformação plástica em chapas com espessura de milíme-
tros sem perder sua estrutura cristalina?
3. Determine os índices de Miller de uma discordância em cunha que tem
vetor de Burgers a⁄2 [01
_1] e está contida no plano (111).
4. O que é escorregamento com desvio (“cross-slip”) de discordâncias?
5. Considere uma discordância em hélice com vetor de Burgers a⁄2 [1
_01]
contida no plano (111) de um cristal CFC.
a) Pode esta discordância sofrer escorregamento com desvio? Justifique.
b) Em caso positivo, indique um plano da família {111} no qual o escorrega-
mento com desvio pode ocorrer.
6. O que é escalada (“climb”) de discordâncias ?
7. Considere uma discordância em cunha com vetor de Burgers a⁄2 [110]
contida no plano (111) de um cristal CFC.
a) Pode esta discordância sofrer escalada? Justifique.
b) Em caso positivo, indique o plano no qual a escalada pode ocorrer.
8. Qual a origem da energia das discordâncias?
9. O que é força de Peierls-Nabarro?
10. Como varia a velocidade média das discordâncias com a tensão externa
aplicada e com a temperatura de deformação?
11. Apresente e explique a expressão geral de Peach-Koehler para forças
externas agindo sobre discordâncias.
12. O que é tensão de linha de uma discordância?
13. Justifique a necessidade da ocorrência de multiplicação de discordâncias
durante a deformação plástica de um metal.
14. Explique, com auxílio da regra da mão direita, o funcionamento de uma
fonte de Frank-Read.
15. Qual a origem dos degraus (“jogs”) nas discordâncias?
16. Como a presença de degraus nas discordâncias afeta o seu movimento?
17. Apresente um mecanismo que justifique a formação de lacunas durante a
deformação plástica.
DEFEITOS DE LINHA (DISCORDÂNCIAS) 179
18. Quando a reação entre discordâncias é possível?
19. Verifique se a reação de dissociação de uma discordância unitária em
parciais em um cristal CFC apresentada abaixo está vetorialmente correta e
se ela é energeticamente favorável.
a⁄2 [1 0 1
_] → a⁄6 [2 1
_ 1
_] + a⁄6 [1 1 2
_]
20. Represente a reação do exercício anterior no tetraedro de Thompson de
vértices:
A(0,1,1) ; B(1,0,1) ; C(1,1,0) e D(0,0,0).
21. O que é uma barreira ou trava de Lomer-Cottrell?
22. Em metais e ligas com estrutura CFC e baixa energia de defeito de
empilhamento, tais como prata, ouro e latão alfa, as discordâncias têm maior
dificuldade de sofrer escorregamento com desvio e escalada. Justifique.
23. Considere três cristais de cobre puro: i) um praticamente livre de discor-
dâncias (“whisker”); ii) um cristal recozido contendo 105 cm/cm3 de discor-
dâncias e iii) um cristal deformado a frio contendo 1011 cm/cm 3 de discor-
dâncias.
a) qual dos cristais apresentará maior resistência ao início da deformação
plástica?
b) qual dos cristais apresentará menor resistência ao início da deformação
plástica?
24. Como você determinaria a densidade de discordâncias dos cristais do
exercício anterior?
Bibliografia consultada
D. HULL & D. J. BACON; Introduction to dislocations, 3rd Edition, Pergamon
Press, Oxford, 1984.
JOHANNES WEERTMAN & JULIA R. WEERTMAN; Elementary dislocation the-
ory, Oxford University Press, New York, 1992.
W. T. READ, Jr.; Dislocations in crystals, McGraw-Hill, New York, 1953.
MARC A. MEYERS & KRISHAN K. CHAWLA; Princípios de metalurgia mecâni-
ca, Capítulo 6: Defeitos de linha, Editora Edgard Blücher Ltda, São Paulo,
1982.
180 CAPÍTULO 9
Defeitos Bidimensionais ou Planares
Os materiais de engenharia apresentam vários tipos de defeitos bidi-
mensionais. Os principais defeitos bidimensionais que ocorrem em materiais
cristalinos são contornos de grão, contornos de subgrão, contornos de macla,
defeitos de empilhamento e interfaces entre fases diferentes. Além destes,
deve-se mencionar as superfícies externas dos cristais, que também são defei-
tos bidimensionais. Caso o material apresente uma fase ordenada, geralmente
ocorre a presença de fronteiras entre as regiões ordenadas e as regiões desor-
denadas. Este tipo de defeito é denominado contorno de antifase. Se o mate-
rial apresentar magnetismo, ou melhor, domínios magnéticos, um outro tipo
de defeito, denominado fronteira de domínio, deve estar presente na microes-
trutura.
Em seguida, todos os defeitos bidimensionais mencionados acima serão
discutidos individualmente.
Superfície externa
A superfície externa dos cristais e dos policristais é o defeito cristalino
que causa maior distúrbio na estrutura e portanto apresenta maior energia por
unidade de área. Esta energia por unidade de área pode ser entendida como
uma tensão superficial ou interfacial entre as fases sólido e vapor (no caso a
atmosfera). Esta energia está associada com as ligações rompidas ou insatis-
feitas na superfície, ou seja, os átomos do cristal localizados na superfície
têm número de coordenação que é aproximadamente a metade do número de
coordenação no interior do cristal. Embora seu valor absoluto seja alto, sua
importância relativa é pequena, pois a quantidade de superfície por unidade
de volume nos componentes é praticamente desprezível. Em algumas áreas,
tais como metalurgia do pó e processamento de materiais cerâmicos.
tidade de superfície por unidade de volume é alta e a energia de superfície
desempenha um papel importante. A tabela 10.1 apresenta valores de energia
de superfície para alguns materiais. De uma maneira geral, quanto maior for
o ponto de fusão do material, maior será sua energia de superfície.
Tabela 10.1 — Energia de superfície de alguns materiais.
Contornos de grãos
A grande maioria dos materiais cristalinos utilizados em engenharia é
policristalina. O agregado policristalino consiste de pequenos cristais, deno-
minados grãos, com dimensões de poucas dezenas de micrômetros, arranja-
dos de maneira a preencher todo o espaço (sem deixar vazios).
Contornos de grãos são as fronteiras bidimensionais que separam cris-
tais de diferentes orientações em um agregado policristalino. As diferenças
de orientação entre grãos vizinhos são de dezenas de graus. Por esta razão,
este tipo de defeito é denominado contorno de alto ângulo. Estas grandes
diferenças de orientação impedem que este tipo de contorno possa ser descri-
to ou representado por arranjos convenientes de discordâncias, pois, neste
caso, elas estariam muito próximas, a ponto de ocorrer interações entre seus
núcleos. Por outro lado, várias observações com auxílio de microscopia ele-
trônica mostram a existência de discordâncias nos contornos de grão. A regi-
ão do contorno tem uma espessura de aproximadamente duas a cinco distân-
cias interatômicas e é bastante defeituosa. Pode-se dizer que os átomos do
182 CAPÍTULO 10
contorno apresentam um número de coordenação menor do que os átomos no
interior dos grãos. A figura 10.1 apresenta contornos de grão simulados por
um modelo de bolhas.
Existem alguns modelos que tentam descrever os contornos de grão em
agregados policristalinos, apesar disto, o conhecimento de sua estrutura é
bastante limitado. Um dos primeiros modelos propostos para descrever os
contornos de grão foi o modelo do cimento amorfo, apresentado em 1900,
por J. A. Ewing e W. Rosenhain. Segundo eles, os contornos de grão são
regiões não cristalinas ou amorfas, que envolvem os diferentes cristais ou
grãos mantendo-os unidos. Atualmente, um dos modelos mais aceitos é o
proposto pelo pesquisador alemão H. Gleiter, apresentado na figura 10.2.
Note neste modelo a presença de degraus (“ledges”) nos contornos de grão.
Degraus em contornos de grão são uma característica importante dos contor-
nos de alto ângulo. Observações recentes utilizando microscopia de alta reso-
lução sugerem que os contornos de alto ângulo consistem de grandes regiões
em que a adaptação atômica entre os dois grãos é relativamente boa separa-
das por regiões de má adaptação. Os degraus estão associados com estas
regiões de má adaptação. De uma maneira geral, pode-se afirmar que a
quantidade (ou densidade) de degraus aumenta com o aumento da diferença
de orientação entre grãos vizinhos.
O contorno de grão tem a ele associado uma energia por unidade de
área ou tensão superficial. Esta energia é praticamente uma constante do
material, embora existam alguns contornos especiais de menor energia, deno-
minados contornos de alta coincidência ou simplesmente contornos de coin-
cidência. A tabela 10.2 apresenta uma coletânea de energias de contornos de
grão para diversos materiais.
Figura 10.1 — Simulação de contornos de grão em um modelo de bolhas
(segundo W.T. Read).
DEFEITOS BIDIMENSIONAIS OU PLANARES 183
Tabela 10.2 — Energia de contorno de grão de alguns materiais.
Material Energia de contorno
A energia dos contornos de grão está relacionada com a energia da
superfície externa (vide exercício 16, no final deste capítulo). De um modo
geral, a energia média de contorno de grão é cerca de 0,45 a 0,75 da energia
de superfície de um material.
É importante destacar que um grão em um agregado policristalino é um
poliedro que deve preencher todo o espaço (sem deixar vazios), satisfazer o
equilíbrio de tensões superficiais e, é claro, satisfazer as relações entre o
número de vértices, arestas e faces (teorema de Euler). O poliedro que mais
se aproxima destas exigências é o ortotetracaidecaedro, apresentado na figu-
ra 10.3.
A figura 10.4 apresenta diferentes secções de um material policristalino
monofásico, conforme observadas por microscopia ótica.
Figura 10.2 — Modelo de contorno de grão contendo degraus
(segundo H. Gleiter).
184 CAPÍTULO 10
O número de faces, arestas e vértices dos grãos em um agregado poli-
cristalino pode ser determinado experimentalmente. Tomemos, por exemplo,
um pedaço de alumínio puro com grãos grandes (isto pode ser obtido fazen-
do-se um tratamento térmico em altas temperaturas, quando ocorre cresci-
mento de grão). Se o alumínio policristalino for colocado em contato com
gálio líquido (ponto de fusão 40°C), ocorre difusão preferencial dos átomos
de gálio pelos contornos de grão do alumínio e a concentração de gálio nestas
regiões é bastante aumentada. A presença de gálio nos contornos (segrega-
ção) diminui a força de coesão entre os grãos, tornando o material frágil
(fragilização por metal líquido). Sob aplicação de pequenas tensões, os grãos
se desagregam por fratura intergranular, como fossem os grãos de uma romã.
Se os números de faces, arestas e vértices de vários grãos forem determina-
dos, os valores médios serão muito próximos aos do ortotetracaidecaedro.
Figura 10.3 — Forma provável dos grãos de um material policristalino:
(a) ortotetracaidecaedro (24 vértices, 36 arestas e 14 faces);
(b) arranjo tridimensional (sem vazios) destes poliedros.
Figura 10.4 — Microestrutura monofásica policristalina.
DEFEITOS BIDIMENSIONAIS OU PLANARES 185
Defeitos de empilhamento
Em capítulos anteriores, foi mencionado que uma determinada estrutura
cristalina pode ser obtida por meio do empilhamento de planos arranjados em
uma seqüência regular. Estas seqüências regulares podem ser localmente alte-
radas por deformação plástica e aglomerados de defeitos puntiformes criados
por irradiação do material com partículas pesadas de alta energia ou por
têmpera, dando origem a defeitos de empilhamento. Os defeitos de empilha-
mento são limitados por discordâncias parciais, conforme mostra esquemati-
camente a figura 10.5. Estas discordâncias parciais se repelem.
Quanto maior for a energia por unidade de área do defeito de empilha-
mento, mais próximas estarão as discordâncias parciais, de modo a minimi-
zar a área defeituosa. A energia de defeito de empilhamento (EDE) pode ser
determinada experimentalmente medindo-se a distância entre as discordân-
cias parciais com auxílio de microscopia eletrônica de transmissão (MET).
Além deste método, existem vários outros, a maioria envolvendo MET, utili-
zados na determinação da EDE. A EDE é um dos mais importantes parâme-
tros indicativos das propriedades dos materiais Por exemplo, um material
com energia de defeito de empilhamento baixa apresenta após deformação
plástica maior densidade de discordâncias, distribuição mais uniforme de
discordâncias e maior energia armazenada na deformação, do que um materi-
al com energia de defeito de empilhamento alta e deformado nas mesmas
condições. Além disto, os materiais com baixa EDE geralmente apresentam
maior taxa de encruamento, maior resistência à fluência e maior suscetibili-
dade à corrosão sob tensão que materiais com alta EDE. A tabela 10.3 apre-
senta energias de defeito de empilhamento de alguns materiais.
discordâncias
parciais
defeitos de empilhamento
A grande maioria das determinações de EDE foram realizadas na tem-
peratura ambiente. As determinações de EDE acima da temperatura ambiente
apresentam dificuldades experimentais. Os poucos resultados experimentais
disponíveis sugerem que a EDE da maioria dos materiais aumenta com o
aumento da temperatura.
Células de discordâncias
A distribuição das discordâncias em um metal ou liga deformado plasti-
camente depende de vários fatores: estrutura cristalina, energia de defeito de
empilhamento, temperatura e velocidade de deformação. Por exemplo, quan-
do um metal com estrutura CFC e baixa EDE é deformado por método usuais
(ensaio de tração, laminação ou forjamento), suas discordâncias têm baixa
mobilidade devido ao fato das discordâncias parciais estarem muito afastadas
entre si. Isto implica em dificuldade para ocorrência de fenômenos de escor-
DEFEITOS BIDIMENSIONAIS OU PLANARES 187
regamento com desvio (“cross-slip”) e escalada (“climb”) de discordâncias.
Uma vez tendo baixa mobilidade, as discordâncias geradas na deformação
tenderão a ter uma distribuição plana (homogênea) na microestrutura, confor-
me mostra esquematicamente a figura 10.6.
Por outro lado, metais e ligas com estrutura CCC, ou metais e ligas com
estrutura CFC e alta EDE, deformados plasticamente por métodos habituais
na temperatura ambiente, apresentam discordâncias dissociadas em parciais
próximas umas das outras, facilitando a ocorrência de escorregamento com
desvio e de escalada. Isto implica em discordâncias com alta mobilidade, que
tendem a se localizar em planos cristalinos de baixos índices de Miller, assim
como aniquilar-se com discordâncias vizinhas de sinal oposto. Devido a estes
fatores, metais e ligas com alta EDE tendem a apresentar uma distribuição
heterogênea de discordâncias, como mostra a figura 10.7. Na figura 10.7 é
representado esquematicamente um grão com células de discordâncias ou
células de deformação no seu interior. As discordâncias concentram-se prefe-
rencialmente nas paredes de célula e o interior das células permanece pratica-
mente livre de discordâncias. A diferença de orientação entre células vizinhas
é em geral muito pequena, menor que 2°.
Aumentos na temperatura de deformação e/ou diminuição na velocida-
de de deformação favorecem a formação de estrutura celular.
Contornos de subgrãos ou subcontornos
Um monocristal ou um grão em um agregado policristalino pode estar
subdividido em regiões (subgrãos) que têm entre si pequenas diferenças de
orientação, em geral menores que 5°. A fronteira que separa os dois subgrãos
é denominada contorno de pequeno ângulo ou subcontorno. Em geral, os
Figura 10.6 — Arranjo de discordâncias homogeneamente
distribuídas em grão encruado (esquemático).
188 CAPÍTULO 10
contornos de pequeno ângulo podem ser descritos por arranjos convenientes
de discordâncias. Um tipo particular de subcontorno é o contorno inclinado
puro, composto apenas de discordâncias em cunha (vide figura 10.8). A
diferença de orientação é dada neste caso pelo ângulo , em radianos, que
pode ser calculado pela relação:
θ = b
D
onde
b é o vetor de Burgers e
D é o espaçamento médio entre discordâncias.
Note que as discordâncias neste tipo de arranjo minimizam a energia
devida aos seus campos de tensão. Embora subcontornos do tipo inclinado
puro realmente existam, a maioria dos subcontornos é mais geral e contém
vários tipos de discordâncias.
Um mecanismo de formação destes subcontornos foi proposto pelo
pesquisador inglês R. W. Cahn, em 1950. Segundo o modelo de Cahn, duran-
te o aquecimento de um metal deformado plasticamente, as discordâncias são
reagrupadas, havendo aniquilação de discordâncias de sinais opostos e rear-
ranjo das restantes minimizando seus campos de tensão elástica (vide figu-
ra 10.9). Este mecanismo é denominado poligonização, devido ao facetamen-
to da superfície externa do cristal. O conceito de poligonização pode ser
ampliado de modo a descrever a formação de subgrãos em monocristais e
policristais.
Durante o aquecimento de um metal deformado plasticamente e que
apresenta subestrutura celular, ocorre o “aperfeiçoamento” das paredes de
Figura 10.7 — Arranjo celular de discordâncias em
grão encruado (esquemático).
DEFEITOS BIDIMENSIONAIS OU PLANARES 189
células (formadas por emaranhados de discordâncias) que se transformam em
subcontornos de grão.
Os materiais com baixa EDE, que não apresentam subestrutura celular
após a deformação a frio, também apresentam formação de subgrãos (poligo-
nização) no posterior recozimento.
De uma maneira geral, pode-se afirmar que mesmo monocristais bem
recozidos podem apresentar subgrãos.
Figura 10.8 — Arranjo de discordâncias em cunha
Figura 10.9 — Representação esquemática do mecanismo de
poligonozação: (a) distribuição ao acaso de discordâncias em um
monocristal deformado por flexão; (b) rearranjo das discordâncias
ativado termicamente originando os subcontornos (poligonização).
190 CAPÍTULO 10
A diferenciação entre células de deformação e subgrãos é um tanto
arbitrária. O principal critério para diferenciá-los é o grau de ativação térmica
envolvido na sua formação, já que ambos são constituídos de arranjos de
discordâncias e a diferença de orientação entre regiões vizinhas que eles
separam é da mesma ordem de grandeza. Em geral, um subcontorno é mais
aperfeiçoado que uma parede de célula, pois a subestrutura de subgrãos
envolve uma considerável ativação térmica durante sua formação, o que per-
mite o rearranjo das discordâncias.
A energia dos subcontornos depende fortemente da diferença de orien-
tação, ao contrário da energia dos contornos de grão. Esta energia depende
também da natureza do subcontorno, ou seja, do tipo e do arranjo de discor-
dâncias do subcontorno. A figura 10.10 compara os arranjos atômicos nas
vizinhanças de contornos de baixo e de alto ângulo.
Contornos de macla
Contornos de macla são imperfeições bidimensionais que separam duas
regiões do cristal ou do grão que são imagens especulares uma da outra,
conforme mostra a figura 10.11.
Este tipo de defeito pode ocorrer durante a solidificação, deformação
plástica, recristalização ou durante o crescimento de grão. Normalmente,
Figura 10.10 — Comparação entre contornos de baixo e de alto ângulo
(segundo W.D. Callister, Jr.).
DEFEITOS BIDIMENSIONAIS OU PLANARES 191
distinguem-se dois tipos de macla conforme a origem: macla de recozimento
e macla de deformação. Embora os dois tipos mencionados sejam cristalogra-
ficamente idênticos na mesma estrutura, as maclas de recozimento, formadas
em altas temperaturas, apresentam contornos retilíneos, enquanto as maclas
de deformação, formadas durante a deformação a frio, apresentam contornos
lenticulares (vide figura 10.12).
As maclas de recozimento ocorrem mais freqüentemente durante a re-
cristalização e/ou durante o crescimento de grão. Elas são mais freqüentes
em materiais com baixa energia de defeito de empilhamento. A energia do
contorno coerente de macla é aproximadamente a metade da energia de de-
feito de empilhamento. Desta maneira, é esperado que materiais com baixa
EDE apresentem alta frequência de maclas de recozimento. Por exemplo, as
maclas de recozimento são raríssimas em alumínio, ferro-alfa, nióbio, mo-
libdênio e tungstênio, mas são muito freqüentes em cobre, prata, ouro, latão e
em aços inoxidáveis austeníticos. As maclas de recozimento são raras no
estado bruto de fundição, mesmo em materiais de baixa EDE. Isto mostra
que sua formação ocorre principalmente durante a recristalização e o cresci-
Figura 10.11 — Arranjo dos átomos em torno de uma
macla no reticulado cúbico simples.
Figura 10.12 — Grãos maclados: (a) e (b) maclas de recozimento em
materiais com estrutura CFC;(c) macla de deformação em
materiais com estrutura HC.
192 CAPÍTULO 10
mento de grão, quando ocorre migração de contornos de alto ângulo. Fre-
qüentemente, as maclas de recozimento terminam no interior do grão. Neste
caso, aparece um contorno incoerente de macla (vide figura 10.13). A energia
por unidade de área destes contornos incoerentes de macla é comparável a
energia dos contornos de grão.
A maclação mecânica (maclas de deformação) é uma maneira alternati-
va de deformação plástica, conforme mostra a figura 10.14.
Como este modo de deformação plástica exige o movimento coordena-
do de muitos átomos, embora os deslocamentos sejam pequenos, ele ocorre
principalmente em situações em que a deformação plástica por deslizamento
de planos é muito difícil. A maclação mecânica ocorre, por exemplo, em
metais HC, devido ao baixo número de sistemas de escorregamentos nesta
estrutura. Em metais CCC, quando deformados abaixo a temperatura ambi-
ente ou com altas velocidades de deformação, também ocorre maclação me-
cânica. Este mecanismo de deformação plástica não tem muita importância
em metais e ligas com estrutura CFC.
Figura 10.13 — Contornos coerentes e incoerentes de macla:
(a) arranjo atômico; (b) aspecto observado em metalografia.
DEFEITOS BIDIMENSIONAIS OU PLANARES 193
A maclação mecânica não envolve difusão, exige o movimento coorde-
nado de átomos e este movimento envolve pequenos deslocamentos. Estas
características são comuns às transformações martensíticas ou “militares”.
Interfaces
A grande maioria dos materiais de engenharia apresenta na sua micro-
estrutura mais de uma fase, isto é, eles são polifásicos. Freqüentemente, as
fases presentes na microestrutura de um material polifásico apresentam dife-
rentes composições e estruturas, embora também ocorram casos em que a
estrutura cristalina é a mesma mas a composição é diferente e vice-versa. A
fronteira que separa as duas fases é denominada interface. A figura 10.15
apresenta uma microestrutura policristalina e bifásica vista em três dimen-
sões.
Dependendo das relações de orientação entre as duas fases, as interfaces
podem ser classificadas como coerentes, semicoerentes ou incoerentes. As
interfaces coerentes são mais raras e só ocorrem quando as duas fases apre-
sentam mesma estrutura cristalina e parâmetros de rede quase idênticos.
Além disto, uma das fases deve estar dispersa na outra (matriz) e ter dimen-
sões muito pequenas, em geral, menores que 0,1 μm. As interfaces semicoe-
rentes são mais freqüentes e podem ocorrer mesmo quando as duas fases tem
diferentes estruturas cristalinas. Neste caso, o ajuste dos reticulados das duas
fases pode ser facilitado pela presença de discordâncias na interface. As
interfaces incoerentes são muito mais freqüentes e representam o caso geral.
Os três tipos de interface mencionados são apresentados na figura 10.16.
Figura 10.14 — Maclação mecânica em metais CFC
(segundo M.A. Meyers e K.K. Chawla).
194 CAPÍTULO 10
Quanto mais diferentes forem as duas fases entre si e principalmente
quanto maior for o grau de desajuste entre as suas estruturas tanto maior será
a energia da interface. A tabela 10.4 apresenta as energias de interface para
alguns sistemas.
Tabela 10.4 — Energias de interface de alguns sistemas.
Sistema Tipo de interface Desorientação (%) Energia (mJ/m2
)
Ni-Al coerente 0,5 14
Cu-Co coerente 1,8 18-21
Feα/Feγ incoerente — 560
Fe/Fe3C incoerente — 740
Ni/ThO 2 incoerente — 1500
Os valores da tabela 10.4 mostram que a energia por unidade de área de
uma interface coerente é comparável com a energia de subcontornos e con-
tornos coerentes de macla. Por outro lado, a energia das interfaces incoeren-
tes é comparável com a energia dos contornos de grão.
Figura 10.15 — Microestrutura policristalina e bifásica
vista em três dimensões.
Figura 10.16 — Arranjo dos átomos ao redor das interfaces:
(a) coerente; (b) semicoerente e (c ) incoerente (segundo E. Hornbogen).
DEFEITOS BIDIMENSIONAIS OU PLANARES 195
Contornos de antifase
Conforme já foi mencionado em capítulo anterior, algumas fases apre-
sentam reação do tipo ordem-desordem. Em geral, as regiões ordenadas tem
o mesmo tipo de estrutura cristalina que a matriz. Vamos considerar o caso
do latão β, com concentração equiatômica de cobre e zinco. Em altas tempe-
raturas predomina a estrutura CCC, com os átomos de cobre e de zinco
ocupando as posições do centro da célula e dos vértices indistintamente e
sem preferência. Diz-se nesta situação que a fase é desordenada. Em tempe-
raturas mais baixas, os átomos de cobre têm preferência pelas posições do
centro da célula enquanto os átomos de zinco ocupam as posições do vértice
do cubo. Diz-se nesta situação que a fase é ordenada.
Uma liga ou uma fase que sofre ordenação apresenta regiões em que o
tipo de ordem difere. A fronteira entre estas regiões é denominada contorno
de antifase. A figura 10.17 apresenta este tipo de defeito bidimensional.
A passagem de uma discordância por uma fase ordenada pode criar um
contorno de antifase. Por esta razão, as discordâncias atravessam as fases
ordenadas aos pares. Enquanto a discordância “à frente” desordena, a discor-
dância “de trás” reconstitui a ordem. Este par de discordâncias é denominado
superdiscordância.
Figura 10.17 — Estrutura ordenada bidimensional apresentando
contornos de antifase (segundo M.A. Meyers e K.K. Chawla).
196 CAPÍTULO 10
Fronteiras de domínio
Em muitas fases ocorre o alinhamento dos spins eletrônicos dando ori-
gem a domínios magnéticos. As fronteiras que separam estes domínios são
denominadas fronteiras de domínio ou fronteiras de Weiss, em homenagem
ao físico francês P. Weiss, que sugeriu pela primeira vez a existência de
domínios magnéticos, em 1907. A figura 10.18 apresenta uma representação
esquemática de domínios magnéticos em um cristal de metal ferromagnético.
As direções de magnetização são representadas na figura 10.18 por flechas.
Existem nos materiais magnéticos outros tipos de domínio e de frontei-
ras de domínio que não foram abordados neste texto, mas podem ser encon-
trados em livros especializados sobre magnetismo e materiais magnéticos.
Exercícios
1. Por que a superfície externa de um cristal é um defeito?
2. O que é um contorno de baixo ângulo (também conhecido como subcon-
torno ou contorno de subgrão)?
3. Os contornos de grão são também chamados de contornos de alto ângulo.
Podem eles serem descritos em termos de arranjos de discordâncias? Justifi-
que.
4. Um grão pode ser descrito como sendo um poliedro. Que fatores determi-
nam o tipo de poliedro?
5. Quais as principais diferenças entre um contorno de grão e um subcontor-
no?
6. Contornos inclinados de pequenos ângulo têm normalmente ângulo de
desorientação menor que 5° e são constituídos apenas por discordâncias em
cunha. Calcule o espaçamento entre as discordâncias de um contorno inclina-
Figura 10.18 — Ilustração de fronteiras de domínio (esquemático).
DEFEITOS BIDIMENSIONAIS OU PLANARES 197
do puro com diferença de orientação (ou ângulo de desorientação) de 2° em
um cristal de cobre. Quais os índices de Miller do plano do contorno? Consi-
dere que as discordâncias do subcontorno são unitárias do tipo a⁄2 <110> e
que o parâmetro de rede do cobre é 3,615 Å.
7. Relacione a energia de defeito de empilhamento com a distância entre as
discordâncias parciais em um cristal com estrutura CFC.
8. Discuta a formação de defeitos de empilhamento nos metais e soluções
sólidas com estrutura CFC.
9. Quais as principais diferenças e semelhanças entre maclas de recozimento
e maclas de deformação?
10. Dois corpos de prova metalográficos, um de prata e outro de alumínio
puros e policristalinos, ambos no estado recozido, foram misturados após
embutimento, polimento e ataque. Como você poderia diferenciá-los?
11. Por que as maclas de recozimento são freqüentes nos aços inoxidáveis
austeníticos e muito raras nos aços inoxidáveis ferríticos?
12. Em que situações a deformação plástica por maclação é favorecida?
13. Quais as principais diferenças entre um contorno de grão e uma interfa-
ce?
14. Na sua opinião, a energia por unidade de área de um contorno de antifase
é mais próxima da energia de um contorno coerente de macla ou de um
contorno de grão?
15. Coloque em ordem crescente de energia os seguintes defeitos planares do
cobre: contorno de grão, superfície externa, contorno de subgrão, defeito de
empilhamento e contorno coerente de macla.
16. Quando um contorno de grão de um policristal intercepta a superfície
externa e o material é exposto à temperaturas maiores que metade da sua
temperatura de fusão em graus Kelvin, forma-se uma fenda térmica (“thermal
groove”) ao longo da linha de intersecção, conforme a figura abaixo.
198 CAPÍTULO 10
A razão da formação da fenda é a redução da energia livre total do sistema.
Calcule a razão entre a energia de superfície e a energia do contorno de grão
em função do ângulo da fenda (Ψ).
17. O esquema da figura abaixo mostra uma partícula de inclusão não metáli-
ca no contorno de grão de um aço baixo carbono. A energia de contorno de
grão deste aço é 780 mJ/m 2
. Estime a energia da interface entre a inclusão e a
matriz. Esta inclusão é coerente ou incoerente?
Bibliografia consultada
MARC A. MEYERS & KRISHAN K. CHAWLA; Princípios de metalurgia mecâni-
ca, capítulo 7: Defeitos planares, Editora Edgar Blücher Ltda, São Paulo, 1982.
W. T. READ, Jr.; Dislocations in crystals, McGraw-Hill, New York, 1953.
D. HULL & D. J. BACON; Introduction to dislocations, Third edition, Pergamon
Press, Oxford, 1984.
R. E. REED-HILL; Physical metallurgy principles, Second edition, D. Van Nostrand
Company, New York, 1973.
ANGELO FERNANDO PADILHA & FRANCISCO AMBROZIO FILHO; Técnicas
de análise microestrutural, Editora Hemus, São Paulo, 1985.
ANGELO FERNANDO PADILHA & FULVIO SICILIANO, Jr.; Encruamento, re-
cristalização, crescimento de grão e textura, segunda edição, ABM, São Paulo,
1996.
DEFEITOS BIDIMENSIONAIS OU PLANARES 199
Principais Ensaios Mecânicos
Neste capítulo serão apresentados os principais ensaios mecânicos utili-
zados na determinação das propriedades mecânicas dos materiais. Os seguin-
tes ensaios serão descritos brevemente: ensaio de tração, ensaio de flexão,
ensaios de dureza, ensaio de impacto, ensaio de fluência e ensaio de fadiga. É
importante destacar que todos esses ensaios são normalizados e que antes de
realizá-los o engenheiro deverá consultar as respectivas normas.
Ensaio de tração
O ensaio de tração é um dos ensaios mais utilizados na determinação das
propriedades mecânicas da maioria dos materiais. No ensaio de tração, um
corpo de prova com formas e dimensões padronizadas (vide figura 14.1) é
submetido à uma força de tração uniaxial que tende a esticá-lo ou alongá-lo.
A cabeça do corpo de prova é fixada nas garras de uma máquina de
ensaio que aplica esforços crescentes na sua direção axial. Durante o ensaio,
são medidas a força e a deformação correspondente. Em geral, o ensaio é
realizado até a ruptura do corpo de prova. A figura 14.2 apresenta uma
máquina de ensaio de tração esquemática. A figura 14.3 apresenta uma curva
força versus alongamento típica de um metal dúctil. A curva da figura 14.3 é
dependente das dimensões do corpo de prova. Para tornar os resultados do
ensaio independentes das dimensões do corpo de prova, entre outras razões, é
conveniente transformar a curva força versus alongamento obtida do registro
da máquina em uma curva tensão de engenharia versus alongamento de
engenharia.
l0 é o comprimento inicial do corpo de prova e
l é o comprimento do corpo de prova durante o ensaio.
A tensão de engenharia não leva em conta a redução da secção reta do
corpo de prova durante o ensaio. A forma da curva tensão de engenharia
versus deformação de engenharia tem a mesma forma da curva força versus
alongamento. O ponto de máximo nos dois casos está associado com o início
da deformação localizada (não uniforme), denominada estricção.
Figura 14.1 — Tipos mais usados de corpos de prova para
ensaio de tração (segundo S.A. de Souza).
238 CAPÍTULO 14
A tensão real, σr , é definida como:
σr = F
A
onde
A é a área da secção reta do corpo de prova em cada instante.
Pode-se definir também uma deformação real, εr , como:
Figura 14.2 — Máquina de ensaio de tração
esquemática (segundo M.A. Meyers e K.K. Chawla).
Figura 14.3 — Curva força versus alongamento (∆l) esquemática.
PRINCIPAIS ENSAIOS MECÂNICOS 239
Supondo-se que a deformação ao longo do corpo de prova seja unifor-
me e admitindo-se volume constante pode-se demonstrar que:
εr = ln (1 + ε) ; σr = σ (1 + ε)
Para o regime elástico, a coincidência das duas curvas é quase comple-
ta, pois as deformações são pequenas (menores que 0,5%). À medida que
aumenta a deformação plástica, as diferenças entre a curva de engenharia e a
curva real se acentuam, conforme ilustra a figura 14.4.
Embora a curva real seja mais precisa, a curva de engenharia é a mais
utilizada. Com auxílio da curva de engenharia (vide figura 14.5) pode-se
definir vários parâmetros importantes:
• Limite de escoamento. É a tensão que separa o comportamento elástico
do plástico. Como, em alguns casos, é difícil determinar-se a tensão
máxima para a qual não há deformação residual plástica, define-se o
limite de escoamento para uma deformação permanente de 0,2%.
• Limite de resistência. É a tensão (de engenharia) máxima que o corpo
de prova resiste. A partir desta tensão, as tensões (de engenharia) caem,
devido à estricção do corpo de prova.
• Tensão de ruptura. É a tensão (de engenharia) na qual ocorre ruptura.
Figura 14.4 — Comparação entre as curvas tensão versus
deformação de engenharia e real (segundo G.E. Dieter).
240 CAPÍTULO 14
• Alongamento uniforme. É o alongamento (de engenharia) que ocorre
até o início da estricção. Corresponde à deformação plástica que ocorre
uniformemente no corpo de prova.
• Alongamento total. É o alongamento (de engenharia) que ocorre até a
ruptura do corpo de prova.
• Estricção. É a diminuição porcentual da área da secção transversal do
corpo de prova após a ruptura.
Finalmente, é importante destacar que o ensaio de tração é realizado
com a temperatura constante e que a velocidade de deformação (velocidade
de afastamento das garras) é mantida aproximadamente constante. O ensaio
de tração pode ser realizado tanto em temperaturas muito baixas como em
altas temperaturas. Para a grande maioria das aplicações, o ensaio é realizado
na temperatura ambiente.
Ensaio de flexão
Para os materiais frágeis, como os materiais cerâmicos, a determinação
das propriedades mecânicas por meio do ensaio de tração é muito difícil
experimentalmente.
Figura 14.5 — Alguns parâmetros importantes definidos com auxílio da
curva tensão versus deformação de engenharia (segundo G.E. Dieter).
PRINCIPAIS ENSAIOS MECÂNICOS 241
No caso de materiais frágeis, o ensaio mais utilizado é o ensaio de
flexão. A figura 14.6 apresenta as duas modalidades mais utilizadas de ensaio
de flexão, em comparação com o ensaio de tração.
A resistência à flexão é definida como a tensão máxima de tração na
ruptura e é denominada freqüentemente como módulo de ruptura, designado
na literatura em inglês como MOR (“modulus of rupture”). A resistência à
flexão é calculada com auxílio de fórmulas, que podem ser encontradas em
textos de resistência dos materiais. A figura 14.7 apresenta as fórmulas para
corpos de prova de secção retangular.
Ensaios de dureza
O ensaio de dureza é provavelmente o ensaio mecânico mais freqüente-
mente utilizado, tanto em empresas como em universidades e centros de
pesquisas.
Existem mais de uma dezena de ensaios de dureza. Estes ensaios podem
ser classificados, conforme a maneira com que o ensaio é realizado, em três
Figura 14.6 — Comparação entre os ensaios: a) flexão em três pontos;
b) flexão em quatro pontos e c) ensaio de tração (segundo D.W. Richerson).
A área hachurada representa a distribuição de tensões de tração ao longo
do comprimento do corpo de prova.
242 CAPÍTULO 14
tipos: por penetração; por choque e por risco. À propósito, a escala de dureza
mais antiga é a escala Mohs, introduzida em 1822, e é baseada na capacidade
de um material riscar o outro. Em seguida serão apresentadas brevemente três
ensaios de dureza: dureza Brinell, dureza Vickers e dureza Rockwell.
A escala Brinell foi proposta em 1900 por J.A. Brinell. O ensaio consis-
te em comprimir lentamente uma esfera de aço, de diâmetro D, sobre uma
superfície plana por meio da aplicação de uma carga P. A compressão da
esfera na superfície do material causa uma impressão permanente. Esta im-
pressão tem a geometria de uma calota esférica, de diâmetro d. A dureza
Brinell (HB) é calculada pelo quociente da carga pela área de contacto:
HB = 2 P
π D (D − √D2 − d2)
A dureza Brinell tem unidade de tensão (pressão) e é normalmente dada
em kg/mm2 .
A escala Vickers foi proposta em 1925 por Smith e Sandland. O nome
Vickers é originário da empresa que fabricava as primeiras máquinas deste
tipo de ensaio. Neste caso, o penetrador é uma pirâmide de diamante de base
quadrada e com ângulo de 136° entre as faces opostas. A impressão, quando
vista ao microscópio óptico, tem a geometria de um losango retangular.
Figura 14.7 — Fórmulas para o cálculo do módulo de ruptura no
ensaio de flexão em: a) três pontos e
b) em quatro pontos (segundo D.W.Richerson).
PRINCIPAIS ENSAIOS MECÂNICOS 243
diagonal l. A dureza Vickers (HV) é dada pelo quociente da carga P pela área
de contato.
A dureza Vickers também tem unidade de tensão e é normalmente dada
em kg/mm2 .
A escala Rockwell foi introduzida em 1922 por Rockwell. Este ensaio
utiliza a profundidade de penetração, sob ação de uma carga constante, como
medida de dureza. O ensaio é muito rápido, pois o resultado é lido auto-
maticamente. Os penetradores são do tipo esférico (esfera de aço temperado)
ou cônico (diamante com 120° de conicidade). Ao contrário das escalas
Brinell e Vickers, a dureza Rockwell não tem unidade. Existem vários tipos
de dureza Rockwell. Os mais utilizados são: Rockwell B (penetrador esféri-
co, φ = 1,59 mm, carga 100 kg) e Rockwell C (penetrador de diamante, carga
150 kg).
No caso dos materiais poliméricos, a escala Shore de dureza é muito
utilizada. A dureza Shore é um tipo de ensaio dinâmico por choque que
produz uma impressão na peça ou corpo de prova por meio de um penetrador.
A escala Shore também é utilizada em materiais metálicos.
Finalmente, deve-se mencionar que os ensaios de dureza são geralmente
realizados na temperatura ambiente. Para materiais cerâmicos, o ensaio de
dureza realizado em temperaturas elevadas é bastante comum.
Ensaio de impacto
Os tipos mais comuns de ensaio de impacto são: ensaio Charpy, ensaio
Izod e ensaio de tração sob impacto. O mais utilizado deles é o ensaio
Charpy. A figura 14.8 mostra o pêndulo de ensaios e os corpos de prova
utilizados.
No ensaio Charpy, o corpo de prova é biapoiado horizontalmente e
recebe o impacto de um pêndulo de peso especificado. O corpo de prova
sofre uma flexão sob impacto e fratura com uma alta taxa de deformação
(aproximadamente 103 s-1). Na região próxima ao entalhe, aparece um estado
triaxial de tensões. Este estado triaxial de tensões e a alta taxa de carrega-
mento propiciam uma tendência para ocorrência de fratura frágil. A forma
244 CAPÍTULO 14
mais frágil de fratura em materiais é a clivagem. Na clivagem, a propagação
da trinca ocorre praticamente sem deformação plástica e a separação ocorre
ao longo de planos cristalinos pelo rompimento das ligações químicas. A
tendência à clivagem e à fratura frágil de um modo geral aumentam com o
aumento da velocidade de deformação e com o abaixamento da temperatura
de ensaio.
Os resultados do ensaio de impacto são geralmente apresentados como
a energia absorvida no processo de fratura do corpo de prova. A energia
absorvida no processo de fratura varia muito com a temperatura de ensaio.
Por esta razão são realizados ensaios em várias temperaturas.
Figura 14.8 — Ensaio de impacto: a) corpo de prova utilizado nos ensaios
Charpy e Izod; b) pêndulo de ensaio (segundo W.D. Callister, Jr.).
PRINCIPAIS ENSAIOS MECÂNICOS 245
Ensaio de fluência
Quando um corpo de prova ou componente é submetido a um carrega-
mento constante em alta temperatura ele deforma-se plasticamente em cente-
nas ou milhares de horas, mesmo que a carga seja menor que o limite de
escoamento do material nesta temperatura. Este fenômeno chama-se fluência
(em inglês “creep”).
O ensaio de fluência é realizado em temperaturas altas (e constante) e
com uma tensão aplicada constante. Como a secção do corpo de prova dimi-
nui durante o ensaio, dificultando a manutenção de uma tensão constante, é
mais comum realizar-se o ensaio com carga constante. No ensaio de fluência,
mede-se o alongamento do corpo de prova em função do tempo.
A fluência torna-se um fenômeno de importância na faixa de temperatu-
ras entre 0,4 T f e o ponto de fusão, onde T f é a temperatura de fusão em K.
Nesta faixa de temperaturas, a difusão é significativa. A difusão, conforme já
foi visto, é um fenômeno termicamente ativado e apresenta uma dependência
exponencial com a temperatura. Abaixo de 0,4 T f , o coeficiente de difusão é
tão baixo que qualquer mecanismo de deformação plástica por fluência é tão
lento que pode ser desprezado.
A temperatura crítica para que a fluência comece a ser significativa
varia de material para material. Por exemplo, enquanto o chumbo apresenta
deformação por fluência na temperatura ambiente, para o ferro ela só se torna
importante acima de cerca de 600°C.
Ensaio de fadiga
A falha por fadiga ocorre quando um material é submetido a carrega-
mento cíclico. Em geral, quanto maior for o limite de resistência (determina-
do com auxílio de um ensaio de tração) do material maior será sua resistência
à fadiga. Por outro lado, quando um corpo de prova ou componente é subme-
tido a esforços dinâmicos, repetidos ou flutuantes, o mesmo pode romper-se
com uma carga muito inferior ao limite de resistência do material. A falha
por fadiga geralmente ocorre de forma repentina e catastrófica. Pontes, aero-
naves e numerosos componentes de máquinas estão sujeitos à falha por fadi-
ga. O termo fadiga é utilizado porque a falha geralmente ocorre após longos
períodos de tempo após solicitação cíclica. Praticamente todos os tipos de
materiais estão sujeitos à falha por fadiga. A ruptura por fadiga é de natureza
246 CAPÍTULO 14
frágil, mesmo em metais dúcteis. As trincas de fadiga iniciam-se em defeitos
superficiais ou próximos da superfície. Estes defeitos podem ser estruturais,
tais como inclusões ou arranhões, mas também podem surgir durante o pro-
cesso de deformação.
Existem várias possibilidades para aplicação de esforços cíclicos tais
como ciclos envolvendo somente compressão, ou compressão/tração ou ainda
flexão alternada.
Os resultados do ensaio de fadiga são em geral representados na forma
de curvas de tensão aplicada versus número de ciclos até a ruptura (curvas de
Wöhler). Alguns materiais não se rompem por fadiga se a tensão aplicada for
menor que um determinado valor, denominado limite de fadiga. Outros mate-
riais não apresentam esta tensão limite. A figura 14.9 apresenta os dois tipos
de comportamento mencionados.
Figura 14.9 — Curvas de Wöhler para: a) material que apresenta limite
de fadiga; b) material que não apresenta limite de fadiga.
PRINCIPAIS ENSAIOS MECÂNICOS 247
Exercícios
1.Quais as principais diferenças entre os ensaios de tração e de fluência?
2. Quais as principais diferenças entre os ensaios de dureza Vickers e Ro-
ckwell C?
3. Com o auxílio da figura a seguir, relativa ao ensaio de dureza Vickers,
calcule: a) a penetração em função da diagonal da impressão d (considere
d = d1 = d2), b) deduza a fórmula HV = 1,8544 F/d2
.
4. Com o auxílio da figura abaixo, relativa ao ensaio de dureza Brinell,
calcule a penetração x, em função de D e d.
5. Uma amostra de alumínio recozido apresenta limite de escoamento por
volta de 20 MPa . O módulo de elasticidade do alumínio é 69 GPa . Qual é a
máxima deformação (em %) elástica que este alumínio pode sofrer ?
6. Repita o exercício anterior para o molibdênio, que apresenta limite de
escoamento por volta de 565 MPa e módulo de elasticidade 324 GPa . Justifi-
que a diferença.
7. Um aço inoxidável austenítico apresenta limite de escoamento 205 MPa e
módulo de elasticidade 193 GPa . Um pedaço de arame deste aço com 50 cm
de comprimento e diâmetro 1mm é tracionado. Qual o comprimento máximo
248 CAPÍTULO 14
que o arame pode atingir no regime elástico ? Qual a força aplicada no arame
exatamente no limite de escoamento ?
8. Determine no gráfico a seguir, referente ao ensaio de tração de um corpo
de prova de secção retangular, os seguintes parâmetros: a) módulo de elastici-
dade; b) limite de escoamento; c) limite de resistência; d) alongamento uni-
forme; e) alongamento total. Transforme o limite de escoamento obtido em
b) e o limite de resistência obtido em c) em termos de tensão real. Transfor-
me o alongamento uniforme obtido em d) em termos de deformação real.
9. O que é clivagem?
10. O que é tenacidade?
11. Consulte um livro sobre ensaios mecânicos (vide bibliografia consultada
neste capítulo) e procure compreender quais as principais diferenças entre os
seguintes conceitos ou parâmetros: ductilidade, tenacidade e resiliência.
12. A tendência à fratura frágil de um material se manifesta mais claramente
em um ensaio de tração ou em um ensaio de impacto? Justifique.
(*) Obs.: Velocidade da ponte é a designação popular da velocidade de afastamento das garras.
PRINCIPAIS ENSAIOS MECÂNICOS 249
Bibliografia consultada
SÉRGIO AUGUSTO DE SOUZA; Ensaios mecânicos de materiais metálicos, 5 a
edição, Editora Edgard Blücher Ltda, São Paulo, 1989.
GEORGE E. DIETER; Mechanical metallurgy, Second Edition, McGraw-Hill,
Tokyo, 1976.
MARC A. MEYERS & KRISHAN K. CHAWLA; Princípios de metalurgia mecâni-
ca, Editora Edgard Blücher Ltda, São Paulo, 1982.
DAVID W. RICHERSON; Modern ceramic engineering, Second Edition, Marcel
Dekker, Inc., New York, 1992.
WILLIAM D. CALLISTER, Jr.; Materials science and engineering, Third edition,
John Wiley & Sons, Inc., New York, 1994.
250 CAPÍTULO 14
Propriedades Mecânicas
Neste capítulo serão discutidas as propriedades mecânicas dos quatro
grupos de materiais: materiais metálicos, materiais cerâmicos, materiais poli-
méricos e materiais compósitos. O comportamento mecânico dos materiais
será, na medida do possível, correlacionado com as respectivas microestrutu-
ras.
Propriedades mecânicas dos materiais metálicos
Inicialmente, será discutida a deformação plástica de monocristais. Em
seguida, serão abordados os principais mecanismos de aumento de resistên-
cia (mecanismos de endurecimento) operantes nos metais e ligas: endureci-
mento por deformação (encruamento), endurecimento por contornos de grão,
endurecimento por solução sólida, endurecimento por dispersão de partículas
incoerentes e endurecimento por precipitação coerente.
Em princípio, um material cristalino pode deformar-se plasticamente
por quatro mecanismos: deslizamento de planos cristalinos causado pela mo-
vimentação de discordâncias, maclação mecânica, difusão e por transforma-
ções de fase. Dentre estes quatro mecanismos, o deslizamento ou escorrega-
mento de planos cristalinos é muito mais significativo que os três outros
mencionados.
Considere o monocristal cilíndrico da figura 15.1a, onde A é a área da
secção reta do cristal, F é a força de tração aplicada e que causa uma tensão
σT , Ox é a direção de deslizamento, λ é o ângulo entre o eixo do cristal e a
direção de deslizamento, θ é o ângulo entre o eixo do cristal e o plano de
deslizamento e φ é o ângulo entre o eixo do cristal e a normal ON ao plano de
deslizamento.
15
251
A tensão no plano de deslizamento é:
F⁄A senθ = σT senθ
A tensão no plano e na direção de deslizamento é:
σ = σT senθ cosλ = σT cosφ cosλ
O limite de escoamento de um monocristal varia muito com a orienta-
ção, conforme ilustra a figura 15.1b. Quando esta tensão (o limite de escoa-
mento) é decomposta no plano e na direção de deslizamento, ela torna-se
invariável. Em outras palavras, um cristal começa a deformar-se plasticamen-
te quando a tensão no plano e na direção de deslizamento atinge um valor
crítico σce:
σce = σe senθe cosλe
onde
σce é a tensão crítica de cisalhamento atuante no plano e na direção de
deslizamento (“critical resolved shear stress”) e
σe é a tensão necessária para ocorrência de deformação plástica
(limite de escoamento).
Figura 15.1 — a) Componentes da tensão no sistema de deslizamento;
b) Variação do limite de escoamento com a orientação para um
monocristal de magnésio (segundo R.W.K. Honeycomb).
252 CAPÍTULO 15
A equação acima é conhecida como lei de Schmid.
A curva tensão versus deformação de um monocristal geralmente apre-
senta estágios característicos. Por exemplo, os cristais com estrutura cristali-
na CFC apresentam três estágios característicos, conforme ilustra a figu-
ra 15.2.
O estágio I na figura 15.2 é denominado estágio de deslizamento fácil
(“easy glide”). Neste estágio, as discordâncias movem-se por longas distânci-
as, predominantemente em um único sistema de escorregamento, praticamen-
te sem encontrar obstáculos e como conseqüência tem-se um pequeno encru-
amento.
O estágio II é denominado estágio de endurecimento linear (“linear
hardening”). Neste estágio, outros sistemas de deslizamento são ativados e
ocorre acentuada interação entre discordâncias, as quais formam emaranha-
dos (“dislocation tangles”), ocasionando considerável encruamento.
O estágio III é denominado estágio de endurecimento parabólico (“pa-
rabolic hardening”). Neste estágio tem-se a ocorrência freqüente de escorre-
gamento com desvio (“cross-slip”) e as discordâncias formam uma subestru-
tura celular (“dislocation cells), caso o material tenha energia de defeito de
empilhamento alta ou até média.
Figura 15.2 — Curva tensão versus deformação típica de cristais CFC.
PROPRIEDADES MECÂNICAS 253
Equações fundamentais da
deformação plástica dos cristais
A deformação plástica dos cristais pode ser melhor entendida com o
auxílio de três equações, as quais serão apresentadas e brevemente discutidas
em seguida.
A primeira equação relaciona a velocidade média das discordâncias
(V m) durante a deformação plástica em função da tensão cisalhante no plano
e na direção de deslizamento (σ) e da temperatura de deformação (T):
V m = K1 σn exp 


−E
RT



onde
K1 e n são constantes que dependem do material;
R é a constante dos gases e
E é a energia de ativação ou barreira de ativação do processo.
A fórmula anterior mostra a forte dependência da velocidade média das
discordâncias com a tensão aplicada (o valor de n é positivo e maior que 1) e
com a temperatura de deformação.
A segunda equação, denominada equação de Orowan, relaciona a defor-
mação (ε) com a densidade de discordâncias móveis (ρ), e com o desloca-
mento médio (X m) e o vetor de Burgers (b)das mesmas:
ε = ρbX m
A equação acima é algumas vezes apresentada na forma derivada com
relação ao tempo:
ε
. = ρbV m
Na diferenciação foi suposto que ρ não varia com o tempo e V m é a
velocidade média das discordâncias.
A terceira equação,denominada equação de Taylor, relaciona a tensão
necessária para deformar o cristal (σ) com a densidade de discordâncias:
σ = σ0 + αGb√ρ
254 CAPÍTULO 15
onde
σ0 é a tensão de cisalhamento para mover uma discordância
na ausência de outras;
G é o módulo de cisalhamento e
α é uma constante.
Mecanismos de endurecimento
Neste tópico serão discutidos brevemente os principais mecanismos de
endurecimento atuantes nos metais e ligas. Mecanismos de endurecimento
são maneiras de aumentar a resistência mecânica de um material, ou seja, são
modos de evitar a ocorrência de deformação plástica. Como nos metais e
ligas, a deformação plástica ocorre predominantemente por movimentação de
discordâncias, aumentar a resistência mecânica significa dificultar a movi-
mentação de discordâncias.
O endurecimento por deformação ou encruamento (“strain-hardening
ou work-hardening”) é o mais utilizado dentre os mecanismos de endureci-
mento, pois praticamente todo metal ou liga pode ser submetido a este tipo
de endurecimento. Este foi provavelmente o primeiro mecanismo de endure-
cimento observado pelo homem. Em 1540, V. Biringuccio, no seu livro clás-
sico De La Pirotechnia, já mencionava que os metais ao serem deformados
tornavam-se mais resistentes à deformação. Em outras palavras, eles endure-
ciam por deformação. Os obstáculos ao movimento das discordâncias são
neste caso outras discordâncias. Durante a deformação plástica, as discordân-
cias movimentam-se, multiplicam-se, interagem entre si adquirindo degraus e
formando emaranhados, de modo que a sua movimentação exige tensões
crescentes. Existem várias teorias que tentam explicar o encruamento. A
teoria de Taylor (G.I.Taylor, Proc. Roy. Soc., vol. A145, pag. 362, 1934)
calcula a tensão necessária para mover uma discordância contra o campo de
tensão oriundo das outras discordâncias. A teoria de Mott (N.F.Mott, Proc.
Roy. Soc.; vol. B64, pag. 729, 1951 e Phil. Mag. vol. 43, pag. 1151, 1952)
considera grupos de discordâncias empilhadas, em lugar de discordâncias
individuais como fontes de tensões internas. A teoria de Seeger (A.Seeger;
J.Diehl; S.Mader; H.Rebstock, Phil. Mag. vol. 2, pag. 323, 1957) considera
que a tensão necessária para deformar um cristal é constituída de dois com-
ponentes: um componente atérmico, de curto alcance, devido à interação com
discordâncias que “furam” o plano de deslizamento (discordâncias floresta) e
PROPRIEDADES MECÂNICAS 255
de outro componente, termicamente ativado, de longo alcance, devido às
discordâncias paralelas ao seu redor. A teoria de Mott e Hirsch (N.F.Mott,
Trans. AIME, vol. 218, pag. 962, 1960 e P.B.Hirsch, Phil. Mag., vol. 7, pag.
67, 1962) considera o encruamento como conseqüência da aquisição de de-
graus pelas discordâncias à medida que elas interceptam outras discordâncias
durante sua movimentação. A teoria de Kuhlmann-Wilsdorf (D.Kuhlmann-
Wilsdorf, Trans. AIME, vol. 224, pag. 1047, 1962) supõe que a tensão neces-
sária para deformar um metal é controlada pela tensão necessária para encur-
var as discordâncias contra a reação oposta pela tensão de linha. A teoria de
Li (J.C.M.Li, J. Appl. Phys., vol. 32, pag. 1873, 1961) considera o campo de
tensão proveniente das discordâncias emaranhadas em paredes, o qual se
opõe à tensão externamente aplicada, reduzindo a tensão efetiva que age
numa discordância em movimento. Nenhuma das teorias mencionadas, con-
segue isoladamente explicar totalmente o encruamento dos cristais. É razoá-
vel considerar que todas as teorias expostas são verdadeiras e seus mecanis-
mos de encruamento atuam em alguma extensão, que varia de caso para caso.
A equação mais utilizado do encruamento já foi apresentada no tópico anteri-
or:
σ = σ0 + αGb√ρ
Os materiais utilizados em engenharia são predominantemente policris-
talinos. Os contornos de grão são barreiras que dificultam a movimentação
das discordâncias, pois uma discordância não consegue atravessá-los. Hall e
Petch (E.O.Hall, Proc. Phys. Soc., vol. B74, pag. 747, 1951 e N.J.Petch, J.
Iron Steel Inst., vol. 174, pag. 25, 1953), independentemente, propuseram
uma equação para o endurecimento causado por refino de grão:
σ = σ0 + K2 d−1⁄2
onde
K2 é uma constante e
d é o diâmetro médio dos grãos do agregado policristalino.
Os átomos de impureza ou elementos de liga em solução sólida distor-
cem a rede cristalina e os campos de tensão ao seu redor interagem com as
discordâncias, dificultando a sua movimentação. Além disto, os átomos de
soluto podem diminuir a energia de defeito de empilhamento, tornando o
material mais susceptível ao endurecimento por deformação. O endurecimen-
256 CAPÍTULO 15
to causado por átomos de soluto em solução sólida é denominado endureci-
mento por solução sólida (“solid-solution hardening”) e pode ser descrito
pela seguinte equação:
σ = σ0 + K3 G cn
onde
K3 é uma constante,
c é a concentração de soluto e
n é uma constante maior que 1/3 e menor que 1, sendo 0,5 o valor
mais freqüente.
Os precipitados também são obstáculos ao movimento das discordân-
cias. Neste caso, deve-se considerar as relações de coerência entre o precipi-
tado e a matriz. No caso do precipitado ser incoerente, não existe continuida-
de entre os planos cristalinos da matriz e os planos cristalinos do precipitado
e as discordâncias em movimento terão que curvarem-se entre os precipita-
dos. Este mecanismo de endurecimento é denominado endurecimento por
dispersão de partículas incoerentes ou mecanismo de Orowan. Se o precipi-
tado for coerente, as discordâncias em movimento poderão cortá-lo ou cisa-
lhá-lo. Este mecanismo de endurecimento é denominado endurecimento por
precipitação coerente. A ocorrência de precipitados incoerentes é muito mais
freqüente que a de precipitados coerentes. Partículas incoerentes em uma
matriz metálica podem ser obtidas por metalurgia do pó, por solidificação e
por precipitação no estado sólido. Partículas coerentes ocorrem apenas em
alguns poucos sistemas em que as relações de coerência entre o precipitado e
a matriz são cristalograficamente possíveis. Neste caso, o aparecimento da
partícula se dá por precipitação no estado sólido. Nos estágios iniciais da
precipitação, os precipitados são completamente coerentes, com o decorrer
do tempo de tratamento térmico tornam-se maiores e semi-coerentes e final-
mente incoerentes.
A figura 15.3 apresenta o mecanismo de Orowan para o endurecimento
por dispersão de partículas incoerentes.
A equação que descreve o endurecimento pelo mecanismo de Orowan é
a seguinte:
σ = σ0 + K4 G b
λ
PROPRIEDADES MECÂNICAS 257
onde
K4 é uma constante e
λ é o espaçamento médio entre as partículas.
O endurecimento por dispersão é proveniente do aumento de tensão
necessária para encurvar a discordância entre os precipitados e a formação
dos anéis é responsável pela alta taxa de encruamento das ligas com disper-
são de precipitados.
A figura 15.4 ilustra de forma esquemática o cisalhamento de uma
partícula causado pela passagem de uma discordância.
O endurecimento por precipitação coerente tem várias causas: aumento
da área de interface causado pelo cisalhamento da partícula, criação de um
contorno de antifase dentro da partícula (no caso da partícula ser uma fase
ordenada), tensões de coerência, diferença de módulo de elasticidade entre a
Figura 15.3 — Mecanismo de Orowan para a interação de discordância
com partículas incoerentes. Observe a formação de
anéis ao redor das partículas.
Figura 15.4 — Cisalhamento de uma partícula
causado pela passagem de uma discordância.
258 CAPÍTULO 15
matriz e o precipitado e diferença de força de Peierls-Nabarro na matriz e no
precipitado. Para cada uma destas causas pode-se deduzir uma equação. Por
outro lado, uma fórmula geral aproximada que engloba todos os efeitos men-
cionados é a seguinte:
σ = σ0 + K5 rm (V v)n
onde
K5, m e n são constantes positivas;
r é o raio médio dos precipitados e
V v é a fração volumétrica dos mesmos.
Dentre os mecanismos de endurecimento mencionados, o mais efetivo é
o endurecimento por precipitação coerente. Infelizmente, os sistemas que
apresentam endurecimento por precipitação coerente são pouco freqüentes.
Finalmente, é importante destacar que a obtenção de ligas de alta resis-
tência mecânica envolve a combinação de vários mecanismos de endureci-
mento.
Propriedades mecânicas dos materiais cerâmicos
Os materiais cerâmicos, de uma maneira genérica, apresentam alto mó-
dulo de elasticidade, são frágeis e muito duros. A resistência à tração dos
materiais frágeis é muito menor que as respectivas resistência à compressão e
módulo de ruptura (MOR). O alongamento plástico da maioria dos materiais
cerâmicos na temperatura ambiente é praticamente desprezível. Por outro
lado, alguns monocristais como por exemplo NaCl, MgO e KBr apresentam
considerável alongamento plástico quando ensaiados em flexão. O alonga-
mento plástico dos materiais cerâmicos cresce com o aumento da temperatu-
ra de ensaio, conforme ilustra a figura 15.5.
Muitos materiais cerâmicos quando ensaiados em altas temperaturas e
com cargas baixas (e constante) deformam-se plasticamente por fluência.
A presença de fase vítrea e porosidade nas cerâmicas tradicionais reduz
consideravelmente a resistência mecânica. Por exemplo, a resistência mecâ-
nica da alumina contendo 25% em volume de poros é cerca de um terço da
resistência mecânica da mesma alumina contendo 5% de porosidade.
PROPRIEDADES MECÂNICAS 259
As fibras de vidro apresentam um comportamento mecânico pouco usu-
al, quando comparado com amostras “normais”, isto é, com diâmetro supe-
rior a 1mm. A resistência mecânica das fibras aumenta acentuadamente com
a diminuição do diâmetro das mesmas (vide figura 15.6). A explicação para
este comportamento é que a diminuição da secção da fibra faz com que as
dimensões e o número dos defeitos superficiais diminuam. Fibras com diâ-
metro por volta de 1μm têm resistência mecânica próxima da resistência
mecânica teórica. As fibras de vidro são muito utilizadas como reforço nos
materiais compósitos de matriz polimérica. De uma maneira geral, os meca-
nismos de aumento de resistência dos vidros envolvem a diminuição de de-
feitos superficiais e a introdução de tensões de compressão na superfície.
Propriedades mecânicas dos materiais poliméricos
Os materiais poliméricos apresentam comportamento mecânico pouco
uniforme. Por exemplo, um material termorígido ou um termoplástico vítreo
(como o poliestireno) apresentam um comportamento tão frágil que lembra o
comportamento mecânico de um material cerâmico. Por outro lado, os mate-
riais termoplásticos parcialmente cristalinos apresentam curvas de tensão ver-
sus deformação no ensaio de tração que lembram os metais dúcteis. Já os
elastômeros apresentam um comportamento atípico. Eles apresentam uma
Figura 15.5 — Efeito da temperatura na curva tensão versus
deformação do cloreto de sódio policristalino com
tamanho de grão constante (
d = 200 μm).
260 CAPÍTULO 15
região elástica muita extensa. Além disto, esta região elástica não é totalmen-
te linear, ao contrário da maioria dos sólidos. Estes três tipos de comporta-
mento são ilustrados na figura 15.7. A curva A é típica de uma resina termorí-
gida, a curva B é típica de um termoplástico parcialmente cristalino e a curva
C é típica de um elastômero. Além dos diferentes níveis de alongamento, o
leitor deve observar os diferentes níveis de resistência dos três materiais.
Figura 15.6 — Variação do limite de resistência em
função do diâmetro para fibras de vidro (segundo E. Hornbogen).
Figura 15.7 — Curvas tensão versus deformação obtidas no ensaio de tra-
ção de diferentes tipos de polímeros: comportamento frágil (A), comporta-
mento dúctil (B) e comportamento elástico (C),(segundo W.D. Callister Jr.).
PROPRIEDADES MECÂNICAS 261
O comportamento mecânico dos polímeros termoplásticos parcialmente
cristalinos apresenta aspectos e particularidades que devem ser esclarecidos.
A figura 15.8 apresenta uma curva tensão versus deformação típica deste tipo
de material. Observe que o ponto de máximo está associado com o início da
estricção, a qual propaga-se ao longo do corpo de prova à medida que o
ensaio prossegue.
O início da estricção na curva da figura 15.8 está associado com a
distribuição de tensões e com as condições de instabilidade ao longo do
corpo de prova. Na região da estricção, as cadeias ficam orientadas e o
material torna-se mais resistente à deformação.
O efeito da temperatura no comportamento mecânico dos diferentes
tipos de materiais poliméricos será discutido em seguida.
A figura 15.9 mostra o efeito da temperatura na resistência mecânica e
no alongamento de um polímero termorígido. Conforme esperado, o aumento
da temperatura tem efeito desprezível no comportamento mecânico de um
termorígido. A temperatura máxima de uso é limitada pela temperatura de
decomposição (T d).
A figura 15.10 ilustra o acentuado efeito da temperatura no comporta-
mento mecânico de um elastômero. Observe que a temperatura de transição
vítrea (T g) define a faixa de uso deste tipo de material, pois abaixo de T g o
elastômero é duro e frágil. As temperaturas T g dos elastômeros estão bem
abaixo da temperatura ambiente.
Figura 15.8 — Curva tensão versus deformação para um polímero
termoplástico parcialmente cristalino (esquemática).
262 CAPÍTULO 15
A figura 15.11 ilustra o efeito da temperatura no comportamento mecâ-
nico de um polímero termoplástico totalmente amorfo. Neste caso, a tempe-
ratura máxima de uso é definida pela temperatura de transição vítrea. Os
valores de T g para esta classe de polímeros situam-se na faixa de 70 a 150°C.
A figura 15.12 ilustra o efeito da temperatura no comportamento mecâ-
nico de um polímero parcialmente cristalino. Neste caso a temperatura míni-
ma de uso é definida pelo valor de T g e a temperatura máxima de uso é
definida pela temperatura em que as regiões cristalinas tornam-se amorfas,
também conhecida como temperatura de fusão cristalina (TF c).
Figura 15.9 — Efeito da temperatura no comportamento mecânico de um
polímero termorígido. A região sombreada representa a faixa de uso.
Figura 15.10 — Efeito da temperatura no comportamento mecânico de um
elastômero. A região sombreada representa a faixa de uso.
PROPRIEDADES MECÂNICAS 263
As temperaturas T g dos polímeros parcialmente cristalinos situam-se
muito abaixo da temperatura ambiente e suas temperaturas de fusão (TF)
estão situadas na faixa de 100 a 200°C.
Finalmente é importante destacar que a velocidade de deformação tem
acentuada influência no comportamento mecânico dos polímeros. O aumento
Figura 15.11 — Efeito da temperatura no comportamento mecânico de
um termoplástico amorfo. A região sombreada representa a faixa de uso.
Figura 15.12 — Efeito da temperatura no comportamento mecânico de
um termoplástico parcialmente cristalino. A região sombreada
representa a faixa de uso.
264 CAPÍTULO 15
da velocidade de deformação tem efeito similar ao efeito do abaixamento da
temperatura de deformação., isto é, aumentam a resistência mecânica e dimi-
nuem o alongamento.
Propriedades mecânicas dos materiais compósitos
Na previsão das propriedades de materiais compósitos é utilizada fre-
qüentemente a chamada regra da mistura:
P M = P1 f1 + P2 f2 + ... + P i f i
∑ fn = 1
onde
P M é a propriedade da mistura;
P1 ... P i são os valores da propriedade de cada componente e
f1 ... fi são os valores da fração volumétrica de cada componente.
Para algumas propriedades tais como densidade e calor específico a
regra da mistura fornece uma excelente aproximação. Na previsão das pro-
priedades mecânicas, a regra da mistura nem sempre oferece uma boa aproxi-
mação. No caso da deformação plástica, dependendo da distribuição das
fases e da orientação das tensões aplicadas, pode-se assumir que:
σM = σ1 f1 + ... σi f i
ou
εM = ε1 f1 + ... εi fi
onde
σ representa as tensões e
ε representa as deformações.
Tenacidade
Freqüentemente, os materiais para aplicações estruturais precisam ofe-
recer não apenas altos limites de escoamento e de resistência, mas também
PROPRIEDADES MECÂNICAS 265
boa tenacidade. A tenacidade de um material é a sua capacidade para absor-
ver energia na região plástica. Uma maneira de se avaliar a tenacidade de um
material é através da área total sob a curva tensão versus deformação obtida
em um ensaio de tração. Esta área é uma indicação da quantidade de trabalho
por unidade de volume que pode ser realizado no material sem causar a sua
fratura. A tenacidade está relacionada tanto com a resistência quanto com a
ductilidade do material.
A tenacidade à fratura pode ser definida de uma maneira mais precisa
como sendo a habilidade do material em resistir à propagação instável de
uma trinca, quando submetido a um carregamento estático. Um parâmetro
muito utilizado para quantificar a tenacidade à fratura é o fator intensificador
de tensão crítico (K IC).
Infelizmente, aumentos de dureza, limite de escoamento e limite de
resistência, por meio, por exemplo, de modificações microestruturais, estão
freqüentemente associados com perdas de tenacidade. Cabe ao especialista
em materiais procurar a melhor combinação entre resistência mecânica e
tenacidade. A tabela 15.1 apresenta valores de limite de escoamento e de K IC
para alguns materiais de engenharia.